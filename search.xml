<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[UE4的内存分配]]></title>
    <url>%2F2021%2F07%2F02%2Fue4-fmemory%2F</url>
    <content type="text"><![CDATA[起因，看spine，看到了string，想起了stringID，然后看里面直接裸memory，在想FMemory和memory有什么区别，以及适用情况。 FMemory内部是区分平台的，但是我没看到GameCore内部区分平台。UE4的window平台直接用的是GenericPlatformMemory，IOS中间有一层包装，但是最后也是走的是GenericPlatformMemory，Android也是，所以其实也还好？ 好吧，我们还是从头开始看吧。 FMemory这个第一个接口是FMemory::GCreateMalloc这里面主要调的是FMemory_GCreateMalloc_ThreadUnsafe，在这里面我们逐步分析。 第一步先取统计接口FPlatformMemory::GetStats() ，但是这里有个非MAC的判定，不知道为啥。 然后就是取GMalloc这里是通过一些模式和命令行在加上架构去分析的，太偏底层的不太熟悉了，有熟悉的大佬可以在下方留言提醒。 在然后就是拉取Crash助手叫做FPlatformMallocCrash它有以下职责： 当内存分配低于16字节对齐的时候会触发crash。 分配器的线程只能是当前线程。 接着就是判断GMalloc-&gt;IsInternallyThreadSafe()里面针对不同的malloc做一些判定是否是线程安全的，这块不是太懂。 接着就是跑内存分析器，这里有个奇怪的宏是IS_MONOLIGHTIC是和mono相关的吗？先不管了。 下一步又判断了以下GMalloc-&gt;IsInternallyThreadSafe()这个感觉是针对profile的，就是说你如果非要非线程安全的，那我就帮你搞一个代理吧，叫FMallocThreadSafeProxy。反正怎么说呢，我认为哈，所以的proxy都是认为，你把握不住的东西，我帮你搞一层代理，容易把你绕晕的地方你就不用管了，也不要瞎搞了。交给我吧。然后在所有的内存操作之前都会做一个同步锁。 下一步又有一个校验器，里面又加了一把锁，外面通过宏切换开关，以我浅薄的认识，这两个可能是不会同时开启的，不然两把锁没有意义呀。这个的作用注释上面写着是过滤无效的指针，原理就是存储了一下指针，做了校验。这个平时开发最好一直开启着。然后暴露出来。 下一步是检查内存泄露的，我猜测和上面的使用方式差不多。不过里面逻辑还是挺多了，首先分配完内存之后，要先判断当前线程是否开启检查，是否开启捕获alloc，是否申请内存高于阈值，小内存你就不考虑了吗？然后又是一把锁，果然很多线程呀。然后里面纪录了一件事情，就是记录内存申请的堆栈，这里感觉和AssetService很相似呀。 下一步就是叫啥有害内存分配代理FMallocPosionProxy又是代理，看到没，人与人之前的就这么不信任的吗？这个主要职责就很简单了，因为我们内存基本都是从池子里面取出来的，可能还会残留一些之前的数据，如果你不清理的话又不赋值直接使用的话，可能会引用到一些奇奇怪怪的东西，我们调试的时候看到空，就知道，哦，他们的忘记赋值了，一看到奇怪的内容，我擦，这是什么意思，怎么会这样呢，害人又害己。 下一步是打印了程序能用到多少内存。 下一步是搞一个看起来像是为了dump搞得，有点没看明白，直接贴代码GMalloc = FMallocDoubleFreeFinder::OverrideIfEnabled(GMalloc) 下一个就是分析统计的GMalloc = FMallocFrameProfiler::OverrideIfEnabled(GMalloc) 分配器1FMemory::Malloc(SIZE_T Count, uint32 Alignment) 使用其实比较简单的，就是根据不同的分配器去分配内存，知乎的大佬 举了一个MallocTBB的例子。 他大概是说分配超出了就回调GetOutOfMemoryDelegate，然后这里字节对齐是8字节的。超过就16字节，这里小伙伴可能会疑惑，你有个FPlatformMallocCrash上面不是说16字节的吗？是的，但是其实这些是针对平台的，我看的那个实例其实是FGenericPlatformMallocCrash，聪明的小伙伴一看这个字面量就知道什么意思了，我这个是针对通用平台的逻辑，而他这个分配器应该是特殊平台的，所以并不冲突。 好了，现在我们回到我们的问题，两个有什么区分，GameCore由于时间问题和一些其它原因，我就不便介绍了，基本可以按照自研项目那一套方式，底层采用操作系统接口，加一下统计分析逻辑，代码的兼容性和健全性肯定是没法和UE4的比了。 好吧，就这样了。时间原因我没法做太多的分析。 水一篇文章吧。]]></content>
      <categories>
        <category>UE4</category>
      </categories>
      <tags>
        <tag>UE4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spine UE4]]></title>
    <url>%2F2021%2F07%2F02%2Fspine-ue4%2F</url>
    <content type="text"><![CDATA[之前看的Spine都是Unity相关的，最近由于项目要转UE4，所以研究一下UE4下的Spine，然后分析一下手游中的Spine的规格是如何的。 explicit 指定构造函数或转换函数（C++11起）为显式，即踏板不能用于隐式转换和复制初始化。（老是忘） 开篇好吧，google搜spine基本都是如何导入UE4的一些操作，只能自己看代码了。spine分为两个部分，一个是spine底层的通用C++层，一个是对UE4的包装。我这边也分为两部分讲解。 通用C++层这里面结构其实都是这一套，动画，图集，附件，骨骼，颜色，约束，事件，IK反向动力学，蒙皮，很奇怪的是里面的代码明显是按照UE4去做的，比如直接用UE_LOG打日志，所以就比较搞不懂，为什么在github是分开的。 动画看到一个有意思的东西，之前看别人说是FString里面是按照4字节存储的，但是如果我们只是存储非宽字节，可以自己写一套，而他这个就是很好的参考。 String这里很简单的就是一个长度，一个缓存区，然后里面采用的FMemory做一些内存分配器。简单，高效。]]></content>
      <categories>
        <category>Spine</category>
      </categories>
      <tags>
        <tag>Spine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UE4 动画系统 源码及原理刨析]]></title>
    <url>%2F2021%2F07%2F01%2Fue4-anim-system%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/qq_23030843/article/details/109103433大佬原文，本文主要是对原文的二次解析和做一个备份，垃圾的CSDN，谁知道那天倒闭呢。其实内心挺想分享给别人的，但是感觉这种东西大家都可以查得到，还是算了吧。内向的人果然精神内耗很严重。原文其实分了两个，一块是解算每一帧的动作位置，一块是渲染。所以我这边也是按照这两块来讲。其实看了一遍，怎么说呢，纸上得来终觉浅，绝知此事要躬行吧。所以这边先简单摸一下字面意思，下次在加工一下。我这边也分两块分析 解算动作先知道解算这块是可以开启多线程加快运算的，具体如何加快，看原文。还有一个概念，AnimInstance是一个数据和运算集中性业务，外面把握不住，所以推出AnimInstanceProxy来配合使用。再有一点是虽然主要讲的是骨骼蒙皮，即skeletonMesh，但是StaticMesh其实也包含进去了。只不过没讲，怎么说呢，其实都属于一块的，只不过没有动，所以就是一个简单的模型处理了。 渲染]]></content>
      <categories>
        <category>UE4</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[UE4渲染第6节：添加一个新的渲染模型]]></title>
    <url>%2F2021%2F06%2F30%2Fue4-rendering-part-6-adding-a-newshading-model%2F</url>
    <content type="text"><![CDATA[带翻译的文章：https://80.lv/articles/river-editor-water-simulation-in-real-time/ 水https://wickedengine.net/2018/05/21/scalabe-gpu-fluid-simulation/ 流体https://necessarydisorder.wordpress.com/2017/11/15/drawing-from-noise-and-then-making-animated-loopy-gifs-from-there/ 各种噪声，不玩了，深陷其中了 原文地址：https://medium.com/@lordned/ue4-rendering-part-6-adding-a-new-shading-model-e2972b40d72d 注意，译文和原文出入已经很大了，译文主要是按照4.26来操作的，如果有疑问，最好看着原文去操作，不过我想原文的版本大家应该都没有把。 （如果你没有读本系列的第五节，请点击这里） 添加一个新的渲染模型UE支持几种通用的开箱即用的渲染模型来针对大多数游戏。UE不仅支持微面元反射的默认光照，同时也支持高质量的头发和眼睛效果。但是这些可能不是最合适的对于你的游戏或者你希望修改或者新增对于你的游戏，尤其是对于高度风格化的游戏。 集成一个新的光照模型只需要少量的代码但是编译引擎可能花费点时间。当你决定要增加之前，最好看一下上一节，这可能会节省10分钟左右的迭代时间。 大部分的代码是基于FelixK的blog，但是已经打不开了。 我们需要修改3个地方来支持新的渲染模型，材质编辑器，材质和一些shader代码。 修改材质编辑器首先打开EngineTypes.h文件，然后找到EMaterialShadingModel。这个枚举决定了在材质编辑器显示那些渲染模型。我们添加一个新的枚举MSM_StylizedShadow在MSM_MAX之前。123456789// Note: Check UMaterialInstance::Serialize if changed!UENUM()enum EMaterialShadingModel&#123; // … Previous entries omitted for brevity MSM_Eye UMETA(DisplayName=”Eye”), MSM_StylizedShadow UMETA(DisplayName=”Stylized Shadow”), MSM_MAX,&#125;; 枚举可能是按照名字序列化的（如果存在？），但对于引擎来说任何地方的序列化的都加在最后。 UE在UMaterialShadingModel枚举警告开发者检查UMaterialInstance::Serialize函数如果我们改变了枚举。看起来我们不需要更改任何东西，当我们添加了新的渲染模型，所以我们忽略这个警告。（如果你却是对这个函数感到兴趣，它确实是改变了一些资产的加载顺序） 当我们编译完成之后（译者注：裂开了，不知道为什么要编译两千多个文件）我们可以在材质编辑器的下拉框中看到我们新加的渲染模型选项，但是它啥事也不能做。FelixK使用Custom Data 0来允许艺术家设置光照衰减的范围。我们需要修改代码来使Custom Data 0起效在我们自定的渲染模型中。 打开Material.cpp（不是Lightmass项目中的那个）然后查找UMaterial::IsPropertyActive_Internal(4.26是这个函数，有点慌，不知道这个文档能不能跟着做下去)函数。材质上的每个可能的引脚（PIN不知道咋翻译，知道的老铁留个言）每次都会去调用它。如果你尝试正在修改材质域（domain暂时不知道指的是啥，虽然源码中也有这个概念，等我以后知道了就改掉这块）（比如贴花，后处理等），你将需要特别小心的处理该函数的第一部分，查看他们的域对于那些引脚应该启用。如果你和我一样正在修改渲染模型，这里可能有点复杂，你需要搞一个switch-case来针对不同的引脚做不同的处理。（我好像可以理解引脚这个概念，其实就是不同的情况吧） 在我们这个case，我们想开启MP_CustomData0这个引脚，我们找到MP_CustomData0然后添加MSM_StylizedShadow来结束它。当你可以改变渲染模型在风格化窗口中的时候，说明这个引脚已经被开启了，允许你连接它在你的材质蓝图。 123case MP_CustomData0: Active = ShadingModels.HasAnyShadingModel(&#123; MSM_ClearCoat, MSM_Hair, MSM_Cloth, MSM_Eye, MSM_StyleizedShadow &#125;); break; 以上是4.26的写法。 理解这段代码的修改UI在材质编辑器上是重要的。然后你还要确保你的数据支持这些引脚在你的shader上。 注意：Custom Data 0和Custom Data 1是单通道的float属性，这个可能是不够支撑你扩展你的自定义渲染模型。Javad Kouchakzadeh 指出你可以创建一个新的引脚，这将让你选择如何生成你的hlsl代码。不过这有点超出我们的教程了，而且也不是这个文章的主题。你如果想体验一下，可以看一下MaterialShared.cpp文件中InitializeAttributeMap()这个函数。 修改HLSL预处理器定义一旦我们在材质编辑器上选择了我们自己的渲染模型之后，我们得需要让我们的shader知道我们做了这件事。 HLSLMaterialTranslator.cpp然后查找FHLSLMaterialTranslator::GetMaterialEnvironment(EShaderPlatform InPlatform, FShaderCompilerEnvironment&amp; OutEnvironment)函数。(用RIDER直接两个shift就直接找函数吧。)这个函数可以看到各种变量配置（各种属性在你的材质上）然后修改OutEnvironment变量来添加定义。 在我们特殊的案例中我们滑倒最后的部分在switch的Property并且添加我们的MSM_StylizedShadowCase，给它一个名字在允许的匹配中。文档与当前的引擎差异已经很大了，我这都是按照语义改的，不知道是否正确，主要是引擎编译起来有点痛苦。我先不加，等全部翻译完在加。试试。 现在，我们把MSM_StylizedShadow设置到HLSL编译器将通过MATERIAL_SHADINGMODEL_STYLEIZED_SHADOW作为一个预定义的。它将允许我们使用#if MATERIAL_SHADINGMODEL_STYLIZED_SHADOW在HLSL代码里面。 Review这里需要修改C++代码，我们已经添加我们的渲染模型在编辑器中，我们也已经改变引脚使用自定义数据，我们也保证了shader能告诉我们在这个模式。不过编译engine的代码需要花费大量时间（早说啊）。我们也不想更改.ush/.usf文件当我们打开编辑器的时候，这回导致重新编译我们的shader。（这里好坑） 更新GBuffer Shading Model ID现在他是可能的构建shader的排列（a permutation of排列是啥意思呀）通过使用我们的光照模型通过使用MATERIAL_SHADINGMODEL_STYLEIZED_SHADOW。第一件事情，我们需要写一个新的Shading Model ID到GBuffer。当运行光照计算的时候，允许DeferredLIghtPixelShader知道切换那个shading model在使用着。 打开 ShadingCommon.ush然后找到#define SHADINGMODELID_UNLIT。在这里我们定义自己的Shading Model ID，然后更新SHADINGMODELID_NUM 12#define SHADINGMODELID_STYLEIZED_SHADOW 12#define SHADINGMODELID_NUM 13 我们需要告诉shader来写shading Model ID到GBuffer，在离开这个文件之前我们应该更新Buffer Visualization &gt; Shading Model 颜色以便告诉那个像素在你的场景是来自你的shading model的渲染的。 在下面可以找到 float3 GetShadingModelColor(uint ShadingModelID)。 我们添加一个入口在switch(ShadingModelID)里面。 123switch(ShadingModelID)&#123;&#125;]]></content>
      <categories>
        <category>UE4</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LevelSequencer]]></title>
    <url>%2F2021%2F06%2F29%2FLevelSequencer%2F</url>
    <content type="text"><![CDATA[LevelSequence（关卡序列）使用说明以下文档都来自官方文档，但是我这边还是单独拿出来分析以下，足以证明，这块还是很有意思的。 基础操作https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/ReferenceEditor/ 仔细看文档，基础操作，没啥说的，但是要注意，文档和引擎有些许差异，影响不大。 从摄像机导轨拍摄https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/CameraRigRail/ 在Sequencer中使用帧标记https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/FrameMarkers/一个书签的东西，运行时不会用，随便搞。 挺有意思的，但是感觉可以用其它方式代替。不过可以试试。 切换Sequencer中Actor的材质https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/MaterialAnimation/ 没啥好说的，跟着做就好。 混合动画属性https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/CharacterAnimation/ 使用模板序列https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TemplateSequences/ 单个轨道复用的，相当于做一个template sequencer可以给多个level sequencer使用。制作的时候可以想清楚，如果有复用的情况下可以用这个。 没啥好说的，两个动画做blend，可以选如何插值。 CineCameraActor（电影摄像机Actor）https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/CineCameraActors/ 这个镜头我还是非常喜欢的，如果项目中可以使用，我是极力推荐的。 启用观看跟踪（Enable Look at Tracking） -选取此选项可以让摄像机跟踪Actor。 提取调试观看跟踪位置（Draw Debug Look at Tracking Position）-选取此项可以让我们看到摄像机正在观看的位置。 要跟踪的Actor（Actor to Track）-将此项设置为ThirdPersonCharacter，因为我们希望在镜头中跟踪此角色。 相对偏移（Relative Offset）-将Z设置为60以将跟踪位置从默认跟踪位置稍微提高。在CineCameraActor的细节（Details）面板中，将菲林版设置（Filmback Settings）设置为使用Super 16mm。菲林板设置（Filmback Settings）提供了不同的格式，虽然我没看懂是啥意思，但是实验了一下，感觉镜头拉的更近了。 淡入淡出场景https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksFade/ 使用的轨道是Fade Track 关卡可见性轨道（项目包装可能与此不同，谨慎使用）https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksLevelVisibility/ 使用的轨道是Level Visibility Track简单来说其实就是卸载一个关卡，在加载另一个关卡的表现形式，但是项目的关卡定义方式可能会与此不同，不过即使不同，我们应该也会有类似的实现方式。所以原理可以参考。做过长动画用这个感觉挺好的。 为材质参数集（Material Parameter Collections）设置动画https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksMaterialParameter/ 使用的轨道是Material Parameter Collection Track设置材质的一些参数。 调整场景的播放速率https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksPlayRate/ 使用的轨道是Time Dilation，这有点坑，文档上面写着是Play Rate，用的时候要注意，这个之前磊子哥用的挺多的，在AGE中叫SetTimeScale。 创建镜头和副镜头https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksShot/ 关于蒙太奇https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/MatineeConversionTool/ 上面这个文档没啥用，他的意思是说之前有蒙太奇的过场动画，说是一个轻量的，但是后来官方不维护了，就没用了。一堆废话，总之，代码还在，但是我们不用了。跟着官方做，没有找到方法，但是找了一个可以把蒙太奇录入到subsequence里面，也是蛮方便的。录入的前提是需要在运行中录入的，非运行时录入应该也可以，但是这时候你如果可以把这个蒙太奇动起来就可以录入吧，我猜的。 https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/SequenceRecorder/ 真正的是看这个文档，说的很清楚就是运行游戏，然后开始录制，不过这个不是录制视频，而是level sequencer，挺好的。感觉可以做新手引导之类的东西，或者找一个样本，然后二次加工。 使用音频轨迹https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksAudio/ 说是要用wwise，做demo感觉可以用这个，不过不管吧，毕竟没啥需求，将来加了wwise，可以在加一个wwise的音频轨道，也好加。 自动关键帧https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/UsingAutoKey/ 没啥可说的，K帧最基本的东西。 保留或存储通过Sequencer进行的修改https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/WhenFinished/ 没啥可说的，播完之后选择如何设置绑定对象或者全局的状态。 媒体轨道https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/UsingMediaTracks/ 使用摄像机镜头切换https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/TracksCameraCut/ 这个东西，反正我挺喜欢的，不过按照AGE来说，我们可能只会用一个镜头，但是说实在的，一个镜头却是靠操控性会差很多。而且程序这边还需要传一个主相机。其实level sequencer和age来比，或者age和其它编辑器来说，最大的优势其实是多种坐标系这个概念，让发生的过场动画，跟你的环境不是受太大的影响。然后引导你去这种编辑一些东西。但是其实这种不太好。美术做的东西本来就很容易受环境影响，不同的环境表现力肯定是不相同的，所以我比较倾向程序尽量少传递这些比如镜头和角色等之类的东西，如果在性能可以hold的情况下。 使用动态变形创建关卡序列https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/DynamicTransforms/ 标题有点难受，其实就是指定坐标原点，相对坐标系那种思路。但是这个是个全局的概念，而不是age那种可以指向到某个轨道上去。 通过Sequencer混合动画蓝图https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/BlendingAnimBPs/ 讲道理来说，我们项目是不推荐使用自带蓝图的，在项目自己的蓝图中没有出来的时候，可以使用这种方式。 扩展使用几何体缓存轨迹https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/HowTo/GeometryCacheTrack/ 有点秀操作的东西，但是我们应该用不上。 非线性动画和混合工具https://docs.unrealengine.com/4.26/zh-CN/AnimatingObjects/Sequencer/AnimationBlendingTools/ 反正官方说是测试功能，不建议使用，我们也就不要使用了吧。大概意思是说，在动画的过渡区域，普通的混合会出现由于骨骼的控制权的归属和权重控制问题导致的错乱。而这个主要是处理这个问题的。但是由于是测试功能，说明还是有些坑没有解决掉的。]]></content>
      <categories>
        <category>UE4</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[UE4常见宏]]></title>
    <url>%2F2021%2F06%2F29%2FUE4_Macro%2F</url>
    <content type="text"><![CDATA[类说明符 Abstract 抽象类说明符将类声明为“抽象基类”，防止用户在虚幻编辑器中向世界添加此类的参与者，或者游戏中创建此类的实例。这对于那些本身没有意义的类很有用。 AdvancedClassDisplay 强制类的所有属性只显示在“Detail”面板的”Advanced”部分中，默认情况下隐藏在”视图“中。若要在某个属性上重写此项，请在属性上使用SimpleDisplay说明符。 AutoCollapseCategories=(Category1, Category2,…)/DontAutoCollapseCategories(Category,Category,…) AutoCollapseCategories类说明取消对父类AutoExpandCategories说明符的列出类别的影响。 DontAutoCollapseCategories否定从父类继承的列出类别的AutoCollapseCategories的说明符。 AutoExpendCategories=(Category1,Category2,…) 指定应在该类的对象”虚幻编辑器“属性窗口中自动展开的一个或多个类别。若要自动声明为无类别的变量，请使用声明变量的类的名称 Blueprintable/NotBlueprintable 将此类公开为创建蓝图可接受的基类。默认是NotBlueprintable，除非继承，否则该说明符由子类继承 BlueprintType 将类型公开可用于蓝图中的变量的类型 ClassGroup=GroupName 表示在Actor浏览器中启用Group View后，Actor浏览器应该在指定的GroupName中包含此类以及它的任何子类 CollapseCategories/DontCollapseCategories 表示不应该将此类的属性分组到属性窗口的类别中。这个说明符将传播给子类，但是，子类可以用DontCollapseCategories说明符来覆盖它 Config=ConfigName 表示允许此类在配置文件中(.ini)中存储数据。如果有使用config或globalconfig说明符属性的任何类属性，则此指定夫将导致这些属性存储在命名的配置文件中。此说明符将传播到所有子类不能被否定，但是子类可以通过re-declaring配置说明符并提供不同的ConfigName来更改配置文件。常见的ConfigName值是”Engine”,”Editor”,”Input”,”Game”。 Const 该类中所有属性和函数都是const的，并以const的形式导出。该说明符由子类继承 ConversionRoot Root转换符将一个子类限制为仅能够转换到为第一个Root类的子类，并上升到层级结构 CustomConstructor 组织自动生成构造函数声明 DefaultToInstanced 这个类的所有实例都被认为是”实例化“的。实例化的类（组件）在构建时被复制。该说明符由子类继承 DependsOn=(ClassName1,ClassName2,…) 列出的所有类将在该类之前编译。类必须在同一个（或上一个）包中指定一个一个类。可以使用由逗号分隔的单个取决于指定多个依赖项类，也可以为每个类使用单独指定。当类使用在另一个类中声明的结构或枚举时，这一点很重要，因为编译器只知道它已编译的类中内容。 Deprecated 这个类不推荐使用，而且这个类的对象在序列化的时候不会被保存。该说明符由子类继承 EditInlineNew/NotEditInlineNew 表示可以从”虚幻编辑器“属性窗口创建此类的对象，而不是从现有资产引用。默认行为时只有对现有对象的引用才可以通过属性窗口分配。此说明符被传播到所有子类；子类可以使用NotEditInlineNew说明符来重写此说明符。 HideCategories=(Category1,Category2,…)/ShowCategories=(Category1,Category2,…) HideCategories列出隐藏在此类对象的”虚幻编辑器“属性窗口的一个或多个类别。若要隐藏声明为”no“类型的属性，请使用声明该变量的名称。此说明符将传播到子类。 ShowCategories为所列出的类别取消一个HideCategories说明符（从基类继承） HideDropdown 防止在虚寒编辑器属性窗口组合框中显示此类 HideFunctions=(Category1,Category2,…)/ShowFunctions=(Category1,Category2,…) HideFunctions从属性查看器隐藏指定类别的所有函数 ShowFunctions从属性查看器中显示列出的类别中所有函数 Intrinsic 这表明这个类是直接用C++声明，并且没有UHT生成的generate文件。不要在新类上使用这个说明符。 MinimalAPI 仅导致要导出的类的类型信息供其它模板使用。类可以被强制转换，单不能调用类的函数（inline除外）。这提高了编译事件，因为不需要在其他模块中访问所有函数的类导出所有内容。 NoExport 表示此类的声明不应包含由UBT自动生成的generate文件。必须在单独的头文件中手动定义C++声明。仅对本机类有效。不要将此用于新类。 Placeable/NotPlaceable 表示可以在编辑器中创建此类，并将其放置于关卡、UI或蓝图中（具体取决于类类型）。此标志将传播到所有子类；子类可以使用NotPlaceable说明符来重写此标志 Transient/NonTransient 属于此类的对象将永远不会保存到磁盘。这与某些非永久性的自然类（如播放器或窗口）结合使用非常有用。此说明符将传播到子类，但可以由NonTransient说明符重写 Within=OuterClassName 这个类的对象不能存在于一个OuterClassName对象的实例之外。这意味着创建这个类的Object需要提供一个OuterClassName的实例将其作为外部对象 元数据修饰符 BlueprintSpawnableComponent 如果存在，组件类可以由蓝图生成 BlueprintThreadSafe 仅对蓝图函数库有效。此说明符将此类的中函数标记为在动画蓝图中的游戏线程上可调用 ChildCannotTick/ChildCanTick ChildCannotTick用于Actor和Component类。如果host不能勾选，基于此Actor或Component的蓝图类永远不会勾选，即使bCanBlueprintsTickByDefault为true CHildCanTick用于Actor和Component类。如果host不能勾选，则基于此参与者或组件的蓝图类可以覆盖bCanEverTick标记，即使bCanBlueprintsTickByDefault是false。 DeprecatedNode 对于行为树节点，指示该类已弃用，并在编译时显示警告 DeprecationMessage=”Message Text” 如果该类被启用，则在尝试编译使用它的蓝图时，此消息奖杯添加到警告中 DisplayName=”Blueprint Node Name” 蓝图中此节点的名称将替换为此处提供的值，而不是代码生成的名称 DontUseGenericSpaenObject 不要在蓝图中使用泛型创建对象节点生成类的对象。此说明符仅对既非参与者也不ActorComponents的BlueprintType类是有意义的 ExposedAsyncProxy 在异步任务节点中公开此类的代理对象 IgnoreCategoryKeywordsInSubcalasses 用于使类的第一个子类忽略所有继承的ShowCategories和HideCategories说明符 IsBlueprintBase=”true/false” 声明此类是（或不是）用于创建蓝图的可接受基类，类似与UCLASS说明 KismetHideOverrides=”Event1,Event2,…” 不允许重写的蓝图事件列表 ProhibiteInterfaces=”Interface1,Interface2,…” 列出与类不兼容的接口 RestrictedToClasses=”Class1,Class2,…” 由蓝图函数库类使用，用于限定列表中命名的类的用法 ShortToolTip 在某些上下文中使用的简短工具提示，其中完整的工具提示可能是压倒性的，如父类选择器对话框 ToolTip 重写代码注释中自动生成的工具提示 ShowWorldContextPin 表示放置在此类所拥有的关系图中的蓝图节点必须显示它们的世界上下文，即使它们通常是隐藏的，因为此类的对象不能用作世界上下文。 UsesHierarchy 表示类使用分层数据。用于实例化detail面板中的分层编辑功能。 Shader中的宏 MOBLIE_MULTI_VIEW 计算View复杂 PACK_INTERPOLANTS 是否使用了顶点雾，多了PackedInterps数组需要计算高度雾 USE_WORLD_POSITION_EXCLUDING_SHADER_OFFSET C++对应bNeedsWorldPositionExcludingShaderOffsets，是否需要世界位置，用于Decal计算 USE_PS_CLIP_PLANE C++中对应r.AllowGlobalClipPlane，是否使用ps裁剪 OUTPUT_GAMMA_SPACE C++中对应LDR_GAMMA_32，使用Gamma空间 FULLY_ROUGH c++对应材质IsFullyRough，是否是fullrough，可以减少计算 NONMETAL C++ MATERIAL_NONMETAL 材质是否金属化，非金属计算量少，EnvBRDFApproxNonmetal EnvBRDFApprox LQ_TEXTURE_LIGHTMAP 是否使用了Lightmap HQ_REFLECTIONS High Quality 反射 ALLOW_CUBE_REFLECTIONS High Quality 反射中的cube反射 MATERIAL_PLANAR_FORWARD_REFLECTIONS Planar 反射 MATERIALBLENDING_SOLID Blend方式 MATERIALBLENDING_MASKED MATERIALBLENDING_APLHACOMPOSITE MATERIALBLENDING_TRANSLUCENT MATERIALBLENDING_ADDITIVE MATERIALBLENDING_MODULATE MATERIAL_SHADINGMODEL_UNLIT 无光照模式 ENABLE_SKY_LIGHT 是否拥有天光 MAX_DYNAMIC_POINT_LIGHTS 动态光 NON_DIRECTIONAL_DIRECT_LIGHTING 这可以在DeferredLightingCommon.ush中找到，但似乎只在ForwardLightingCommon.ush定义 SUPPORT_CONTACT_SHADOWS 为unreal的contact Shadows Feature提供支持。 REFERENCE_QUALITY 在DeferredLightingCommon.ush的顶部定义为0，可能用于cinematic rendering ALLOW_STATIC_LIGHTING 如果r.AllowStaticLighting的控制台变量设置为1，则为true。这与Project Settings&gt;Rendering的Static Lighting support选项匹配 USE_DEVELOPMENT_SHADERS 如果COMPLIE_SHADERS_FOR_DEVELOPMENT是真的（并且平台支持它），则为true]]></content>
      <categories>
        <category>UE4</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2021%2F06%2F17%2FSpatialAntiAliasingTechnology%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[3D游戏与计算机图形学中的数学方法]]></title>
    <url>%2F2019%2F09%2F06%2FMathematical-methods-in-3D-games-and-computer-graphics%2F</url>
    <content type="text"><![CDATA[通过像素包含测试、裁剪测试、Alpha测试、模版测试和深度测试，段数据的最终颜色值被混合到图像缓冲区。图像缓冲区的新颜色值通过将端数据的最终颜色值与图像缓冲区对应位置的颜色值进行混合操作而获得。段数据的Alpha值和保存在图像缓冲区中的Alpha值也可用来决定视见区中显示的最终颜色值。最简单的混合操作就是用段数据的最终颜色值替换图像缓冲区中的颜色值。混合操作也可用来产生透明一类的特殊视觉效果。 内积两个向量的内积也被称为向量的点积或者标量积，是3D图形学忠应用最多的概念之一。内积可用来计算两个向量的方向差。定义2.3 两个n维向量$P$和$Q$的内积可以表示$P\cdot Q$，是一个标量，可以按以下公式计算：$\vec P\cdot \vec Q=\sum_{i=1}^nP_iQ_i$从该定义可以看出，两个向量的内积是每个分量乘积的和，对于三维向量，其内积可以表示为$\vec P\cdot \vec Q=P_xQ_x+P_yQ_y+P_zQ_z$接下来的定理2.4将揭示向量内积被广泛应用的原因。定理2.4 给定任意两个n维向量$\vec P$和$\vec Q$，内积$\vec P \cdot \vec Q$满足以下等式。$\vec P \cdot \vec Q = ||P||\ ||Q||cos\alpha$其中$\alpha$是坐标原点分别与向量$\vec P$和$\vec Q$对应的点之间连线的平面夹角。证明： 如图2.2所示，令其中$\alpha$为向量$\vec P$和向量$\vec Q$之间的夹角，根据余弦定义可知。图 2.2 等式$\vec P \cdot \vec Q = ||P||\ ||Q||cos\alpha$将两个向量的内积与它们的夹角联系在一起 曲线与曲面现代图形硬件已经具备对由大量顶点和平面组成的各类光滑曲面进行有效渲染的能力，因此弯曲几何体的表示与处理已经成为3D图形引擎的必备功能之一。另外，在几何造型系统中，曲线可以表示某个对象的运动轨迹。本章将介绍多种三维的三次曲线，并进一步介绍如何用这些曲线生成双三次参数曲面。 三次曲线三次多项式定义的曲线在操作灵活性和计算简单性方面比较均衡，因此在计算机图形学中被广泛应用。下面将介绍几种不同类型的三次曲线并比较它们之间的性质。三次曲线的基本形式可用以下参数表达式表示。$Q(t)=\vec a+\vec bt+\vec ct^2+\vec dt^3$其中，a，b，c和d为常向量，Q(t)为曲线上与参数t对应的点。Q(t)的分部表达式为$Q_x(t)=\vec a_x+\vec b_xt+\vec c_xt^2+\vec d_xt^3$$Q_y(t)=\vec a_y+\vec b_yt+\vec c_yt^2+\vec d_yt^3$$Q_z(t)=\vec a_z+\vec b_zt+\vec c_zt^2+\vec d_zt^3$上式可以容易地写成矩阵乘积的形式：$Q(t)=\begin{bmatrix}a_x&amp;b_x&amp;c_x&amp;d_x\\a_y&amp;b_y&amp;c_y&amp;d_y\\a_z&amp;b_z&amp;c_z&amp;d_z\end{bmatrix}\begin{bmatrix}1\\t\\t^2\\t^3\end{bmatrix}$写成更紧凑的形式，如下所示：$Q(t)=CT(t)$其中，C为系数矩阵，$T(t)=(1,t,t^2,t^3)$，Q(t)的导数为曲线在t的切线方向，由于矩阵C为常数矩阵，可以很容易地计算出Q(t)的导数，如下式所示。$Q^’(t)=Cd/dtT(t)=C$ 4.4.3 坐标w的几何意义在利用$4\times 4$矩阵进行的变换中，四维向量的w坐标起了重要作用，除了这个作用外，w坐标还有重要的几何意义。前面，通过给三维点扩展一个等于1的w坐标，变成四维空间中的一个点。这里研究一下相反的情况，假设有一个4D点向量$\vec p = (x,y,z,w)$，其中w不为0.令向量$P’$为向量$P$在w=1的三维空间中的映射，如下式所示：$P’=({x\over w},{y\over w},{z\over w})$ 4.6.2 四元数旋转三维空间的旋转可以看成函数$\varphi$在三维向量空间$R^3$内的映射变换。由于函数$\varphi$表示一个旋转变换，它必须保持长度、角度和偏手性不变。如图4.5所示，图中为了方便省略了z轴，3D点向量$P’$为点$P$与坐标系原点的连线与w=1的三维空间的交点，因此，给4D向量P 5.3.1 视场如图5.10所示，投影平面是一个与相机指向垂直的平面，该平面与相机的距离为e，左锥面与右锥面分别与该平面在x=-1和x=1处相交。距离e有时也被称为相机的焦距，与左锥面和右锥面之间的夹角$\alpha$有关，夹角$\alpha$被称为水平视场角。图5.10 相机到投影平面的距离e与水平视场角$\alpha$有关 对于给定的水平视场角$\alpha$，到投影平面的距离e可由以下三角关系表达式给出。$e = {1\over tan( \alpha / 2)}$ 焦距越短，则视场越大。视场角逐渐缩小，相机则进行放大成像，而焦距越大。显示屏幕的宽高比等于显示屏幕的高度除以宽度，例如，像素分辨率为$640\times 480$的显示器的宽高比为0.75。由于大多数显示器不是正方形而是长方形，所以垂直视场不等于水平视场。低锥平面和顶锥平面与投影平面在$y=\pm a$处相交，a为显示器的宽高比，这可构成图5.11所示的三角形，则垂直视场角$\beta$的表达式如下：$\beta=2tan^{-1}(a/e)$ 图5.11 垂直视场角$\beta$与高宽比a有关 视锥的4个边平面在从投影平面切出一个长方形，该长方形与相机距离为e，它的四条边分别位于$x=\pm 1$和$y=\pm a$处。 5.3.2 锥平面6个视锥平面在相机空间的法向量如图5.12所示，其中4个边锥平面的法向量向内，指向视锥内部，可以通过将边平面中的边的方向向里旋转90°获得。由于每个边锥平面都经过坐标系原点，其平面四锥表达式中的D=0。近锥平面与原点距离为n，与原点的相对方向与其法向量相同，所以D=-n。远锥平面与原点距离为f，与原点的相对方向与其法向量相反，所以D=f。表5.1总结了视锥的6个锥平面的四维平面表示向量。在表5.1中，4个边锥平面的法向量已经规范化成长度为单位长度的向量。图5.12 在OpenGL的相机空间中的视锥平面的法向量方向表5.1 在OpenGL的相机空间中的视锥平面向量 深度值偏移在很多游戏中，经常遇到渲染一些特殊效果的情况，如墙上的火烧痕迹和地面上的脚印，这些内容都不是原始场景的一部分，而是在游戏过程中产生的，在9.2节中将介绍这些特效的方法。这些修饰性的对象通常被贴到当前的物体表面上，因此这些对象包含的多边形与场景中的插值深度值，很少会等于与共面的另一多边形某一部分对应的渲染像素的插值深度值，这将导致一个不想要的渲染结果，即原始表面的多边形会透过贴上去的多边形而显示出来。为了解决上述问题，需要寻找一个方法可以将多边形在场景中的深度适当偏移而不改变它的投影屏幕坐标或者调整多边形的纹理映射透视处理方法。多数3D图形系统包含一些多边形偏移函数，借用这些函数可实现处理目标。然而，这些办法缺少灵活的控制方法，常会导致逐顶点的复杂运算。本节将介绍一个通过修改投影矩阵而获得深度偏移效果的方法。 投影矩阵调整首先分析标准的OpenGL透视投影矩阵对观察空间一点$P = (P_x,P_y,P_z,1)$的变换结果。]]></content>
      <categories>
        <category>Computer graphics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Calculus]]></title>
    <url>%2F2019%2F09%2F06%2FCalculus%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[建筑场景的阴影实现]]></title>
    <url>%2F2019%2F09%2F06%2FArchitecturalShadow%2F</url>
    <content type="text"><![CDATA[首先看一下我们的效果需求，我们是一款SLG游戏，主程中的建筑都是3D的建筑，玩家到后期主城内有上百个建筑，而且建筑都是可以让玩家随意摆放的。我们的建筑要实现自身的阴影和在地面上的投影。如下图：一般我们在游戏中要实现建筑的阴影有两种方案：1.灯光的实时影音；2.使用Lightmap烘培阴影信息。 方案1在移动端使用的很少，如果没有实时光影的变化，类似天气系统之类的需求，基本上是不会使用的。要多一个pass去计算阴影，相当于场景中的三角面数翻倍。 方案2是目前大多数移动端上使用的，开销的话只是用第二套UV去采样一次Lightmap贴图而已。但是这种方法烘培Lightmap]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Occlusion Map（环境光散射贴图）]]></title>
    <url>%2F2019%2F09%2F06%2FStandardShaderMaterialParamterOcclusionMap%2F</url>
    <content type="text"><![CDATA[The occlusion map is used to provide information about which areas of the model should receive high or low indirect lighting.Indirect lighting comes from ambient lighting and reflections,and so steep concave parts of your model such as a crack or fold would not realistically receive much indirect light. Occlusion texture maps are normally calculated by 3D applications directly from the 3D model using the modeller or third party software. An occlusion map is a greyscale image（灰度图像）,with white indicating areas（白色显示区域） that should receive full indirect lighting（间接光照）,and black indicating（指示） no indirect lighting.Sometimes this is as simple as a greyscale hightmap,for simple surface(such as the knobbly stone wall（有节的石墙）texture shown in the heightmap example above). At other times,generating the correct occlusion texture is slightly more complex（稍微复杂的）.For example,if a character in you scene is wearing a hood（戴着头巾）,the inside edegs of the hood should be set to very low indirect lighting（头巾外围应该设置很低的间接光）,or none at all（或者一点也没有）.In these situations（状况）,occlusion maps will be often be produced by artists,using 3D applications to automaticalyy generate an occlusion map based on the model. This occlusion map identifies ares on a character’s sleeve（头套）that are exposed（暴露）or hidden from ambient lighting.It is used on the model pictured below.（它用在下面的模型） Before and after applying an occlusion map.The areas that partially obscured,（部分模糊的区域）particularly in the folds of fabric around the neck.（特别是在脖子周围的织物褶皱上）are lit too brightly on the left.After the ambient occlusion map is assigned,these ares are no longer lit by the green ambient light from the surrounding wooded envirnoment.]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[纹理过滤模式中的Bilinear、Trilinear以及Anistropic Filtering]]></title>
    <url>%2F2019%2F09%2F05%2FBilinear-Trilinear-Anistropic-Filtering%2F</url>
    <content type="text"><![CDATA[为什么在纹理采样时需要texture filter（纹理过滤）我们的纹理是要贴到三维图形表面的，而三维图形上的pixel中心和纹理上的texel中心点并不一致（pixel不一定对应texture的采样中心texel），大小也不一定一致。当纹理大于三维图形表面时，导致一个像素被映射到许多纹理像素上；当纹理小于三维图形表面时，许多个像素都映射到同一个纹理。当这些情况发生时，贴图就会变得模糊或发生错位，马赛克。要解决此类问题，必须通过技术平滑texel和pixel之间的对应。这种技术就叫纹理滤波。不同的过滤模式，计算复杂度不一样，会得到不同的效果。过滤模式由简单到复杂包括：Nearest Point Sampling（最近采样点），Bilinear（双线性过滤），Trilinear（三线性过滤）、Anisotropic Filtering（各项异性过滤）。 什么是各向同性和各向异性？当需要贴图的三维表面平行于屏幕（viewport），则是各向同性的。当要贴图的三维表面与屏幕有一定角度的倾斜，则是各向异性的。 Nearest Point Sampling（最近点采样）这个最简单，每个像素的纹理坐标，并不是刚好对应Texture上的一个采样点texel，怎么办呢？最近点采样取最接近的texel进行采样。当纹理的大小与贴图的三维图形的大小差不多时，这种方法非常有效和快捷。如果大小不同，纹理就需要进行放大或缩小，这样，结果就会变得矮胖、变形或模糊。]]></content>
  </entry>
  <entry>
    <title><![CDATA[GPU Gems 2]]></title>
    <url>%2F2019%2F09%2F05%2FGPU-Gems-2%2F</url>
    <content type="text"><![CDATA[前言《GPU Gems 2》这本书除了丰富的内容之外，还有两个特点。 虚幻引擎之父Tim Sweeney为《GPU Gems 2》作序。作为Epic Games的创始人，Unreal Engine早期主要开发者，Tim也在序中展示了《GPU Gems 2》出版伊始（2005年3月）时开发完成的Unreal Engine 3。UE3可谓是开创了一个时代。随后包括《新鬼泣》在内的100+款大作（2005年~2015年），都是基于UE3开发。 《GPU Gems 2》的中文版是龚大2005年，但可以不夸张地说，书中介绍的很多方法技巧trick，哪怕是放到现在，依然非常值得学习和借鉴。 ok，篇幅原因，开场话就不多说了，放一张本文的核心内容，真是感植物渲染的图，我们就直接开始正题。 实现照片级真实感的虚拟植物（Toward Photorealism in Virtual Botany）内容概览众所周知，植物的渲染需要很多的视觉深度和细节才能令人信服。 本章即关于渲染逼真自然场景的技术，描述了对实时游戏引擎友好的、用于渲染更真实的自然场景的策略。讲述了在不需要大量CPU或GPU占用的前提下渲染出包含大量植物和树组成的绿色植物场景。 内容安排方面，这章从管理大型户外场景数据这一基础开始描述。然后，提供一些细节，例如关于如何最大化GPU吞吐量，以便可以看到密集的草丛。接下来扩展这些技术，增加地面杂物和大型植物，如树，将阴影和环境影响组合进去。 一些真实感植物渲染的效果图： 场景管理（Scene Management）任何3D游戏引擎都应该有环境相关渲染技术的管理和组织。 游戏引擎必须管理其渲染技术，以适合于它们希望看到的环境范围。以自然场景为主的游戏由上千棵树，灌木和可能上百万片草叶组成。直接分开渲染会出现数据管理问题，只有解决了这一问题才能以交互的帧率实时渲染。 我们的目标是在一个逼真的室外场景中大范围地移动游戏相机，而不需要在任务管理上花费过多的存储器资源。 种植栅格（The Planting Grid）场景管理方面，首先是使用了虚拟栅格的思想。 我们在相机周围建立一个世界空间固定的栅格，来管理每一层的植物和其他自然物体的种植数据。每个栅格单元包含渲染它所在物理空间层的所有数据。特别是，单元数据结构存储了对应的顶点、索引缓冲区和材质信息来再现需要绘制的内容。 对植物的每个层，建立相机到层的距离，层需要用它来产生视觉效果，这决定了虚拟栅格的大小。相机移动，虚拟栅格也随之移动。当一个栅格单元不再在虚拟栅格中时，丢弃它，并在需要维护完成栅格结构的地方添加新的单元。在添加每个单元格时，用一种种植算法把渲染所需的数据填充到层。如下图。图注：内层有一个世界空间对齐的固定大小的栅格。深绿的单元表现为活动单元。当相机向前移动时，丢弃标记为X的单元，添加新的单元（显示为亮绿色）以维持虚拟栅格的大小，实现过程中有用的改进是使用栅格单元池且循环使用，因为当一个旧单元被丢弃时，总会增加一个新单元。 种植策略（Planting Strategy）对于充满自然物体的每个单元，需要在地面上选择需要放置物体的适当位置。采用试探的方法根据被防止对象对象类型来选择这些点。通常，需要的密度随机选点，然后看地面上的对应点是否适合要种植的东西。而地面多边形的材质决定了一个层是否适用。]]></content>
      <categories>
        <category>GPU Gems</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[GPU Architectures]]></title>
    <url>%2F2019%2F09%2F05%2FGPU-Architectures%2F</url>
    <content type="text"><![CDATA[Graphics pipeline “Logical” pipeline described in OGL/DX specification It’s an abstraction At physical level things are very different As long as specs are met there’s no problem Today we will look at things from a slightly closer POV. Anatomy of a GPU Extremely Parallel machine Thousands of “threads” in flight But Limited flow control Some threads shares program counter No Inter process communication Memory bandwidth is very high（内存带宽很高） Hundreds of GB/s But Very high latency（延迟很高） Thousand of cycles Latency hidind mechanism necessary]]></content>
  </entry>
  <entry>
    <title><![CDATA[OpenGL ES 3.0 Fragment Shader]]></title>
    <url>%2F2019%2F09%2F04%2FOpenGLES-Fragment-Shader%2F</url>
    <content type="text"><![CDATA[第9章介绍了在片段着色器中创建和应用纹理的基础知识。在本章中，我们提供了片段着色器的更多细节，并描述它的一些用户。特别是，我们聚焦于如何用片段着色器实现固定功能技术。本章介绍的主题包括： 固定功能片段着色器 可编程片段着色器概述 多重纹理 雾化 Alpha测试 用户裁剪平面 在图10-1中，已经包含了可编程管线的顶点着色器、图元装配和光栅化阶段。我们已经讨论了在片段着色器中使用纹理。现在，我们将重点放在管线的片段着色器部分，介绍片段着色器编写方面的其余细节。 固定功能片段着色器对可编程片段管线还不熟悉但是已经使用过OpenGL ES 1.x的读者可能熟悉固定功能片段管线。在研究片段着色器的细节之前，我们认为值得简单地回顾一下老式的固定功能片段管线，这将帮助你理解老式的固定功能管线映射到片段着色器的方式。在转到更先进的片段编程技术之前，这是很好的起点。 在OpenGL ES 1.1中，可以使用一组有限的方程式，确定如何组合片段着色的不同输入。在固定功能管线中，实际上可以使用3种输入：插值顶点颜色、纹理颜色和常量颜色。顶点颜色通常保存一个预先计算的颜色或者顶点照明计算的结果。纹理颜色来自于使用图元纹理坐标绑定中读取的值，而常量颜色可以对每个纹理单元设置。 内建特殊变量OpenGL ES 3.0有内建特殊变量，这些变量由片段着色器输出或者作为片段着色器的输入。片段着色器中可用的内建特殊变量如下所示： gl_FragCoord——片段着色器中的一个只读变量。这个变量保存片段的窗口相对坐标(x,y,z,1/w)。在一些算法中，知道当前片段的窗口坐标是很有用的。例如，可以使用窗口坐标作为某个随机噪声贴图纹理读取的偏移量，噪声贴图的值用于旋转阴影贴图的过滤核心。这种技术用于减少阴影贴图的锯齿失真。 gl_FrontFacing——片段着色器中的一个只读变量。这个布尔变量在片段是正面图元的一部分时为true，否则为false。 gl_PointCoord——一个只读变量，可以在渲染点精灵时使用。它保存点精灵的纹理坐标，这个坐标在点光栅化期间自动生成，处于[0,1]区间内。第14章中有一个使用该变量渲染点精灵的示例。 gl_FragDepth——一个只写输出变量，在片段着色器中写入时，覆盖片段的固定功能深度值。这一个功能应该谨慎使用（只在必要时），因为它可能禁用许多GPU的深度优化。例如，许多GPU有所谓的“Early-Z”功能，在执行片段着色器之前进行深度测试。使用Early-Z的好处是不能通过深度测试的片段永远不回被着色（从而保护了性能）。但是，使用gl_FragDepth时，必须禁用该功能，因为GPU在执行片段着色器之前不知道深度值。 内建变量下面是与片段着色器有关的内建变量：123456const mediump int gl_MaxFragmentInputVectors = 15;const mediump int gl_MaxTextureImageUnits = 16;const mediump int gl_MaxFragmentUniformVectors = 224;const mediump int gl_MaxDrawBuffers = 4;const mediump int gl_MinProgramTexelOffset = -8;const mediump int gl_MaxProgramTexelOffset = 7; 内建常量描述如下最大项： gl_MaxFragmentInputVectors——片段着色器输入（或者可变值）的最大数量。所有ES 3.0实现支持的最小值为15。 gl_MaxTextureImageUnits——可用纹理图像单元的最大数量。所有ES 3.0 实现支持的最小值为16。 gl_MaxFragmentUniformVectors——片段着色器内可以使用vec4统一变量项目的最大数量。所有ES 3.0实现支持的最小值为224。开发者实际可以使用的vec4统一变量项目的数量在不同实现以及不同片段着色器可能不一样。这个问题在第8张中说明过，同样适用于片段着色器。 gl_MaxDrawBuffers——多重渲染目标（MRT）的最大支持数量。所有ES 3.0实现支持的最小值为4。 gl_MinProgramTexelOffset/gl_MaxProgramTexelOffset——通过内建ESSL函数texture*Offset()偏移参数支持的最大和最小偏移量。 多重纹理我们从多重纹理入手，这是片段着色器中非常常见的操作，用于组合多个纹理贴图。例如，QuakeIII等多种游戏里曾经使用一种技术，将来自光照计算的照明效果存储在一个纹理贴图中。然后，这个贴图在片段着色器中与基本纹理贴图合并，以表现静态照明。多重纹理还有许多其他的示例，我们将在第14张介绍。例如，纹理贴图常常用于存储反射指数和遮罩，以衰减和遮盖反射光的分布。许多游戏还是用法线贴图，这种纹理以比逐顶点法线更高级别的细节存储法线信息，以便在片段着色器中计算照明。 雾化应用雾化是渲染3D场景的一种常见技术。在OpenGL ES 1.1中，雾化作为一种固定功能操作。雾化如此普遍应用的原因之一是，它可以用于减少绘图距离，并且消除靠近观看者的几何体的“突现”现象。 雾化的计算有几种可能的方式，使用可编程片段着色器，你就不必局限于任何特定的方程式。下面我们将介绍如何用片段着色器计算线性雾化。要计算任何类型的雾化，需要两个输入：像素到眼睛的距离以及雾化的颜色。要计算线性雾化，还需要雾化所覆盖的最小和最大距离。 片段测试和操作下面几个小节描述可以应用到OpenGL ES片段的各种测试。默认情况下，所有片段测试和操作都被禁用，片段在写入帧缓冲区时按照接受它们的顺序变成像素。通过启用不通的片段，可以应用操作性测试，以选择哪些片段成为像素并影响最终的图像。 每个片段测试都可以通过调用glEnable单独启用，该函数所带的标志参数如表11-1所示。 表11-1 片段测试启用标志 glEnable标志 描述 GL_DEPTH_TEST 控制片段的深度测试 GL_STENCIL_TEST 控制片段的模版测试 GL_BLEND 控制片段与颜色缓冲区中存储的颜色的混合 GL_DITHER 在写入颜色颜色缓冲区前控制片段颜色的抖动 GL_SAMPLE_COVERAGE 控制样本范围值的计算 GL_SAMPLE_ALPHA_TO_COVERAGE 控制样本范围值计算中样本Alpha的使用 使用裁剪测试裁剪测试通过制定一个矩形区域（进一步限制帧缓冲区中可以写入的像素）提供了额外的裁剪层次。使用裁剪矩形是两步的过程。首先，需用glScissor函数指定矩形区域：void glScissor(GLint x, GLint y, GLsizei width, GLsizei height);x,y 以视口坐标指定裁剪矩形左下角width 指定裁剪矩形宽度（以像素表示）height 指定裁剪矩形高度（以像素显示） 指定裁剪矩形之后，需通过条用glEnable(GL_SCISSOR_TEST)启用它，以实施更多的裁剪。所有渲染（包括视口清除）都限于裁剪矩形之内。 一般来说，裁剪矩形是视口中的一个子区域，但是这两个区域不一定真正交叉。当两个区域不交叉时，裁剪操作将在视口区域外渲染的像素上进行。注意，视口的变换发生在片段着色器之前，而裁剪测试发生在片段着色器阶段之后。 模版缓冲区测试应用到片段的下一个操作是模版测试。模版缓冲区是一个逐像素掩码，保存可用于确定某个像素是否应该被更新的值。模版测试由应用程序启用或者禁用。模版缓冲区的使用可以看做两步的操作。第一步是用逐像素掩码初始化模版缓冲区，这可以通过渲染几何形状并制定模版缓冲区的更新方式来完成。第二部通常是使用这些值控制后续在颜色缓冲区中的渲染。在两种情况下，都制定参数在模版测试中的使用方式。 模版测试实际上是一个位测试，就像在C程序中使用掩码确定某一位是否置位一样。控制模版测试的运算符和值的模版函数由glStencilFunc或glStencilFuncSeparate函数控制。void glStencilFunc(GLenum func,GLint ref, GLuint mask)void glStencilFuncSeparate(GLenum face, GLenum func, GLint ref, GLuint mask)]]></content>
      <categories>
        <category>OpenGL ES 3.0</category>
      </categories>
      <tags>
        <tag>OpenGL ES 3.0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当我们谈优化时，我们谈些什么]]></title>
    <url>%2F2019%2F09%2F04%2FGPU-Optimize%2F</url>
    <content type="text"><![CDATA[过去几年里，我经历过大约几十场面试，几乎在每次面试的时候，面试官都会提问一个问题：“你在渲染性能优化方面有什么经验？”这个时候我就会开始揣测面试官的意图，试着去回忆他之前提的问题，看看面试官到底想听什么样的回答，往往这种尝试都是失败的，结果就是不知道从何说起，因为没有具体的情景，最后只能说“整个渲染流程中很多地方都可能出现瓶颈，只能case by case的去查看，找到项目的具体瓶颈，然后针对性的去解决，”几乎所有听到这个问题回答的面试官都会对我意味深长地一小，不置可否，一旦看到这种消融，我就知道糟了，之后的面试反馈中，很多人对我评价就是“对渲染算法比较熟悉，但是在优化方面经验欠缺”。 总得来说我觉得这不是一个好问题，因为太过宽泛而没有针对性。我并不想泛泛地说：“减少模型数量，减少/合并draw call，缩减贴图尺寸，压缩贴图，使用LOD”，因为这就是所谓“正确但无用的话”，所有游戏不都是这么优化的吗？此外，对于一个项目来讲，模型的面数，贴图尺寸，LOD的级别这些信息往往是在DEMO阶段就已经由TA主导确定的。对于引擎程序员来讲，需要你提出优化方案的，通常是在项目的开发过程中产生的新瓶颈（当然你首先需要定位它）。但反过来，我的回答其实也是废话，所有性能优化流程不都是这样吗？所以，当我们谈论性能优化的时候，我们究竟在谈些什么呢？ 我试着理解了这个问题的意图，如果我们换一种问法，比如“渲染常见的性能瓶颈有哪些？具体可能出现在什么样的情境下？为什么这些情景会造成对应的性能瓶颈？”会不会是一个更好的问题？所以这篇文章，是在试着回答这个新问题。不同于以往的文章，优化本身确实是一个比较宽泛的主题，所以本文的组织也比较松散，很多内容可能是我想到哪里就写到哪里。其中有些概念基于我对硬件的理解，如有错误之处，欢迎指正。 说说GPU架构核弹厂有一篇关于自己GPU架构和逻辑管线的非常好的文章[1]，如果你想要对GPU的结构有一个完整系统的认识，请一定不要错过。比较可惜的是，这边文章只更新到Maxwell这代架构，没有较新的Pascal架构（GTX10x0系列）和Turing架构（RTX20x0）的技术细节，不过总体来说，现代GPU的设计架构已经趋于稳定，一般只是针对某些单元做优化，或者增加feature，所以文章中的大部分内容仍然是有效的，这是文中的一张图：这张图是基于数据的流向，对GPU的硬件单元进行了大致的划分，实际上GPU中，最核心的部分可以被分为三大块，我画了图中示意他们大致的协作模式：通常来说，GPU会有三个比较重要的部分，分别是控制模块，计算模块（图中GPC）和输出模块（图中的FBP）。通常来说，GPU架构的设计需要有课伸缩性，这样通过增加/阉割计算和输出模块，就能产生性能不同的同架构产品（比如GTX1070和GTX1080的主要区别就是GPC和FBP的数量），以满足不同消费水平和应用场景的需求。 控制模块控制模块负责接收和验证（主要是Host和Front End）来自CPU的经过打包的PushBuffer（经过Driver翻译的Command Buffer），然后读取顶点索引（注意是Vertex Indices不是Vertex Attributes，主要是由Primitive Distributor负责）分发到下游管线或者读取Compute Grid的信息（主要由CWD负责，这部分是Compute Pipeline，不做展开）并向下游分发给CTA。 Tips：计算管线和图形管线共享大部分的芯片单元，只在分发控制的单元上各自独享（PD和CWD）。许多较新的Desktop GPU允许图形和计算管线并行执行，可以在一些SM压力轻的图形计算环节（比如Shadow Map绘制），利用Compute Shader去做一些SM压力重的工作（比如后处理），让各个硬件单元的负载更加平衡。 什么情景会造成性能瓶颈？Shader的优化减少分支我们已经解释过GPU是如何实现分支的， 用贴图缓存中间计算结果？很多时候，我们会把一些数学上的中间计算缓存到一张贴图里，这些贴图的数值本身不代表视觉信息，而是纯粹的数学。比如Marschner Hair Mode用LUT去存BRDF；UE4用LUT去存储PBR的环境光BRDF。]]></content>
  </entry>
  <entry>
    <title><![CDATA[移动GPU架构浅析]]></title>
    <url>%2F2019%2F09%2F04%2FMobile-GPU-Architecture%2F</url>
    <content type="text"><![CDATA[移动GPU相对桌面GPU只能算小弟弟，移动GPU的劣势主要表现在理论性能和带框。移动GPU受限于芯片面积，能耗以及成本所以必须牺牲部分性能和带宽来求得性价比和电池续航的平衡。与桌面GPU动辄256bit甚至512bit的带宽、1.2-1.5GHz的高频显存相比，移动GPU不仅要和CPU共享内存带宽，而且普遍使用的是双32bit位宽、LPDDR2-800或1066左右的内存系统，总带宽普遍在10GB/s以内。 在上图中移动处理器中内存带宽最高的是iPad 3/4，因为他们使用Retina屏幕，2048x1536的高分辨率对GPU带宽要求更高，不过就算是这两款产品，17GB/s的带宽与PC显卡动辄200GB/s以上的带宽相比还是小儿科，没有带宽就没有大容量纹理数据，也就不会有高画质。尽管带宽不是制约移动GPU发展的唯一因素，但是在目前的限制下，移动GPU厂商关心的头等大事就是如何尽可能小的带宽需求下提升GPU性能及画质，纹理压缩是一个方法，还有一种就是使用不通的渲染架构。目前在GPU领域主要有IMR、TBR及TBDR等三种主流架构。 移动GPU的模型IMR模式 IMR（Immediate Mode Rendering）就如字面意思一样，提交的每个渲染命令都会立即执行，并且该渲染命令会在整条流水线中执行完毕后才开始执行下一个渲染命令。 这种模式的优点： GPU架构比TBR模式简单直接。 在一帧里面执行FBO操作时，不会因为需要清空缓冲的渲染指令而影响性能。 不用像TBR架构一样需要片上高速缓存来保存中间结果。 不用像TBR架构一样缓存Triangle List，因此在有大量顶点运算的场景时比TBR有优势。例如PC上面的复杂模型可能有几百万个triangle。 这种模式的缺点就是： IMR的渲染会存在浪费带宽的情况。例如，当两次渲染有前后遮蔽关系时，IMR模式因为两次draw命令都要执行，因此会存在经过Pixel Shader后的Pixel被Depth test抛弃，这样就浪费了Shader Unit运算能力。不过幸运的是，目前几乎所有的IMR架构的GPU都会提供Early Z的判断方式，一般是在Rasterizer里面对图形的遮蔽关系进行判断，如果需要渲染的图形被遮挡住，那么就直接抛弃该图形而不需要执行Pixel Shader。 IMR的另外一个缺点就是其渲染命令在执行需要随时读写frame buffer，depth buffer和stencil buffer，这带来大量的内存带宽消耗，在移动平台上面访问片外内存是最消耗电量和最耗时的操作。 因此在桌面GPU灵越，TBR节省带宽和低性能不符合PC机的要求，IMR一统江湖。但是在移动GPU领域，TBR的低带宽消耗，低功耗正好满足移动设备需求，与其在PC端的待遇相反，移动设备领域TBR几乎一统江湖。IMR模式的代表是NVIDIA的Tegra和Vivante的GC系列芯片。在此列出Vivante GC芯片的内部架构图，我们可以看到Vivante的GPU架构相当简单。 TBR模式 与IMR简单粗暴的做法不通，TBR（Tile Based Rendering）它将需要渲染的画面分成一个个的矩形区块（tile）,tile一般是4x4或者8x8的矩形块。模型的顶点金经过过Vertex Shader运算以后会组装成一个个的triangle，这些triangle会被缓冲在一个triangle cache里面。如果某个triangle需要在某个tile里面绘制，那么就会在该tile的triangle list中存在一个索引。等一帧里面所有的渲染命令都经过执行完Vertex Shader生成triangle以后，每个tile就会有一个triangle list，这list就包含了需要在该tile内部绘制的所有triangle。然后GPU在基于triangle list执行每个tile的raster和Per-fragment operation。 TBR的优点是执行raster和Per-fragment operation时不需要反复的访问frame buffer，depth buffer，stencil buffer。这是因为GPU可能把整个tile的frame buffer/depth buffer/stencil buffer保存在一个片上的高速缓冲中，这样GPU就直接访问tile，而不需要访问外部内存。这大大减少了内存的带宽消耗，也意味着能耗的降低。 TBR的缺点是需要保存Vertex Shader执行后的结构以及每个tile的triangle list。这意味着如果场景里面有很多的顶点，那么片上缓存就不可能存下这么多顶点信息和triangle list，就不能不依靠外部内存来存储，就会有额外的带宽消耗。不过庆幸的是当前的移动3D绘制都会不会有太多的triangle的场景。一个复杂的模型也就是1万多个triangle，因此一个通常的场景大概就是几十万triangle。随着移动游戏越来越复杂精美，模型的复杂程度也会快速上升，这也是TBR架构在未来将会面临的一大挑战。 如果在一帧里面有两遍及其以上的渲染，那么就需要使用Frame buffer object 来缓存中间结果，这对TBR又是一大性能损耗。根据我们前面的讲解，TBR需要缓冲一帧所有的图元，所有图元执行完毕后才开始raster和Per-fragment operation。在这种情况下，一旦后面的draw命令需要使用前面渲染生成的结果，那么就不得不在该命令前执行，要求GPU把缓存的所有draw命令都执行完毕，然后放弃当前缓存内容。在极端情况下，例如每次draw都需要读取前一次draw渲染的结果，那么TBR就会直接退化成IMR模式。 基于以上的缺点，我们可以看出在桌面GPU领域TBR没有任何优势，因此其完全退出桌面GPU市场。但是在移动GPU市场它更适应性能/带宽/能耗三者的平衡。 TBR的代表有ARM的Mali和高通的Adreno。下图是Mali的架构图： TBDR模式 TBDR（Tile Based Deferred Rendering，贴图延迟渲染）算是TBR的近亲，它跟TBR原理相似，但是通过HSR（Hidden Surface Removal，隐藏面消除）操作，在执行Pixel Shader之前进一步减少了不需要渲染的fragment，降低了带宽需求。在执行Pixel Shader之前，对Raster生成的每个像素都做depth test比较，剔除被遮挡的像素，这就是HSR的原理。理论上经过HSR剔除以后，使得TBDR每帧需要渲染的像素上限就是屏幕像素的数量（没有考虑alpha blend的情况下）。而传统的TBR在执行复杂一点的游戏时可能需要渲染6倍于屏幕的像素。 TBDR是PowerVR的王牌，因为TBR的HSR带来的带宽和运算开销的降低，使得苹果手机的续航能力让人惊叹。下图是PowerVR的SGX系列的GPU架构图，可以看到其复杂程度大大超过Vivante这类IMR的架构。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Life of a triangle - NVIDIA's logical pipeline]]></title>
    <url>%2F2019%2F09%2F03%2FLife-of-a-triangle%2F</url>
    <content type="text"><![CDATA[Since the release of the ground breaking Fermi architecture almost 5 years have gone by. it might be time to refresh the principle graphics architecture beneath it.]]></content>
  </entry>
  <entry>
    <title><![CDATA[浅谈CPU三级缓存和缓冲命中率]]></title>
    <url>%2F2019%2F09%2F03%2FCPU-Buffer-hit-ratio%2F</url>
    <content type="text"><![CDATA[CPU缓冲（Cache Memory）是位于CPU与内存之间的临时存储器，它的容量比内存小的多但是交换速度却比内存快得多。缓存的出现主要是为了解决CPU运算速度与内存读写速度不匹配的矛盾，因为CPU运算速度要比内存读写速度快很多，这样会使CPU花费很长时间数据到来或数据写入内存。在缓存中的数据是内存的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。由此可见，在CPU中加入缓冲是一种高效的解决方案，这样整个内存存储器（缓存+内存）就变成了既有缓存的高速度，又有内存的大容量的存储系统了。缓存对CPU的性能影响很大，主要是因为CPU的数据交换顺序和CPU与缓存间的带宽引起的。 缓存的工作原理是当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并送给CPU处理；如果没有找到，就用相对慢的速度内存中读取并送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。正是这样的读取机制使CPU读取缓冲缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在缓存中，大约10%需要从内存读取。]]></content>
  </entry>
  <entry>
    <title><![CDATA[显存]]></title>
    <url>%2F2019%2F09%2F03%2FVideo-Memory%2F</url>
    <content type="text"><![CDATA[显存全称显示存储器，]]></content>
  </entry>
  <entry>
    <title><![CDATA[MatCap]]></title>
    <url>%2F2019%2F09%2F03%2FMatCap%2F</url>
    <content type="text"><![CDATA[DescriptionMatCap (Material Capture) shader,for displaying objects with reflective materials with uniform surface coloring,like Zbrush or Mudbox can.It uses an image of a sphere as a view-space environment map.It’s very cheap,and looks great when the camera doesn’t rotate.用于均一表面反射材质的着色器，在Zbrush/Mudbox等软件中被广泛运用。它借助一幅含有球面的图片作为视线空间的环境映射，计算成本非常低廉，当相机不转动时视觉效果极其出色。 UsageUse a regular normal map for your object, and a render or a photo of a sphere for the MatCap.Matcap的原理并不复杂，就是使用一张中间为球面的图片作为不同法线方向的光照颜色，然后将这些颜色根据模型的法线信息渲染到相应的位置。 例如下图图二（黑白）中，球形就是Matcap贴图，箭头代表了右下朝向的法线，车与人模型发现朝向此相同方向时，就会渲染为球形贴图上相应点的颜色——白色。 ShaderLab-MatCap.shader12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455Shader "MatCap Bumped"&#123; Properties &#123; _Color ("Main Color", Color)=(0.5,0.5,0.5,1) _BumpMap("BumpMap (RGB)",2D)="bump"&#123;&#125; _MatCap("MatCap (RGB)",2D)="white"&#123;&#125; &#125; SUbShader&#123; Tags &#123;"RenderType"="Queue"&#125; Fog &#123;Color [_AddFog]&#125; Pass &#123; Name "BASE" Tags &#123;"LightMode"="Always"&#125; CGPROGRAM #pragma exclude_renderers xbox360 #pragma vertex vert #pragma fragment frag #pragma fragmentoption ARB_fog_exp2 #pragma fragmentoption ARB_precision_hint_fastes #include "UnityCG.cginc" struct v2f&#123; float4 pos : SV_POSITION; float2 vu : TEXCOORD0; float3 TtoV0 : TEXCOODR1; float3 TtoV1 : TEXCOORD2; &#125;; uniform float4 _BumpMap_ST; v2f vert(appdata_tan v)&#123; v2f o; o.pos = mul(UNITY_MATRIX_MVP,v.vertex); o.uv = TRANSFORM_TEX(v.texcoord,_BumpMap); TANGENT_SPACE_ROTATION o.TtoV0 = mul(rotation,UNITY_MATRIX_IT_MV[0].xyz); o.TtoV1 = mul(rotation,UNITY_MATRIX_IT_MV[1].xyz); return o; &#125; uniform float4 _Color; uniform sampler2D _BumpMap; uniform sampler2D _MatCap; float4 frag (v2f i) : Color &#123; float3 normal = UnpackNormal(tex2D(_BumpMap,i.uv); half2 vn; vn.x = dot(i.TtoV0,normal); vn.y = dot(i.TtoV1,normal); float4 matcapLookup = tex2D(_MatCap,vn*0.5+0.5); matcapLookup.a = 1; return _Color*mapcapLookup*2; &#125; ENDCG &#125; &#125;&#125;]]></content>
      <categories>
        <category>Unity Community Wiki</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Matcap Shader]]></title>
    <url>%2F2019%2F09%2F03%2FMatcap-Shader%2F</url>
    <content type="text"><![CDATA[简介Matcap Shader是一种在某些层面能替代甚至超越PBR的次时代渲染方案。它的效率极高、计算成本极低，显示效果极佳，却能完美运行于不通的移动平台，并兼容AR、VR设备。但Matcap也有很多局限性和缺点，此系列文章就是用于讲解Matcap的实现方法针对其问题的优化。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Finite State Machine]]></title>
    <url>%2F2019%2F09%2F03%2FFinite-State-Machine%2F</url>
    <content type="text"><![CDATA[DescriptionThis is Deterministic Finite State Machine framework based on chapter 3.1 of Game Programming Gems 1 by Eric Dybsend. There are two classes and two enums.Include them in your project and follow the explanations to get the FSM working properly.There’s also a complete example script at the end of this page. Components Transition enum:This enum contains the labels to the transition that can be fired by the system.Don’t change the first label,NullTransition,as the FSMSystem class uses it. StateID enum:This is the ID of the states the game may have.You could use references to the real State’s classes but using enums makes the system less susceptible to have code having access to objects it is not supposed to.All the state’s ids should be placed here.Don’t change the first label,NullStateID,as the FSMSystem class uses it.]]></content>
  </entry>
  <entry>
    <title><![CDATA[腾讯游戏开发精粹]]></title>
    <url>%2F2019%2F09%2F02%2FTencent-Game-Development-Gem%2F</url>
    <content type="text"><![CDATA[基于SDF的摇杆移动在当前MOBA手游中，移动方式大多采用摇杆移动，摇杆移动首先要解决的问题是与障碍物的碰撞检测，以及发生碰撞后如何行走（碰撞后直接停止的体验非常糟糕）。根据地图数据的不通，摇杆移动的碰撞检测方式有多重。 物理碰撞方式：直接使用点（或圆）与多边形进行碰撞检测，然后绕多边形的边移动。 NavMesh方式：同样需要做点（或圆）与多边形碰撞检测，然后绕多边形的边移动。 栅格方式：检测点是否在阻挡栅格内，或者圆与阻挡栅格的距离，碰撞后移动方向不好确定。 这里提供一种更为高效的且更为方便地解决其他移动相关需求的方案，即：基于SDF的摇杆移动。SDF（Signed Distance Field）即有号距离场，表示空间中点到形状表面的最短距离，一般用正值表示形状外部，用负值表示形状内部。用数学公式表示，首先定义$\phi:R^n&gt;R$对于一个形状点集S，有检测某点x是否在形状（障碍物）之内表示为：$/phi(x)\le 0$，如果预先知道每个店的有号距离$\phi(x)$，那么碰撞检测只需要一次查表即可。因为SDF数据的生成较为耗时，因此需要预计算生成。顶视角MOBA游戏只需要做二维SDF计算，为减少数据存储量，先栅格化地图，通过点到多边形（障碍物）的距离离线计算栅格顶点的有号距离，从而生成SDF数据。运行时使用双线性过滤采样可以获得地图任意点的有号距离值，与角色碰撞半径比较判断是否和障碍物发生碰撞，检测过程只需查表和进行插值乘法计算，时间复杂度为O(1)。 SDF的梯度方向代表最大的变化方向，因此可以将梯度算子作为边界法线，当角色与障碍物发生碰撞后可沿着法线垂直方向滑行，同样可以根据梯度方向快速迭代来处理在MOBA游戏中击飞后”卡”在障碍物中的问题。对于瞬间位移（比如闪现）且不能穿越障碍物的需求，可以采用圆盘投射，以有号距离作为迭代补偿。对于AI寻路，SDF也可以通过修改探索函数（判断有号距离与碰撞半径的大小）来实现，且可以修改碰撞半径搜索贴近或远离障碍物的路径，打破寻路对称性。 前面讲到呃SDF是离线预生成的，那么对于MOBA游戏中动态障碍物的处理，可以使用程序式SDF和CSG运算来实现。不过，SDF在提高效率的同时也存在着存储空间大、较难动态更新（地形发生大的变化）的问题。 利用栅格数据预计算SDFSDF 记录的是点到障碍物的距离，核心思想即空间换时间；如果动态计算点x的有号距离$\phi(x)$，那么复杂度跟物理碰撞检测的方案没什么区别。因此，我们需要预计算得到整张地图的SDF数据，因为不可能存储地图上所有的点，需要根据障碍精度对地图进行栅格化，比如主流MOBA游戏的5v5地图可以使用256x256栅格。首先介绍一种基于栅格的SDF预计算方法。根据场景障碍生成如图1.2所示的栅格地图，灰色表示阻挡，白色表示可行走区域。使用Meijster算法计算栅格中任意各自$(x,y)$到栅格阻挡区中最近各自的距离：图1.2 栅格地图]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redirecting Functions in Shared ELF Libraries]]></title>
    <url>%2F2019%2F09%2F02%2Felf-hook%2F</url>
    <content type="text"><![CDATA[This article includes brief description of ELF structure and principles of its usage.It is used to provide the solution for intercepting function calls from one library into another one. The problemWe all use Dynamic Link Libraries(DLL).They provide excellent possibilities.First,such library loads into the physical address space only once for all processes.Secondly,you can expand the functionality of the program by loading the additional library,which will provide this functionality.And that is without restarting the program.Also a problem of updating is solved.It is possible to define the standard interface for the DLL and to influence the functionality and the quality of the basic program by changing the version of the library. Such methods of the code reusability were called “plug-in architecture”. But let’s move on. Of course,not every dynamic link library relies only on itself and the memory.Libraries use libraries or just standard libraries. For example, programs in the C\C++]]></content>
  </entry>
  <entry>
    <title><![CDATA[全局光照技术：从离线到实时渲染]]></title>
    <url>%2F2019%2F08%2F31%2FtheGIbook%2F</url>
    <content type="text"><![CDATA[全局光照全局光照几乎代表了计算机图形学渲染相关的全部内容，它是一个渲染器力求模拟真实物理关于物体代表交互的全部自然现象的全部内容（当然目前计算机图形学研究领域主要限于几何光学，它并不包括更微观的如干涉，衍射等光学现象，参见第1章的介绍）：即光从光源触发，以无限的速度在环境中直线前进，经过与表面发生多次反射和折射，最后进入人的眼睛形成图像。然后由于光照方程是一个沿全空间方向的积分，这使得渲染过程非常耗时，在现有的硬件条件几乎不可能按照原始的光照方程进行图形渲染。不过研究发现，我们并不需要完全按照原始的光照方程进行计算，即可以生成令人信服的图像，在这个级别我们通常称为Realistic Rendering。于是人们寻求简化的光照模型以求能达到这种渲染平直，在原始光照方程的基础之上，人们提出两种简化模型： 基于有限元分解的辐射度理论 有限元分解是一种常见的积分计算方法，它将一个沿无限空间的积分分解为一个有限唯独（称为一个有限元）的积分，在每个纬度，我们只需要求出有限元的均值，并可以很容易地计算出光照积分方程。在每个纬度，我们只需要求出该有限元的均值，并可以很容易地计算出光照积分方程。在辐射度理论中，通常我们通过Monte Carlo等方法预计算出每个有限元的均值，均渲染时光照方程的实时计算。 基于Monte Carlo方法的光线追踪技术 Monte Carlo方法通过随机抽样，使用有限个采样点的值，来计算积分方程的值。 这两种方法均能达到非常高的图像品质，然后它们的计算仍然十分耗时，因此主要用于电影等离线渲染领域（例如皮克斯的渲染产品RenderMan就是基于光线追踪的渲染器）。在游戏等实时渲染领域，人们寻求更简化的渲染模型，与辐射度和光线追踪技术通过简化积分方程的思路不同，实时渲染领域的主意思路是根据光学现象或者其它理论拆分光照方程，使得光照效果最终由多种效果叠加而成，例如Direct lighting（光从光源出发经过物体表面反射或者折射一次后进入如烟），（Soft）shadow，Diffuse lighting，Specular lighting，Indirect lighting，Ambient Occlusion，Subsurface Scattering，Environment lighting，Reflection等等。这些效果可能分别使用不通的方法来计算，例如Shadow可以使用GPU的光栅化特性来计算，Ambient Occlusion可以使用Post processing基于屏幕空间（Screen Space）进行计算，Environment lighting则可以使用简单的贴图实现；另一些算法则使用一些特定的数据格式来加速其中的一些计算，例如Unreal Engine 4通过对整个场景构建一个Distance field的数据结构，通过它来加速遮挡关系的计算从而实现Soft shadow以及Ambient occlusion等效果，其它一些方法则通过使用Spherical Harmonic来存储一些点的近似的“环境函数”，从而能够快速地计算各个间接反射的效果。 光与表面的交互计算机图形学（computer graphics）然而，要达到逼真的视觉效果，尤其在实时的环境下，这个渲染的过程异常复杂。从技术上讲，这里有两个突出的困难需要解决：首先，对于表面上的每个点，我们必须在该点法线方向对应的半空间（hemisphere）上做积分运算以便求出该点的颜色值，因为每个点都可能接受来自场景中所有其他点反射的光照；其次，对于空间中传播的每一条光线（） 辐射度量学光学中关于光的测量这一分支，称为辐射度量学（radiometry）。[Kajiya,1986]首次将辐射度量学引入到计算机图形学忠，用于测量和计算计算机图形学中光的传播，并由此推导出渲染方程（the rendering equation）。渲染方程保留了辐射度量学两个最基本的特性即赫姆霍兹互反律（helmholtz reciprocity）和能量守恒（energy conservation），现代图形学理论基于渲染方程提出了大量的模型用于简化和加速渲染方程的计算，在这两个基本物理特征的保障下，这些模型能够达到非常真实的图形品质。 辐射度量学定义了一组基本的物理量用来测量光辐射，因此这些度量也称为计算机图形学中最重要的基本概念，这几个度量的名称及单位如表1.1所示。 表1.1：辐射度量学中的基本度量，这些度量也称为渲染方程的基本度量 中文名称 英文名称 单位 符号 辐射能量 radiant energy $J$ $Q$ 辐射通量 radiant flux $W$ $\Phi$ 辐射照度 irradiance $W/m^2$ $E$ 辐射强度 radiant intensity $W/sr$ $I$ 辐射亮度 radiant $W/(m^2 \cdot sr)$ $L$ 再开始讨论这些度量之前，必须首先了解立体角（solid angle）的概念，如图1.10所示。图 1.10 立体角的概念，它表示单位球体上一块区域对应的球面部分的面积。根据立体角的定义，如果球面上任意一块区域的面积等于球半径的平方，当从球心观察时，该区域面积就是1sr。 在几何学中，立体角是2D角度的概念在3D空间的延伸，它表示在3D空间，从某个点观察，另外一个物体有多“大”。立体角的数学符号通常用$\Omega$表示，其单位是sr，它是球面度（steradians）的缩写。立体角也可以理解为3D空间中以某一点为起点的多个方向的集合。 正如在2D中，使用单位圆上一段弧线的长度来表示其对应“角度”的大小，在3D中，使用单位球体上一块区域面积的大小来表示其对应的“立体角”的大小。所以一个物体相对于某一点的立体角的大小，等于这个物体投影到以该点为球心的单位球体上的面积。 根据上述立体角的定义，如果球面上任意一块区域的面积等于球半径的平方，当从球心观察时，该区域面积就是1sr。 在球面坐标中，单位球体上任意一块区域A的面积可以简单地表示为：$\Omega = \int\int_Asin\theta d\theta d\phi $ 其中，$\theta$表示经度，$\phi$表示纬度，所以整个球面的立体角为4π，对于一个正方体的面，]]></content>
      <categories>
        <category>theGIbook</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[游戏开发相关实时渲染技术之体积光]]></title>
    <url>%2F2019%2F08%2F28%2FVolume-light%2F</url>
    <content type="text"><![CDATA[散射是一种非常美丽的自然现象，在自然界中光传过潮湿或者含有杂质的介质时产生散射，散射的光线进入人眼，让这些介质看起来像拢住了光线一样，也就是所谓的体积光。在游戏中体积光是很常用的一种光照特效，主要用来表现光线照射到遮蔽物体时，在物体透光部分泄漏出的光柱。由于视觉上给人很强的体积感，所以称之为体积光。体积光特效在现今的中高端游戏中非常常见，优秀的体积光特效在烘托游戏氛围，提高画质感方面发挥了很大的作用。图中清晨透过树林间隙射出的体积光为游戏增色不少作为一种常用特效，体积光的制作方式多种多样，不通游戏对于处理性能，画面要求和渲染质量要求各不相同，也会使用不同的体积光表现方式。早期游戏中由于机能限制经常使用的是BillBoard贴片和径向模糊这两种方式。在这里简单介绍一下两种方式，重头戏还是后面最新的基于光线追踪的方式。 BillBoard贴片BillBoard贴片和容易理解，用PHOTOSHOP生成一个随机的明暗条纹，加上遮罩，让它看起来有光条的感觉。]]></content>
  </entry>
  <entry>
    <title><![CDATA[插值多边形纹理映射和阴影]]></title>
    <url>%2F2019%2F08%2F28%2FInterpolation-for-Polygon-Texture-Mapping-and-Shading%2F</url>
    <content type="text"><![CDATA[摘要提出了一种简单、快速的多边形纹理坐标和阴影参数插值方法。该方法可应用于z-buffer等扫描转换算法和painter算法中，对纹理坐标、颜色、法向量等阴影参数进行屏幕空间插值。以前的一些方法在屏幕空间中执行线性插值，但这是一种可旋转的变体，在纹理映射的情况下，会导致不可靠的“橡胶片”效果。为了正确地计算屏幕空间和参数空间之间的非线性投影变换，我们在多边形上使用有理线性插值，在每个像素上执行多个分割。我们提供了更简单的公式来设置这些插值计算，将每个多边形的设置成本降低到零，并将每个顶点的成本降低到几个除法。 介绍我们首先定义了我们的术语，然后总结了一种简单的线性方法，用于在扫描转换期间插值着色参数。通过对线性插值的缺陷进行分析，描述了该方法，并证明了其正确性。 定义我们定义了以下坐标系:对象空间是三维坐标系，其中定义了每个多边形。可以有多个对象空间。世界空间是一个坐标系统，通过三维建模转换(平移、旋转和缩放)与每个对象空间相关。三维屏幕空间是显示器的三维坐标系统，是一个像素坐标(x,y)和深度z的“透视空间”。相机参数与世界空间有关。最后，二维屏幕空间(简称“屏幕空间”)是没有z的三维屏幕空间的二维子空间。为了方便仿射和射影(透视)变换，我们使用齐次符号[Maxwell46]，例如，二维实点(x,y)由三维齐次向量p = (xw,yw,w)表示，其中w是一个任意的非零数。我们将漫不经心地处理w = 0的情况。在齐次表示法中，二维点用3向量表示，三维点用4向量表示。我们使用下面符号： COORDINATE SYSTEM REAL HOMOGENEOUS 3-D object space $(x_0,y_0,z_0)$ $P_0=(x_0w_0,y_0w_0,z_0w_0,w_0)$ 3-D screen space $(x,y,z)$ $P_\delta=(xw,yw,zw,w)$ 2-D screen space $(x,y)$ $P_s=(xw,yw,w)$ 投影和仿射映射We will use two classes of mapping (transformation): affine and projective.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Graphics rendering pipeline]]></title>
    <url>%2F2019%2F08%2F28%2FGraphics-rendering-pipeline%2F</url>
    <content type="text"><![CDATA[图形渲染管线是实时渲染的核心组件。 三角形遍历(Triangle Traversal)其实三角形遍历的操作我们在前面基本都说过了，通过屏幕空间的坐标组装三角形后，我们遍历这些三角形图元覆盖了哪些片段的采样点，随后得到该图元所对应的片元。]]></content>
      <categories>
        <category>Graphics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[homogeneous coordinates]]></title>
    <url>%2F2019%2F08%2F28%2Fhomogeneous-coordinates%2F</url>
    <content type="text"><![CDATA[齐次坐标就是将一个原本n维的向量用一个n+1维向量来表示，是指一个用于投影几何里的坐标系统。优点：合并矩阵运算中的乘法和加法。实投影平面可以看做是一个具有额外点的欧式平面，这些点称之为无穷远点，并被认为是位于一条新的线上（该线称之为无穷远线）。每一个无穷远点对应至一个方向（由一条线之斜率给出），可非正式地定义为一个点自原点朝该方向移动之极限。在欧式平面里的平行线可看成会在其对应共同方向之无穷远点上相交。给定欧式平面上的一点(x,y)，对任意非零实数Z，三元组(xZ,yZ,Z)即称之为该点的齐次坐标。依据定义，将齐次坐标内的数值乘上同一个非零实数，可得到同一点的另一组齐次坐标。例如，笛卡尔坐标上的(1,2)点在齐次坐标中即可表示成(1,2,1)或(2,4,2)。原来的笛卡尔坐标可通过将前两个数值除以第三个数值取回。因此，与笛卡尔坐标不通，一个点可以无限多个齐次坐标表示法。]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RizomUV]]></title>
    <url>%2F2019%2F07%2F01%2FRizomUV%2F</url>
    <content type="text"><![CDATA[快捷键 说明 Alt+Mouse Left 旋转视图 Alt+Mouse Mid 平移视图 Alt+Mouse Right 缩放视图 F2 线模式 F4 面模式 C 剪切(cut) W 焊接(weld)]]></content>
      <categories>
        <category>RizomUV</category>
      </categories>
      <tags>
        <tag>RizomUV</tag>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maya]]></title>
    <url>%2F2019%2F07%2F01%2Fmaya%2F</url>
    <content type="text"><![CDATA[快捷键 说明 Alt+Mouse Left 旋转视图 Alt+Mouse Mid 平移视图 Alt+Mouse Right 缩放视图]]></content>
      <categories>
        <category>Maya</category>
      </categories>
      <tags>
        <tag>Artist</tag>
        <tag>Maya</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL ES 3.0 顶点属性、顶点数组和缓冲区对象]]></title>
    <url>%2F2019%2F06%2F25%2Fopengles-vertex%2F</url>
    <content type="text"><![CDATA[指定顶点属性数据顶点属性数据可以用一个顶点数组对每个顶点指定，也可以将一个常量值用于一个图元的所有顶点。所有OpenGL ES 3.0实现必须支持最少16个顶点属性。应用程序可以查询特定实现支持的顶点属性的准确数量。下面的代码说明应用程序如何查询OpenGL ES 3.0实现真正支持的顶点属性数量。12GLint maxVertexAttribs; // n will be &gt;= 16glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &amp;maxVertexAttribs); 假定每个顶点有4个顶点属性——位置、发现和两个纹理坐标——这些属性一起保存在为所有顶点分配的一个缓冲区中。顶点位置属性以3个浮点数的向量(x,y,z)的形式指定，顶点发现也以3个浮点数组成的向量的形式指定，每个纹理坐标以两个浮点数组成的向量的形式指定。下图给出了这个缓冲区的内存布局。在这个例子中，缓冲区的跨距为组成顶点的所有属性总大小（一个顶点等于10个浮点数或者40个字节——12个字节用于位置、12字节用于发现，8个字节用于Tex0，8个字节用于Tex1）。下面例子中描述了如何用glVertexAttribPointer指定这4个顶点属性。注意，我们在此介绍如何使用客户端顶点数组，以便解释逐顶点数据指定的概念。我们建议应用程序使用顶点缓冲区对象，避免使用客户端顶点数组，以实现最佳性能。在OpenGL ES 3.0中支持客户端顶点数组只是为了与OpenGL ES 2.0兼容。在OpenGL ES 3.0中，总是建议使用顶点缓冲区对象。结构数组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#define VERTEX_POS_SIZE 3 // x,y, and z#define VERTEX_NORMAL_SIZE 3 // x,y, and z#define VERTEX_TEXCOORD0_SIZE 2 // s and t#define VERTEX_TEXCOORD1_SIZE 2 // s and t#define VERTEX_POS_INDX 0#define VERTEX_NORMAL_INDX 1#define VERTEX_TEXCOORD0_INDX 2#define VERTEX_TEXCOORD1_INDX 3// the following 4 defines are used to determine the locations// of various attributes if vertex data are stoored as an array// of structures#define VERTEX_POS_OFFFSET 0#define VERTEX_NORMAL_OFFSET 3#define VERTEX_TEXCOORD0_OFFSET 6#define VERTEX_TEXCOORD1_OFFSET 8#define VERTEX_ATTRIB_SIZE (VERTEX_POS_SIZE + \ VERTEX_NORMAL_SIZE + \ VERTEX_TEXCOORD0_SIZE + \ VERTEX_TEXCOORD1_SIZE)float *p = (float*)malloc(numVertices * VERTEX_ATTRIB_SIZE * sizeof(float));// position is vertex attribute 0glVertexAttribPointer(VERTEX_POS_INDX, VERTEX_POS_SIZE, GL_FLOAT, GL_FALSE, VERTEX_ATTRIB_SIZE * sizeof(float), p);// normal is vertex attribute 1glVertexAttribPointer(VERTEX_NORMAL_INDX, VERTEX_NORMAL_SIZE, GL_FLOAT, GL_FALSE, VERTEX_ATTRIB_SIZE * sizeof(float), (p + VERTEX_NORMAL_OFFSET));// texture coordinate 0 is vertex attribute 2glVertexAttribPointer(VERTEX_TEXCOORD0_INDX, VERTEX_TEXCOORD0_SIZE, GL_FLOAT, GL_FALSE, VERTEX_ATTRIB_SIZE * sizeof(float), (p + VERTEX_TEXCOORD0_OFFSET));// texture coordinate 1 is vertex attribute 3glVertexAttribPointer(VERTEX_TEXCOORD1_INDX, VERTEX_TEXCOORD1_SIZE, GL_FLOAT, GL_FALSE, VERTEX_ATTRIB_SIZE * sizeof(float), (p + VERTEX_TEXCOORD1_OFFSET));]]></content>
      <categories>
        <category>OpenGL ES 3.0</category>
      </categories>
      <tags>
        <tag>OpenGL ES 3.0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XCode操作指南]]></title>
    <url>%2F2019%2F06%2F24%2Fxcode%2F</url>
    <content type="text"><![CDATA[快捷键 释义 Windows键+鼠标右键 转定义 Windows键+Ctrl+-&gt; 前进 Windows键+Ctrl+&lt;- 后退 Windows将+Shift+o 快速打开函数]]></content>
      <categories>
        <category>XCode</category>
      </categories>
      <tags>
        <tag>XCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重心坐标系]]></title>
    <url>%2F2019%2F06%2F20%2Fbarycentric-coordinate%2F</url>
    <content type="text"></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝塞尔曲线]]></title>
    <url>%2F2019%2F06%2F20%2Fbezier-curve%2F</url>
    <content type="text"><![CDATA[二阶贝塞尔曲线在平面内选3个不同线的点并且依次用线段连接。在AB和BC线段上找出点D和点E，使得AD/AB=BE/BC连接DE，在DE上寻找点F，F点需要满足：DF/DE=AD/AB=BE/BC根据DE线段和计算公式找出所有的F点，然后将这些点连起来。$B(t)=(1-t)^2P_0+2t(1-t)P_1+t^2P_2,t\in[0,1]$ 三阶贝塞尔与N阶贝塞尔曲线在平面内选4个不同线的点并且依次用线段连接。在线段上找对应的点(E,F,G)，对应的点符合AE/AB=BF/BC=CG/CD；找到对应的点以后接着连接EF,FG；接着在EF、FG线段上继续找点H、I，对应的点依旧符合等比计算规则，也就是EH/EF=FI/FG；最后连接H、I线段，在HI线段上继续找J，点J符合：EH/EF=FI/FG=HJ/HI重复步骤二的动作，找到所有的J点，依次将J点连接起来$B(t)=(1-t)^3P_0+3t(1-t)^2P_1+3t^2(1-t)P_2+t^3P_3,t\in[0,1]$12345678template&lt;class T&gt;inline void EvaluateCache (const typename AnimationCurveTpl&lt;T&gt;::Cache&amp; cache, float curveT, T&amp; output)&#123;// DebugAssertIf (curveT &lt; cache.time - kCurveTimeEpsilon || curveT &gt; cache.timeEnd + kCurveTimeEpsilon); float t = curveT - cache.time; output = (t * (t * (t * cache.coeff[0] + cache.coeff[1]) + cache.coeff[2])) + cache.coeff[3]; DebugAssertIf (!IsFinite(output));&#125; Unity中的AnimationCurve正是使用的3阶贝塞尔曲线。四阶贝塞尔如下：一阶贝塞尔(线性插值)：$B(t)=P_0+(P_1-P_0)t=(1-t)P_0+tP_1,t\in[0,1]$]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[美术-投影]]></title>
    <url>%2F2019%2F06%2F20%2Fprojection%2F</url>
    <content type="text"><![CDATA[这是美剧《权力的游戏》剧照，多么迷人的投影～可是同样的圆桌会议，如果不好好运用投影，可能就会整成下面这样所以大家都感受到投影的力量了，那么投影要如何画呢？ 我们从四个方面来探讨： 1.投影的轮廓 2.投影的深浅 3.投影的形状 4.投影的色彩 投影的轮廓下面是我自己在家里拍的静物照片可以看出不同的照片里，瓶子投影的虚实程度不同，而即使在同一张照片中，投影轮廓的虚实程度也并非是同样清晰的，而是有虚实变化，有的地方清晰，有的地方模糊，可别小瞧了这个属性，虚实变化是让画面具有韵律感节奏感的重要表现手法之一。那么什么情况下投影轮廓该虚，什么情况下该实呢？为了说明其物理光学原理，我制作了下面这张图：如图所示，投影边缘的虚实与投影的虚化范围有关，虚化范围越大，投影轮廓越模糊，虚化范围越小，投影轮廓越清晰。从光路图可以看出，投影的虚实与三个因素相关：1.光源与投影物体之间的距离（距离越近投影越虚） 2.光源的实际大小（光源越大投影越虚） 3.投影物体与投影面之间的距离（距离越远投影越虚） 综合这三点来判断投影虚实变化，来看一个例子：上图是我画的《叶天眉》的局部（左图），这里我设定的是一个阴天的天气，所以投影的边缘轮廓不是像艳阳天一样清晰，这也更容易让我画出轮廓虚实变化。注意鼻子的投影，左侧越远轮廓就越模糊，靠近鼻底的地方投影轮廓较清晰，而再观察仔细一些会发现，人中的起伏也造成了投影的虚实变化，突起的地方距离鼻子较近，投影较清晰，人中中间凹陷的地方距离鼻子较远，投影较模糊。右图是个反面例子，假如投影边缘都画得一样清晰就显得比较生硬了。 值得一提的是，现实生活中常常是看不到这么明显的虚实变化的，特别像五官这种较小的物体的投影的虚实变化一般很难观察出来，往往需要进行人为夸张才能达到好看的效果，这也是来源于生活而高于生活的绘画表达手法。 道理容易理解，可是在画的时候要同时判断三个因素的综合效果其实容易让人犯晕，尤其是光源的大小，有的光源实际大小很大，但距离比较远，综合之下如何判断其投影的清晰度呢？这里我想表达的观点是，我们绘画不是照相，不需要完全让你的大脑如同计算机一样精准判断出投影的虚实程度，我们要画的是对比、是变化，我们需要做的是判断画面中同时出现的两种光源产生的投影，哪个更虚哪个更实。如此一来就容易多了╰(°▽°)╯ 因此我们可以把第一条“光源与投影物体之间的距离”与第二条“光源的实际大小”融合成一条：“光源的相对大小”。在上一篇《关于“暗部”》中提到过，太阳实际很大，但它离我们很远，而假设投影物体旁边有另一个墙面大小的光源，它实际比太阳小很多，但它离我们很近。那么这两个光源的相对大小如何判定? 判断的方法其实很简单：你假想你站在投影物体的位置去看光源，是太阳看起来更大呢？还是身边的墙面看起来更大呢？当然是墙面更大，所以墙面是大光源，太阳是小光源，通过墙面反射的光产生的投影会比太阳光的投影更模糊。 这个原理在画暗部反光的二次投影时常常用到，可以用它来制造出丰富多变又合情合理的投影对比关系，如图：这个光影模型在实际运用中，暗部的小球往往会以头发、突起的肩胛等形式出现，他们遮挡了墙面的反光，形成了二次投影，这种相对大光源的投影边缘轮廓较为柔软，与亮部阳光的清晰投影形成对比。我们画画就是要营造和夸张对比，让画面形成韵律节奏，这是此种审美逻辑在投影中的运用。 看一个例子:同样是《权力的游戏》剧照，小恶魔脚下的投影是阳光的投影，来源于“小光源”太阳，轮廓清晰，他暗部的左手对于盔甲有一个轮廓模糊的投影，这个投影是来源于地面这个“大光源”的反射光。 投影的深浅投影的深浅跟环境光的强弱和性质有关，如果投影附近有反射物，会将直射光反射进投影区域从而影响投影的亮度深浅，这需要依据具体情况分析，但通常情况下，投影所处的区域越开阔，投影越浅，因为足够的距离让环境光有更多的机会投射进投影区域，而投影面所处的区域越闭塞，投影越深，甚至可以形成很深投影区，我们把这称为光的死角，例如下图中的接近瓶底的投影区域。我们对于极深的颜色的运用要惜墨如金，极深的颜色往往可以用来作为画面素描调子的点缀，不适合大面积出现，因此这种极端区域通常是以点或者线的形式出现，面积很小，但作用很大。如图：看一个例子：《叹息之刃》局部，我在画她鼻子投影的时候，最深的地方点缀在了鼻翼轮廓的边缘，这是一个相对闭塞的区域，可以用来藏一些较深的颜色。 投影的形状 如何把投影画得好看？投影的形状是最需要发挥主观意识的部分了，也就是按照审美需求有意识地布局投影的形状和位置。 这就涉及到一个问题，什么样的投影是符合审美需求的？人喜欢看什么样的投影呢? 答案是：切割与节奏 当影子投射到物体上时，投影轮廓对物体进行切割，切割产生美感，因为同一个物体会因为投影而获得两种不同的光源环境区域，从而使其获得了逻辑统一而形式多样化的光影信息。 看一个例子：​同样是《权力的游戏》里的小恶魔（投影让你如此美丽&lt;(▰˘◡˘▰)&gt; ） 按照图中从左上方来的光，头部应该是能够被照亮的，然而并没有，导演设置了一个遮挡物让头部处于投影里，于是形成了这么迷人的光影效果：肩部受左上方来的直射光影响，而头部受左下方来的反光影响，这两个区域的主光源方向不同。 注意：切割头部与脖子之间的投影轮廓十分模糊，结合前面的知识点，这应该是一个较远物体的投影，投影面离投影物体越远，投影轮廓越模糊。这也暗示了这间屋子是一个宽敞的大厅。 再看一个例子：小恶魔下半身隐没在投影里，光影切割美得很魔性(￣∇￣) 其实投影的切割不仅仅适用于人物，对于场景来说，投影的切割同样具有迷之魅力。看下图！巨大的投影将近处的场景笼罩在暗部，中景被光影切割，很好的起到了视觉引导作用，画面有一种戏剧性的美感。 再看一个例子：我的作品《水瓶座》，就是运用的投影切割原理，人体的上下半身分别处于不同的光影环境中。投影切割的方式有很多种，产生的视觉效果也不同，大家有兴趣可以多尝试。 所以投影是可以根据你的画面需要进行布局的，特别是对于来自画面外部景物的投影，几乎可以随心所欲安排。我曾经在一次讲座上开玩笑提出一个“板砖理论”：凭什么他身上会有这样一块投影？因为在画面外我没有画出来的地方，悬挂了一块“板砖”：）你是画中世界的造物主，你说了算╮(╯▽╰)╭ 再来看一下投影的节奏： 常常我们的投影并不是一整块，可以是大小不同的穿插，人眼是十分迷恋这种光影斑驳的效果的，如下图：穿插虽美，但散乱无序的切割会让画面显得花和乱，这就需要依据审美需求对其布局，看一个类似效果的运用：这是我的作品《平行三界》局部。注意头发对脸部的投影，投影的切割主要集中在额头部分，脸部是相对完整的块面，细碎的小块面与完整的大块面形成了节奏对比。这与前面那张树影的照片是否有异曲同工之美呢？ 小块面投影的切割是种细节的点缀，能够起到丰富画面的效果，只要注意了大小分布的疏密搭配，常常能让画面效果锦上添花。 我们刚才探讨了很多关于投影形状的运用，但不要忘记了投影形状的光学逻辑合理性，特别是对于出现在画面中的物体的投影，要分析出它应有的投影形状，这需要联系和经验的积累，来讲一个我常常在学生作业里发现的问题类型：依然拿我的作品《平行三界》局部做例子。很多同学喜欢给脸部边缘打一个轮廓光，用来强调面部轮廓，这是打光技巧中的一种，这很好，但是实际运用上要注意光影逻辑关系，比如上面左图，脸部下方的轮廓光十分好看，但是由于没有考虑到头发对这束光的影响，让下颚的亮部显得有点奇怪，右图将头发的投影表现上去就自然多了。因此要充分考虑画面中存在的物体对于彼此的投影关系。 投影的色彩投影也是属于暗部区域的组成部分，会受到各种环境光的影响，例如朝上的投影面可能会受到冷色天光的影响而呈现偏冷的颜色，具体可以参考上一篇《关于“暗部”》的色彩部分，这里主要想探讨的是投影边缘的色彩分布。 我们常常看到很多美术作品的投影边缘会出现一圈高饱和度的色彩，有时是橙色，有时是黄绿色，有时甚至出现紫色的轮廓，还有些情况投影轮廓是不存在明显色彩的，其实关于色彩的理论十分复杂，尤其是微妙色彩变化，它受很多因素影响，固有色、环境色、光源色、材质透光度等等，其原理涉及到光的衍射、散射、折射等，所以关于投影轮廓的颜色如果要用物理逻辑十分精准地推算出来是很困难的，为了写这一部分的内容我查阅了很多资料，甚至咨询了北大物理系的朋友，其实光学原理的逻辑很简单，但难就难在具体情况的复杂性。 有一种理论说是光谱的色彩连续性形成了投影轮廓的颜色：如果投影偏蓝，亮部偏黄，那么蓝色与黄色之间的连接色会是色环左边的紫红橙色区域还是右边的黄绿色区域呢？那么到底应该取黄绿还是紫红呢？看下面一张图：​投影轮廓边缘确实存特殊的色彩，神奇的是，同一张图同一个环境下，有的投影轮廓是橙红紫色系，有的投影轮廓竟然是黄绿色系(/= _ =)/~┴┴ 再看一张图：​中景墙壁上的两条投影，左边的投影有明显的紫红色边缘，右边投影没有明显的色彩轮廓边。。。（这个现象我曾用肉眼观察到）这些现象奇特又令人迷惑，因此这里我并不能给出大家绝对的答案，虽然我们画画并非要与客观事物完全一致，但我还是希望了解其中逻辑原理，如果大家有什么好的见解也可以在这片篇贴子下面讨论。 虽然关于投影边缘的色彩问题我们作为一个开放命题供大家探讨，但有一种情况是需要注意的，那就是在人体上的投影。人体皮肤是一个半透明组织，下面充满了毛细血管，流动着鲜红的血液，当光穿透皮肤表层再反射回来时，会被皮下组织反射出偏红的色彩，因此在皮肤上的投影要考虑到皮肤透光这个重要因素，常常皮肤上的投影都是具有暖色轮廓的（特别是当强光照射时）。]]></content>
      <categories>
        <category>Artist</category>
      </categories>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[暗部]]></title>
    <url>%2F2019%2F06%2F20%2Fshade%2F</url>
    <content type="text"><![CDATA[暗部的画法对于很多人来说一直是难点，比如暗部容易画焦画脏，暗部不透气，暗部细节过花，暗部单调等等。 其实暗部的处理方式很多，我们看到过一些画面暗部十分通透迷人，也见过一些作品暗部只是一个黑色剪影同样深沉大气。所以暗部到底怎么来画并不是千篇一律，但同样有规律可循，下面我们就从暗部的“暗”、暗部的“亮”、暗部的“透”三个方面来聊聊暗部的表达方式。 暗部的“暗” 如上图（《权力的游戏》剧照截图），在某些特定情况下暗部可以是黑色的剪影或是融入黑暗中的色块，这种时的暗部深沉厚重，轮廓清晰硬朗，几乎没有反光的影响，视觉信息与对比关系集中于亮部区域，给人很强烈的视觉冲击，而暗部的剪影也给人很多想象空间。 这种暗部往往出现于两种情况下：1.环境光较弱，光源是衰减性较强的光源，如蜡烛或强光的二次反光（如下图）2.远景或中景有强光，主体处于近景逆光或投影里（如下图）暗部的暗只要用对情形，并不会产生脏或焦的效果，而暗部的概括也能凸显亮部的信息，拉开画面的细节节奏感。 一个小技巧： 为了避免块面化的暗部产生单调感，可用一些空气中飘散的“小点”来丰富画面，这些小点可以是火花、雪花、气泡、灰尘等等形式（比如下面我画的这张《巨蟹座》，暗部是使用水里的小气泡来点缀的） 暗部的“亮”在大多数CG插画的绘制中，暗部的信息是被表达出来的，也就是“亮”起来，这让画面的信息量更丰富，视觉效果更华丽，我个人的是偏爱这样的处理，这就牵涉到暗部亮起来的方式，以及呈现方法。 我们要达到某种画面效果，就要为其营造合理的形成因素。比如暗部要亮起来，就需要被光照射，我们要营造这种暗部光线产生的合理环境。 最简单的方式是给暗部打一盏补光，这盏光可以是火光、灯光等与环境和谐的形式出现，如图：PS:这次我用了很多《权力的游戏》剧照来做例子，这片的美术真是绝赞～尤其是布光，可以好好研究下，第六季又开始了，好开森ヾ(=^▽^=)ノ 我在《蛇夫座》这张画里用的是发光的酒杯作为脸部暗部的补光光源的(如图）还有这张《龙王》也是值得注意的是，要根据暗部补光光源的类型来绘制暗部的光影效果，例如点光源的属性是发散、强衰减、清晰的投影（小光源投影清晰，注意与后面会提到的大光源对比） 暗部亮起来的另一种光的来源是来自反光。 这包括主光源的反光以及整个环境的漫反射环境光，这两者常常是同时存在的。如图，人物面部的暗部同时受到环境天光和地面反光的影响。额，到这里难度逐渐提升了哦，但还不是最难的。。。后面还有暗部色彩这个BOSS呢（╯－＿－）╯╧╧值得注意的是，不管是光源的反光（镜面反射除外）还是整个环境的漫反射环境光都是属于“大光源”，什么是大光源呢？如果把光源的类型和属性展开来讲又需要长篇大论一番了，以后有机会再说，这里就简单描述一下。 所谓光源的大小呢，是指加上透视效果后人眼看到光源的相对大小。太阳实际很大，但它离我们很远，加上人眼透视效果之后它的相对大小就要小于我们身边的一堵墙面，如果光是通过墙面进行反射的，那么墙面是大光源，太阳是小光源。前面提到小光源投影较清晰，大光源投影较模糊。比如这张我画的《莲姬》的局部图，脸颊就是受到肩部的反光影响，鬓角的头发对于脸颊产生的反射光的投影是非常模糊的，因为肩胛的反光面离脸部很近，是大光源。 既然暗部反光一般都属于大光源（镜面反射除外），基于反光影响的暗部就要按照大光源的效果来画：投影模糊或无投影，暗部的深色集中于光的死角。另外，反光（镜面反射除外）具有强衰减的属性，例如肩胛对脸的反光，可能只能照亮下颚，到眼窝下方就衰减得很暗淡了。 而环境漫反射光的衰减几乎可以忽略不计，特别是表现角色的时候，巨大的环境所产生的环境光在角色的尺度上的衰减是微乎其微的，例如天光。虽说是漫反射，但我们还是要给环境光一个主体方向，这样画起来比较好表现，比如天光虽是笼罩式的，但我们通常还是认为天光的主体方向是由上至下的。 最常见的情况是暗部画脏，问题出在对于反光的判断上。看这张石膏，光从左上方投射下来，同样是暗部，头顶的暗部隐没于黑暗，而下颚的暗部却较亮，这是由于肩膀对于下颚的反光，并且迅速衰减造成的，在无参考的情况下，如果这个反光没有被分析出来，则会造成下颚不合理的焦黑，形成“脏”的感觉。如果忽略了反光的强衰减属性，把头顶暗部也画得很亮，则会产生暗部很花很乱，细节琐碎的感觉。 再次强调一下，主光源反射形成的反光往往是属于较柔和的面状大光源（镜面反射除外），不会在暗部产生轮廓清晰的的二次投影。这种情况下你所看到的暗部的黑色是主光源和反光都无法照射到的光的死角（如下颚与颈部交接处的褶皱） 当暗部的环境光与主光源反射光同时存在的时候，往往暗部的面积较大才能明确体现二者的存在，届时只需按照两者的方向、衰减属性、影响面积来分析即可。 还要补充一点，一定要控制暗部的对比关系，我们常常说“明实暗虚”，通常暗部是属于弱对比，暗部反光和补光的强度需要进行控制，不要让暗部的对比度强于亮部，否则也会产生“花”和“脏”的感觉。 终于要讲到暗部的色彩了 Σ( ° △ °|||)︴ 色彩又是一个庞大的理论体系呀，以后有机会再展开，这里只针对暗部的用色来浅聊一下。 首先要明确的是，色彩的冷暖是对比出来的、是相对的。低饱和度的暖色相对于高饱和度的暖色就显得冷，低饱和度的冷色相对于高饱和度的暖色就显得暖。 例如在一个暖光源为主的画面中，你要表现一个暗部的冷色并不需要画上蓝色这样绝对意义的冷色，你只需要画一抹低饱和度的黄，而这样做往往比你直接画冷色效果要更和谐，你如果直接画蓝色可能反而会让暗部显得很焦。如图图中取色部分看起来仿佛是一抹紫灰色，但它其实是饱和度很低的橙色。 所以你无法直接回答，当亮部是暖色时暗部是冷色还是暖色，它受非常多因素的影响，比如色彩的相对性、固有色、环境色、反光的颜色、透光的颜色等，当你把这些因素都考虑进去了，你的暗部的色彩自然就丰富了。 通常，我们会把更多精彩的色彩变化放在暗部，而非亮部。 当然，考虑的因素越多，难度也就越大，我们主要分几个类别来讨论。 首先是固有色。常出现的问题是固有色缺失，过于强调环境色而忽略了固有色，造成色彩混乱。固有色其实是我们首先要考虑的色彩因素，而学多了色彩理论之后，固有色却常常被忽视，我们需要了解固有色在不同色光影响下的变化程度，这与固有色的明度、饱和度、材质都有关系，涉及的类别比较多，需要系统总结，以后有机会再详细说一下，这次就不展开了。 刚才我们谈到了暗部的反射光与环境光，接下来我们看看他们对色彩的影响。看下面这幅图注意白马身体的暗部有着明显的冷暖变化，蓝色与黄色呈现强烈的对比，白马的暗部受到向下的天光影响和向上的地面反射光影响，由于大气层对阳光的散射，通常天光呈现冷色，而土黄色的地面反射出与其固有色接近的暖色反光，因此马身体暗部朝上的面偏冷，超下的面偏暖。这是室外阳光环境里非常常见的一种暗部用色方法，比如我这张作品《射手座》就是运用的这种光色原理当然，实际环境可能会受到很多其他因素影响，需要精细考量，比如靠近具有高饱和度固有色物体，容易被其反射光渲染，当然这种渲染的反射光也是具有强烈衰减属性的，含蓄表达即可，不可过于夸张。暗部色彩的冷暖表达要结合固有色的属性，利用前面提到的饱和度对冷暖的影响来综合判断。 另一个影响暗部色彩的因素是“透光”，也就是我们要聊的暗部的“透”。 光线通过半透明的物体透射进暗部，带来固有色饱和度加强的透光效果，如图被阳光直射的葡萄暗部呈现比亮部更高饱和度的黄色，注意暗部透光部位的明度要低于亮部的明度。 透光的效果会给暗部带来高饱和度的点缀色，是十分出彩的暗部色彩营造方式。为了营造这种效果，我们常常想方设法让光透过一些半透明材质，如：人的耳朵（如图）、鼻翼、怪物的粘液、晶体材质等。例如这张《恰克》， 注意观察耳朵和鼻孔内的鲜艳的红色。 暗部透光的效果能让暗部有种通透感，对于避免暗部的脏、糊、焦很有帮助，还能用于区分空间层次。还有一种处理方式是将暗部的透光人为夸张，产生一种类似暗部自发光的效果，比较风格化，可以根据自己的喜好酌情尝试。任何好看效果的使用都得有个度，太夸张的通透感会让画面显得琐碎轻浮，所以还是要与合理的物理规律逻辑相结合运用。《蛇夫座》头部后面的景物有自发光效果，用于强调头部的轮廓，并拉开前后层次。]]></content>
      <categories>
        <category>Artist</category>
      </categories>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[边缘]]></title>
    <url>%2F2019%2F06%2F20%2Fmargin%2F</url>
    <content type="text"><![CDATA[之前写过两篇绘画理论教程《关于“暗部”》与《关于“投影”》，是对于光影的客观物理规律在绘画中运用的探讨，这次要写的《关于“边缘”》则更强调绘画主观意识和审美判断力。在写实绘画中，边缘的处理能起到强化视觉重点，区分空间层次，拉开画面节奏，烘托虚实关系，以及营造畅快淋漓绘画感的作用，我们依然要从一张《权力的游戏》剧照说起。我们这次聊的是边缘，Margaery处在镜头的焦点，人物整体边缘是很清晰的，而远离焦点的邪恶小国王的边缘就比较模糊。这只是一张照片，相机镜头通过聚焦与散焦功能展现了边缘的虚实变化，虽然它已经很美了，但跟绘画比起来，相机的在这方面的能力只是小儿科而已，绘画中的边缘处理远比照片要丰富多变得多，细看好的绘画作品总能感动于画者的审美与智慧。我们就从”边缘的形状”、”边缘的对比”、”边缘的虚实”几个方面来说说“关于边缘”的那些事儿。 “边缘的形状”我们也可以称为”轮廓”，它是造型的基础，美术基础练习中的速写就是训练这方面的，其塑形的工具是线，用线要避免死板，要点在于线的轻与重、断与续、松与紧、顺与钝，其核心在于概括与夸张，这些理论并不难理解也经常在各种地方被人提到，但要运用得好却很难，理论与实践之间的鸿沟是很难跨越的。我们以人体举例，探讨人体轮廓表现，也顺带聊一下人体练习方面的经验。来看看前列宾美院教师布洛欣的速写作品（他是一位有名的当代油画家，但身边很多朋友都认为他的素描更好，其作品在网上很容易找到）在他的作品里我们能看到十分灵动的线条，仿佛音律般跳跃在画面上，看下面这张图：右图是布洛欣的手部速写，左图是我的自拍，对比实物与画作比较容易体会作者的思路。首先我们发现的是:作者在肌肉和骨骼等凹凸转折部位做了夸张，这是对边缘形状表现的常见手法：结合人体解剖知识，在理解的基础上夸张出模特本身并不明显的结构。 这里有一个常见的误区，我们很多人记忆人体结构是从记忆肌肉开始的，而忽略了骨骼的表现，其实骨骼与肌肉同等重要，尤其在动势人体中，对于骨骼引起的形变的描绘是让线条生动的关键。 人体之所以难，难在传神，仅仅追求“画准”是不够的，很多令人惊叹的人体速写作品的厉害之处在于在他突破了模特原本的结构框架，做了很多主观的夸张变形之后看起来反而更准更到位了。就如同我们在绘画时把现实中看不见的色彩夸张出来是一个道理。 难点在于如何夸张以及夸张的程度，夸张出去还能再收得回来，游离于准确之外，却让人看起来觉得合理。这不能依靠记忆，甚至无法用理论算计，灵动的线条、恰到好处的变化节奏，似乎来源于作者长期练习形成的一种审美直觉、一种自然流露的灵感，这些线条并不精巧却很自由。 我们常说：人体是要练一辈子的。对于骨骼及肌肉功能、形状、运动范围等一系列的练习记忆，这是一个浩大的工程，苦练人体当然是必要的，但绝不仅仅是“苦练”那么简单。那么除了苦练之外，还缺什么？这里说一点个人经验。 我把它称为“一种需要被培养成直觉的灵感”——-理论与苦练都是机械枯燥的，只有灵感才是美术浪漫的灵魂，即使简单的写生也需要灵感，作品才会灵动，而灵感并不是一种天赋，它是可以培养的。 为了找到其中的奥秘，我在照片边缘按照作者夸张的方式勾勒了一些红线并且标注了线条的走势，照片上的手似乎立刻活动了起来，当我的手也不由自主地跟着动起来的时候，我感觉到自身与作品的同步，一种奇妙的灵感油然而生，是的，关键就在于“与画中的人物同步”，至少在你的脑海中你要做到这一点，想象与画中人物做相同的动作，体会他在做这个动作时候的用力方式、身体感受，你不是在画他，你是在画你自己，这样你就会下笔如有神，达到“人画合一”的境界(≖ ‿≖)✧ 咳咳。。。其实也没那么玄啦，很多人都是在无意识中靠直觉完成的，比如在画一个哭泣的女孩的时候自己脸上也不由自主地带上了悲伤的表情，我们常常下意识在这样做，但我想强调的是有意识地培养并留住这种灵感让它更深入地作用于我们的绘画中，并成为一种直觉，即使是在画人体这样看似严谨的题材时也要调动你的每一根神经去感受。 举一个简单的例子，我常常看到有人在画弓箭手拉弓射箭的姿态，但弓手眼神游离，并没有看向他瞄准的方向，整个动感和气势一下泄掉，这就是没有仔细体会角色当时的情境造成的，连眼神都控制不了，更别说与他的骨骼、他的关节、他的肌肉同步，画出来的姿态肯定是呆板僵硬的。 扯远了些，我们再回到边缘的形状上来，刚才是基于人体的”形”的表达与练习方式的讨论，而除却人体之外，其他物体虽然千变万化但却简单许多，其形的提炼离不开人类审美的判断，比如松与紧、疏与密的对比，直线与曲线的搭配，牵涉到造型、设计、构图等多方面，这里就不再发散了。 下面来说说“边缘的对比”。上面两幅油画作品，第一幅主体比背景亮，第二幅主体比背景暗，边缘的内外侧通过明度对比实现了主体的突出，这种手法是我们常说的“暗衬亮”，和”亮衬暗”，指让背景与主体物的明度相区别，从而突出边缘和形体的一种手法。当画面显得糊、不明快、视觉冲击力不强的时候，不妨检查一下，主体的边缘是不是与背景色太接近了。我们在安排画面构图的时候要考虑到这一点，用以安排画面中的元素，看看布格罗这幅《圣母神慰》画中圣子洁白的肌肤在圣母暗色的服饰的衬托下显得格外鲜明，而圣母自身的深色轮廓却借助金色背景得以衬托，画面构成十分巧妙。 总而言之，上述是一种依靠固有色的深浅来区分边缘对比关系的方式，适用于光源比较柔和且主体与背景固有色深浅差别较大的情况。当光源具有较强方向性，并在主体上形成较强对比的亮部和暗部时，边缘的对比就出现了下面这种情况：在光的作用下，人体受光部位比背景浅，暗部比背景深，以此来实现了边缘的对比，强调了主体轮廓。而且这种边缘的对比处理方式更有光的变化的韵味，让画面显得比第一种方式更生动有情趣。当然第一种边缘处理方式也有它的优点，那就是更具庄重典雅韵味。 讲到这里，我们发散一下思路，这种利用光影来形成边缘对比的方式的运用十分广泛，我们在安排画面的时候多了一个非常有力的武器：那就是“光”，看下面这张图。这是美国一档真人秀访谈节目的嘉宾截图，注意背景的衰减光和人物头顶的轮廓光，背景渐变的衰减光让人的肩膀轮廓从背景中显现出来，而头顶的轮廓光当然也是为了强调头发的边缘，而这样做的目的也不全是为了边缘清晰，对比看看下面这张图：同样边缘对比十分清晰，但画面的视觉效果就弱了很多。原因是什么呢？ 这里不得不提到一些打光的知识，侧光能凸显体积感，逆光和衰减明显的范围光都是很具画面效果的打光方式，将多种光源结合运用在同一画面中，能增加画面的戏剧性，当然这个前提是要保持画面不乱不糊，这就要结合前面讲到的轮廓的对比来处理了。 好了，现在我们分析了两种强调边缘的方式，但实际上在很多情形下，并不是所有轮廓的边缘都要清晰，也不是所有边缘的对比都要强调。对比强的地方最能吸引人的视觉，所以视觉重点部位的边缘对比往往是强烈的，而画面次要部位边缘的对比则需要被弱化。如下面这幅旅美画家吴兆铭的油画作品：​我们常说：明实暗虚。“实”的意思是刻画清晰、对比强烈；“虚”则相反。图中亮部的边缘对比十分强烈，突出了亮部的”实”；暗部的边缘与背景色调接近，并逐渐隐没到背景的暗色中，采用的是弱对比，体现着“虚”。虚实结合的画面会显得更有空间感、韵律感。而我们也可以采用边缘的虚实对比来突出主体，弱化次要部位，强调视觉中心。 其实我们仔细观察会发现，画面的虚实处理并不只这么简单如图，即使是在“实”的区域里，也是有“虚”的存在的。同样，在暗部“虚”的区域里，也有边缘较清晰的部位，只是亮部边缘实多虚少，暗部边缘虚多实少。我把这称为“虚实关系的嵌套”。其审美逻辑在于，当人在欣赏一幅画的时候，首先是看整体，因此我们需要先确立整体的视觉主体和整体的虚实关系，然后观赏者会慢慢欣赏画面局部，视觉会形成多点聚焦，我们让画面的局部也具有虚实变化，就满足了这一审美需求，注意局部的虚实处理要以不破坏整体的虚实关系为前提。 来看看以上几点的实际运用，在创作的时候，我们可以通过对画面中场景元素和光影的安排来体现边缘处理的思路，比如我画的《造天使》这幅画：毫无疑问，被背叛被猎杀的天使是画面的主角，而右下角的小兵们是配角，因此天使的轮廓大多是明快清晰的，我用了很多“暗衬亮”或“亮衬暗”的对比穿插来塑造其边缘的对比变化，这些变化都是经过悉心安排的，比如对比最强烈的边缘留给了视觉重点：头部，雪白的翅膀给了逆光的头部一个很好的亮衬。虽然裙摆也很白，但人体与裙摆交界的腿部正好是也是亮部，因此其对比并不如处于暗面的头部与翅膀之间来得那么强烈。 这里还要提一下这个小兵：他是画面的次重点，是另一个对立正营的代表，所有小兵只有他是踏在雪白裙摆上的，因此也只有他拥有强对比的轮廓，但这个轮廓仅限于腿的部分，因为他毕竟不是主角，试想如果我把他的上半身衬一个强对比的浅色背景，观众会不知不觉中把其当成主角而对人类一方产生同理心，那么这幅画的意义有可能会被颠倒。 简而言之，我在一大群配角里面找了一个典型去描绘，但要控制他弱于主体的地位。再看其余的小兵，他们的轮廓边缘大多是弱对比的，我借助光影和固有色的安排实现了这一点。而边缘轮廓的互相穿插、被其他物体遮挡截断，也能起到弱化次要角色视觉吸引力的作用。 其实如果想要从这堆小兵里找到其他次典型主体也是可以找到的，但没有必要深入分析了，只要有对比的嵌套意识就好。​再来说下这只腿，它处于画面的中间，构图上起到连接左右两大阵营的作用，我给它的定位是画面中的一个节奏点，也就是说，观者会在这里停留一下视觉，但不能太久，抛开造型设计不谈，这次只说边缘对比，为什么白色布料只出现在小腿右侧，而没有越过小腿的投影出现在小腿左侧？因为如果那样的话，小腿暗部的边缘对比就太强了，小腿的视觉吸引力会超越我给它设定的程度。而现在看小腿的边缘，大部分是暗衬暗，亮衬亮，属于弱对比轮廓，配合花纹与配色，将其调试到合适的突显程度。 画面中的景物的造型、颜色、亮度、光影都是可以自行控制的，要根据视觉引导的思路去布局。当然，这些秘密都藏在画面里，别人看到的要是一幅合情合理自然而然的画面。 最后来说说“边缘的虚实”。 其实前面我们就提到过虚实关系了，但之前说的虚实是基于对比关系的虚实，这一节我们要聊的虚实是绘画技法方面的。 回头看看一开始那张《权力的游戏》剧照：​近处角色的虚化处理方式十分简单，我们只需要在PS里面使用模糊工具就能实现，但不得不说，从绘画的角度来讲，这样“简单粗暴”的虚化处理边缘的方式是比较不可取的，这也是绘画高于摄影的方面，我们看看好的绘画作品，边缘的处理极具人性光辉，笔触、纹理、虚实、层次的变化仿佛在听一首美妙的交响乐，看画的同时能体会到作者绘画时的情绪思维。​这是美国画家Casey.Baugh的一幅素描作品，作者在边缘的处理方面做得十分生动，可以看到他在五官及脸部边缘是用较清晰且强对比的方式来呈现，因为这一部分是画面的视觉中心。而对于头发边缘的表现则极富变化，来看几个小部位边缘的处理： 我们可以发现，生动边缘的描绘首先要制造“断续感”，边缘会时而被一些虚化的笔触打断，而这些虚化笔触本身是具有层次和空间感的，虽然模糊了边缘损失了一些形状信息，但却用另一种信息替代，细看仿佛是一个个让人浮想联翩的小场景，源于笔触变化带来的层次感。虽然这是一副素描作品，但在CG绘画中有很多笔刷也可以实现这样的边缘效果，这里介绍几个笔刷：这是我比较常用的几个虚化边缘的笔刷，分别用来画不同虚化程度的部位，有纹理较清晰的和较模糊的，结合起来运用能画出层次感十分丰富的虚化效果，下面是一个运用实例：​这是我一幅画的某个局部，就是用上述笔刷做的虚化，选择虚化部位的时候注意节奏的把握，虚化太多容易产生“毛茸茸”的感觉，要留出一些清晰边缘来，一般我会把较清晰边缘的位置留在关节部位或细节较多的部位，向外凸起弧线的顶端也是常常保留清晰边缘的地方，有利于体积表达。 值得一提的是，其实这幅画原作是下面这个效果：原图有做一些边缘虚化，但并没有我前面一幅虚化示范的效果那么夸张，原因是虚化程度要跟整幅画的整体风格相搭配，如果整幅画都是刻画较精细、边缘较清晰的，那么局部边缘虚化也不能太夸张。 还有另外一种技法常常用来做边缘虚化，那­就是涂抹工具。 涂抹工具的虚化效果是这样的：它有一种很潇洒的速度感，但却也带着一些油腻感，跟前面的虚化纹理画笔结合使用会比较好。 我把前面提到的几个虚化笔刷与涂抹工具笔刷放到了网盘上，大家可以下载来试试。网盘地址： http://pan.baidu.com/s/1jI1C4vW关于边缘的内容就聊到这里了，这一次有很多是关于绘画主观处理方面的，并没有绝对的答案，不同的绘画风格、审美喜好都会影响我们的判断，也带来更多探索空间。]]></content>
      <categories>
        <category>Artist</category>
      </categories>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[男女人体、肌肉、血管、骨骼、三视图]]></title>
    <url>%2F2019%2F06%2F19%2Fhuman-body-view%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Artist</category>
      </categories>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[头发动画和渲染]]></title>
    <url>%2F2019%2F06%2F18%2Fgpugem2-0%2F</url>
    <content type="text"><![CDATA[渲染在水中飘动的金色长发需要一个计算头发自阴影生成算法，还需要一个通过每一串头发来模拟光纤散射的反射模型。把这些结合起来，就能实时创建出极其真实的头发影像。]]></content>
      <categories>
        <category>GPUGem2</category>
      </categories>
      <tags>
        <tag>GPUGem2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZBrush模型的细分]]></title>
    <url>%2F2019%2F06%2F11%2Fzbrushdivide%2F</url>
    <content type="text"><![CDATA[在ZBrush中对模型进行雕刻时，随着细节越来越丰富，原有的面数已经不能满足我们对细节的要求，为了得到更多的细节，我们就必须增加模型的面数，让更多的面来支持我们进行雕刻，如下图（左）和下图（右）所示，设置不同细分级别时模型的雕刻结果。打开Light Box(灯光盒子)，选择DemoHead，拖拽鼠标左键，在场景中绘制一个DemoHead，单机tool-&gt;GempHead，（工具-&gt;几何体）命令，打开其菜单，它是ZBrush中用于控制细分功能的主要菜单，如图所示，当导入的模型在菜单中显示出自身共有3级细分。在ZBrush中三维模型由多边形网格构成，每个网格有4条边，当增加一级细分时，一个四边形网格经被分割为4个网格，所以每增加一级细分，总体的网格数量就会增加4倍。可以通过以下两种方式观察当前模型的网格数量。 通过顶部工具架右侧的ActivePoints（活动点数）和PotalPoints（合计点数）数值来查看当前模型的网格数量。如果屏幕分辨率不足以显示顶部工具架上全部的命令，这两个参数可以在Preferences-&gt;Misc（参数-&gt;杂项）命令中找到，如图所示。 将鼠标指针停留在Tool（工具）菜单当前模型的工具图标上数秒，便可以显示当前模型的相关信息，如图所示。 Geometry（几何）菜单中相关命令的使用方式如下。 模型在最高级别的细分时，单机Divide（细分）（快捷键是Ctrl+D）按钮可以增加一级细分（当模型处于最高级别状态或是模型由隐藏部分时，此功能不能正常使用）。下图（左）为细分之前；（右）细分之后。 Smt（细分平滑）：此命令可以使模型在增加细分时进行光滑处理。 Suv（平滑UV）：此命令可以增加细分时UV接缝保持光滑（用于导入其他三维软件建立的低级细分的模型并且已经编辑好UV时使用）。 Lower Res（降低细分）/Highter Res（提高细分）/SDiv（细分级别）：当物体存在多细分级别时，可以通过Lower Res（降低细分）命令、Higher Res（提高细分）命令或者SDiv（细分级别）滑块参数来控制当前模型显示哪一级别的细分。 Del Lower（删除低级）/Del Highter（删除高级）：如果有需要也可以单机Del Lower（删除低级）命令或Del Highter（删除高级）命令来取消不需要细分级别。]]></content>
      <categories>
        <category>ZBrush</category>
      </categories>
      <tags>
        <tag>ZBrush</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3DMax快捷键]]></title>
    <url>%2F2019%2F06%2F10%2F3dmaxshortcutkey%2F</url>
    <content type="text"><![CDATA[快捷键 快捷键 说明 F1 帮助 F2 加亮所选物体的面(开关) F3 线框显示(开光)/光滑加亮 F4 在透视图中线框显示(开关)显示分段数 F5 约束到X轴 F6 约束到Y轴 F7 约束到Z轴 F8 约束到XY/YZ/ZX平面(切换) F9 用前一次的配置进行渲染(渲染先前渲染过的那个视图) F10 打开渲染菜单 F11 打开脚本编辑器 F12 打开移动/渲染/缩放等精确数据输入对话框 ` 刷新所有视图 1 进入物体层级1层 2 进入物体层级2层 3 进入物体层级3层 4 进入物体层级4层 Shift+4 进入有指向性灯光视图 5 进入物体层级5层 Alt+6 显示/隐藏主工具栏 Alt+W 最大化视图 Alt+C 切割 Ctrl+V 拷贝复制 美术资源软件地址3Dmax各版本软件下载链接: [有效] http://pan.baidu.com/s/1jIa4DvS 密码: chdw各个版本的3Dmax（附加Vary）链接：https://pan.baidu.com/s/1fAhYzCec9yZ0X6mVtkr87Q 提取码：ofpqVray各版本软下载链接: [有效] https://pan.baidu.com/s/1ctHPs6 密码: 4ufaCAD各版本软件下载链接: [有效] http://pan.baidu.com/s/1eRBAuYI 密码: pbjkPS各版本软件下载链接: [有效] http://pan.baidu.com/s/1nuUYNNz 密码: chxiCDR各版本软件下载链接: [有效] http://pan.baidu.com/s/1qXSkWKs 密码: cxv8AI各版本软件下载链接: [有效] https://pan.baidu.com/s/1gfOFISz 密码: 2gnnoffice各版本软件下载链接: [有效] http://pan.baidu.com/s/1jHND2Sm 密码: 37hw 视频地址3DMAX灯光教程全套视频：https://www.bilibili.com/video/av27889940/?spm_id_from=333.788.b_636f6d6d656e74.543DMAX材质教程全套视频：https://www.bilibili.com/video/av27252253/3Dmax基础教程全套视频：https://www.bilibili.com/video/av26994483/3DMAX建模教程全套视频：https://www.bilibili.com/video/av26368250/3DMAX灯光渲染全套教程：https://www.bilibili.com/video/av26287976/3dmax别墅模型建模视频：https://www.bilibili.com/video/av26017246/3dmax家具建模详细教程：https://www.bilibili.com/video/av29328398/3dmax灯光渲染详细教程：https://www.bilibili.com/video/av29357444/]]></content>
      <categories>
        <category>3DMax</category>
      </categories>
      <tags>
        <tag>3DMax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[game]]></title>
    <url>%2F2019%2F06%2F09%2Fgame%2F</url>
    <content type="text"><![CDATA[霸体在霸体过程中被任何招式击中都不会有被攻击判定(但是有伤害照算的,还有加成).霸体招式可以强制出完.实战而言有霸体的话可以胜任很多插动的场合,如果对手攻击还很容易被这类招式打出counter,之后能够继续连段的话,对压制方是很大的打击.当人物进行攻击时人物的某些判定点(具有被攻击判定)在受到对方攻击且攻击判定成立的情况下,任务的动作依旧持续(受攻击时可能稍微停顿),人物的出招过程无法被打断.在此判定点上形成的伤害一般有以下几种情况下不受伤,受伤减少,受伤增加]]></content>
      <categories>
        <category>Game</category>
      </categories>
      <tags>
        <tag>Game</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac]]></title>
    <url>%2F2019%2F06%2F05%2Fmac%2F</url>
    <content type="text"><![CDATA[型号 分辨率 宽高比 iPad1 1024*768 1.3333333 iPad2 1024*768 1.3333333 iPad3 2048*1536 1.3333333 iPad4 2048*1536 1.3333333 iPad air 2048*1536 1.3333333 iPad air2 2048*1536 1.3333333 iPad mini 1024*768 1.3333333 iPad mini2 2048*1536 1.3333333 被认定的标准屏幕 1280*720 1.77777778]]></content>
  </entry>
  <entry>
    <title><![CDATA[Inter GPA Android真机调试]]></title>
    <url>%2F2019%2F06%2F04%2Fintergpaandroid%2F</url>
    <content type="text"><![CDATA[下载安装完成Intel GPA套件后，一共有五个工具，分别是：Graphics MonitorGraphics Frame AnalyzerPlatform AnalyzerSystem AnalyzerTrace Analyzer在Android平台进行图形调试的时候，我们主要用到的工具是System Analyzer和Graphics Frame Analyzer。首先需要打开测试手机的开发者选项中的允许调试。在一台安装配置完成Andriod开发环境的PC，使用USE连接需要测试的Android手机，然后在命令提示符中键入adb devices，饭回设备ID保证连接成功。然后打开System Analyzer，界面会显示当前的Android设备ID，点击Connect，然后允许GPA软件在手机上的安装。连接提示： Device error:setenforce:Couldn&#39;t set enforcing status to &#39;O&#39;:Permission denied 表示没有Root权限。小米Mix2，先去解锁，通过小米助手安装驱动。看完我的团长我的团，以第一人称叙事的角度描述故事。我想，在我的博客也应该这样，应该添加一些废话，毕竟博客是给我自己一个人看的。也可以抄，毕竟它只是给我一个人看的。然后这时候解锁工具就可以解锁了。然后很不幸，解锁失败了，提示让我72个小时，三天之后在解锁。我日他先人板板。要不是没钱，早就自己买一个手机了。继续看Vulkan吧。]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>性能分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[赤子之心]]></title>
    <url>%2F2019%2F05%2F31%2Ffiction-3%2F</url>
    <content type="text"><![CDATA[赤子之心，就是一颗率直、纯真、善良、热爱生命、好奇而富想象力、生命力旺盛的心，能够常常怀着赤子之心，才可以大人。老子道德经：含德之厚，比于赤子。说的就是这个道理吧。芹说他不知道自己算不算有赤子之心，但是经历了这么多。他说他想有赤子之心。以前以为，功夫，两个字，一横一竖，对的，站着，错的，倒下。只有站着的才有资格说话。后来见过了高山，才发现最难过的原来是生活。]]></content>
      <tags>
        <tag>混沌</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抗锯齿技术]]></title>
    <url>%2F2019%2F05%2F29%2Fsmaa%2F</url>
    <content type="text"><![CDATA[SMAAD技术的全称为”Enhanced Subpixel Morphological Antialiasing”，与FXAA一样同为后期处理抗锯齿技术，可以提供基于过滤算法的通用图像抗锯齿解决方案。SMAA技术使用了更好的几何形体和对角形体检测处理机制，通过图形边缘局部特征对比来识别图像的锯齿特征，并通过重建子像素的方式实现抗锯齿功能，效果与传统的4x MSAA相近而且可以根据游戏的需要进行定制。 通过”以模糊换取精确“的手段来消除显示屏上的锯齿，而这个过程我们称其为采样(Sampling)，也就是针对某一点的像素，通过让它带有周围像素的特性，因此在足够的分辨率下，这一点便不再顽固般地锐利，也达到消除锯齿的目的。 超级采样抗锯齿(Super Sampling Anti-Aliasing,SSAA)通过名字就知道，SSAA最大的特点来自采样过程，以常见的SSAA4为例，在面对一张最后需要以19201080像素渲染的画面时，SSAA会首先渲染一张尺寸位3840*2160像素的缓存，再在这种长宽都乘以2的画面上进行采样，采样的精度和效果当然是最理想的，但是你也可以想象，这种只为追求理想情况的手段对于硬件资源的消耗非常大，成本也非常高。更重要的是，即使在原理上SSAA拥有最理想的精度，但是最现实的情况万般变化中的游戏世界，SSAA并不能永远保证采样效果是最讨好眼睛的，换句话说性价比会随着新技术的现身而面临越来越大的挑战，这其中就包括SSAA本身的一种灵活的变体：多重采样抗锯齿技术(Multi-Sampling Anti-Aliasing,MSAA)。 MSAA的原理和SSAA一致，都是通过将图形拉伸至更高倍率之下的缓存之后再精细的图像上进行采样，但是前者真正聪明的地方在于，再开始狮子大开口之前MSAA存在一个判断的过程，换句话说MSAA仅仅针对画面中边缘部分进行放大处理，这么一来对于硬件的负担着实大大减轻，正式因为如此，MSAA早已是最流行的抗锯齿方案之一，对于任何一款现代游戏来说，不支持MSAA几乎是不可想象的。 无论是SSAA还是MSAA，他们运作都集中在非常考前的位置，比如光栅化阶段，因此对于硬件开销有较大的呼声，但是从2012年的GeFore 600系列以来，NVIDIA就已经开始推广一款全新的抗锯齿方案，它们最大的特点就是出发点非常靠前，作为一款后处理抗锯齿它的硬件需求非常低，甚至达到几乎难以察觉的地步，同时因为较低的实现难度，它已经成为MSAA之后最流行的抗锯齿方案之一，就是快速近似抗锯齿(Fast approximate anti-aliasing)。 SSAA画质与性能变化我们再来对比开启SSAA之后的情况，首先这里可以看到SSAA的一个特点，虽然抗锯齿技术逃不过采样的过程，但是这里可以看到开启SSAA之后，原本充满锯齿的地方首先还是一如既往的清晰、锐利，衣物和衣物的过度非常干净，完全没有后处理抗锯齿那种模糊的干净，而是锯齿真的缩小既视感，不过开启SSAA的代价确实高，2倍环境下Benchmark成绩已经滑落至49.08帧。 OpenGL中的MSAA如果我们想要在OpenGL中使用MSAA，我们必须要使用一个能在每个像素中存储大于1个颜色值的颜色缓冲（因为多重采样需要我们为每个采样点都储存一个颜色）。所以，我们需要一个新的缓冲类型，来存储特定数量的的多重采样样本，它叫做多重采样缓冲（Multisample Buffer）。 大多数的窗口系统都应该提供一个多重采样缓冲，用以代替默认的颜色缓冲。GLFW同样给了我们这个功能，我们所要做的只是提示(Hint)GLFW，我们希望使用一个包含N个样本的多重采样缓冲。这可以在创建窗口之前调用glfwWindowHint来完成。 1glfwWindowHint(GLFW_SAMPLES, 4); 现在再调用glfwCreateWindow创建渲染窗口时，每个屏幕坐标就会调用一个包含4个子采样点的颜色缓冲了。GLFW会自动创建一个每像素4个子采样点的深度和样本缓冲。这也意味着所有缓冲的大小都增长了4倍。 现在我们已经向GLFW请求了多重采样缓冲，我们还需要调用glEnable并启用GL_MULTISAMPLE，来启用多重采样。再大多数OpenGL的驱动上，多重采样都是默认启用的，所以这个调用可能会有点多余，但显示地调用可能会有点多余，但显示地调用一下会更保险一点。这样子不论是什么OppenGL地实现都能够正常启用多重采样了。1glEnable(GL_MULTISAMPLE); 只要默认的帧缓冲有了多重采样缓冲的附件，我们所要做的只是调用glEnable来启用多重采样。因为多重采样的算法都在OpenGL驱动的光栅器中实现了，我们不需要再多做什么。如果现在再来渲染本节一开始的那个绿色的立方体，我们应该能看到更平滑的边缘： 离屏MSAA由于GLFW负责了创建多重采样缓冲，启用MSAA非常简单。然而，如果我们想要使用我们自己的帧缓冲来进行离屏渲染，那么我们就必须要自己手动生成多重采样缓冲了。 有两种方式可以创建多重采样缓冲，将其作为帧缓冲的附件：纹理附件和渲染缓冲附件，这和帧缓冲教程中所讨论的普通附件很相似。 多重采样纹理附件为了创建一个支持存储多个采样点的纹理，我们使用glTexImage2DMultisample来替代glTexImage2D，它的纹理目标是GL_TEXTURE_2D_MULTISAPLE。 123glBindTexture(GL_TEXTURE_2D_MULTISAPLE, tex);glTexImage2DMultisample(GL_TEXTURE_2D_MULTISAPLE, samples, GL_RGB, width, height, GL_TRUE);glBindTexture(GL_TEXTURE_2D_MULTISAPLE, 0);]]></content>
      <categories>
        <category>计算机图形学</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>后处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GameEngine]]></title>
    <url>%2F2019%2F05%2F29%2Fgameengine%2F</url>
    <content type="text"><![CDATA[python2.7GnuWin32 Tools https://sourceforge.net/projects/getgnuwin32/ 执行download.bat和install.bat完成安装。添加环境变量 CLang是基于LLVM。所谓LLVM，就是一个小小的虚拟机。这个虚拟机抽象了不同的硬件平台，如x86/arm/mips等。最近还抽象了GPU。有点像Java的VM，但是又和Java的VM很不同。Java的VM是比较高层的，它的byte code包括很多硬件平台并不能直接支持的功能。而LLVM的byte code则是更加接近硬件(CPU/GPU)的实际功能，只不过它是独立于任何一个具体硬件存在的。非常简单粗糙比喻的话，各种CPU/GPU就好比各个地方的人，说各个地方的方言；而LLVM的byte code则有些像普通话，与方言有着类似1对1的对应关系。 所以，首先需要迁出LLVM的代码，如下操作： svn co http://llvm.org/svn/llvm-project/llvm/trunk llvm Clang是作为LLVM的一个前端，即，把C/C++翻译成LLVM可以懂的byte code的工具。LLVM再把byte code翻译成具体的机器指令。执行下面的命令可以迁出Clang的代码并放在LLVM妥当的位置。123456cd llvm\toolssvn co http://llvm.org/svn/llvm-project/cfe/trunk clangcd ../..mkdir build&quot;C:\PROGRAM FILES (X86)\MICROSOFT VISUAL STUDIO\2017\COMMUNITY\COMMON7\IDE\COMMONEXTENSIONS\MICROSOFT\CMAKE\CMake\bin\cmake.exe&quot; -G &quot;Visual Studio 15&quot; ../llvmmsbuild LLVM.sln Visual Studio 15 Win64指定编译平台为64位. 编译完成之后，我们来测试我们编译出的clang是否有问题。首先我们需要将生成物的目录加入环境变量PATH，以便在命令行能够找到它重启命令行，检查是否可以找到clang12345C:\Users\Administrator&gt;clang -vclang version 9.0.0 (trunk 361927) (llvm/trunk 361929)Target: i686-pc-windows-msvcThread model: posixInstalledDir: D:\build\Debug\bin 然后确保我们目前处于LLVM的顶级目录，就是下面有llvm和build这两个目录的那一集目录，执行下面的命令：1D:\&gt;python.exe build/Debug/bin/llvm-lit.py -sv --param build_mode=Debug --param clang_site_config=build/tools/clang/test/lit.site.cfg build/tools/clang/test --param=build_config=Debug 我这里的环境执行会失败，python提示找不到一些测试用的程序。需要修改build\tools\clang\test\lit.site.cfg把所有的%(build_mode)改为%(build_config)如果用vim修改，可以用:%s/build_mode/build_config/g最后clang main.cpp编译我们的项目。http://clang.llvm.org/get_started.html Linux 编译我这边的环境是Centos7.2的虚拟机环境。 yum install docker systemctl start docker docker pull tim03/clang docker run -it --rm -v$(pwd):/usr/src tim03/clang bash-4.4# bash-4.4# clang main.c]]></content>
      <categories>
        <category>GameEngine</category>
      </categories>
      <tags>
        <tag>GameEngine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vulkan]]></title>
    <url>%2F2019%2F05%2F28%2Fvulkan%2F</url>
    <content type="text"><![CDATA[以下是Vulkan中的特性和改进，相较于OpenGL具有更多的优势： 降低驱动程序的开销以及CPU使用率：Vulkan旨在更接近底层的图形硬件。因此，它为上层的应用程序提供了对主机计算资源的直接控制，以便GPU尽可能地进行渲染，这种方式同时也允许软件直接访问图形处理器，从而获得更好地性能。 多线程可扩展性：OpenGL中的多线程扩展效果非常差，要想利用线程的特性，从而更好地利用CPU是一件非常困难地事情。然后，Vulkan对此进行了专门设计，用于允许终端用户以一种非常透明地方式利用CPU的多线程特性，不存在隐式的全局状态。从创建作业以及提交作业（用于执行）时开始，不同线程下的作业之间会保持分离。 一套“显示”的API：OpenGL是一套“隐式”的API，其中的资源管理是驱动程序的责任。驱动程序需要应用程序的提示并跟踪资源的状态，这是一种不必要的开销。Vulkan是一套“显式”的API；在这里，驱动程序不负责跟踪资源以及它们之间的关系，把这项任务分配给了应用程序。这种干净的方法更可预测；驱动程序不会再幕后执行某些操作来管理资源（就像在OpenGL中一样）。因此，作业的处理简化且直接，从而实现最佳性能和可预测的行为。 预编译的中间着色语言：与需要着色器shader作为OpenGL(GLSL)源代码提供的OpenGL不同，SPIR-V(Standard Portable Intermediate Language：标准可移植中间语言)是Vulkan用于并行计算和图形操作的标准中间语言。 注意：用于源语言的编译器，例如GLSL，HLSL和LLVM必须符合SPIR-V规范，并提供实用的工具程序来提供SPIR-V的输入。Vulkan采用Vulkan这种即时执行的二进制中间输入形式并会在着色器阶段使用。 驱动程序层和应用程序层：在OpenGL中，与驱动程序层相比，应用程序层更薄，因为驱动程序的自动化考虑了资源管理和状态跟踪，Vulkan正好与此相反。它会确保驱动程序更接近底层的硬件且开销更小。管理逻辑、资源和状态是应用程序的责任。下图显示了这两个API的驱动程序和应用程序代码库的厚度： 内存控制：Vulkan能够在系统上暴露若干种内存类型，并要求应用程序开发人员为每个资源的预期用途选择适当的内存类型。相比之下，OpenGL驱动程序则会根据内部启发模式决定资源的放置位置，不同供应商之间的启发模式存在一定的差异，如果稍后驱动程序移动了资源，OpenGL可能会产生次优的放置或出现意外的故障。 可预测性：与OpenGL相比，Vulakn具有高度的可预测性；它在渲染时不会导致任何滞后或挂起。一旦将作业提供给驱动程序，就会立即提交，而OpenGL作业提交不是预先提供的，而是受到驱动调度程序的支配。 一套API：OpenGL为桌面API(OpenGL)和嵌入式API(OpenGL ES)提供了不同的版本。Vulkan很干净，只有一套适用所有平台的API。 直接访问GPU：Vulkan通过公开其功能和硬件设施，为应用程序用户提供了很多控制权。它公开了各种可用的物理设备、内存类型、命令缓冲区以及扩展。这种行为可以确保软件层更接近真实的硬件。 错误检查和验证：当使用OpenGL时，运行良好的应用程序在检查错误会付出一些代价，而错误在执行的时候根本不会出发。相比之下，Vulkan将这些检查和验证作为附加服务来提供，可以在需要时启用合计禁用。这些检查是可选的，可以通过启用错误检查和其他的验证层注入到运行时。因此，通过避免不必要的检查，可以减少CPU开销。理想情况下，这些错误和验证层必须在开发阶段的调试器打开，并在发布期间关闭。 支持各种GPU硬件：Vulkan支持移动设备光栅化器和桌面光栅化器作为实现的集成部分。它支持嵌入式平台的基于瓦片或延期的光栅化器以及本地基于平铺的前反馈光栅化器。 在深入探讨基本细节之前，先来看看Vulkan中用到的一些比较重要技术术语。随着我们的进一步深入，本书还会覆盖更多的技术术语。 物理设备和设备：系统可能包含多个具有Vulkan功能的物理硬件设备。物理设备表示唯一的设备，而设备device则是指应用程序中物理设备的逻辑表示，即逻辑设备。 队列：队列表示执行引擎和应用程序之间的口。物理设备始终包含了一个或多个队列（图形队列、计算队列、DMA队列/传输队列等）。队列的职责是收集作业（命令缓冲区）并将其分派给物理设备进行处理。 内存类型：Vulkan公开了各种内存类型。在更广泛的层面上，有两种类型的内存：主机内存和设备内存。 命令：命令是做某种行为的指令。命令可以大致分为动作，设置状态或者同步。 动作命令：这些命令可用于绘制图元、清除表面、复制缓冲区，查询/时间戳操作以及开始/结束子通道操作。这些命令能够更改帧缓冲区附件，读取或写入内存（缓冲区或图像）以及编写查询池。 同步命令：同步有助于满足两个或多个操作命令的要求，这些操作命令可能会争夺资源或具有一些内存依赖性。其中包括设置事件、等待时间，插入管线屏障以及渲染通道或子通道的依赖关系。 命令缓冲区：命令缓冲区是一组命令；它会记录这些命令并将它们提交给队列。 Vulkan的执行模型具有Vulkan功能的系统能够查询并显示系统上可用的物理设备的数量。每个物理设备会暴露一个或多个队列。这个队列会分为不同的族，每个族都有特定的功能。例如，这些功能包括图形，计算，数据传输以及稀疏内存管理。队列族的每个成员都可以包含一个或多个类似的队列，从而使它们互相兼容。例如，给定的实现可能支持同一队列上的数据传输和图形操作。 Vulkan允许开发人员通过应用程序对内存控制进行显式的管理，它公开了设备上可用的各种类型的堆，其中的每个堆属于不同的内存区域。Vulkan的执行模式非常直接，此处，命令缓冲区会被提交到队列中实现的。然后由物理设备使用，以便进行各种处理。 Vulkan应用程序负责控制各种Vulkan设备，这是通过把大量的命令记录到命令缓冲区并将它们提交到队列中实现的。该队列由驱动程序读取，驱动程序会按提交的顺序预先执行作业。命令缓冲区的构建非常昂贵，因此，一旦构建完成，就可以对它进行缓存以及将其提交到队列中，以便根据具体的需求执行若干次。此外，在应用程序中，可以使用多线程同时并行构建多个命令缓冲区。下图显示了执行模型的简化图示： 在这里，应用程序记录了两个包含多个命令的命令缓冲区。然后根据工作性质将这些命令提供给一个或多个队列。队列将这些命令缓冲区做呕也提交到设备进行处理。最后，设备处理结构并将其显示在输出显示屏上，或将它们返回给应用程序进行一部的处理。 在Vulkan中，应用程序负责以下内容： 为成功执行命令提供所有必要的先决条件：这其中可能包括准备资源、预编译的着色器以及将资源附加到着色器、指定渲染状态、构建管线以及绘制调用。 内存管理 同步 主机和设备之间的同步 设备上可用的不同队列之间的同步 危害管理 Vulkan的队列队列是Vulkan中的媒介，就是通过它将命令缓冲区送入设备的。命令缓冲区会记录一个或多个命令并将它们提交到所需的队列。设备也可能会公开多种队列，因此，应用程序有责任将命令缓冲区提交给正确的队列。 可以将命令缓冲区提交到以下几项： 一个队列——命令缓冲区的提交顺序以及执行、回放都将保持不变，命令缓冲区以串行方式执行； 多个队列——允许在两个或多个队列中并行执行命令缓冲区。除非明确指定，否则无法保证命令缓冲区的提交和执行顺序，同步它们的顺序是应用程序的责任，如果没有进行同步，执行的顺序可能会完全超出预期。 Vulkan提供了几种同步方式，是程序可以在单个队列或跨越多个队列对作业的执行进行相对控制。这些同步方式有： 信号量(Semaphore)：该同步机制可以跨多个队列进行同步，火灾单个队列中同步粗粒度的命令缓冲区提交。 事件(Events)：事件用来控制细粒度的同步并且被应用于单个队列，允许我们对提交给单个队列的一个命令缓冲区或若干个命令缓冲区序列之间进行同步工作。宿主机也可以参与基于事件的同步。 栅栏(Fences)：该方式能够在主机和设备之间进行同步操作。 管线屏障(Pipeline barriers)：管线屏障是一个插入指令，用于确保在该命令缓冲区中，在管线屏障之前的命令必须在被指定的、管线屏障之后的命令之前执行。 对象模型在应用程序级别，所有的实体（包括设备、队列、命令缓冲区、帧缓冲区、管线等）都被称为Vulkan对象。在内部，在API级别，这些Vulkan对象用句柄进行识别。这些句柄有两种类型：可分发句柄和不可分发句柄。 可分发句柄(a dispatchable handle)：这是一个指针，指向了内部不透明形状的实体(opaque-shaped entity)。不透明的类型不允许您直接访问这种结构的字段。只能使用API例程访问这些字段。每个可分发句柄都有一个关联的可分发类型(dispatchable type)，用于在API命令中作为参数传递。下面是一些示例：VKInstance|VkCommandBuffer|VkPhysicalDevice|VkDevice|VkQueue 不可分发句柄(Non-dispatchable handles)：这些是64位整型类型的句柄，可以包含对象信息本身，而不是指向结构的指针。示例如下：VKSemaphore|VkFence|VkQueryPool|VkBufferViewVkDeviceMemory|VkBuffer|VkImage|VkPipelineVkShaderModule|VkSampler|VkRenderPass|VkDescriptorPool 对象生命周期和命令语法在Vulkan中，根据每个应用程序的逻辑，都要显示创建和销毁对象，并且应用程序要负责管理这些对象。Vulkan中的对象使用Create创建并使用Destroy命令销毁： 创建语法：对象使用vkCreate *形式的命令创建的；这类命令接受一个Vk *CreateInfo结构作为输入参数。 销毁语法：对应的，使用vkCreate命令生成的对象要使用vkDestroy进行销毁。作为现有对象池或堆的一部分而创建的对象要使用Allocate命令创建并使用Free命令从池或者堆中进行释放。 分配语法：作为对象池的一部分创建的对象使用vkAllocate *形式的命令，并且使用Vk* AllocateInfo作为输入参数。 销毁语法：相应的，使用vkFree*命令把对象释放回池或者内存中。 使用vkGet命令可以轻松访问任何给定的实现信息。vkCmd形式的API实现用于在命令缓冲区中记录命令。 错误检查和验证Vulkan专门提供高性能而设计，这是通过保持错误检查和验证功能作为一种可选项的形式实现的。在运行时，错误检查和验证的部分少之又少，从而使得构建命令缓冲区和提交变得更加高效。这些可选功能可以通过Vulkan的分层体系结构来实现，该分层体系结构允许把各种层（调试层和验证层）动态注入到正在运行的系统中。 了解 Vulkan应用以下框图显示了系统中不同组件模块以及对应的联系： 驱动程序具有Vulkan功能的系统至少包含一个CPU和GPU。IHV的供应商为其专用GPU架构提供了指定Vulkan规范实现的驱动程序。驱动程序充当应用程序设备本身之间的接口。它为应用程序提供了一些高级设施，以便能够与设备进行通信。例如，驱动程序通知了系统上可用的设备数量、它们的队列和队列功能、可用的堆及其相关属性等。 应用程序应用程序是指用户编写的程序，旨在利用Vulkan API来执行图形或计算任务。应用程序从硬件和软件的初始化开始，它会检测驱动程序并加载所有的Vulkan API。展示层(presentation layer)使用Vulkan的窗口系统集成——Window System Integration——(WSI)API进行初始化；WSI将用于渲染期间在显示表面(display surface)上绘制图形图像。应用程序创建资源并使用描述符(descripors)将它们绑定到着色器阶段(shader stage)。描述符集布局(descriptor set layout)用于把创建的资源绑定到创建的底层管线对象pipeline object(图形或计算类型graphics or compute type)。最后，记录命令缓冲区并将其提交到队列进行处理。 WSI窗口系统集成WSI(Windows System Integration)是来自Khronos的一组扩展，用于跨平台(如Linux,Windows和Android)。 SPIR-VSPIR-V提供了一种预编译的二进制格式，用于指定Vulkan着色器。编译器可用于各种着色器语言，其中包括能够生成SPIR-V的GLSL和HLSL变种。 LunarG SDKLunarG的Vulkan SDK包含了各种工具和资源，用以辅助Vulkan应用程序的开发。这些工具和资源包括Vulkan加载程序、验证层、跟踪和回放工具、SPIR-V工具、Vulkan运行时安装程序、文档，示例以及演示。 Vulkan编程模型入门下图显示了Vulkan应用程序编程模型自顶向下的方法； 硬件初始化当Vulkan应用程序启动的时候，它的第一个工作就是硬件的初始化。在这个阶段，应用程序通过与加载器进行通信来激活Vulkan驱动程序。下图展示了一个加载器Loader及其子组件的框图： Loader：加载程序是应用启动时使用的一段代码，可以跨平台、以一种统一的方式在系统中定位Vulkan驱动程序。以下是加载Loader的职责： 定位驱动程序(Locating dirvers)：作为其主要的任务，加载程序知道在给定系统中到哪里搜索驱动程序。它会找到正确的驱动程序并加载。 不依赖平台(Platform-independent)：初始化Vulkan在所有平台上都是一致的。这与OpenGL不同，OpenGL创建上下文需要针对每个环境(EGL,GLX,WGL)使用不同的窗口系统API。Vulkan中的平台差异以扩展名表示。 可注入的层(Injectable layers)：加载器支持层次化的体系结构并提供在运行时注入各层的能力。最大的改进就是驱动程序在确定应用程序堆API的使用是否有效时不需要执行任何工作，也不会保留执行该工作所需的任何状态。因此，建议在开发阶段根据应用要求打开选定的可注入层，并在部署阶段将其关闭。例如，可注入层可以以下内容： 跟踪Vulkan API命令 捕获要渲染的场景并在稍后执行场景的渲染 用于调试目的的错误检查和验证 Vulkan应用程序首先执行与加载程序库的握手并初始化Vulkan具体实现的驱动程序。加载程序库会动态加载Vulkan API。加载程序还提供了一种机制，允许将特定的层自动加载到所有Vulkan应用程序中；这被称为隐式启用层。 一旦加载程序找到驱动程序并成功链接到API，应用程序就要复杂以下操作： 创建一个Vulkan实例 查询物理设备的可用队列 查询扩展并将它们存储位函数指针，如WSI或特殊功能的API 启用可注入曾，进行错误检查、调试或验证操作 窗口展示表面(Window presentation surfaces)一旦加载器找到Vulkan具体实现的驱动程序， 好了，抄完上面的就懒得抄了，我总是这个样子，做事情一直坚持不下来。无论是上面，无所谓了，这就是我吧，感觉也没什么坏处了，唯一的坏处就是常年在外然后和李浩然拌拌嘴，其他也真没上面，哦哦，还有就是来了金山这边有点能吃了，虽然吃饭不要钱。跟着Vulkan 向导走着，url是：https://vulkan-tutorial.com/Development_environment#page_Setting_up_Visual_Studio 访问还得翻墙，本来想买VPN来着，但是又舍不得掏钱，总是舍不得掏钱，于是配置了半天XX-NET，终于可以将就的看了。但是目前卡在了glw下载的过程中，趴着梯子看外面的世界确实不好受呀。]]></content>
      <categories>
        <category>Vulkan</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>Vulkan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[填充三角形]]></title>
    <url>%2F2019%2F05%2F27%2Ffilltriangle%2F</url>
    <content type="text"><![CDATA[填充三角形线性插值来复习一下画线,我们知道画线的时候我们做的实际上是这样的事情：对于要画的线AB，在满足我们设定的条件（斜率 ≤ 1, A &lt; B）之后，因为我们要画的是整数的像素点，对于x每增加1，我们算出对应的y，然后来画点（x，y），这样重复直到x增加到B点： 对于 AB 上的任意一点 P 满足： P = A + t(B - A), 0 \le t \le 1也可以写成： P = (1 - t)A + tB , 0 \le t \le 1这个公式是著名的线性插值，实际上也是我们画线的基础。因为在画线部分核心代码长这样： 12345for (int x=x0; x&lt;=x1; x++) &#123; float t = (x-x0)/(float)(x1-x0); int y = y0 + (y1 - y0)*t; ...&#125; 对于P点，我们根据增加后的x算出t值，然后算出y，得到应该画的点。 其实在画框架的时候我们已经画过三角形了，就画三条线就OK。现在我们要做的是来填充三角形。 扫描法若要填充一个三角形，最简单的能想到的办法是对于三角形的每一个y，我们找到对应的左侧和右侧，x_left和x_right，我们画上x_left到x_right的线，那么从三角形最上面的点按y增加扫到最下面的点既可。 为了简单起见，我们先把三角形拆成上下两部分： 那么对于一个特定的y，我们想要找到它的左边和右边 A B 两点，思路是这样： 首先排序，保证 t0 ≤ t1 ≤ t2 整个三角形的高度必为 t2.y - t0.y 那么对于上半部分，y每增加1（注意有可能t0 == t1),我们用插值法算出对应的两点A和B 这样就能算出对应的 A 和 B 12345678910111213141516void triangle(Vec2i t0, Vec2i t1, Vec2i t2, TGAImage &amp;image, TGAColor color) &#123; // sort the vertices, t0, t1, t2 lower−to−upper (bubblesort yay!) if (t0.y&gt;t1.y) std::swap(t0, t1); if (t0.y&gt;t2.y) std::swap(t0, t2); if (t1.y&gt;t2.y) std::swap(t1, t2); int total_height = t2.y-t0.y; for (int y=t0.y; y&lt;=t1.y; y++) &#123; int segment_height = t1.y-t0.y+1; float alpha = (float)(y-t0.y)/total_height; float beta = (float)(y-t0.y)/segment_height; // be careful with divisions by zero Vec2i A = t0 + (t2-t0)*alpha; Vec2i B = t0 + (t1-t0)*beta; image.set(A.x, y, red); image.set(B.x, y, green); &#125; &#125; 那么有了 A 和 B 之后，我们在AB之间调用我们的画线函数，再用同样的方法给下半部分填满，问题既解决。 1234567891011121314151617181920212223242526272829void triangle(Vec2i t0, Vec2i t1, Vec2i t2, TGAImage &amp;image, TGAColor color) &#123; // sort the vertices, t0, t1, t2 lower−to−upper (bubblesort yay!) if (t0.y&gt;t1.y) std::swap(t0, t1); if (t0.y&gt;t2.y) std::swap(t0, t2); if (t1.y&gt;t2.y) std::swap(t1, t2); int total_height = t2.y-t0.y; for (int y=t0.y; y&lt;=t1.y; y++) &#123; int segment_height = t1.y-t0.y+1; float alpha = (float)(y-t0.y)/total_height; float beta = (float)(y-t0.y)/segment_height; // be careful with divisions by zero Vec2i A = t0 + (t2-t0)*alpha; Vec2i B = t0 + (t1-t0)*beta; if (A.x&gt;B.x) std::swap(A, B); for (int j=A.x; j&lt;=B.x; j++) &#123; image.set(j, y, color); // attention, due to int casts t0.y+i != A.y &#125; &#125; for (int y=t1.y; y&lt;=t2.y; y++) &#123; int segment_height = t2.y-t1.y+1; float alpha = (float)(y-t0.y)/total_height; float beta = (float)(y-t1.y)/segment_height; // be careful with divisions by zero Vec2i A = t0 + (t2-t0)*alpha; Vec2i B = t1 + (t2-t1)*beta; if (A.x&gt;B.x) std::swap(A, B); for (int j=A.x; j&lt;=B.x; j++) &#123; image.set(j, y, color); // attention, due to int casts t0.y+i != A.y &#125; &#125; &#125; 这样三角形填充就解决。代码里有很多重复的部分，然后这里决定让代码短一点，代价是读起来没那么清楚了： 1234567891011121314151617181920void triangle(Vec2i t0, Vec2i t1, Vec2i t2, TGAImage &amp;image, TGAColor color) &#123; if (t0.y==t1.y &amp;&amp; t0.y==t2.y) return; // I dont care about degenerate triangles // sort the vertices, t0, t1, t2 lower−to−upper (bubblesort yay!) if (t0.y&gt;t1.y) std::swap(t0, t1); if (t0.y&gt;t2.y) std::swap(t0, t2); if (t1.y&gt;t2.y) std::swap(t1, t2); int total_height = t2.y-t0.y; for (int i=0; i&lt;total_height; i++) &#123; bool second_half = i&gt;t1.y-t0.y || t1.y==t0.y; int segment_height = second_half ? t2.y-t1.y : t1.y-t0.y; float alpha = (float)i/total_height; float beta = (float)(i-(second_half ? t1.y-t0.y : 0))/segment_height; // be careful: with above conditions no division by zero here Vec2i A = t0 + (t2-t0)*alpha; Vec2i B = second_half ? t1 + (t2-t1)*beta : t0 + (t1-t0)*beta; if (A.x&gt;B.x) std::swap(A, B); for (int j=A.x; j&lt;=B.x; j++) &#123; image.set(j, t0.y+i, color); // attention, due to int casts t0.y+i != A.y &#125; &#125; &#125; wavefront obj上一章我们画了框架，这下我们来填上三角形： 好吧，并不是很动人=。=之所以不动人是因为光影光影，我们只有颜色，没有考虑光， 代码 重心坐标法除了上面提到的扫描法之外，另外一个可以想到的办法是，因为我们终究是画到二维平面上的像素，一个一个的点，那么对于我们要画的区域内的每一个点，我们是否可以检测看它是否在三角形之内，如果是的话，画它，否则不理之。这样的思路是可行的，对于三角形内及其边上的任意一点，我们都可以用重心坐标系来表示： P = (1 - u - v)A + uB + vC, 0 \le u,v \le 1这个长得也很像线性插值。 运算: P = A + u\overrightarrow{AB} + v\overrightarrow{AC}继续： u\overrightarrow{AB} + v\overrightarrow{AC} + \overrightarrow{PA} = 0PA是AB和AC的线性组合。 拆一拆： u\overrightarrow{AB}_x + v\overrightarrow{AC}_x + \overrightarrow{PA}_x = 0 u\overrightarrow{AB}_y + v\overrightarrow{AC}_y + \overrightarrow{PA}_y = 0实际上我们都可以看做是我们在寻找向量 $(u, v, 1)$ 同时垂直于向量 $(\overrightarrow{AB}_x, \overrightarrow{AC}_x,\overrightarrow{PA}_x)$ 和向量 $(\overrightarrow{AB}_y, \overrightarrow{AC}_y,\overrightarrow{PA}_y)$。 这就是叉乘。 12345xvector = (B_x - A_x, C_x - A_x, A_x - P_x)yvector = (B_y - A_y, C_y - A_y, A_y - P_y)u = xvector x yvector# 如果 u 的 z 分量不等于1则说明P点不在三角形内 因为我们的计算有浮点数，可能u的z分量不会一定等于1,令 u 的三个分量是 (a, b, c),我们代入原式子： a\overrightarrow{AB} + b\overrightarrow{AC} + c\overrightarrow{PA} = 0 P = (1 - a/c - b/c)A + a/cB + b/cC, c \ne 0代码我们这样写： 123456789101112Vec3f barycentric(Vec2f A, Vec2f B, Vec2f C, Vec2f P) &#123; Vec3f s[2]; for (int i=2; i--; ) &#123; s[i][0] = C[i]-A[i]; s[i][1] = B[i]-A[i]; s[i][2] = A[i]-P[i]; &#125; Vec3f u = cross(s[0], s[1]); if (std::abs(u[2])&gt;1e-2) // dont forget that u[2] is integer. If it is zero then triangle ABC is degenerate return Vec3f(1.f-(u.x+u.y)/u.z, u.y/u.z, u.x/u.z); return Vec3f(-1,1,1); // in this case generate negative coordinates, it will be thrown away by the rasterizator&#125; 我们当然也不用把平面区域的每个点代入P去做检查，我们只需要找到三角形的 bounding_box,然后看其中的每一个整数点，如果在其中，那就画之。 用同样的方法来给模型填色，效果一样。 代码 效果跟之前依旧一致，我们给每个三角形随机填上色： 随机填色这个我们看起来倒是有点cool.]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>光栅</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2019%2F05%2F27%2Fpython%2F</url>
    <content type="text"><![CDATA[python3 怎么安装 PIL关于Pillow与PIL PIL(Python Imaging Library)是Python一个强大方便的图像处理库，名气也比较大。不过只支持到Python 2.7。 PIL官方网站：http://www.pythonware.com/products/pil/ Pillow是PIL的一个派生分支，但如今已经发展成为比PIL本身更具活力的图像处理库。目前最新版本是3.0.0。 Pillow的Github主页：https://github.com/python-pillow/PillowPillow的文档(对应版本v3.0.0)：https://pillow.readthedocs.org/en/latest/handbook/index.htmlPillow的文档中文翻译(对应版本v2.4.0)：http://pillow-cn.readthedocs.org/en/latest/ Python 3.x 安装Pillow 给Python安装Pillow非常简单，使用pip或easy_install只要一行代码即可。 在命令行使用PIP安装：pip install Pillow 或在命令行使用easy_install安装：easy_install Pillow 安装完成后，使用from PIL import Image就引用使用库了。比如：from PIL import Imageim = Image.open(“bride.jpg”)im.rotate(45).show()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DrawLine]]></title>
    <url>%2F2019%2F05%2F27%2FDrawLine%2F</url>
    <content type="text"><![CDATA[画线我们先从屏幕画线开始。 首先，y = ax + b 这个并不能画出所有的线，并且有两个问题： 如果a很大，那么x由 $x_0$ 增加到 $x_0+1$ 那么y增加a，如果 a 很大，那么会有分裂的样式 无法画出平行于 y 的竖线 针对这种状况，我们采用的画图方式是利用如下的代码： 12345678910111213Interpolate (i0, d0, i1, d1)&#123; if i0 == i1 &#123; return [d0] &#125; values = [] a = (d1 - d0) / (i1 - i0) d = d0 for i = i0 to i1&#123; values.append(d) d = d + a &#125; return values&#125; 首先是我们利用的是要么 y = ax + b , 要么 x = ay + b, 意思是要么我们让 y 随着 x 变化，要么让 x 随着 y 变化. 在上述的伪码中，我们的 d 是 dependent value， i 是 independent value，我们让 d 随着 i 变化。 其次是我们分情况，看线是更加水平或者是更加竖直，如果线更加水平，那么 y 随着x变化，如果更竖直，那么x 随着y变化，这样来作图。 1234567891011121314151617181920212223DrawLine(P0, P1, color) &#123; if abs(x1 - x0) &gt; abs(y1 -y0)&#123; # Line is horizontal-ish # Make sure x0 &lt; x1 if x0 &gt; x1 &#123; swap(P0, P1) &#125; ys = Interpolate(x0, y0, x1, y1) for x = x0 to x1&#123; canvas.PutPixel(x, ys[x-x0], color) &#125; &#125; else &#123; # Line is vertical-ish # Make sure y0 &lt; y1 if y0 &gt; y1 &#123; swap(P0,P1) &#125; xs = Interpolate(y0, x0, y1, x1) for y = y0 to y1&#123; canvas.PutPixel(xs[y-y0], y, color) &#125; &#125;&#125; 画出来 代码]]></content>
      <categories>
        <category>计算机图形学</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>光栅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[光线跟踪]]></title>
    <url>%2F2019%2F05%2F27%2FRayTracying%2F</url>
    <content type="text"><![CDATA[RayTracyingRayTracying最关键的点是： 👁看出去的世界 而非世界如何达到👁 这也是这个算法叫做ray tracying - 光线跟踪的原因。 例子1.预备知识1.1 屏幕坐标 vs 画布坐标一般来说屏幕坐标都是始于左上角，然后朝右和下延伸。 不过这里为了作图方便，我们把坐标系按照数学中更常见的方式把原点放于屏幕中央，x和y的延伸方向按照平时的习惯来放。 这样可以知道屏幕坐标系$S_x$和画布坐标系$C_x$的变换: S_x = \frac{C_w}{2} + C_x S_y = \frac{C_h}{2} - C_y1.2 画布 vs 窗户因为我们屏幕是二维的，无论我们怎样模拟，实际上都是要把物体画在一个二维的平面（画布）上，我们这里就假设我们把👁放在原点上，而有一扇窗户在坐标轴 z = d 处 ，我们眼睛能看到的也就是窗户出去的世界。 那么对于画布上的任意一点，在窗户上都有一个对应的位置，因为它们是中心相同平面平行。 所以对画布上的每一个点$C_x, C_y$我们都能找到窗户上的对应点$V_x, V_y$，加上上一段话中的对应关系，实际上就是一个比例的问题，所以我们可以继续知道画布坐标系$C_x, C_y$在窗户上的对应坐标$V_x, V_y$为： V_x = C_x\frac{V_w}{C_w} V_y = C_y\frac{V_h}{C_h}同时因为窗户放在 z = d 处，我们知道： V_z = d这就有了如何将画布上的每一点转化为窗户上的每一点的坐标变换。 1.3 窗户 vs 空间从眼睛👁射出的光线，我们都可以看成是$\overrightarrow{OP}$。 同时P点位置也可以写成： $P = O + t(V-O)$, 令$\overrightarrow{D}$为$V-O$，也就是其方向的向量，如下图： P = O + t\overrightarrow{D} 这里需要注意的是: O,P,V是位置，$\overrightarrow{OP}， \overrightarrow{D}$是向量。 同时知道： t &lt; 0: 逆向于光线上的点 t = 0: 原点 t &gt; 0 &amp;&amp; t &lt; 1: 原点到V点之间的点，也就是原点到窗户之间的点 t = 1: V点 t &gt; 1: V点之后，依旧在射出的光线之上，当t取某个值为P点 2.空间放物体这里我们在空间中放置一个球体 球心为C，那么球上点P需要满足方程： |P - C| = r3. 处理交互 跟踪光线假设OP就是我们看出去的光线，来追踪它，当看向球体时，它会与球体产生交互，图中这条光线就是和球体相遇了： 球上的属于这条光线的P点应该满足： P = O + t\overrightarrow{D} |P - C| = r代入1式进2式： | O + t\overrightarrow{D} - C| = r | t\overrightarrow{D} + \overrightarrow{OC}| = r来解方程： (t\overrightarrow{OD} + \overrightarrow{OC})(t\overrightarrow{OD} +\overrightarrow{OC}) = r^2展开： t^2|\overrightarrow{OD}|^2 + 2 t\overrightarrow{OD}\cdot\overrightarrow{OC} + |\overrightarrow{OC}|^2 -r^2 = 0令 k_1 = |\overrightarrow{OD}|^2 ​ k_2 = 2 \overrightarrow{OD}\cdot\overrightarrow{OC}​ k_3 = |\overrightarrow{OC}|^2 -r^2这就变成解关于t的一元二次方程： {t_1, t_2} = \begin{equation} \frac{ -k_2 \pm \sqrt{k_2^2 - 4k_1k_3} } {2k_1} \end{equation}会出现： $k_2^2 - 4k_1k_3 &gt; 0$ ： 两个解 $k_2^2 - 4k_1k_3 = 0$ ： 一个解 $k_2^2 - 4k_1k_3 &lt; 0$ ： 无解 对应的就是下图的状况： 所以问题就变简单了，如果我们有交互，那么我们应该展示的是近的点$t_1$的颜色，如果我们没有交互，那么我们展示的就是背景色。 以上就是光线追踪的根本原理。 至此の伪码跟踪光线与球相交 IntersectRaySphere1234567891011121314151617IntersectRaySphere(O, D, sphere)&#123; C = sphere.center r = sphere.radius oc = O - C k1 = dot(OD, OD) k2 = 2 * dot(OC, OD) k3 = dot(OC,OC) - r*r discriminant = k2 * k2 - 4 * k1 * k3 if discriminant &lt; 0: return inf, inf t1 = (-k2 + sqrt(discriminant))/(2*k1) t2 = (-k2 - sqrt(discriminant))/(2*k1) return t1, t2&#125; t1 的颜色TraceRay这里我们在空间里放入好几个球体，然后计算t1处的颜色伪码如下： 123456789101112131415161718TraceRay(O, D, t_min, t_max)&#123; closest_t = inf closest_sphere = NULL for sphere in scene.Spheres &#123; t1, t2 = IntersectRaySphere(O, D, sphere) if t1 in [t_min, t_max] &amp;&amp; t1 &lt; closest_t closest_t = t1 closest_sphere = sphere if t2 in [t_min, t_max] &amp;&amp; t2 &lt; closest_t closest_t = t2 closest_sphere = sphere &#125; if closest_sphere == NULL return BACKGROUND_COLOR return closest_sphere.color &#125; 我们在空间中放入三个小球： 画到画布上在上述三个伪码函数中，最终是TraceRay这个函数调用了其余两个函数，那么我们现在需要来设定它的参数。 DD这个实际上之前已经写到，就是从O到V的向量，那么我们的V又由最早的画布到窗户可以得知，所以我们可以有函数： 123CanvasToViewport(x, y)&#123; return (x * Vw/Cw, y * Vh/Ch, d)&#125; t_min, t_maxt = 1 是V，是在窗户上，t &gt; 1 是窗户之后，是场景，所以我们需要取的值是 t_min = 1,我们并不需要摄像头和窗户之间的颜色，因为我们也没有放任何东西在那里，我们需要的是窗户之后的景色，所以 t_min = 1, t_max = inf 组装最后，我们需要的是来做循环，把所有的代码组装在一起，放在屏幕上，所以伪码如下： 123456789O = &lt;0,0,0&gt;for x in [-Cw/2, Cw/2]&#123; for y in [-Ch/2, Ch/2]&#123; D = CanvasToViewport(x, y) color = TraceRay(O, D, t_min, t_max) canvas.putPixel(x, y, color) &#125;&#125; 对应的窗户大小和距离都可以在代码中看到，看结果： 这根本看起来不3d，很简单，因为我们并没有考虑光的作用。 代码链接]]></content>
      <categories>
        <category>计算机图形学</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>光栅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[500行代码学懂OpenGL之二画线]]></title>
    <url>%2F2019%2F05%2F27%2Fopengldrawline%2F</url>
    <content type="text"><![CDATA[画线画完了点，我们来开始画线。画线的同时我们依旧要记得，我们是画在一个一个整数的pixel上。 尝试一： 按照参数绘制直线1234567void line(int x0, int y0, int x1, int y1, TGAImage &amp;image, TGAColor color) &#123; for (float t=0.; t&lt;1.; t+=.01) &#123; int x = x0 + (x1-x0)*t; int y = y0 + (y1-y0)*t; image.set(x, y, color); &#125; &#125; 这里的问题有两个： 效率低 t如何控制 t取大了画出来的并不是线，而是一堆点。t取小了会浪费，有很多重复的x和y。 尝试二： 按x的增加画线1234567void line(int x0, int y0, int x1, int y1, TGAImage &amp;image, TGAColor color) &#123; for (int x=x0; x&lt;=x1; x++) &#123; float t = (x-x0)/(float)(x1-x0); int y = y0 + (y1 - y0)*t; image.set(x, y, color); &#125; &#125; 我们想着要节约，就每次 x 增加1，然后来画y。 这样画线是对的因为我们假设 $y = mx + b $, 直线斜率m， 截距b \frac{y_1 - y_0}{x_1 - x_0} = m y_0 = mx_0 + b y = y_0 + \frac{y_1 - y_0}{x_1 - x_0}(x - x_0)所以 y = y_0 + mx - mx_0 = mx + (y_0 - mx_0) = mx + b同时它的问题是我们也已经指出: 如果直线斜率太大，比如 m = 3, 那么x每增加1个像素，y增加3个像素，这样画出来就是分离的点。 只能适用于 x0 &lt; x1的状况 尝试三所以想法是： 如有必要交换 x0 和 x1，这样使得 x0 一定小于 x1 如果斜率比较大，则交换 x 和 y 看代码： 123456789101112131415161718192021void line(int x0, int y0, int x1, int y1, TGAImage &amp;image, TGAColor color) &#123; bool steep = false; if (std::abs(x0-x1)&lt;std::abs(y0-y1)) &#123; // if the line is steep, we transpose the image std::swap(x0, y0); std::swap(x1, y1); steep = true; &#125; if (x0&gt;x1) &#123; // make it left−to−right std::swap(x0, x1); std::swap(y0, y1); &#125; for (int x=x0; x&lt;=x1; x++) &#123; float t = (x-x0)/(float)(x1-x0); int y = y0 + (y1 - y0)*t; if (steep) &#123; image.set(y, x, color); // if transposed, de−transpose &#125; else &#123; image.set(x, y, color); &#125; &#125; &#125; 这样就可以完善上述出现的问题来画线了。 这里其实还是有一些可以进步的空间，比如出现了浮点数t，同时也依旧我们之前说的我们只需要画在整数上。可以参见： 再谈绘制直线中的优化部分。 不过我们画线就暂时停在这里。我们就用这个函数来画了，因为compiler的优化已经足够好了。 wavefront obj之前我们已经用过这个文件，上次我们认识了v 代表顶点（vertex),这次我们来多认识一个f 代表面（face)，实际上是三角形面，在这个文件中我们的一行f有： 1f 1193/1240/1193 1180/1227/1180 1179/1226/1179 我们现在只需要知道每组的第一个数字： 1193,1180,1179 是代表vertex list中的三个顶点的索引（index），这三个顶点构成一个三角形。 所以进一步修改model parser，我们来用这个画出线框，核心代码长这样： 1234567891011121314for (int i = 0; i &lt; model-&gt;nfaces(); i++) &#123; std::vector&lt;int&gt; face = model-&gt;face(i); // face: i0,i1,i2 of triangle for (int j = 0; j &lt; 3; j++) &#123; Vec3f v0 = model-&gt;vert(face[j]); // this % used for when j = 2 to get i2, i0 Vec3f v1 = model-&gt;vert(face[(j+1)%3]); int x0 = (v0.x+1.)*width/2.; int y0 = (v0.y+1.)*height/2.; int x1 = (v1.x+1.)*width/2.; int y1 = (v1.y+1.)*height/2.; line(x0, y0, x1, y1, image, white); &#125;&#125; 代码]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>光栅</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMakeLists]]></title>
    <url>%2F2019%2F05%2F26%2Fcmakefile%2F</url>
    <content type="text"><![CDATA[123456789101112131415#1.cmake verson,指定cmake版本cmake_minimum_required (VERSION 2.6)#2.指定项目名称，一般和项目的文件夹名对应project (Tutorial)#3.头文件目录INCLUDE_DIRECTORIES( ./)#4.源文件目录SET(SOURCE_FILES ./main.cpp./tgaimage.cpp)SET(EXECUTABLE_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;/../bin) #设置可执行文件的输出目录ADD_EXECUTABLE("Prepare" $&#123;SOURCE_FILES&#125;)]]></content>
      <categories>
        <category>CMakeFile</category>
      </categories>
      <tags>
        <tag>CMakeFile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[500行代码学懂OpenGL之一画点]]></title>
    <url>%2F2019%2F05%2F26%2Fopengldrawpoint%2F</url>
    <content type="text"><![CDATA[项目来自https://github.com/ssloy/tinyrenderer，作者尝试用500行代码来写一个tiny render，让我们明白OpenGL是怎样工作的。 从画点开始TGAImage生成图像我们使用TGAImage，这个使用起来很简单：12345678910111213#include "tgaimage.h"const TGAColor white = TGAColor(255,255,255,255);const TGAColor red = TGAColor(255,0,0,255);int main(int argc, char ** argv)&#123; TGAImage image(100,100,TGAImage::RGB); image.set(52,41,red); image.filp_vertically(); image.write_tga_file("output.tga"); return 0;&#125; 项目:https://github.com/zentia/tinyrender.git wavefront obj然后我们来学习一种3d格式文件，wavefront obj file:12345678910111213141516171819202122232425# List of geometric vertices, with (x, y, z [,w]) coordinates, w is optional and defaults to 1.0. v 0.123 0.234 0.345 1.0 v ... ... # List of texture coordinates, in (u, [v ,w]) coordinates, these will vary between 0 and 1, v and w are optional and default to 0. vt 0.500 1 [0] vt ... ... # List of vertex normals in (x,y,z) form; normals might not be unit vectors. vn 0.707 0.000 0.707 vn ... ... # Parameter space vertices in ( u [,v] [,w] ) form; free form geometry statement ( see below ) vp 0.310000 3.210000 2.100000 vp ... ... # Polygonal face element (see below) f 1 2 3 f 3/1 4/2 5/3 f 6/4/1 3/5/3 7/6/5 f 7//1 8//2 9//3 f ... ... # Line element (see below) l 5 8 1 2 4 9 我们现在只需要知道顶点是v，现在我们想把一个文件中的3d模型的顶点v(x,y,z)给画出来，(因为我们已经知道怎么在图上相应的位置放像素)这个文件所有的x,y,z∈[-1,1]，所以我们需要把它们映射到合适范围，然后注意我们画的点 image.set(52,41,red); ，这里的是52和41是int，映射之后需要转成int，因为我们总是画在一个一个像素点上。写一个简单的parser读入文件建立模型。核心部分长这样：123456for (int i = 0; i != model-&gt;nverts();i++)&#123; Vec3f v = model-&gt;vert(i); Vec2i p = world2screen(v); image.set(p.x,p.y,white);&#125;]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>光栅</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#运算符优先级]]></title>
    <url>%2F2019%2F05%2F24%2Fcsharp-precedence-of-operator%2F</url>
    <content type="text"><![CDATA[优先级运算符使用形式结合方向 1[]数组名[整形表达式]左到右 () . -> 2--表达式右到左 (类型) ++ -- **指针表达式 6--表达式左到右 > >=]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua参考手册下半部分]]></title>
    <url>%2F2019%2F05%2F24%2Fluarefermanual%2F</url>
    <content type="text"><![CDATA[当前大部分来源是5.1的标准 lua_Readertypedef const char * (*lua_Reader) (lua_State *L, void *data, size_t *size); lua_load 用到的读取器函数， 每次它需要一块新的 chunk 的时候， lua_load 就调用读取器， 每次都会传入一个参数 data 。 读取器需要返回含有新的 chunk 的一块内存的指针， 并把 size 设为这块内存的大小。 内存块必须在下一次函数被调用之前一直存在。 读取器可以通过返回一个 NULL 来指示 chunk 结束。 读取器可能返回多个块，每个块可以有任意的大于零的尺寸。 lua_registervoid lua_register (lua_State *L, const char *name, lua_CFunction f); 把 C 函数 f 设到全局变量 name 中。 它通过一个宏定义： #define lua_register(L,n,f) \ (lua_pushcfunction(L, f), lua_setglobal(L, n)) lua_removevoid lua_remove (lua_State *L, int index); 从给定有效索引处移除一个元素， 把这个索引之上的所有元素移下来填补上这个空隙。 不能用伪索引来调用这个函数， 因为伪索引并不指向真实的栈上的位置。 lua_replacevoid lua_replace (lua_State *L, int index); 把栈顶元素移动到给定位置（并且把这个栈顶元素弹出）， 不移动任何元素（因此在那个位置处的值被覆盖掉）。 lua_resumeint lua_resume (lua_State *L, int narg); 在给定线程中启动或继续一个 coroutine 。要启动一个 coroutine 的话，首先你要创建一个新线程 （参见 lua_newthread ）； 然后把主函数和若干参数压到新线程的堆栈上； 最后调用 lua_resume ， 把 narg 设为参数的个数。 这次调用会在 coroutine 挂起时或是结束运行后返回。 当函数返回时，堆栈中会有传给 lua_yield 的所有值， 或是主函数的所有返回值。 如果 coroutine 切换时，lua_resume 返回 LUA_YIELD ， 而当 coroutine 结束运行且没有任何错误时，返回 0 。 如果有错则返回错误代码（参见 lua_pcall）。 在发生错误的情况下， 堆栈没有展开， 因此你可以使用 debug API 来处理它。 出错信息放在栈顶。 要继续运行一个 coroutine 的话，你把需要传给 yield 作结果的返回值压入堆栈，然后调用 lua_resume 。 lua_setallocfvoid lua_setallocf (lua_State *L, lua_Alloc f, void *ud); 把指定状态机的分配器函数换成带上指针 ud 的 f 。 lua_setfenvint lua_setfenv (lua_State *L, int index); 从堆栈上弹出一个 table 并把它设为指定索引处值的新环境。 如果指定索引处的值即不是函数又不是线程或是 userdata ， lua_setfenv 会返回 0 ， 否则返回 1 。 lua_setfieldvoid lua_setfield(lua_State *L, int index, const char *k); 等价于t[k] = v的操作，这里t是给出的有效索引index处的值，而v是栈顶的那个值。这个函数将把这个值弹出堆栈。 跟在Lua中一样，这个函数可能触发一个newindex事件的元方法。 lua_setglobalvoid lua_setglobal (lua_State *L, const char *name); 从堆栈上弹出一个值，并将其设到全局变量 name 中。 它由一个宏定义出来： #define lua_setglobal(L,s) lua_setfield(L, LUA_GLOBALSINDEX, s) lua_setmetatableint lua_setmetatable(lua_State *L, int index); 把一个table 弹出堆栈，并将其设为给定索引处的值的 metatable 。 lua_settablevoid lua_settable(lua_State *L, int index); 作一个等价于 t[k] = v的操作，这里t是一个给定有效索引 index 处的值， v 指栈顶的值， 而 k 是栈顶之下的那个值。这个函数会把键和值都从堆栈中弹出。 和在 Lua 中一样，这个函数可能触发 “newindex” 事件的元方法。 lua_settopvoid lua_settop(lua_State *L, int index); 参数允许传入任何可接受的索引以及0。它将把堆栈的栈顶设为这个索引。如果新的栈顶比原来的大，超出部分的新元素将被填为nil。如果index为0，把栈上所有元素移除。 lua_Statetypedef struct luaState lua_State;一个不透明的结构，它保存了整个 Lua 解释器的状态。 Lua 库是完全可重入的： 它没有任何全局变量。 （译注：从 C 语法上来说，也不尽然。例如，在 table 的实现中 用了一个静态全局变量 dummynode ，但这在正确使用时并不影响可重入性。 只是万一你错误链接了 lua 库，不小心在同一进程空间中存在两份 lua 库实现的代码的话， 多份 dummynode_ 不同的地址会导致一些问题。） 所有的信息都保存在这个结构中。 这个状态机的指针必须作为第一个参数传递给每一个库函数。 lua_newstate 是一个例外， 这个函数会从头创建一个 Lua 状态机。 lua_statusint lua_status (lua_State *L); 返回线程 L 的状态。正常的线程状态是 0 。 当线程执行完毕或发生一个错误时，状态值是错误码。 如果线程被挂起，状态为 LUA_YIELD 。 lua_tobooleanint lua_toboolean (lua_State *L, int index); 把指定的索引处的的Lua值转换为一个C中的boolean值（0或是1）。和Lua中做的所有测试一样，lua_toboolean会把任何不同于false和nil的值当作1返回； 否则就返回0。 如果用一个无效索引去调用也会返回0。 （如果你想只接收真正的boolean值，就需要使用lua_isboolean来测试值的类型。） lua_tocfunctionlua_CFunction lua_tocfunction (lua_State *L, int index); 把给定索引处的 Lua 值转换为一个 C 函数。 这个值必须是一个 C 函数；如果不是就返回 NULL 。 lua_tointegerlua_Integer lua_tointeger (lua_State *L, int idx); 把给定索引处的 Lua 值转换为 lua_Integer 这样一个有符号整数类型。 这个 Lua 值必须是一个数字或是一个可以转换为数字的字符串 （参见 §2.2.1）； 否则，lua_tointeger 返回 0 。如果数字不是一个整数， 截断小数部分的方式没有被明确定义。 lua_tolstringconst char *lua_tolstring (lua_State *L, int index, size_t *len); 把给定索引处的 Lua 值转换为一个 C 字符串。 如果 len 不为 NULL ， 它还把字符串长度设到 *len 中。 这个 Lua 值必须是一个字符串或是一个数字； 否则返回返回 NULL 。 如果值是一个数字，lua_tolstring 还会把堆栈中的那个值的实际类型转换为一个字符串。 （当遍历一个表的时候，把 lua_tolstring 作用在键上，这个转换有可能导致 lua_next 弄错。） lua_tolstring 返回 Lua 状态机中 字符串的以对齐指针。 这个字符串总能保证 （ C 要求的）最后一个字符为零 (‘\0’) ， 而且它允许在字符串内包含多个这样的零。 因为 Lua 中可能发生垃圾收集， 所以不保证 lua_tolstring 返回的指针， 在对应的值从堆栈中移除后依然有效。 lua_tonumberlua_Number lua_tonumber (lua_State *L, int index); 把给定索引处的 Lua 值转换为 lua_Number 这样一个 C 类型（参见 lua_Number ）。 这个 Lua 值必须是一个数字或是一个可转换为数字的字符串 （参见 §2.2.1 ）； 否则，lua_tonumber 返回 0 。 lua_topointerconst void *lua_topointer (lua_State *L, int index); 把给定索引处的值转换为一般的 C 指针 (void*) 。 这个值可以是一个 userdata ，table ，thread 或是一个 function ； 否则，lua_topointer 返回 NULL 。 不同的对象有不同的指针。 不存在把指针再转回原有类型的方法。这个函数通常只为产生 debug 信息用。 lua_tostringconst char *lua_tostring (lua_State *L, int index); 等价于 lua_tolstring ，而参数 len 设为 NULL 。 lua_tothreadlua_State *lua_tothread (lua_State *L, int index); 把给定索引处的值转换为一个 Lua 线程（由 lua_State* 代表）。 这个值必须是一个线程；否则函数返回 NULL 。 lua_touserdatavoid *lua_touserdata (lua_State *L, int index); 如果给定索引处的值是一个完整的userdata ，函数返回内存块的地址。 如果值是一个 light userdata ，那么就返回它表示的指针。 否则，返回 NULL 。 lua_typeint lua_type (lua_State *L, int index); 返回给定索引处的值的类型， 当索引无效时则返回 LUA_TNONE （那是指一个指向堆栈上的空位置的索引）。 lua_type 返回的类型是一些个在 lua.h 中定义的常量： LUA_TNIL ， LUA_TNUMBER ， LUA_TBOOLEAN ， LUA_TSTRING ， LUA_TTABLE ， LUA_TFUNCTION ， LUA_TUSERDATA ， LUA_TTHREAD ， LUA_TLIGHTUSERDATA 。 lua_typenameconst char *lua_typename (lua_State *L, int tp); 返回 tp 表示的类型名， 这个 tp 必须是 lua_type 可能返回的值中之一。 lua_Writertypedef int (lua_Writer) (lua_State L, const void p, size_t sz, void ud); 由 lua_dump 用到的写入器函数。 每次 lua_dump 产生了一块新的 chunk ，它都会调用写入器。 传入要写入的缓存 (p) 和它的尺寸 (sz) ， 还有 lua_dump 的参数 data 。写入器会返回一个错误码： 0 表示没有错误； 别的值均表示一个错误，并且会让 lua_dump 停止再次调用写入器。 lua_xmovevoid lua_xmove (lua_State *from, lua_State *to, int n); 传递 同一个 全局状态机下不同线程中的值。这个函数会从 from 的堆栈中弹出 n 个值， 然后把它们压入 to 的堆栈中。 lua_yieldint lua_yield (lua_State *L, int nresults); 切出一个 coroutine 。这个函数只能在一个 C 函数的返回表达式中调用。如下： return lua_yield (L, nresults); 当一个 C 函数这样调用 lua_yield ， 正在运行中的 coroutine 将从运行中挂起， 然后启动这个 coroutine 用的那次对 lua_resume 的调用就返回了。 参数 nresults 指的是堆栈中需要返回的结果个数，这些返回值将被传递给 lua_resume 。 3.8 - 调试接口Lua 没有内建的调试设施。 取而代之的是提供了一些函数接口和钩子。 利用这些接口，可以做出一些不同类型的调试器， 性能分析器，或是其它一些需要从解释器中取到“内部信息”的工具。 lua_Debugtypedef struct lua_Debug { int event; const char *name; /* (n) */ const char *namewhat; /* (n) */ const char *what; /* (S) */ const char *source; /* (S) */ int currentline; /* (l) */ int nups; /* (u) upvalue 个数 */ int linedefined; /* (S) */ int lastlinedefined; /* (S) */ char short_src[LUA_IDSIZE]; /* (S) */ /* 私有部分 */ 其它域 } lua_Debug; 一个用来携带活动中函数的各种信息的结构。 lua_getstack 仅填写这个结构中的私有部分， 这些部分以后会用到。 调用 lua_getinfo 则可以填上 lua_Debug 中有用信息的那些域。 lua_Debug 中的各个域有下列含义： source: 如果函数是定义在一个字符串中，source 就是这个字符串。 如果函数定义在一个文件中， source 是一个以 ‘@’ 开头的文件名。short_src: 一个“可打印版本”的 source，用于出错信息。linedefined: 函数定义开始处的行号。lastlinedefined: 函数定义结束处的行号。what: 如果函数是一个 Lua 函数，则为一个字符串 “Lua” ； 如果是一个 C 函数，则为 “C”； 如果它是一个 chunk 的主体部分，则为 “main”； 如果是一个作了尾调用的函数，则为 “tail” 。 别的情况下，Lua 没有关于函数的别的信息。currentline: 给定函数正在执行的那一行。 当提供不了行号信息的时候，currentline 被设为 -1 。name: 给定函数的一个合理的名字。 因为 Lua 中的函数也是一个值， 所以它们没有固定的名字： 一些函数可能是全局复合变量的值， 另一些可能仅仅只是被保存在一个 table 中。 lua_getinfo 函数会检查函数是这样被调用的，以此来找到一个适合的名字。 如果它找不到名字，name 就被设置为 NULL 。namewhat: 结实 name 域。 namewhat 的值可以是 “global”, “local”, “method”, “field”, “upvalue”, 或是 “” （空串）。 这取决于函数怎样被调用。 （Lua 用空串表示其它选项都不符合）nups: 函数的 upvalue 的个数。 lua_gethooklua_Hook lua_gethook (lua_State *L); 返回当前的钩子函数。 lua_gethookcountint lua_gethookcount (lua_State *L); 返回当前钩子记数。 lua_gethookmaskint lua_gethookmask (lua_State *L); 返回当前的钩子掩码 (mask) 。 lua_getinfoint lua_getinfo (lua_State *L, const char *what, lua_Debug *ar); 返回一个指定的函数或函数调用的信息。当用于取得一次函数调用的信息时， 参数 ar 必须是一个有效的活动的记录。 这条记录可以是前一次调用 lua_getstack 得到的， 或是一个钩子 （参见 lua_Hook）得到的参数。用于获取一个函数的信息时，可以把这个函数压入堆栈， 然后把 what 字符串以字符 ‘&gt;’ 起头。 （这个情况下，lua_getinfo 从栈顶上弹出函数。） 例如，想知道函数 f 在哪一行定义的， 你可以下下列代码： lua_Debug ar; lua_getfield(L, LUA_GLOBALSINDEX, &quot;f&quot;); /* 取到全局变量 &#39;f&#39; */ lua_getinfo(L, &quot;&gt;S&quot;, &amp;ar); printf(&quot;%d\n&quot;, ar.linedefined); what 字符串中的每个字符都筛选出结构 ar 结构中一些域用于填充，或是把一个值压入堆栈： ‘n’: 填充 name 及 namewhat 域；‘S’: 填充 source， short_src， linedefined， lastlinedefined，以及 what 域；‘l’: 填充 currentline 域；‘u’: 填充 nups 域；‘f’: 把正在运行中指定级别处函数压入堆栈； （译注：一般用于获取函数调用中的信息， 级别是由 ar 中的私有部分来提供。 如果用于获取静态函数，那么就直接把指定函数重新压回堆栈， 但这样做通常无甚意义。）‘L’: 压一个 table 入栈，这个 table 中的整数索引用于描述函数中哪些行是有效行。 （有效行指有实际代码的行， 即你可以置入断点的行。 无效行包括空行和只有注释的行。）这个函数出错会返回 0 （例如，what 中有一个无效选项）。 lua_getlocalconst char *lua_getlocal (lua_State *L, lua_Debug *ar, int n); 从给定活动记录中获取一个局部变量的信息。 参数 ar 必须是一个有效的活动的记录。 这条记录可以是前一次调用 lua_getstack 得到的， 或是一个钩子 （参见 lua_Hook）得到的参数。 索引 n 用于选择要检阅哪个局部变量 （ 1 表示第一个参数或是激活的第一个局部变量，以此类推，直到最后一个局部变量）。 lua_getlocal 把变量的值压入堆栈并返回它的名字。以 ‘(‘ （正小括号）开始的变量指内部变量 （循环控制变量，临时变量，C 函数局部变量）。当索引大于局部变量的个数时，返回 NULL （什么也不压入）。 lua_getstackint lua_getstack (lua_State *L, int level, lua_Debug *ar); 获取解释器的运行时栈的信息。这个函数用正在运行中的给定级别处的函数的活动记录来填写 lua_Debug 结构的一部分。 0 级表示当前运行的函数， 而 n+1 级处的函数就是调用第 n 级函数的那一个。 如果没有错误，lua_getstack 返回 1 ； 当调用传入的级别大于堆栈深度的时候，返回 0 。 lua_getupvalueconst char *lua_getupvalue (lua_State *L, int funcindex, int n); 获取一个 closure 的 upvalue 信息。 （对于 Lua 函数，upvalue 是函数需要使用的外部局部变量， 因此这些变量被包含在 closure 中。） lua_getupvalue 获取第 n 个 upvalue ， 把这个 upvalue 的值压入堆栈，并且返回它的名字。 funcindex 指向堆栈上 closure 的位置。 （ 因为 upvalue 在整个函数中都有效，所以它们没有特别的次序。 因此，它们以字母次序来编号。） 当索引号比 upvalue 数量大的时候，返回 NULL （而且不会压入任何东西） 对于 C 函数，这个函数用空串 “” 表示所有 upvalue 的名字。 lua_Hooktypedef void (*lua_Hook) (lua_State *L, lua_Debug *ar); 用于调试的钩子函数类型。无论何时钩子被调用，它的参数 ar 中的 event 域 都被设为触发钩子的事件。 Lua 把这些事件定义为以下常量： LUA_HOOKCALL， LUA_HOOKRET, LUA_HOOKTAILRET， LUA_HOOKLINE， and LUA_HOOKCOUNT。 除此之外，对于 line 事件，currentline 域也被设置。 要想获得 ar 中的其他域， 钩子必须调用 lua_getinfo。 对于返回事件，event 的正常值可能是 LUA_HOOKRET， 或者是 LUA_HOOKTAILRET 。 对于后一种情况，Lua 会对一个函数做的尾调用也模拟出一个返回事件出来； 对于这个模拟的返回事件，调用 lua_getinfo 没有什么作用。当 Lua 运行在一个钩子内部时，它将屏蔽掉其它对钩子的调用。 也就是说，如果一个钩子函数内再调回 Lua 来执行一个函数或是一个 chunk ， 这个执行操作不会触发任何的钩子。 lua_sethookint lua_sethook (lua_State *L, lua_Hook f, int mask, int count); 设置一个调试用钩子函数。 参数 f 是钩子函数。 mask 指定在哪些事件时会调用： 它由下列一组位常量构成 LUA_MASKCALL， LUA_MASKRET， LUA_MASKLINE， 以及 LUA_MASKCOUNT。 参数 count 只在 mask 中包含有 LUA_MASKCOUNT 才有意义。 对于每个事件，钩子被调用的情况解释如下：call hook: 在解释器调用一个函数时被调用。 钩子将于 Lua 进入一个新函数后，函数获取参数前被调用。return hook: 在解释器从一个函数中返回时调用。 钩子将于 Lua 离开函数之前的那一刻被调用。 你无权访问被函数返回出去的那些值。 （译注：原文 (You have no access to the values to be returned by the function) 如此。 但“无权访问”一词值得商榷。 某些情况下你可以访问到一些被命名为 (*temporary) 的局部变量， 那些索引被排在最后的 (temporary) 变量指的就是返回值。 但是由于 Lua 对特殊情况做了一些优化，比如直接返回一个被命名的局部变量， 那么就找不到对应的 (temporary) 变量了。本质上，返回值一定存在于此刻的局部变量中， 并且可以访问它，只是无法确定是哪些罢了。至于这个时候函数体内的其它局部变量， 是不保证有效的。进入 return hook 的那一刻起，实际已经退出函数内部的运行环节， 返回值占用的局部变量空间以后的部分，都有可能因 hook 本身复用它们而改变。）line hook: 在解释器准备开始执行新的一行代码时， 或是跳转到这行代码中时（即使在同一行内跳转）被调用。 （这个事件仅仅在 Lua 执行一个 Lua 函数时发生。）count hook: 在解释器每执行 count 条指令后被调用。 （这个事件仅仅在 Lua 执行一个 Lua 函数时发生。）钩子可以通过设置 mask 为零屏蔽。 lua_setlocalconst char *lua_setlocal (lua_State *L, lua_Debug *ar, int n); 设置给定活动记录中的局部变量的值。 参数 ar 与 n 和 lua_getlocal 中的一样 （参见 lua_getlocal）。 lua_setlocal 把栈顶的值赋给变量然后返回变量的名字。 它会将值从栈顶弹出。当索引大于局部变量的个数时，返回 NULL （什么也不弹出）。 lua_setupvalueconst char *lua_setupvalue (lua_State *L, int funcindex, int n); 设置 closure 的 upvalue 的值。 它把栈顶的值弹出并赋于 upvalue 并返回 upvalue 的名字。 参数 funcindex 与 n 和 lua_getupvalue 中的一样 （参见 lua_getupvalue）。当索引大于 upvalue 的个数时，返回 NULL （什么也不弹出）。 4 - The Auxiliary LibraryThe auxiliary library provides several convenient functions to interface C with Lua. While the basic API provides the primitive functions for all interactions between C and Lua, the auxiliary library provides higher-level functions for some common tasks. All functions from the auxiliary library are defined in header file lauxlib.h and have a prefix luaL_. All functions in the auxiliary library are built on top of the basic API, and so they provide nothing that cannot be done with this API. Several functions in the auxiliary library are used to check C function arguments. Their names are always luaL_check or luaL_opt\. All of these functions raise an error if the check is not satisfied. Because the error message is formatted for arguments (e.g., “bad argument #1”), you should not use these functions for other stack values. 4.1 - Functions and TypesHere we list all functions and types from the auxiliary library in alphabetical order. luaL_addcharvoid luaL_addchar (luaL_Buffer *B, char c); Adds the character c to the buffer B (see luaL_Buffer). luaL_addlstringvoid luaL_addlstring (luaL_Buffer *B, const char *s, size_t l); Adds the string pointed to by s with length l to the buffer B (see luaL_Buffer). The string may contain embedded zeros. luaL_addsizevoid luaL_addsize (luaL_Buffer *B, size_t n); Adds to the buffer B (see luaL_Buffer) a string of length n previously copied to the buffer area (see luaL_prepbuffer). luaL_addstringvoid luaL_addstring (luaL_Buffer *B, const char *s); Adds the zero-terminated string pointed to by s to the buffer B (see luaL_Buffer). The string may not contain embedded zeros. luaL_addvaluevoid luaL_addvalue (luaL_Buffer *B); Adds the value at the top of the stack to the buffer B (see luaL_Buffer). Pops the value.This is the only function on string buffers that can (and must) be called with an extra element on the stack, which is the value to be added to the buffer. luaL_argcheckvoid luaL_argcheck (lua_State *L, int cond, int narg, const char *extramsg); Checks whether cond is true. If not, raises an error with the following message, where func is retrieved from the call stack: bad argument #&lt;narg&gt; to &lt;func&gt; (&lt;extramsg&gt;) luaL_argerrorint luaL_argerror (lua_State *L, int narg, const char *extramsg); Raises an error with the following message, where func is retrieved from the call stack: bad argument #&lt;narg&gt; to &lt;func&gt; (&lt;extramsg&gt;) This function never returns, but it is an idiom to use it in C functions as return luaL_argerror(args). luaL_Buffertypedef struct luaL_Buffer luaL_Buffer;Type for a string buffer.A string buffer allows C code to build Lua strings piecemeal. Its pattern of use is as follows:First you declare a variable b of type luaL_Buffer.Then you initialize it with a call luaL_buffinit(L, &amp;b).Then you add string pieces to the buffer calling any of the luaL_add* functions.You finish by calling luaL_pushresult(&amp;b). This call leaves the final string on the top of the stack.During its normal operation, a string buffer uses a variable number of stack slots. So, while using a buffer, you cannot assume that you know where the top of the stack is. You can use the stack between successive calls to buffer operations as long as that use is balanced; that is, when you call a buffer operation, the stack is at the same level it was immediately after the previous buffer operation. (The only exception to this rule is luaL_addvalue.) After calling luaL_pushresult the stack is back to its level when the buffer was initialized, plus the final string on its top. luaL_buffinitvoid luaL_buffinit (lua_State *L, luaL_Buffer *B); Initializes a buffer B. This function does not allocate any space; the buffer must be declared as a variable (see luaL_Buffer). luaL_callmetaint luaL_callmeta (lua_State *L, int obj, const char *e); Calls a metamethod.If the object at index obj has a metatable and this metatable has a field e, this function calls this field and passes the object as its only argument. In this case this function returns 1 and pushes onto the stack the value returned by the call. If there is no metatable or no metamethod, this function returns 0 (without pushing any value on the stack). luaL_checkanyvoid luaL_checkany (lua_State *L, int narg); Checks whether the function has an argument of any type (including nil) at position narg. luaL_checkintint luaL_checkint (lua_State *L, int narg); Checks whether the function argument narg is a number and returns this number cast to an int. luaL_checkintegerlua_Integer luaL_checkinteger (lua_State *L, int narg); Checks whether the function argument narg is a number and returns this number cast to a lua_Integer. luaL_checklonglong luaL_checklong (lua_State *L, int narg); Checks whether the function argument narg is a number and returns this number cast to a long. luaL_checklstringconst char *luaL_checklstring (lua_State *L, int narg, size_t *l); Checks whether the function argument narg is a string and returns this string; if l is not NULL fills *l with the string’s length. luaL_checknumberlua_Number luaL_checknumber (lua_State *L, int narg);Checks whether the function argument narg is a number and returns this number. luaL_checkoptionint luaL_checkoption (lua_State *L, int narg, const char *def, const char *const lst[]); Checks whether the function argument narg is a string and searches for this string in the array lst (which must be NULL-terminated). Returns the index in the array where the string was found. Raises an error if the argument is not a string or if the string cannot be found.If def is not NULL, the function uses def as a default value when there is no argument narg or if this argument is nil.This is a useful function for mapping strings to C enums. (The usual convention in Lua libraries is to use strings instead of numbers to select options.) luaL_checkstackvoid luaL_checkstack (lua_State L, int sz, const char msg);Grows the stack size to top + sz elements, raising an error if the stack cannot grow to that size. msg is an additional text to go into the error message. luaL_checkstringconst char luaL_checkstring (lua_State L, int narg);Checks whether the function argument narg is a string and returns this string. luaL_checktypevoid luaL_checktype (lua_State *L, int narg, int t);Checks whether the function argument narg has type t. luaL_checkudatavoid luaL_checkudata (lua_State L, int narg, const char *tname);Checks whether the function argument narg is a userdata of the type tname (see luaL_newmetatable). luaL_dofileint luaL_dofile (lua_State L, const char filename);Loads and runs the given file. It is defined as the following macro: (luaL_loadfile(L, filename) || lua_pcall(L, 0, LUA_MULTRET, 0)) It returns 0 if there are no errors or 1 in case of errors. luaL_dostringint luaL_dostring (lua_State L, const char str);Loads and runs the given string. It is defined as the following macro: (luaL_loadstring(L, str) || lua_pcall(L, 0, LUA_MULTRET, 0)) It returns 0 if there are no errors or 1 in case of errors. luaL_errorint luaL_error (lua_State *L, const char *fmt, ...); Raises an error. The error message format is given by fmt plus any extra arguments, following the same rules of lua_pushfstring. It also adds at the beginning of the message the file name and the line number where the error occurred, if this information is available.This function never returns, but it is an idiom to use it in C functions as return luaL_error(args). luaL_getmetafieldint luaL_getmetafield (lua_State *L, int obj, const char *e); Pushes onto the stack the field e from the metatable of the object at index obj. If the object does not have a metatable, or if the metatable does not have this field, returns 0 and pushes nothing. luaL_getmetatablevoid luaL_getmetatable (lua_State *L, const char *tname); Pushes onto the stack the metatable associated with name tname in the registry (see luaL_newmetatable). luaL_gsubconst char *luaL_gsub (lua_State *L, const char *s, const char *p, const char *r); Creates a copy of string s by replacing any occurrence of the string p with the string r. Pushes the resulting string on the stack and returns it. luaL_loadbufferint luaL_loadbuffer (lua_State *L, const char *buff, size_t sz, const char *name); Loads a buffer as a Lua chunk. This function uses lua_load to load the chunk in the buffer pointed to by buff with size sz.This function returns the same results as lua_load. name is the chunk name, used for debug information and error messages. luaL_loadfileint luaL_loadfile (lua_State *L, const char *filename); Loads a file as a Lua chunk. This function uses lua_load to load the chunk in the file named filename. If filename is NULL, then it loads from the standard input. The first line in the file is ignored if it starts with a #.This function returns the same results as lua_load, but it has an extra error code LUA_ERRFILE if it cannot open/read the file.As lua_load, this function only loads the chunk; it does not run it. luaL_loadstringint luaL_loadstring (lua_State *L, const char *s); Loads a string as a Lua chunk. This function uses lua_load to load the chunk in the zero-terminated string s.This function returns the same results as lua_load.Also as lua_load, this function only loads the chunk; it does not run it. luaL_newmetatableint luaL_newmetatable (lua_State *L, const char *tname); If the registry already has the key tname, returns 0. Otherwise, creates a new table to be used as a metatable for userdata, adds it to the registry with key tname, and returns 1.In both cases pushes onto the stack the final value associated with tname in the registry. luaL_newstatelua_State *luaL_newstate (void); Creates a new Lua state. It calls lua_newstate with an allocator based on the standard C realloc function and then sets a panic function (see lua_atpanic) that prints an error message to the standard error output in case of fatal errors.Returns the new state, or NULL if there is a memory allocation error. luaL_openlibsvoid luaL_openlibs (lua_State *L); Opens all standard Lua libraries into the given state. luaL_optintint luaL_optint (lua_State *L, int narg, int d);If the function argument narg is a number, returns this number cast to an int. If this argument is absent or is nil, returns d. Otherwise, raises an error. luaL_optintegerlua_Integer luaL_optinteger (lua_State *L, int narg, lua_Integer d); If the function argument narg is a number, returns this number cast to a lua_Integer. If this argument is absent or is nil, returns d. Otherwise, raises an error. luaL_optlonglong luaL_optlong (lua_State *L, int narg, long d); If the function argument narg is a number, returns this number cast to a long. If this argument is absent or is nil, returns d. Otherwise, raises an error. luaL_optlstringconst char *luaL_optlstring (lua_State *L, int narg, const char *d, size_t *l); If the function argument narg is a string, returns this string. If this argument is absent or is nil, returns d. Otherwise, raises an error.If l is not NULL, fills the position *l with the results’s length. luaL_optnumberlua_Number luaL_optnumber (lua_State *L, int narg, lua_Number d); If the function argument narg is a number, returns this number. If this argument is absent or is nil, returns d. Otherwise, raises an error. luaL_optstringconst char *luaL_optstring (lua_State *L, int narg, const char *d); If the function argument narg is a string, returns this string. If this argument is absent or is nil, returns d. Otherwise, raises an error. luaL_prepbufferchar *luaL_prepbuffer (luaL_Buffer *B); Returns an address to a space of size LUAL_BUFFERSIZE where you can copy a string to be added to buffer B (see luaL_Buffer). After copying the string into this space you must call luaL_addsize with the size of the string to actually add it to the buffer. luaL_pushresultvoid luaL_pushresult (luaL_Buffer *B); Finishes the use of buffer B leaving the final string on the top of the stack. luaL_refint luaL_ref (lua_State *L, int t); Creates and returns a reference, in the table at index t, for the object at the top of the stack (and pops the object).A reference is a unique integer key. As long as you do not manually add integer keys into table t, luaL_ref ensures the uniqueness of the key it returns. You can retrieve an object referred by reference r by calling lua_rawgeti(L, t, r). Function luaL_unref frees a reference and its associated object. If the object at the top of the stack is nil, luaL_ref returns the constant LUA_REFNIL. The constant LUA_NOREF is guaranteed to be different from any reference returned by luaL_ref. luaL_Regtypedef struct luaL_Reg { const char *name; lua_CFunction func;} luaL_Reg; Type for arrays of functions to be registered by luaL_register. name is the function name and func is a pointer to the function. Any array of luaL_Reg must end with an sentinel entry in which both name and func are NULL. luaL_registervoid luaL_register (lua_State *L, const char *libname, const luaL_Reg *l); Opens a library. When called with libname equal to NULL, it simply registers all functions in the list l (see luaL_Reg) into the table on the top of the stack.When called with a non-null libname, luaL_register creates a new table t, sets it as the value of the global variable libname, sets it as the value of package.loaded[libname], and registers on it all functions in the list l. If there is a table in package.loaded[libname] or in variable libname, reuses this table instead of creating a new one.In any case the function leaves the table on the top of the stack. 12345678910111213141516static int foo(lua_State *L)&#123; lua_pushnumber(L, 1); return 1;&#125;static const struct lua_Reg modulename[] = &#123; &#123;"foo", foo&#125;, &#123;NULL, NULL&#125;,&#125;;int luaopen_modulename(lua_State *L)&#123; luaL_newlib(L, modulename);// 5.2之前使用的Lua_register(L, "modulename", modulename); return 1;&#125; 工程目录 https://github.com/metanqy/binary_world.git luaL_typenameconst char luaL_typename (lua_State L, int idx);Returns the name of the type of the value at index idx. luaL_typerrorint luaL_typerror (lua_State L, int narg, const char tname);Generates an error with a message like the following: location: bad argument narg to &#39;func&#39; (tname expected, got rt) where location is produced by luaL_where, func is the name of the current function, and rt is the type name of the actual argument. luaL_unrefvoid luaL_unref (lua_State *L, int t, int ref); Releases reference ref from the table at index t (see luaL_ref). The entry is removed from the table, so that the referred object can be collected. The reference ref is also freed to be used again. If ref is LUA_NOREF or LUA_REFNIL, luaL_unref does nothing. luaL_wherevoid luaL_where (lua_State *L, int lvl); Pushes onto the stack a string identifying the current position of the control at level lvl in the call stack. Typically this string has the following format: chunkname:currentline: Level 0 is the running function, level 1 is the function that called the running function, etc.This function is used to build a prefix for error messages. Standard LibrariesThe standard Lua libraries provide useful functions that are implemented directly through the C API. Some of these functions provide essential services to the language (e.g., type and getmetatable); others provide access to “outside” services (e.g., I/O); and others could be implemented in Lua itself, but are quite useful or have critical performance requirements that deserve an implementation in C (e.g., sort). All libraries are implemented through the official C API and are provided as separate C modules. Currently, Lua has the following standard libraries: basic library;package library;string manipulation;table manipulation;mathematical functions (sin, log, etc.);input and output;operating system facilities;debug facilities.Except for the basic and package libraries, each library provides all its functions as fields of a global table or as methods of its objects. To have access to these libraries, the C host program should call the luaL_openlibs function, which opens all standard libraries. Alternatively, it can open them individually by calling luaopen_base (for the basic library), luaopen_package (for the package library), luaopen_string (for the string library), luaopen_table (for the table library), luaopen_math (for the mathematical library), luaopen_io (for the I/O and the Operating System libraries), and luaopen_debug (for the debug library). These functions are declared in lualib.h and should not be called directly: you must call them like any other Lua C function, e.g., by using lua_call. The basic library provides some core functions to Lua. If you do not include this library in your application, you should check carefully whether you need to provide implementations for some of its facilities. assert (v [, message])Issues an error when the value of its argument v is false (i.e., nil or false); otherwise, returns all its arguments. message is an error message; when absent, it defaults to “assertion failed!”collectgarbage (opt [, arg])This function is a generic interface to the garbage collector. It performs different functions according to its first argument, opt: “stop”: stops the garbage collector.“restart”: restarts the garbage collector.“collect”: performs a full garbage-collection cycle.“count”: returns the total memory in use by Lua (in Kbytes).“step”: performs a garbage-collection step. The step “size” is controlled by arg (larger values mean more steps) in a non-specified way. If you want to control the step size you must experimentally tune the value of arg. Returns true if the step finished a collection cycle.“setpause”: sets arg/100 as the new value for the pause of the collector (see §2.10).“setstepmul”: sets arg/100 as the new value for the step multiplier of the collector (see §2.10).dofile (filename)Opens the named file and executes its contents as a Lua chunk. When called without arguments, dofile executes the contents of the standard input (stdin). Returns all values returned by the chunk. In case of errors, dofile propagates the error to its caller (that is, dofile does not run in protected mode).error (message [, level])Terminates the last protected function called and returns message as the error message. Function error never returns.Usually, error adds some information about the error position at the beginning of the message. The level argument specifies how to get the error position. With level 1 (the default), the error position is where the error function was called. Level 2 points the error to where the function that called error was called; and so on. Passing a level 0 avoids the addition of error position information to the message. _GA global variable (not a function) that holds the global environment (that is, _G._G = _G). Lua itself does not use this variable; changing its value does not affect any environment, nor vice-versa. (Use setfenv to change environments.)getfenv (f)Returns the current environment in use by the function. f can be a Lua function or a number that specifies the function at that stack level: Level 1 is the function calling getfenv. If the given function is not a Lua function, or if f is 0, getfenv returns the global environment. The default for f is 1.getmetatable (object)If object does not have a metatable, returns nil. Otherwise, if the object’s metatable has a “__metatable” field, returns the associated value. Otherwise, returns the metatable of the given object. ipairs (t)Returns three values: an iterator function, the table t, and 0, so that the construction for i,v in ipairs(t) do body end will iterate over the pairs (1,t[1]), (2,t[2]), ···, up to the first integer key absent from the table. load (func [, chunkname])Loads a chunk using function func to get its pieces. Each call to func must return a string that concatenates with previous results. A return of nil (or no value) signals the end of the chunk. If there are no errors, returns the compiled chunk as a function; otherwise, returns nil plus the error message. The environment of the returned function is the global environment. chunkname is used as the chunk name for error messages and debug information. loadfile ([filename])Similar to load, but gets the chunk from file filename or from the standard input, if no file name is given. loadstring (string [, chunkname])Similar to load, but gets the chunk from the given string. To load and run a given string, use the idiom assert(loadstring(s))() next (table [, index])Allows a program to traverse all fields of a table. Its first argument is a table and its second argument is an index in this table. next returns the next index of the table and its associated value. When called with nil as its second argument, next returns an initial index and its associated value. When called with the last index, or with nil in an empty table, next returns nil. If the second argument is absent, then it is interpreted as nil. In particular, you can use next(t) to check whether a table is empty. The order in which the indices are enumerated is not specified, even for numeric indices. (To traverse a table in numeric order, use a numerical for or the ipairs function.) The behavior of next is undefined if, during the traversal, you assign any value to a non-existent field in the table. You may however modify existing fields. In particular, you may clear existing fields. pairs (t)Returns three values: the next function, the table t, and nil, so that the construction for k,v in pairs(t) do body end will iterate over all key–value pairs of table t. See function next for the caveats of modifying the table during its traversal. pcall (f, arg1, ···)Calls function f with the given arguments in protected mode. This means that any error inside f is not propagated; instead, pcall catches the error and returns a status code. Its first result is the status code (a boolean), which is true if the call succeeds without errors. In such case, pcall also returns all results from the call, after this first result. In case of any error, pcall returns false plus the error message. print (···)Receives any number of arguments, and prints their values to stdout, using the tostring function to convert them to strings. print is not intended for formatted output, but only as a quick way to show a value, typically for debugging. For formatted output, use string.format.rawequal (v1, v2)Checks whether v1 is equal to v2, without invoking any metamethod. Returns a boolean.rawget (table, index)Gets the real value of table[index], without invoking any metamethod. table must be a table; index may be any value.rawset (table, index, value)Sets the real value of table[index] to value, without invoking any metamethod. table must be a table, index any value different from nil, and value any Lua value.This function returns table. select (index, ···)If index is a number, returns all arguments after argument number index. Otherwise, index must be the string “#”, and select returns the total number of extra arguments it received. setfenv (f, table)Sets the environment to be used by the given function. f can be a Lua function or a number that specifies the function at that stack level: Level 1 is the function calling setfenv. setfenv returns the given function. As a special case, when f is 0 setfenv changes the environment of the running thread. In this case, setfenv returns no values. setmetatable (table, metatable)Sets the metatable for the given table. (You cannot change the metatable of other types from Lua, only from C.) If metatable is nil, removes the metatable of the given table. If the original metatable has a “__metatable” field, raises an error. This function returns table. tonumber (e [, base])Tries to convert its argument to a number. If the argument is already a number or a string convertible to a number, then tonumber returns this number; otherwise, it returns nil.An optional argument specifies the base to interpret the numeral. The base may be any integer between 2 and 36, inclusive. In bases above 10, the letter ‘A’ (in either upper or lower case) represents 10, ‘B’ represents 11, and so forth, with ‘Z’ representing 35. In base 10 (the default), the number may have a decimal part, as well as an optional exponent part (see §2.1). In other bases, only unsigned integers are accepted. tostring (e)Receives an argument of any type and converts it to a string in a reasonable format. For complete control of how numbers are converted, use string.format.If the metatable of e has a “__tostring” field, then tostring calls the corresponding value with e as argument, and uses the result of the call as its result. type (v)Returns the type of its only argument, coded as a string. The possible results of this function are “nil” (a string, not the value nil), “number”, “string”, “boolean”, “table”, “function”, “thread”, and “userdata”.unpack (list [, i [, j]])Returns the elements from the given table. This function is equivalent to return list[i], list[i+1], ···, list[j]except that the above code can be written only for a fixed number of elements. By default, i is 1 and j is the length of the list, as defined by the length operator (see §2.5.5). _VERSIONA global variable (not a function) that holds a string containing the current interpreter version. The current contents of this variable is “Lua 5.1”.xpcall (f, err)This function is similar to pcall, except that you can set a new error handler. xpcall calls function f in protected mode, using err as the error handler. Any error inside f is not propagated; instead, xpcall catches the error, calls the err function with the original error object, and returns a status code. Its first result is the status code (a boolean), which is true if the call succeeds without errors. In this case, xpcall also returns all results from the call, after this first result. In case of any error, xpcall returns false plus the result from err. Coroutine ManipulationThe operations related to coroutines comprise a sub-library of the basic library and come inside the table coroutine. coroutine.create (f)Creates a new coroutine, with body f. f must be a Lua function. Returns this new coroutine, an object with type “thread”. coroutine.resume (co [, val1, ···])Starts or continues the execution of coroutine co. The first time you resume a coroutine, it starts running its body. The values val1, ··· are passed as the arguments to the body function. If the coroutine has yielded, resume restarts it; the values val1, ··· are passed as the results from the yield. If the coroutine runs without any errors, resume returns true plus any values passed to yield (if the coroutine yields) or any values returned by the body function (if the coroutine terminates). If there is any error, resume returns false plus the error message. coroutine.running ()Returns the running coroutine, or nil when called by the main thread. coroutine.status (co)Returns the status of coroutine co, as a string: “running”, if the coroutine is running (that is, it called status); “suspended”, if the coroutine is suspended in a call to yield, or if it has not started running yet; “normal” if the coroutine is active but not running (that is, it has resumed another coroutine); and “dead” if the coroutine has finished its body function, or if it has stopped with an error. coroutine.wrap (f)Creates a new coroutine, with body f. f must be a Lua function. Returns a function that resumes the coroutine each time it is called. Any arguments passed to the function behave as the extra arguments to resume. Returns the same values returned by resume, except the first boolean. In case of error, propagates the error. coroutine.yield (···)Suspends the execution of the calling coroutine. The coroutine cannot be running a C function, a metamethod, or an iterator. Any arguments to yield are passed as extra results to resume. ModulesThe package library provides basic facilities for loading and building modules in Lua. It exports two of its functions directly in the global environment: require and module. Everything else is exported in a table package.module (name [, ···])Creates a module. If there is a table in package.loaded[name], this table is the module. Otherwise, if there is a global table t with the given name, this table is the module. Otherwise creates a new table t and sets it as the value of the global name and the value of package.loaded[name]. This function also initializes t._NAME with the given name, t._M with the module (t itself), and t._PACKAGE with the package name (the full module name minus last component; see below). Finally, module sets t as the new environment of the current function and the new value of package.loaded[name], so that require returns t. If name is a compound name (that is, one with components separated by dots), module creates (or reuses, if they already exist) tables for each component. For instance, if name is a.b.c, then module stores the module table in field c of field b of global a. This function may receive optional options after the module name, where each option is a function to be applied over the module. require (modname)Loads the given module. The function starts by looking into the package.loaded table to determine whether modname is already loaded. If it is, then require returns the value stored at package.loaded[modname]. Otherwise, it tries to find a loader for the module. To find a loader, first require queries package.preload[modname]. If it has a value, this value (which should be a function) is the loader. Otherwise require searches for a Lua loader using the path stored in package.path. If that also fails, it searches for a C loader using the path stored in package.cpath. If that also fails, it tries an all-in-one loader (see below). When loading a C library, require first uses a dynamic link facility to link the application with the library. Then it tries to find a C function inside this library to be used as the loader. The name of this C function is the string “luaopen_” concatenated with a copy of the module name where each dot is replaced by an underscore. Moreover, if the module name has a hyphen, its prefix up to (and including) the first hyphen is removed. For instance, if the module name is a.v1-b.c, the function name will be luaopen_b_c. If require finds neither a Lua library nor a C library for a module, it calls the all-in-one loader. This loader searches the C path for a library for the root name of the given module. For instance, when requiring a.b.c, it will search for a C library for a. If found, it looks into it for an open function for the submodule; in our example, that would be luaopen_a_b_c. With this facility, a package can pack several C submodules into one single library, with each submodule keeping its original open function. Once a loader is found, require calls the loader with a single argument, modname. If the loader returns any value, require assigns the returned value to package.loaded[modname]. If the loader returns no value and has not assigned any value to package.loaded[modname], then require assigns true to this entry. In any case, require returns the final value of package.loaded[modname]. If there is any error loading or running the module, or if it cannot find any loader for the module, then require signals an error. package.cpathThe path used by require to search for a C loader. Lua initializes the C path package.cpath in the same way it initializes the Lua path package.path, using the environment variable LUA_CPATH (plus another default path defined in luaconf.h). package.loadedA table used by require to control which modules are already loaded. When you require a module modname and package.loaded[modname] is not false, require simply returns the value stored there. package.loadlib (libname, funcname)Dynamically links the host program with the C library libname. Inside this library, looks for a function funcname and returns this function as a C function. (So, funcname must follow the protocol (see lua_CFunction)). This is a low-level function. It completely bypasses the package and module system. Unlike require, it does not perform any path searching and does not automatically adds extensions. libname must be the complete file name of the C library, including if necessary a path and extension. funcname must be the exact name exported by the C library (which may depend on the C compiler and linker used). This function is not supported by ANSI C. As such, it is only available on some platforms (Windows, Linux, Mac OS X, Solaris, BSD, plus other Unix systems that support the dlfcn standard). package.pathThe path used by require to search for a Lua loader. At start-up, Lua initializes this variable with the value of the environment variable LUA_PATH or with a default path defined in luaconf.h, if the environment variable is not defined. Any “;;” in the value of the environment variable is replaced by the default path. A path is a sequence of templates separated by semicolons. For each template, require will change each interrogation mark in the template by filename, which is modname with each dot replaced by a “directory separator” (such as “/“ in Unix); then it will try to load the resulting file name. So, for instance, if the Lua path is &quot;./?.lua;./?.lc;/usr/local/?/init.lua&quot; the search for a Lua loader for module foo will try to load the files ./foo.lua, ./foo.lc, and /usr/local/foo/init.lua, in that order. package.preloadA table to store loaders for specific modules (see require). package.seeall (module)Sets a metatable for module with its __index field referring to the global environment, so that this module inherits values from the global environment. To be used as an option to function module. 5.4 - String ManipulationThis library provides generic functions for string manipulation, such as finding and extracting substrings, and pattern matching. When indexing a string in Lua, the first character is at position 1 (not at 0, as in C). Indices are allowed to be negative and are interpreted as indexing backwards, from the end of the string. Thus, the last character is at position -1, and so on. The string library provides all its functions inside the table string. It also sets a metatable for strings where the __index field points to the string table. Therefore, you can use the string functions in object-oriented style. For instance, string.byte(s, i) can be written as s:byte(i). string.byte (s [, i [, j]])Returns the internal numerical codes of the characters s[i], s[i+1], ···, s[j]. The default value for i is 1; the default value for j is i.Note that numerical codes are not necessarily portable across platforms. string.char (···)Receives zero or more integers. Returns a string with length equal to the number of arguments, in which each character has the internal numerical code equal to its corresponding argument.Note that numerical codes are not necessarily portable across platforms. string.dump (function)Returns a string containing a binary representation of the given function, so that a later loadstring on this string returns a copy of the function. function must be a Lua function without upvalues. string.find (s, pattern [, init [, plain]])Looks for the first match of pattern in the string s. If it finds a match, then find returns the indices of s where this occurrence starts and ends; otherwise, it returns nil. A third, optional numerical argument init specifies where to start the search; its default value is 1 and may be negative. A value of true as a fourth, optional argument plain turns off the pattern matching facilities, so the function does a plain “find substring” operation, with no characters in pattern being considered “magic”. Note that if plain is given, then init must be given as well.If the pattern has captures, then in a successful match the captured values are also returned, after the two indices. string.format (formatstring, ···)Returns a formatted version of its variable number of arguments following the description given in its first argument (which must be a string). The format string follows the same rules as the printf family of standard C functions. The only differences are that the options/modifiers *, l, L, n, p, and h are not supported and that there is an extra option, q. The q option formats a string in a form suitable to be safely read back by the Lua interpreter: the string is written between double quotes, and all double quotes, newlines, embedded zeros, and backslashes in the string are correctly escaped when written. For instance, the call string.format(‘%q’, ‘a string with “quotes” and \n new line’)will produce the string: &quot;a string with \&quot;quotes\&quot; and \ new line&quot; The options c, d, E, e, f, g, G, i, o, u, X, and x all expect a number as argument, whereas q and s expect a string. This function does not accept string values containing embedded zeros. string.gmatch (s, pattern)Returns an iterator function that, each time it is called, returns the next captures from pattern over string s.If pattern specifies no captures, then the whole match is produced in each call. As an example, the following loop s = &quot;hello world from Lua&quot; for w in string.gmatch(s, &quot;%a+&quot;) do print(w) end will iterate over all the words from string s, printing one per line. The next example collects all pairs key=value from the given string into a table: t = {} s = &quot;from=world, to=Lua&quot; for k, v in string.gmatch(s, &quot;(%w+)=(%w+)&quot;) do t[k] = v end string.gsub (s, pattern, repl [, n])Returns a copy of s in which all occurrences of the pattern have been replaced by a replacement string specified by repl, which may be a string, a table, or a function. gsub also returns, as its second value, the total number of substitutions made.If repl is a string, then its value is used for replacement. The character % works as an escape character: any sequence in repl of the form %n, with n between 1 and 9, stands for the value of the n-th captured substring (see below). The sequence %0 stands for the whole match. The sequence %% stands for a single %. If repl is a table, then the table is queried for every match, using the first capture as the key; if the pattern specifies no captures, then the whole match is used as the key. If repl is a function, then this function is called every time a match occurs, with all captured substrings passed as arguments, in order; if the pattern specifies no captures, then the whole match is passed as a sole argument. If the value returned by the table query or by the function call is a string or a number, then it is used as the replacement string; otherwise, if it is false or nil, then there is no replacement (that is, the original match is kept in the string). The optional last parameter n limits the maximum number of substitutions to occur. For instance, when n is 1 only the first occurrence of pattern is replaced. Here are some examples: x = string.gsub(&quot;hello world&quot;, &quot;(%w+)&quot;, &quot;%1 %1&quot;) --&gt; x=&quot;hello hello world world&quot; x = string.gsub(&quot;hello world&quot;, &quot;%w+&quot;, &quot;%0 %0&quot;, 1) --&gt; x=&quot;hello hello world&quot; x = string.gsub(&quot;hello world from Lua&quot;, &quot;(%w+)%s*(%w+)&quot;, &quot;%2 %1&quot;) --&gt; x=&quot;world hello Lua from&quot; x = string.gsub(&quot;home = $HOME, user = $USER&quot;, &quot;%$(%w+)&quot;, os.getenv) --&gt; x=&quot;home = /home/roberto, user = roberto&quot; x = string.gsub(&quot;4+5 = $return 4+5$&quot;, &quot;%$(.-)%$&quot;, function (s) return loadstring(s)() end) --&gt; x=&quot;4+5 = 9&quot; local t = {name=&quot;lua&quot;, version=&quot;5.1&quot;} x = string.gsub(&quot;$name%-$version.tar.gz&quot;, &quot;%$(%w+)&quot;, t) --&gt; x=&quot;lua-5.1.tar.gz&quot; string.len (s)Receives a string and returns its length. The empty string “” has length 0. Embedded zeros are counted, so “a\000bc\000” has length 5.string.lower (s)Receives a string and returns a copy of this string with all uppercase letters changed to lowercase. All other characters are left unchanged. The definition of what an uppercase letter is depends on the current locale.string.match (s, pattern [, init])Looks for the first match of pattern in the string s. If it finds one, then match returns the captures from the pattern; otherwise it returns nil. If pattern specifies no captures, then the whole match is returned. A third, optional numerical argument init specifies where to start the search; its default value is 1 and may be negative.string.rep (s, n)Returns a string that is the concatenation of n copies of the string s.string.reverse (s)Returns a string that is the string s reversed.string.sub (s, i [, j])Returns the substring of s that starts at i and continues until j; i and j may be negative. If j is absent, then it is assumed to be equal to -1 (which is the same as the string length). In particular, the call string.sub(s,1,j) returns a prefix of s with length j, and string.sub(s, -i) returns a suffix of s with length i.string.upper (s)Receives a string and returns a copy of this string with all lowercase letters changed to uppercase. All other characters are left unchanged. The definition of what a lowercase letter is depends on the current locale.5.4.1 - PatternsCharacter Class:A character class is used to represent a set of characters. The following combinations are allowed in describing a character class: x: (where x is not one of the magic characters ^$()%.[]*+-?) represents the character x itself..: (a dot) represents all characters.%a: represents all letters.%c: represents all control characters.%d: represents all digits.%l: represents all lowercase letters.%p: represents all punctuation characters.%s: represents all space characters.%u: represents all uppercase letters.%w: represents all alphanumeric characters.%x: represents all hexadecimal digits.%z: represents the character with representation 0.%x: (where x is any non-alphanumeric character) represents the character x. This is the standard way to escape the magic characters. Any punctuation character (even the non magic) can be preceded by a ‘%’ when used to represent itself in a pattern.[set]: represents the class which is the union of all characters in set. A range of characters may be specified by separating the end characters of the range with a ‘-‘. All classes %x described above may also be used as components in set. All other characters in set represent themselves. For example, [%w] (or [%w]) represents all alphanumeric characters plus the underscore, [0-7] represents the octal digits, and [0-7%l%-] represents the octal digits plus the lowercase letters plus the ‘-‘ character.The interaction between ranges and classes is not defined. Therefore, patterns like [%a-z] or [a-%%] have no meaning. set. represents the complement of set, where set is interpreted as above. &#8617; For all classes represented by single letters (%a, %c, etc.), the corresponding uppercase letter represents the complement of the class. For instance, %S represents all non-space characters. The definitions of letter, space, and other character groups depend on the current locale. In particular, the class [a-z] may not be equivalent to %l. Pattern Item:A pattern item may be a single character class, which matches any single character in the class;a single character class followed by ‘‘, which matches 0 or more repetitions of characters in the class. These repetition items will always match the longest possible sequence;a single character class followed by ‘+’, which matches 1 or more repetitions of characters in the class. These repetition items will always match the longest possible sequence;a single character class followed by ‘-‘, which also matches 0 or more repetitions of characters in the class. Unlike ‘‘, these repetition items will always match the shortest possible sequence;a single character class followed by ‘?’, which matches 0 or 1 occurrence of a character in the class;%n, for n between 1 and 9; such item matches a substring equal to the n-th captured string (see below);%bxy, where x and y are two distinct characters; such item matches strings that start with x, end with y, and where the x and y are balanced. This means that, if one reads the string from left to right, counting +1 for an x and -1 for a y, the ending y is the first y where the count reaches 0. For instance, the item %b() matches expressions with balanced parentheses.Pattern:A pattern is a sequence of pattern items. A ‘^’ at the beginning of a pattern anchors the match at the beginning of the subject string. A ‘$’ at the end of a pattern anchors the match at the end of the subject string. At other positions, ‘^’ and ‘$’ have no special meaning and represent themselves. Captures:A pattern may contain sub-patterns enclosed in parentheses; they describe captures. When a match succeeds, the substrings of the subject string that match captures are stored (captured) for future use. Captures are numbered according to their left parentheses. For instance, in the pattern “(a(.)%w(%s))”, the part of the string matching “a(.)%w(%s)” is stored as the first capture (and therefore has number 1); the character matching “.” is captured with number 2, and the part matching “%s*” has number 3. As a special case, the empty capture () captures the current string position (a number). For instance, if we apply the pattern “()aa()” on the string “flaaap”, there will be two captures: 3 and 5. A pattern cannot contain embedded zeros. Use %z instead. 5.5 - Table ManipulationThis library provides generic functions for table manipulation. It provides all its functions inside the table table. Most functions in the table library assume that the table represents an array or a list. For these functions, when we talk about the “length” of a table we mean the result of the length operator. table.concat (table [, sep [, i [, j]]])Given an array where all elements are strings or numbers, returns table[i]..sep..table[i+1] ··· sep..table[j]. The default value for sep is the empty string, the default for i is 1, and the default for j is the length of the table. If i is greater than j, returns the empty string.table.insert (table, [pos,] value)Inserts element value at position pos in table, shifting up other elements to open space, if necessary. The default value for pos is n+1, where n is the length of the table (see §2.5.5), so that a call table.insert(t,x) inserts x at the end of table t. table.maxn (table)Returns the largest positive numerical index of the given table, or zero if the table has no positive numerical indices. (To do its job this function does a linear traversal of the whole table.) table.remove (table [, pos])Removes from table the element at position pos, shifting down other elements to close the space, if necessary. Returns the value of the removed element. The default value for pos is n, where n is the length of the table, so that a call table.remove(t) removes the last element of table t. table.sort (table [, comp])Sorts table elements in a given order, in-place, from table[1] to table[n], where n is the length of the table. If comp is given, then it must be a function that receives two table elements, and returns true when the first is less than the second (so that not comp(a[i+1],a[i]) will be true after the sort). If comp is not given, then the standard Lua operator &lt; is used instead.The sort algorithm is not stable; that is, elements considered equal by the given order may have their relative positions changed by the sort. 5.6 - Mathematical FunctionsThis library is an interface to the standard C math library. It provides all its functions inside the table math. math.abs (x)Returns the absolute value of x. math.acos (x)Returns the arc cosine of x (in radians). math.asin (x)Returns the arc sine of x (in radians). math.atan (x)Returns the arc tangent of x (in radians). math.atan2 (x, y)Returns the arc tangent of x/y (in radians), but uses the signs of both parameters to find the quadrant of the result. (It also handles correctly the case of y being zero.) math.ceil (x)Returns the smallest integer larger than or equal to x. math.cos (x)Returns the cosine of x (assumed to be in radians). math.cosh (x)Returns the hyperbolic cosine of x. math.deg (x)Returns the angle x (given in radians) in degrees. math.exp (x)Returns the the value ex. math.floor (x)Returns the largest integer smaller than or equal to x. math.fmod (x, y)Returns the remainder of the division of x by y. math.frexp (x)Returns m and e such that x = m2e, e is an integer and the absolute value of m is in the range [0.5, 1) (or zero when x is zero). math.hugeThe value HUGE_VAL, a value larger than or equal to any other numerical value. math.ldexp (m, e)Returns m2e (e should be an integer). math.log (x)Returns the natural logarithm of x. math.log10 (x)Returns the base-10 logarithm of x. math.max (x, ···)Returns the maximum value among its arguments. math.min (x, ···)Returns the minimum value among its arguments. math.modf (x)Returns two numbers, the integral part of x and the fractional part of x. math.piThe value of pi. math.pow (x, y)Returns xy. (You can also use the expression x^y to compute this value.) math.rad (x)Returns the angle x (given in degrees) in radians. math.random ([m [, n]])This function is an interface to the simple pseudo-random generator function rand provided by ANSI C. (No guarantees can be given for its statistical properties.) When called without arguments, returns a pseudo-random real number in the range [0,1). When called with a number m, math.random returns a pseudo-random integer in the range [1, m]. When called with two numbers m and n, math.random returns a pseudo-random integer in the range [m, n]. math.randomseed (x)Sets x as the “seed” for the pseudo-random generator: equal seeds produce equal sequences of numbers. math.sin (x)Returns the sine of x (assumed to be in radians). math.sinh (x)Returns the hyperbolic sine of x. math.sqrt (x)Returns the square root of x. (You can also use the expression x^0.5 to compute this value.) math.tan (x)Returns the tangent of x (assumed to be in radians). math.tanh (x)Returns the hyperbolic tangent of x. 5.7 - Input and Output FacilitiesThe I/O library provides two different styles for file manipulation. The first one uses implicit file descriptors; that is, there are operations to set a default input file and a default output file, and all input/output operations are over these default files. The second style uses explicit file descriptors. When using implicit file descriptors, all operations are supplied by table io. When using explicit file descriptors, the operation io.open returns a file descriptor and then all operations are supplied as methods of the file descriptor. The table io also provides three predefined file descriptors with their usual meanings from C: io.stdin, io.stdout, and io.stderr. Unless otherwise stated, all I/O functions return nil on failure (plus an error message as a second result) and some value different from nil on success. io.close ([file])Equivalent to file:close(). Without a file, closes the default output file. io.flush ()Equivalent to file:flush over the default output file. io.input ([file])When called with a file name, it opens the named file (in text mode), and sets its handle as the default input file. When called with a file handle, it simply sets this file handle as the default input file. When called without parameters, it returns the current default input file. In case of errors this function raises the error, instead of returning an error code. io.lines ([filename])Opens the given file name in read mode and returns an iterator function that, each time it is called, returns a new line from the file. Therefore, the construction for line in io.lines(filename) do body end will iterate over all lines of the file. When the iterator function detects the end of file, it returns nil (to finish the loop) and automatically closes the file. The call io.lines() (with no file name) is equivalent to io.input():lines(); that is, it iterates over the lines of the default input file. In this case it does not close the file when the loop ends. io.open (filename [, mode])This function opens a file, in the mode specified in the string mode. It returns a new file handle, or, in case of errors, nil plus an error message. The mode string can be any of the following: “r”: read mode (the default);“w”: write mode;“a”: append mode;“r+”: update mode, all previous data is preserved;“w+”: update mode, all previous data is erased;“a+”: append update mode, previous data is preserved, writing is only allowed at the end of file.The mode string may also have a ‘b’ at the end, which is needed in some systems to open the file in binary mode. This string is exactly what is used in the standard C function fopen. io.output ([file])Similar to io.input, but operates over the default output file. io.popen (prog [, mode])Starts program prog in a separated process and returns a file handle that you can use to read data from this program (if mode is “r”, the default) or to write data to this program (if mode is “w”). This function is system dependent and is not available on all platforms. io.read (···)Equivalent to io.input():read. io.tmpfile ()Returns a handle for a temporary file. This file is opened in update mode and it is automatically removed when the program ends. io.type (obj)Checks whether obj is a valid file handle. Returns the string “file” if obj is an open file handle, “closed file” if obj is a closed file handle, or nil if obj is not a file handle. io.write (···)Equivalent to io.output():write. file:close ()Closes file. Note that files are automatically closed when their handles are garbage collected, but that takes an unpredictable amount of time to happen. file:flush ()Saves any written data to file. file:lines ()Returns an iterator function that, each time it is called, returns a new line from the file. Therefore, the construction for line in file:lines() do body end will iterate over all lines of the file. (Unlike io.lines, this function does not close the file when the loop ends.) file:read (···)Reads the file file, according to the given formats, which specify what to read. For each format, the function returns a string (or a number) with the characters read, or nil if it cannot read data with the specified format. When called without formats, it uses a default format that reads the entire next line (see below). The available formats are “n”: reads a number; this is the only format that returns a number instead of a string.“a”: reads the whole file, starting at the current position. On end of file, it returns the empty string.“*l”: reads the next line (skipping the end of line), returning nil on end of file. This is the default format.number: reads a string with up to this number of characters, returning nil on end of file. If number is zero, it reads nothing and returns an empty string, or nil on end of file.file:seek ([whence] [, offset])Sets and gets the file position, measured from the beginning of the file, to the position given by offset plus a base specified by the string whence, as follows: “set”: base is position 0 (beginning of the file);“cur”: base is current position;“end”: base is end of file;In case of success, function seek returns the final file position, measured in bytes from the beginning of the file. If this function fails, it returns nil, plus a string describing the error. The default value for whence is “cur”, and for offset is 0. Therefore, the call file:seek() returns the current file position, without changing it; the call file:seek(“set”) sets the position to the beginning of the file (and returns 0); and the call file:seek(“end”) sets the position to the end of the file, and returns its size. file:setvbuf (mode [, size])Sets the buffering mode for an output file. There are three available modes: “no”: no buffering; the result of any output operation appears immediately.“full”: full buffering; output operation is performed only when the buffer is full (or when you explicitly flush the file (see io.flush)).“line”: line buffering; output is buffered until a newline is output or there is any input from some special files (such as a terminal device).For the last two cases, sizes specifies the size of the buffer, in bytes. The default is an appropriate size. file:write (···)Writes the value of each of its arguments to the file. The arguments must be strings or numbers. To write other values, use tostring or string.format before write. 5.8 - Operating System FacilitiesThis library is implemented through table os. os.clock ()Returns an approximation of the amount in seconds of CPU time used by the program. os.date ([format [, time]])Returns a string or a table containing date and time, formatted according to the given string format. If the time argument is present, this is the time to be formatted (see the os.time function for a description of this value). Otherwise, date formats the current time. If format starts with ‘!’, then the date is formatted in Coordinated Universal Time. After this optional character, if format is the string “*t”, then date returns a table with the following fields: year (four digits), month (1—12), day (1—31), hour (0—23), min (0—59), sec (0—61), wday (weekday, Sunday is 1), yday (day of the year), and isdst (daylight saving flag, a boolean). If format is not “*t”, then date returns the date as a string, formatted according to the same rules as the C function strftime. When called without arguments, date returns a reasonable date and time representation that depends on the host system and on the current locale (that is, os.date() is equivalent to os.date(“%c”)). os.difftime (t2, t1)Returns the number of seconds from time t1 to time t2. In POSIX, Windows, and some other systems, this value is exactly t2-t1. os.execute ([command])This function is equivalent to the C function system. It passes command to be executed by an operating system shell. It returns a status code, which is system-dependent. If command is absent, then it returns nonzero if a shell is available and zero otherwise. os.exit ([code])Calls the C function exit, with an optional code, to terminate the host program. The default value for code is the success code. os.getenv (varname)Returns the value of the process environment variable varname, or nil if the variable is not defined. os.remove (filename)Deletes the file or directory with the given name. Directories must be empty to be removed. If this function fails, it returns nil, plus a string describing the error. os.rename (oldname, newname)Renames file or directory named oldname to newname. If this function fails, it returns nil, plus a string describing the error. os.setlocale (locale [, category])Sets the current locale of the program. locale is a string specifying a locale; category is an optional string describing which category to change: “all”, “collate”, “ctype”, “monetary”, “numeric”, or “time”; the default category is “all”. The function returns the name of the new locale, or nil if the request cannot be honored. When called with nil as the first argument, this function only returns the name of the current locale for the given category. os.time ([table])Returns the current time when called without arguments, or a time representing the date and time specified by the given table. This table must have fields year, month, and day, and may have fields hour, min, sec, and isdst (for a description of these fields, see the os.date function). The returned value is a number, whose meaning depends on your system. In POSIX, Windows, and some other systems, this number counts the number of seconds since some given start time (the “epoch”). In other systems, the meaning is not specified, and the number returned by time can be used only as an argument to date and difftime. os.tmpname ()Returns a string with a file name that can be used for a temporary file. The file must be explicitly opened before its use and explicitly removed when no longer needed. 5.9 - The Debug LibraryThis library provides the functionality of the debug interface to Lua programs. You should exert care when using this library. The functions provided here should be used exclusively for debugging and similar tasks, such as profiling. Please resist the temptation to use them as a usual programming tool: they can be very slow. Moreover, several of its functions violate some assumptions about Lua code (e.g., that variables local to a function cannot be accessed from outside or that userdata metatables cannot be changed by Lua code) and therefore can compromise otherwise secure code. All functions in this library are provided inside the debug table. All functions that operate over a thread have an optional first argument which is the thread to operate over. The default is always the current thread. debug.debug ()Enters an interactive mode with the user, running each string that the user enters. Using simple commands and other debug facilities, the user can inspect global and local variables, change their values, evaluate expressions, and so on. A line containing only the word cont finishes this function, so that the caller continues its execution. Note that commands for debug.debug are not lexically nested within any function, and so have no direct access to local variables. debug.getfenv (o)Returns the environment of object o.debug.gethook ([thread])Returns the current hook settings of the thread, as three values: the current hook function, the current hook mask, and the current hook count (as set by the debug.sethook function). debug.getinfo ([thread,] function [, what])Returns a table with information about a function. You can give the function directly, or you can give a number as the value of function, which means the function running at level function of the call stack of the given thread: level 0 is the current function (getinfo itself); level 1 is the function that called getinfo; and so on. If function is a number larger than the number of active functions, then getinfo returns nil. The returned table may contain all the fields returned by lua_getinfo, with the string what describing which fields to fill in. The default for what is to get all information available, except the table of valid lines. If present, the option ‘f’ adds a field named func with the function itself. If present, the option ‘L’ adds a field named activelines with the table of valid lines. For instance, the expression debug.getinfo(1,”n”).name returns a name of the current function, if a reasonable name can be found, and the expression debug.getinfo(print) returns a table with all available information about the print function. debug.getlocal ([thread,] level, local)This function returns the name and the value of the local variable with index local of the function at level level of the stack. (The first parameter or local variable has index 1, and so on, until the last active local variable.) The function returns nil if there is no local variable with the given index, and raises an error when called with a level out of range. (You can call debug.getinfo to check whether the level is valid.) Variable names starting with ‘(‘ (open parentheses) represent internal variables (loop control variables, temporaries, and C function locals). debug.getmetatable (object)Returns the metatable of the given object or nil if it does not have a metatable. debug.getregistry ()Returns the registry table (see §3.5). debug.getupvalue (func, up)This function returns the name and the value of the upvalue with index up of the function func. The function returns nil if there is no upvalue with the given index. debug.setfenv (object, table)Sets the environment of the given object to the given table. Returns object. debug.sethook ([thread,] hook, mask [, count])Sets the given function as a hook. The string mask and the number count describe when the hook will be called. The string mask may have the following characters, with the given meaning: “c”: The hook is called every time Lua calls a function;“r”: The hook is called every time Lua returns from a function;“l”: The hook is called every time Lua enters a new line of code.With a count different from zero, the hook is called after every count instructions. When called without arguments, debug.sethook turns off the hook. When the hook is called, its first parameter is a string describing the event that has triggered its call: “call”, “return” (or “tail return”), “line”, and “count”. For line events, the hook also gets the new line number as its second parameter. Inside a hook, you can call getinfo with level 2 to get more information about the running function (level 0 is the getinfo function, and level 1 is the hook function), unless the event is “tail return”. In this case, Lua is only simulating the return, and a call to getinfo will return invalid data. debug.setlocal ([thread,] level, local, value)This function assigns the value value to the local variable with index local of the function at level level of the stack. The function returns nil if there is no local variable with the given index, and raises an error when called with a level out of range. (You can call getinfo to check whether the level is valid.) Otherwise, it returns the name of the local variable. debug.setmetatable (object, table)Sets the metatable for the given object to the given table (which can be nil). debug.setupvalue (func, up, value)This function assigns the value value to the upvalue with index up of the function func. The function returns nil if there is no upvalue with the given index. Otherwise, it returns the name of the upvalue. debug.traceback ([thread,] [message] [, level])Returns a string with a traceback of the call stack. An optional message string is appended at the beginning of the traceback. An optional level number tells at which level to start the traceback (default is 1, the function calling traceback). 6 - Lua Stand-aloneAlthough Lua has been designed as an extension language, to be embedded in a host C program, it is also frequently used as a stand-alone language. An interpreter for Lua as a stand-alone language, called simply lua, is provided with the standard distribution. The stand-alone interpreter includes all standard libraries, including the debug library. Its usage is: lua [options] [script [args]] The options are: -e stat: executes string stat;-l mod: “requires” mod;-i: enters interactive mode after running script;-v: prints version information;—: stops handling options;-: executes stdin as a file and stops handling options.After handling its options, lua runs the given script, passing to it the given args as string arguments. When called without arguments, lua behaves as lua -v -i when the standard input (stdin) is a terminal, and as lua - otherwise. Before running any argument, the interpreter checks for an environment variable LUA_INIT. If its format is @filename, then lua executes the file. Otherwise, lua executes the string itself. All options are handled in order, except -i. For instance, an invocation like $ lua -e&#39;a=1&#39; -e &#39;print(a)&#39; script.lua will first set a to 1, then print the value of a (which is ‘1’), and finally run the file script.lua with no arguments. (Here $ is the shell prompt. Your prompt may be different.) Before starting to run the script, lua collects all arguments in the command line in a global table called arg. The script name is stored at index 0, the first argument after the script name goes to index 1, and so on. Any arguments before the script name (that is, the interpreter name plus the options) go to negative indices. For instance, in the call $ lua -la b.lua t1 t2 the interpreter first runs the file a.lua, then creates a table arg = { [-2] = &quot;lua&quot;, [-1] = &quot;-la&quot;, [0] = &quot;b.lua&quot;, [1] = &quot;t1&quot;, [2] = &quot;t2&quot; } and finally runs the file b.lua. The script is called with arg[1], arg[2], ··· as arguments; it can also access these arguments with the vararg expression ‘…’. In interactive mode, if you write an incomplete statement, the interpreter waits for its completion by issuing a different prompt. If the global variable _PROMPT contains a string, then its value is used as the prompt. Similarly, if the global variable _PROMPT2 contains a string, its value is used as the secondary prompt (issued during incomplete statements). Therefore, both prompts can be changed directly on the command line. For instance, $ lua -e&quot;_PROMPT=&#39;myprompt&gt; &#39;&quot; -i (the outer pair of quotes is for the shell, the inner pair is for Lua), or in any Lua programs by assigning to _PROMPT. Note the use of -i to enter interactive mode; otherwise, the program would just end silently right after the assignment to _PROMPT. To allow the use of Lua as a script interpreter in Unix systems, the stand-alone interpreter skips the first line of a chunk if it starts with #. Therefore, Lua scripts can be made into executable programs by using chmod +x and the #! form, as in #!/usr/local/bin/lua (Of course, the location of the Lua interpreter may be different in your machine. If lua is in your PATH, then #!/usr/bin/env lua is a more portable solution.) 7 - Incompatibilities with the Previous VersionHere we list the incompatibilities that you may found when moving a program from Lua 5.0 to Lua 5.1. You can avoid most of the incompatibilities compiling Lua with appropriate options (see file luaconf.h). However, all these compatibility options will be removed in the next version of Lua. 7.1 - Changes in the LanguageThe vararg system changed from the pseudo-argument arg with a table with the extra arguments to the vararg expression. (See compile-time option LUACOMPAT_VARARG in luaconf.h.)There was a subtle change in the scope of the implicit variables of the for statement and for the repeat statement.The long string/long comment syntax ([[string]]) does not allow nesting. You can use the new syntax ([=[string]=]) in these cases. (See compile-time option LUA_COMPAT_LSTR in luaconf.h.)7.2 - Changes in the LibrariesFunction string.gfind was renamed string.gmatch. (See compile-time option LUA_COMPAT_GFIND in luaconf.h.)When string.gsub is called with a function as its third argument, whenever this function returns nil or false the replacement string is the whole match, instead of the empty string.Function table.setn was deprecated. Function table.getn corresponds to the new length operator (#); use the operator instead of the function. (See compile-time option LUA_COMPAT_GETN in luaconf.h.)Function loadlib was renamed package.loadlib. (See compile-time option LUA_COMPAT_LOADLIB in luaconf.h.)Function math.mod was renamed math.fmod. (See compile-time option LUA_COMPAT_MOD in luaconf.h.)Functions table.foreach and table.foreachi are deprecated. You can use a for loop with pairs or ipairs instead.There were substantial changes in function require due to the new module system. However, the new behavior is mostly compatible with the old, but require gets the path from package.path instead of from LUA_PATH.Function collectgarbage has different arguments. Function gcinfo is deprecated; use collectgarbage(“count”) instead.7.3 - Changes in the APIThe luaopen* functions (to open libraries) cannot be called directly, like a regular C function. They must be called through Lua, like a Lua function.Function lua_open was replaced by lua_newstate to allow the user to set a memory-allocation function. You can use luaL_newstate from the standard library to create a state with a standard allocation function (based on realloc).Functions luaL_getn and luaL_setn (from the auxiliary library) are deprecated. Use lua_objlen instead of luaL_getn and nothing instead of luaL_setn.Function luaL_openlib was replaced by luaL_register.Function luaL_checkudata now throws an error when the given value is not a userdata of the expected type. (In Lua 5.0 it returned NULL.)8 - The Complete Syntax of LuaHere is the complete syntax of Lua in extended BNF. (It does not describe operator precedences.) chunk ::= {stat [`;´]} [laststat [`;´]] block ::= chunk stat ::= varlist1 `=´ explist1 | functioncall | do block end | while exp do block end | repeat block until exp | if exp then block {elseif exp then block} [else block] end | for Name `=´ exp `,´ exp [`,´ exp] do block end | for namelist in explist1 do block end | function funcname funcbody | local function Name funcbody | local namelist [`=´ explist1] laststat ::= return [explist1] | break funcname ::= Name {`.´ Name} [`:´ Name] varlist1 ::= var {`,´ var} var ::= Name | prefixexp `[´ exp `]´ | prefixexp `.´ Name namelist ::= Name {`,´ Name} explist1 ::= {exp `,´} exp exp ::= nil | false | true | Number | String | `...´ | function | prefixexp | tableconstructor | exp binop exp | unop exp prefixexp ::= var | functioncall | `(´ exp `)´ functioncall ::= prefixexp args | prefixexp `:´ Name args args ::= `(´ [explist1] `)´ | tableconstructor | String function ::= function funcbody funcbody ::= `(´ [parlist1] `)´ block end parlist1 ::= namelist [`,´ `...´] | `...´ tableconstructor ::= `{´ [fieldlist] `}´ fieldlist ::= field {fieldsep field} [fieldsep] field ::= `[´ exp `]´ `=´ exp | Name `=´ exp | exp fieldsep ::= `,´ | `;´ binop ::= `+´ | `-´ | `*´ | `/´ | `^´ | `%´ | `..´ | `&lt;´ | `&lt;=´ | `&gt;´ | `&gt;=´ | `==´ | `~=´ | and | or unop ::= `-´ | not | `#´]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑网3口袋版笔记]]></title>
    <url>%2F2019%2F05%2F23%2Fjx3m%2F</url>
    <content type="text"><![CDATA[Unity版本2018.32D场景，3D模型，确实有点惊喜，场景里面的东西看到的基本都是用片做的。那么定位就应该偏向格斗了，可能是帧同步吧。 以下基本是静态分析结果。 启动流程start场景挂了两个节点一个是Start在上面下挂了一个GameStart脚本，作为启动脚本，另一个是Camera没什么必要。GameStart在Start函数调用RuntimeCoroutineTracker.InvokeStart(this, HelperUtil.Steper(30, Initialize(), Sleep));封装协程的目的是抓帧用的。HelperUtil.Steper间隔执行。在Initialize中初始化逻辑，其中yield return Lifecycle.GameModuleMgr.InitCoroutine(0, RefreshProgress);加载游戏模块。在到GameModule的InitCoroutine中执行Init。说实在的OOP这一套看代码看的确实很烦。然后看一下GameMoudle有哪些 AccountModule AchievementManager AngleFilterDataModule AngleFilterManager ArenaModule BarrageManager BattlegroundModule BrokenManager CameraManagerController CameraMotionPathManager ChallengeModule CharacterVoceManager CharManager SceneLoad MidasManager PVEModule Lua 好了由于太多了就不一一列举了。虽然都是Module但是会涵盖具体玩法和一些公共组件。让人看起来很迷，甚至认为有的代码真的会用到的感觉吗。这里我们重点分析Lua。在Lua.OnInit中，调用luasvr = new LuaSvr();这里面会生成一个LuaSvrProxy这个GameObject，然后在它的Update中处理time等的tick事件。加载了一个调用DoFile(UIDef.LuaScriptPath);其中UIDef.LuaScriptPath = “Lua/PreLoadList.lua”;这块进行了预加载Lua脚本。 Lualua使用的slua。首先我不是引战，我只是想大家有自己清晰的认识slua到底好不好。好了，这里是ulua的官网，大家可以去看一下。http://www.ulua.org/cstolua.html我们看一个addMember函数12345678910111213141516171819202122public static void addMember(IntPtr l, string name, LuaCSFunction get, LuaCSFunction set, bool instance)&#123; checkMethodValid(get); checkMethodValid(set); int t = instance ? -2 : -3; LuaDll.lua_createtable(l, 2, 0); if (get == null) LuaDLL.lua_pushnil(l); else pushValue(l, get); LuaDll.lua_rawseti(l, -2, 1); if (set == null) LuaDLL.lua_pushnil(l); else pushValue(l, set); LuaDLL.lua_rawseti(l, -2, 2); // t[n]=v,n是2，v是-2出的值，lua是栈存储结构，栈索引值越小，说明越早压栈 LuaDll.lua_setfield(l, t, name); // t[name]=v&#125; 其他注册方式类似。然后slua对于用户感觉是透明的，然后每个注册之后都要返回两个参数，大部分来说。生成的cs文件完全是调用另一个文件的函数。这种加一层的包装真好的好吗，难道用户不需要知道里面的东西吗？（PS：个人感受，slua这种warp的方式真的好难受），好吧，自动化的注册确实跟不要钱一样。 模块这里的模块是自定义的，而不是根据配置读取的，其实也无可厚非，只不过会增加了一些代码量，这里的代码量仅仅指模块名称。比如UILoadHelper.SpawdPrefabFromPool，在这里UILoadHelper被我们习惯称为模块。 AssetBundle好吧，这块真的是异常痛苦的，以至于我F12了好半天，才看到一个UnityEngine.AssetBundle.LoadFromFile(path);在ResourcesHook.cs中有两个接口1234567891011121314public static UnityEngine.AssetBundle LoadFromFile(string path)&#123; ResourceLoadProfiler.Begin(); UnityEngine.AssetBundle ret = UnityEngine.AssetBundle.LoadFromFile(path); ResourceLoadProfiler.End("AssetBundle.LoadFromFile", path, null); return ret;&#125;public static AssetBundleCreateRequest LoadFromFileAsync(string path)&#123; AssetBundleCreateRequest ret = UnityEngine.AssetBundle.LoadFromFileAsync(path); ResourceLoadProfiler.AddAsyncRequest(ret, "AssetBundle.LoadFromAsync", path, null); return ret;&#125; UI开发模式属于MV模式。 目录结构NGUI + sluaUI脚本目录 Assets/StreamingAssets/Lua数据控制逻辑在LogicData目录下 CommonTimer.luaHelperUIHelper.luaAddTimer123456function UIHelper.AddTimer(script, nTime, func) local nid = Timer:Add(nTime, func) script._tbUnscaledTime = script._tbUnscaledTimer or &#123;&#125; script._tbUnscaledTime[nId] = func return nIdend 123456789101112131415161718192021-- 按钮注册事件function UIHelper.BindUIEvent(go, szEvent, func, tbParam, nIntervals) if not go or not szEvent or not func then return end local listenter = UIEventLister.Get(go.gameObject) if tbParam ~= nil and type(tbParam) == "table" then listener.paramter = tbParam end if nInterval ~= nil then UIClickIntervalsController.Instance:RegisterInterval(go.gameObject, nIntervals) end if szEvent == UI_EVENT.onClick then listener.onClick = func elseif then elseif then elseif then else LOG.ERROR("未知的按钮事件类型&#123;0&#125;", szEvent) endend UILoadHelper.luaLoadPrefabHandleAsync123456789101112131415161718192021222324-- 异步加载预制体接口function UILoadHelper.LoadPrefabHandleAsync(script, nID, parent, szRename, nPostNameID, ...) if not script or not nID or not parent then LOG.ERROR("UILoadHelper.LoadPrefabHandleAsync param exception") return end nPostNameID = nPostNameID or -1 local handle = Lua2CS.LoadPrefabHandleAsync(nID, parent, transform, szRename, nPostNameID, ...) if not handle then LOG.ERROR("UILoadHelper.LoadPrefabHandleAsync Don't Get handle") return end if not script.tbPrefabHandle then script.tbPrefabHandle = &#123;&#125; end script.tbPrefabHandle[handle.nHandleId] = handle return handleend LoadImg(img, nID, bMakePerfect)—- 加载图片(UISprite, UITexture)12345function UILoadHelper.LoadImg(img, nID, bMakePerfect) if not img or not nID then LOG.ERROR("UILoadHelper.LoadImg 传入空参数") return end bMakePerfect = bMakePerfect or false Lua2CS.LoadImg(img, nID, UIImgUsageType.MainTexture, true, bMakePerfect)end UINavigateHelper.lua1234567891011121314151617--- 打开新界面（异步）function UINavigateHelper.NavigateViewAsync(nViewID,...) if UIViewOpenSequenceManager.AddView(nViewID, false, true, ...) then return end local shell = UINavigationManager.Instance:NavigateView(nViewID, false, true, ...) -- 注册异步消息管理 if shell and not shell.IsViewLoad then local config = UIAsyncMsgTab[nViewID] if config then local msgAsyncHolder = UIAsyncMsgHelper.RegisterMsgAysnc(config) shell.AsyncMsg = msgAsyncHolder end end return shellend 表格文件表格路径：Assets/JX3Game/Source/File/UI转换成lua文件方法：123456789101112131415161718192021[MenuItem("Tools/Excel to Lua/Export")]public static void ExcelToLua()&#123; Lua.ExcelToLua();&#125;public static void ExcelToLua()&#123; try &#123; System.Diagnostics.Process pro = new System.Diagnostics.Process(); pro.StartInfo.WorkingDirectory = Application.dataPath + "/JX3Game/Source/File/ToLuaTool/"; pro.StartInfo.FileName = Application.dataPath + "/JX3Game/Source/File/ToLuaTool/run.bat"; pro.StartInfo.UseShellExecute = true; pro.Start(); pro.WaitForExit(); &#125; catch(System.Exception) &#123; &#125;&#125; 注意：如果你看源码的时候发现生成的文件工程中的文件不一致，比如我看UICardTab.lua的时候，就发现缺少第一句注释，然后我尝试生成了以下，注释就加上了。原理：其实是把表格文件转成lua文件了，寻仙的时候在在线转的，这里是离线转的。对比：比如 UIAchieveLabelTab.xls（其实是一个txt文件，这块让人刚开始有点雾水）大小是12KB，而生成的UIAchieveLabelTab.lua却占105KB。缺点是会让包体增大，那么带来一系列的坏处就是加载这块的问题。而如果在线转的问题是在转的这块要做好优化。个人更喜欢在线转。事实上常见的也是在线转。 UIPrefab绑定Lua 这个东西很坑的，一般来说我们的选择器都是把所有节点罗列出来，然后供你选择，而这里的是要你输入文件名然后进行匹配。。。是节省性能吗？交互做好的UI，然后我们这边绑上LuaBind脚本，好吧，要注意，序列化这件事情，即没有用的变量就不要绑定了。Unity序列化给人感觉还是不太友好，尤其是Prefab的序列化。绑定完之后点击生成头部检测函数，如下图： 点击生成头部检测可以将绑定的变量输出到控制台上，然后我们将输入的日志自己拷贝粘贴到lua文件中。好吧，这里我可以说好坑的吗，我们做了那么多自动化的工具，为什么这里却是要自己把日志手动粘贴到Lua文件中的呢？然后还有刷新按钮，当我们点击刷新的时候，会重新检测文件中绑定数据，这个时候才可以进行删除操作。好吧，这样的目的是为了防止安全，但是这些反人类设计真的要吐槽。继续吐槽，绑定变量数组不能在数组元素中插入吗？ Lua脚本是如何生成的呢？ 我们注意到在Editor目录下有一个LuaTemplate.lua模板文件。该文件通过LuaFileCreator.cs中的12345[MenuItem("Assets/Create/Lua Script", false, 80)]public static void CreateNewLua()&#123; ProjectWindowUtil.StartNameEditingIfProjectWindowExists(0, ScriptableObject.CreateInstance&lt;CreateScriptAsset&gt;(), GetSelectedPathOrFallback() + "/New Lua.lua", null, "Assets/Editor/LuaTemplate.lua");&#125; 这里开发的同学应该要注意，生成的模板文件如果我们不需要的时候，需要把它干掉！类似的做法在C#的MonoBehaviour脚本也适用。 字体字体使用的动态字体。表现效果好，但是CPU，内存占用大。不过这个也在情理之中，而且也是很常见的做法。 图集图集可能不是使用Texturepacker，但是都是2的幂次方，应该是要根据不同设备进行压缩的。在编辑器下观察，应该都是带alpha通道的，那么这块其实是可以优化的。比如将rgb和r通道分离。之前潘多拉就是这样的做法，这样其实和etc2的差别不是很大，但是和RGB32的差别还是肉眼可见的。好吧，浪费还是蛮严重的。 艺术字看着像是按照静态字体的方式制作的。 相机相机有一个UIMainCamera和一个FrontCamera，这里有个坑的地方就是在编辑器和模拟器上当前视图是使用的FrontCamera渲染，后置视图使用UIMainCamera并添加高斯模糊。所以要注意在任何时候的相机操作。 工具调试器这里有很多调试器，都值得一试，它可能会帮助你修复难以解决的问题。在Tools下面有RemoteDebugger.HierarchyPanel，打开面板，点击Query，然后所有的对象可以陈列在面板上，而且你可以对他进行修改，除了name和transform。name是禁止修改的，但是transform怀疑是bug，导致无法修改。]]></content>
      <categories>
        <category>JX3M</category>
      </categories>
      <tags>
        <tag>JX3M</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpritePacker]]></title>
    <url>%2F2019%2F05%2F22%2Fspritepacker%2F</url>
    <content type="text"><![CDATA[Version:2018.3 NGUI图集和UGUI图集的区别NGUI是必须先打出图集然后才能开始做界面，这一点很烦，因为始终都要考虑你的UI图集。比如图集会不会超过1024，图集该如何规划等。而UGUI的原理则是，让开发者不要去关心自己的图集。做界面的时候只用小图，而最终打包的时候Unity才会把你的小图合并在一张大的图集里面，然而这一切都是自动完成的，开发者不需要去care它。 启用在Edit-&gt;Project Settings-&gt;Editor-&gt;Sprite Packer-&gt;Mode中进行设置 Disabled: 不启用 Enabled For Builds(Legacy Sprite Packer):打包的时候使用，过时的 Always Enabled(Legacy Sprite Packer):总是开启，过时了 Enabled For Builds: 打包的时候使用 Always Enabled: 总是使用，推荐方式开始的时候我们需要清楚看到现在的有几个Draw Call，从而才能优化小图。在最终打包的时候Unity会自动构建大的图集，将同一图集的所有图片的packing tag设置成一个名字就可以看到这个图集占几个Draw Call了。 图集的预览仅仅是让你看看你的图集大概长什么样子。图集保存在Libary/AtlasCache里面。Window-&gt;2D-&gt;Sprite Packer此时在Hierarchy试图中创建两个Image对象。如下图所示，我们发现此时Draw Calls变成了1。注意你的图片不能放在Resources文件夹下面，Resources文件夹下的资源将不会被打入图集。此时在Hierarchy试图中创建两个Image对象。可以发现Draw Call已经被合并成1了。 1[MenuItem("Build AssetBundle")]]]></content>
      <categories>
        <category>UGUI</category>
      </categories>
      <tags>
        <tag>UGUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AssetsStudio]]></title>
    <url>%2F2019%2F05%2F22%2Fassetstudio%2F</url>
    <content type="text"><![CDATA[AssetsStudio url: https://github.com/Perfare/AssetStudio.gitAssetsStudio Release url: https://ci.appveyor.com/project/Perfare/assetstudio/branch/master/artifactsfbx url: https://github.com/arturoc/ofxFBX.git]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生死界]]></title>
    <url>%2F2019%2F05%2F14%2Ffiction-2-1%2F</url>
    <content type="text"><![CDATA[当芩醒来的时候，发现周围的环境他已经不认识了，脑袋有点昏昏沉沉的，像是睡了好久。很奇怪，没有阳光，天空是黑色的，什么也看不见，但是周围的环境却看到一清二楚。这时，从远处走来了一个男子，身穿黑色长袍，手里拿着一本不知道是书还是记事簿的东西，走过来对芩说，“走吧。”。“去哪里？”，芩问道。“自然是去你该去的地方。”，黑衣男子说道。“哪里是我该去的地方呢？”，芩仍然问道。“哟，你今天的话似乎有点多。”，黑衣男子调侃道。“你怎么知道我以前的话不多？”，芩疑惑的问道。“你不喜欢你之前的世界，所以话不多，我猜的，一个人不会对他不喜欢的东西还说那么多话，不是吗？”，黑衣男子笑道。“之前的世界，所以说，我死了？那么这里是阴曹地府吗？”，芩仍然疑惑的问道。“嗯，你死啦。但是这里不是阴曹地府，不过你待会去的地方算是阴曹地府吧，只不过我们称之为死界，你生活的地方是生界，所以现在这个地方是生死界，连接生界和死界的地方，而我是负责将你们送到死界的人，吧！”，黑衣男子娓娓道来。“果然我还是死了，唉，算啦，本来也不打算抱活着的希望，而且没什么牵挂，死了好，死了好呀。”，芩心里想着，并露出了微笑。“哈哈，你果然是不喜欢之前的世界，对吧，一般很少有人像你一样，来了这个地方还满带笑意的，他们都舍不得那个世界呀。”，黑衣男子感叹道。“你说错了，人们总喜欢对新出生婴儿的家庭说恭喜恭喜，却对死去人的家庭说可惜可惜，这并不是说他们喜欢活着的世界，只是他们不知道死去的世界，所以选择了活着的世界，而我去哪里都一样，我都可以接受。”，芩淡淡的说道。]]></content>
      <tags>
        <tag>混沌</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三角形中心坐标]]></title>
    <url>%2F2019%2F05%2F13%2Ftriangle%2F</url>
    <content type="text"><![CDATA[P用A,B,C来表示对于三角形内任意一点P其实学过向量的就能想到，$\vec{AP}$，$\vec{AB}$，$\vec{AC}$线性相关。可以写成：$\vec{AP}=u\vec{AB}+v\vec{AC}$展开：$A-P=u(A-B)+v(A-C)$得到：$P=(1-u-v)A+uB+vC$这也是P的表示，其中$0\le{u,v}\le{1}$，来取特殊一点的u，v可以得到A，B，C。这个公式长得很像AB上任意一点D的计算：$D=A+t(B-A),0\le{t}\le{1}$也就是线性插值：$D=(1-t)A+tB,0\le{t}\le{1}$ 计算当然也可以把ABC看成坐标系，始于A点，基于：$\vec{AB}$和$\vec{AC}$。所以这个叫做重新坐标系（barycentric，bary-重的）也能得到公式：$\vec{AP}=u\vec{AB}+v\vec{AC}$转换成：$u\vec{AB}+v\vec{AC}+\vec{PA}=0$甚至我们还可以把它写成矩阵形式：$\begin{bmatrix}{u}&amp;{v}&amp;{1}\\end{bmatrix}\begin{bmatrix}{\vec{AB_x}}\{\vec{AC_x}}\{\vec{PA_x}}\\end{bmatrix} = 0$$\begin{bmatrix}{u}&amp;{v}&amp;{1}\\end{bmatrix}\begin{bmatrix}{\vec{AB_y}}\{\vec{AC_y}}\{\vec{PA_y}}\\end{bmatrix} = 0$实际上我们都可以看做是我们在寻找向量(u,v,1)同时垂直于向量$(\vec{AB_x},\vec{AC_x},\vec{PA_x})$和向量$(\vec{AB_y},\vec{AC_y},\vec{PA_y})$。这不就是叉乘吗？同时这给了我们一个有了P点，求u和v的思路。 xvector = (B_x - A_x, C_x - A_x, A_x - P_x) yvector = (B_y - A_y, C_y - A_y, A_y - P_y) u=xvector x yvector # 因为我们讨论的是二维三角形，如果u的z分量不等于1则说明P点不在三角形内 编码然后我们来代码阶段，因为我们的计算中涉及到浮点数，可能u的z分量不会一定等于1.0，令u的三个分量是(a, b, c)，我们代入原公式：$a\vec{AB}+b\vec{AC}+c\vec{PA}=0$$P=(1-a/c-b/c)A+a/cB+b/cC,c\neq{0})$123456789101112Vec3f barycentric(Vec2f A, Vec2f B, Vec2f C, Vec2f P)&#123; Vec3f s[2]; for (int i = 2; i &gt; 0;i--)&#123; s[i][0] = C[i] - A[i]; s[i][1] = B[i] - A[i]; s[i][2] = A[i] - P[i]; &#125; Vec3f u = cross(s[0], s[1]); if (std::abs(u[2])&gt;1e-2) return Vec3f(1.f-(u.x+u.y)/u.z, u.y/u.z,u.x/u.z); return Vec3f(-1,1,1);&#125; 1234567891011def barycentric(A,B,C,P) """ A,B,C,P:Vector3, points return u: Vector3, barycentric coordinate of P """ s1 = Vector3(B.x - A.x, C.x - A.x, A.x - P.x) s2 = Vector3(B.y - A.y, C.y - A.y, A.y - P.y) u = s1.cross(s2) if abs(u.z) &gt; EPSILON return Vector3(1-(u.x+u.y)/u.z,u.x/u.z,u.y/u.z) return Vector3(-1,1,1) 应用重心坐标在CG中的应用可以有以下： 填充三角形之前我也想过这个问题，因为我们生成图像，归根结底是在于画像素点，那么如果我们要填充一个三角形，对于一个一个的像素点，我们只需要放到上述函数里面去，就可以判断P是否在三角形内，我们就去画它。这样填一个三角形的算法可以就是O(image.width*image.height)，我们甚至可以进一步降低复杂度，对于一个三角形来说，我们可以由它的bounding box，只需要检测它的bounding box里面的点，然后就可以用来填充。 z-buffer其实这里也不止于z-buffer，我们已经把P点表示成了A，B，C的线性组合形式，那么对于P点的Z，我们也可以这样来看，我们把P点z值也可以看成A，B，C的线性组合，其实不仅仅是P点的z，对于P点的任意性质，只要我们觉得可以用线性组合来看的，我们都可以用这个坐标系统。]]></content>
      <categories>
        <category>图形学笔记</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
        <tag>光栅</tag>
        <tag>三角形</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Artist]]></title>
    <url>%2F2019%2F05%2F13%2Fartist%2F</url>
    <content type="text"><![CDATA[https://www.artstation.com/ 非常不错的美术作品网站。 头发制作中有没有什么特别的工具或者是插件？还有毛发的排序是怎么解决的？ 头发的建模方面，现在是zbrush手调发卡。头发排序方面，我们用的是抖动，也就是一下黑一下白的那个方式，不需要解决排序的问题，所以在表现方面还是有一些优势。 有一种说法是PBR在皮肤表现上并不是非常好的感觉，有没有单独写这个皮肤的材质，或者说有什么技巧？ PBR就是用现实做参考而做出来的材质，大量的材质都可以归为PBR，很多人对PBR的了解就是GGX反射模型的了解，但是那个定义就比较局限。现在游戏界的皮肤普遍用的是ScreenSpaceSubsurface。大部分的现在单机游戏的皮肤几乎全部都是他的那个原理，包括神秘海域都是用他的这个模式。 画眉1根短2根长3皮肤较黑：以深色系为主，例如黑咖色、朱古力色、深灰色皮肤较白：以浅色系为主，例如浅咖色、浅棕色、烟灰色]]></content>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三大面五大调]]></title>
    <url>%2F2019%2F05%2F13%2Fartist-3-face-5-major%2F</url>
    <content type="text"><![CDATA[物体调子的规律可归纳为“三大面、五大调子” 三大面黑白灰。 五大调 受光面（亮面）：是物体受光线90°直射的地方，这部分受光最大，调子淡，两部的受光焦点叫“高光”，一般只有光滑的物体才会出现。 中间色（灰面）：是物体受光测射的部分。 明暗交界线：由于它收到环境光的影响，但又受不到主要光源的照射，因此对比强烈，给人的感觉调子最深。 反光：暗部由于受周围物体的反射作用，会产生反光。反光作为暗部的一部分，一般要比亮部最深的中间颜色要深。 投影：就是物体本身影子的部分。它作为一个大的色块出现。投影的边缘近处清楚，渐远的模糊。 五大调子的规律是塑造立体感的主要方法。其是表现质感、量感、空间的重要手段。素描造型正确表现出这种关系，就可以达到十分真实的效果，明暗交界线是由亮部由转向暗部转折的部分。 五大条子的规律是塑造立体感的主要法则，也是表现质感，量感，空间感的重要手段，素描造型正确地表现出这种关系，就可以达到十分真实的效果。五大调的明暗对比的基本顺序是：高光&gt;亮灰&gt;反光&gt;暗灰&gt;明暗交界线。]]></content>
      <categories>
        <category>Artist</category>
      </categories>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unity-computeshader]]></title>
    <url>%2F2019%2F05%2F13%2Funity-computeshader%2F</url>
    <content type="text"><![CDATA[Compute Shader如何创建：Project-&gt;Create-&gt;Compute Shader123#pragma kernel CSMain[numthreads(8,8,1)] #pragma kernel CSMain 制定了这个程序的入口函数（ComputeShader的Main函数） [numthreads(8,8,1)] 这一行指定了ComputeShader创建线程组的大小。GPU利用了大量的并行处理使得GPU创建的一些线程可以同时运行。 12345678910111213public ComputeShader shader;void RunShader()&#123; int kernelHandle = shader.FindKernel("CSMain"); RenderTexture tex = new RenderText("256,256,24"); tex.enableRandomWrite = true; tex.Create(); shader.SetTexture(kernelHandler, "Result", tex); shader.Dispatch(kernelHandler, 256/8,256/8);&#125;]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前程似锦]]></title>
    <url>%2F2019%2F05%2F13%2Ffiction-2%2F</url>
    <content type="text"><![CDATA[既然我们不知道未来如何相遇或者还是不遇，那我就祝你前程似锦吧。这样总归不是错的。]]></content>
      <tags>
        <tag>混沌</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL ES 3.0]]></title>
    <url>%2F2019%2F05%2F12%2Fopengles%2F</url>
    <content type="text"><![CDATA[Windows配置OpenGLES3开发环境OpenGL ES 3.0实现了具有可编程着色功能的图形管线，由两个规范组成：OpenGL ES 3.0 API规范和OpenGL ES着色语言3.0规范（OpenGL ES SL）。下图展示了OpenGL ES 3.0图形管线。图中带有阴影的方框表示OpenGL ES 3.0中管线的可编程阶段。下面概述OpenGL ES 3.0 图形管线的各个阶段。 顶点着色器本节简单概述顶点着色器。顶点和片段着色器将在后面的章节中深入介绍。顶点着色器实现了顶点操作的通用可编程方法。顶点着色器的输入包括： 着色器程序：描述顶点上执行操作的顶点着色器程序源代码或者可执行文件。 顶点着色器输入（或者属性）：用顶点数组提供的每个顶点的数据。 统一变量（uniform）：顶点（或者片段）着色器使用的不变数据。 采样器：代表顶点着色器使用纹理的统一变量类型。 顶点着色器的输出在OpenGL ES 2.0中称作可变（varying）变量，但在OpenGL ES 3.0中改名为顶点着色器输出变量。在图元光栅化阶段，为每个生成的片段计算顶点着色器输出值，并作为输入传递给片段着色器。用于从分配给每个图元顶点的顶点着色器输出生成每个片段值的机制称作插值（Interpolation）。此外，OpenGL ES 3.0增加了一个新功能——变化反馈，使顶点着色器输出可以选择性地写入一个输出缓冲区（除了传递给片段着色器之外，也可能代替这种传递）。例如，在第14章中介绍的变换反馈示例中，在顶点着色器中实现了一个粒子系统，其中的粒子用变换反馈输出到一个缓冲区对象。顶点着色器的输入和输出如下图所示。 顶点着色器可以用于通过矩阵变换位置、计算照明公式来生成逐顶点颜色以及生成或者变换纹理坐标等基于顶点的传统操作。此外，因为顶点着色器由应用程序规定，所以它可以用于执行自定义计算，实施新的变换、照明或者较传统的固定功能管线所不允许的基于顶点的效果。下面展示了用OpenGL ES着色语言编写的一个顶点着色器。我们将在本文后面详细说明顶点着色器，这里提供的着色器只是让你对顶点着色器有个概念。下面代码中的顶点着色器取得一个位置及相关的颜色数据作为输入属性，用一个4x4矩阵变换位置，并输出变换后的位置和颜色。12345678910111213#version 300 esuniform mat4 u_mvpMatrix; // matrix to convert a_position from model space to normalized device space// attributes input to the vertex shaderin vec4 a_position; // position valuein vec4 a_color; // input vertex color// output of the vertex shader - input to fragment shaderout vec4 v_color; // output vertex colorvoid main()&#123; v_color = a_color; gl_Position = u_mvpMatrix * a_position;&#125; 第1行提供了着色语言的版本-这一信息必须出现在着色器的第1行（#version 300 es表示OpenGL ES着色语言v3.00）。第2行描述了统一变量u_mvpMatrix，它存储组合的模型视图和投影矩阵。第4行和第8行描述了顶点着色器的输入，被称作顶点属性。a_position是输入顶点位置属性，a_color是输入顶点颜色属性。第8行声明了输出变量v_color，用于存储描述每个顶点颜色的顶点着色器输出。内建变量gl_Position是自动声明的，着色器必须将变换后的位置写入这个变量。片段着色器的顶点有一个单一入口点，称作主函数。第9行~13行描述顶点着色器main函数。在第11行中，读入顶点属性输入a_color，并将其写入顶点输出颜色v_color。第12行中，变换后的顶点位置写入gl_Position输出。 图元装配顶点着色器之后，OpenGL ES 3.0图形管线的下一阶段是图元装配。图元（Primitive）是三角形、直线或者点精灵等几何对象。图元的每个顶点被发送到顶点着色器的不同拷贝。在图元装配期间，这些顶点被组合成图元。对于每个图元，必须确定图元是否位于视锥体（屏幕上可见的3D空间区域）内。如果图元没有完全在视锥体内，则可能需要进行裁剪。如果图元完全处于该区域之外，它就会被抛弃。裁剪之后，顶点位置杯转换为屏幕坐标。也可以执行一次淘汰操作，根据图元面向前方或者后方抛弃它们。裁剪和淘汰之后，图元便准备传递给管线的下一阶段——光栅化阶段。 光栅化下一阶段是光栅化如下图，在此阶段绘制对应的图元（点精灵、直线或者三角形）。光栅化是将图元转化为一组二维片段的过程，然后，这些片段由片段着色器处理。这些二维片段代表着可在屏幕上绘制的像素。 片段着色器片段着色器为片段上的操作实现了通用的可编程方法。如下图所示，对光栅化阶段生成的每个片段执行这个着色器，采用如下输入： 着色器程序——描述片段上所执行操作的片段着色器程序源代码或者可执行文件。 输入变量——光栅化单元用插值为每个片段生成的顶点着色器输出。 统一变量——片段（或者顶点）着色器使用的不变数据。 采样器——代表片段着色器所用纹理的特殊统一变量类型。 片段着色器可以抛弃片段，也可以生成一个或者颜色值作为输出。一般来说，除了渲染到多重渲染目标之外，片段着色器只输出一个颜色值；在多重渲染目标的情况下，为每个渲染目标输出一个颜色值。光栅化阶段生成的颜色、深度、模板和屏幕坐标位置$(x_w,y_w)$变成OpenGL ES 3.0管线逐片段操作阶段的输入。 逐片段操作在片段着色器之后，下一个阶段是逐片段操作。光栅化生成的屏幕坐标为$(x_w,x_y)$的片段只能修改帧缓存区中位置为$(x_w,y_w)$的像素。下图描述了OpenGL ES 3.0逐片段操作阶段。 在逐片段操作阶段，在每个片段上执行如下功能： 像素归属测试——这个测试确定帧缓冲区中位置$(x_w,y_w)$的像素目前是不是归OpenGL ES所有。这个测试使窗口系统能够控制帧缓冲区中的哪些像素属于当前OpenGL ES上下文。例如，如果一个显示OpenGL ES帧缓冲区窗口的窗口被另一个窗口所遮蔽，则窗口系统可以确定被遮蔽的像素不属于OpenGL ES上下文，从而完全不显示这些像素。虽然像素归属测试OpenGL ES的一部分，但是它不由开发人员控制，而是在OpenGL ES内部进行。 裁剪测试——裁剪测试确定$(x_w,y_w)$是否位于作为OpenGL ES状态的一部分的裁剪矩形范围内。如果该片段位于裁剪区域之外，则被抛弃。 模板和深度测试——这些测试在输入片段的模板和深度值上进行，以确定片段是否应该被拒绝。 混合——混合将生成的片段颜色值与保存在帧缓冲区$(x_w,y_w)$位置的颜色值组合起来。 抖动——抖动可用于最小化因为使用有限精度在帧缓冲区中保存颜色值而产生的假象。 在逐片段操作阶段的最后，片段或者被拒绝，或者在帧缓冲区的$(x_w,y_w)$位置写入片段的颜色、深度或者模板值。写入片段颜色、深度和模板值取决于启用的相应写入掩码。写入掩码可以更精细地控制写入相关缓冲区的颜色、深度和模板值。例如，可以设置颜色缓冲区的写入掩码，使得任何红色值不被写入颜色缓冲区。此外，OpenGL ES 3.0提供一个接口，以从帧缓冲区读回像素。 OpenGL ES 3.0新功能纹理 sRGB纹理和帧缓冲区——允许应用程序执行伽马矫正渲染。纹理可以保存在经过伽马矫正的sRGB空间，在着色器中读取时反矫正到线性空间，然后在输出到帧缓冲区时换回sRGB伽马矫正空间。通过在线性空间中正确地进行照明和其他计算，可能得到更高的视觉保真度。 2D纹理数组——保存一组2D纹理的纹理目标。例如，这些数组可以用于执行纹理动画。在2D纹理数组出现之前，这种动画一般通过在单个2D纹理中平铺动画帧并修改纹理坐标改变动画帧实现。有了2D纹理数组，动画的每个帧可以在数组的一个2D切片中指定。 3D纹理——一些OpenGL ES 2.0实现通过扩展支持3D纹理，而OpenGL ES 3.0将此作为强制的功能。3D纹理对于许多医学成像应用是必不可少的，例如执行三维数据（如CT、MRI或者PET数据）直接体渲染的程序。 深度纹理和阴影比较——启用存储在纹理中的深度缓冲区。深度纹理的最常见用途是渲染阴影，这时深度缓冲区从光源的角度渲染，然后用于在渲染场景时比较，以确定片段是否在阴影中。除了深度纹理之外，OpenGL ES 3.0可以在读取时比较深度纹理，从而在深度纹理上完成双线性过滤（也称作百分比渐进过滤（PCF））。 无缝立方图——在OpenGL ES 2.0中，利用立方图渲染可能在立方图之间的边界产生伪像。 浮点纹理——OpenGl ES 3.0大大扩展了所支持的纹理格式，支持并可以过滤浮点半浮点（16位）纹理，也支持全浮点（32位）纹理，但是不能过滤。访问浮点纹理数据的能力有许多应用，包括高动态范围纹理和多功能计算。 ETC2/EAC纹理压缩——多种OpenGL ES 2.0实现支持供应商专用压缩纹理格式（例如高通的ATC、Imagination Technologies的PVRTC）。在OpenGl ES 3.0中强制支持ETC2/EAC。ETC2/EAC的格式为RGB888、RGB8888和单通道及双通道有符号/无符号纹理数据。纹理压缩具有很多好处，包括更好的性能（因为更好地利用了纹理缓存）以及减少GPU内存占用。 整数纹理——OpenGL ES 3.0引入了渲染和读取保存为未规范化有符号或者无符号8位、16位和32位整数纹理的能力。 其他纹理格式——除了前面提到的格式之外，OpenGL ES 3.0还包含了对11-11-10RGB浮点纹理、共享指数RGB 9-9-9-5纹理、10-10-10-2整数纹理以及8位分量有符号规范化纹理的支持。 非2幂次纹理（NPOT）——纹理现在可以指定为不为2的幂次的尺寸。这在许多情况下都很有用，例如来自视频或者摄像头的以不为2的幂次尺寸捕捉/记录的纹理。 纹理细节级别（LOD）功能——现在，可以强制使用用于确定读取哪个Mipmap的LOD参数。此外，可以强制基本和最大Mipmap级别。这两个功能组合起来，可以流化Mipmap。在更大的Mipmap级别可用时，可以提供基本级别，LOD值可以平滑地增加，以提供平滑的流化纹理。这一功能非常实用，例如，用于通过网络连接下载纹理Mipmap。 后缀 整数类型 C语言类型 GL类型 b 8位有符号整数 signed char GLbyte ub 8位无符号整数 unsigned char GLubyte、GLboolean s 16位有符号整数 short GLshort us 16位无符号整数 unsigned short GLushort i 32位有符号整数 int GLint ui 32位无符号整数 unsigned int GLuint、GLbitfield、GLenum x 16.16定点数 int GLfixed f 32位浮点数 float GLfloat、GLclampf i64 64位整数 khronos_int64_t(取决于平台) GLint64 ui64 64位无符号整数 khronos_uint64_t(取决于平台) GLuint64 最后，OpenGL ES定义了GLvoid类型。该类型用于接受指针的OpenGL ES命令。 错误处理若不正确使用OpenGL ES命令，应用程序会生成一个错误代码。这个错误代码将被记录，可以用glGetError查询。在应用程序用glGetError查询第一个错误代码之前，不会记录其他错误。一旦查询到错误代码，当前错误代码便被复位为GL_NO_ERROR。 错误代码 描述 GL_NO_ERROR 从上一次调用glGetError以来没有生成任何错误 GL_INVALID_ENUM GLenum参数超出范围。忽略生成该错误的命令 GL_INVALID_VALUE 数值型参数超出范围。忽略生成这个错误的命令 GL_INVALID_OPERATION 特定命令在当前OpenGL ES状态下不能执行。忽略生成该错误的命令 GL_OUT_OF_MEMORY 内存不足时执行该命令。如果遇到这个错误，除非是当前错误代码，否则OpenGL ES管线的状态被认为未定义 基本状态管理每个管线阶段都有一个可以启用或者警用的状态，每个上下文维护相应的状态值。状态的例子有混合启用、混合因子、剔除启用、提出曲面。在初始化OpenGL ES上下文(EGLContext)时，状态用默认值初始化。启用状态可以用glEnable和glDisable命令设置。12void glEnable(GLenum cap);void glDisable(GLenum cap); glEnable和glDisable启用各种功能。除了GL_DITHER被设置为GL_TRUE之外，其他功能的初始化均被设置为GL_FALSE。如果cap不是有效的状态枚举值，则生成错误代码GL_INVALID_ENUM。cap是要启用或者禁用的状态，可以是：123456789GL_BLENDGL_CULL_FACEGL_DEPTH_TESTGL_POLYGON_OFFSET_FILLGL_PRIMITIVE_RESTART_FIXED_INDEXGL_SAMPLE_APLHA_TO_COVEARAGEGL_SAMPLE_COVERAGEGL_SCISSOR_TESTGL_STENCIL_TEST 你好，三角形：一个OpenGL ES 3.0实例 用EGL创建屏幕上的渲染表面 加载顶点和片段着色器 创建一个程序对象，连接顶点和片段着色器，并链接程序对象 设置视口 清除颜色缓冲区 渲染简单图元 时颜色缓冲区的内从在EGL窗口表面中可见 显示后台缓冲区终于到了将三角形绘制到帧缓冲区的时候了。现在，我们必须介绍最后一个细节：如何在屏幕上真正显示帧缓冲区的内容。在介绍这一点之前，我们先讨论双缓冲区（Double Buffering）的概念。屏幕上可见的帧缓冲区由一个像素数据的二维数组表示。我们可以将屏幕上显示图像视为绘制时简单地更新可见帧缓冲区中地像素数据。但是，直接在可显示缓冲区上更新像素有一个严重的问题—也就是说，在典型的显示系统中，物理屏幕以固定的速率从帧缓冲区内存中更新。如果我们直接绘制到帧缓冲区，那么用户在部分更新帧缓冲区时会看到伪像。为了解决这个问题，我们使用所谓的双缓冲区。在这种方案中，有两个缓冲区：前台缓冲区和后台缓冲区。所有渲染都发生在后台缓冲区，它位于不可见于屏幕的内存区域。当所有渲染完成后，这个缓冲区被“交换”到前台缓冲区（或者可见缓冲区）。然后前台缓冲区变成下一帧的后台缓冲区。使用这种技术，我们在一帧上的所有渲染完成之前不显示可见表面。在OpenGL ES应用程序中，这种活动通过EGL函数eglSwapBuffers控制（我们的框架在调用Draw回调函数之后调用该函数）：eglSwapBuffers(esContext-&gt;eglDisplay, esContext-&gt;eglSurface);这个函数通知EGL切换前台缓冲区和后台缓冲区。发送到eglSwapBuffers的参数时EGL显示器和表面。这两个参数分别代表物理显示器和渲染表面。 属性 描述 默认值 EGL_BUFFER_SIZE 颜色缓冲区中所有颜色分量的位数 0 EGL_RED_SIZE 颜色缓冲区中红色分量位数 0 EGL_GREEN_SIZE 颜色缓冲区中绿色分量位数 0 EGL_BLUE_SIZE 颜色缓冲区中蓝色分量位数 0 EGL_LUMINANCE_SIZE 颜色缓冲区中亮度位数 0 EGL_ALPHA_SIZE 颜色缓冲区中Alpha值位数 0 EGL_ALPHA_MASK_SIZE 掩码缓冲区中Alpha掩码位数 0 EGL_BIND_TO_TEXTURE_RGB 如果可以绑定到RGB纹理，则为真 EGL_DONT_CARE EGL_BIND_TO_TEXTURE_RGBA 如果可以绑定到RGBA问你，则为真 EGL_DONT_CARE EGL_COLOR_BUFFER_TYPE 颜色缓冲区类型：EGL_RGB_BUFFER或EGL_LUMINANCE_BUFFER EGL_RGB_BUFFER EGL_CONFIG_CAVEAT 和配置相关的任何注意事项 EGL_DONT_CARE EGL_CONFIG_ID 唯一的EGLConfig标识符值 EGL_DONT_CARE EGL_CONFORMANT 如果用这个EGLConfig创建的上下文兼容，则为真 - EGL_DEPTH_SIZE 深度缓冲区位数 0 EGL_LEVEL 帧缓冲区级别 0 EGL_MAX_PBUFFER_WIDTH 用这个EGLConfig创建的PBuffer的最大宽度 - EGL_MAX_PBUFFER_HEIGHT 用这个EGLConfig创建的PBuffer的最大高度 - EGL_MAX_PBUFFER_PIXELS 用这个EGLConfig创建的PBuffer的最大尺寸 - EGL_MAX_SWAP_INTERVAL 最大缓冲区交换间隔 EGL_DONT_CARE EGL_MIN_SWAP_INTERVAL 最小缓冲区交换间隔 EGL_DONT_CARE EGL_NATIVE_RENDERABLE 如果原生渲染库可以渲染到用EGLConfig创建的表面，则为真 EGL_DONT_CARE EGL_NATIVE_VISUAL_ID 关于应原生窗口系统可视ID句柄 EGL_DONT_CARE EGL_NATIVE_VISUAL_TYPE 关于原生窗口系统可视类型 EGL_DONT_CARE EGL_RENDERABLE_TYPE 由EGL_OPENGL_ES_BIT、EGL_OPENGL_ES2_BIT、EGL_OPENGL_ES3_BIT_KHR(需要EGL_KHR_create_context扩展)、EGL_OPENGL_BIT或EGL_OPENVG_BIT组成的位掩码，代表配置支持的渲染接口 EGL_OPENGL_ES_BIT EGL_SAMPLE_BUFFERS 可用多重采样缓冲区数量 0 EGL_SAMPLES 每个像素的样本数量 0 EGL_STENCIL_SIZE 模板缓冲区为主 0 EGL_SURFACE_TYPE 支持的EGL表面类型，可能是EGL_WINDOW_BIT、EGL_PIXMAP_BIT、EGL_PBUFFER_BIT、EGL_MULTISAMPLE_RESOLVE_BOX_BIT、EGL_SWAP_BEHAVIOR_PRESERVED_BIT、EGL_VG_COLORSPACE_LINER_BIT或者EGL_VG_ALPHA_FORMAT_PRE_BIT EGL_WINDOW_BIT EGL_TRANSPARENT_TYPE 支持的透明度 EGL_NONE EGL_TRANSPARENT_RED_VALUE 解读为透明的红色值 EGL_DONT_CARE EGL_TRANSPARENT_GREEN_VALUE 解读为透明的绿色值 EGL_DONT_CARE EGL_TRANSPARENT_BLUE_VALUE 解读为透明的蓝色值 EGL_DONT_CARE 与窗口系统通信EGL提供了OpenGL ES 3.0（和其他Khrons图形API）和运行于计算机上的原生窗口系统（如GNU/Linux系统上常见的X Window系统、Microsoft Windows或者Mac OS X的Quartz）之间的一个“结合”层次。在EGL能够确定可用的绘制表面类型（或者底层系统的其他特性）之前，它必须打开和窗口系统的通信渠道。注意，Apple提供自己的EGL API的iOS实现，称为EAGL。因为每个窗口系统都有不同的语义，所以EGL提供基本的不透明类型—EGLDisplay，该类型封装了所有系统相关，用于和原生窗口系统接口。任何使用EGL的应用程序必须执行的第一个操作是创建和初始化与本地EGL显示的连接。这采用例3-1所示的两次调用序列完成。例3-1 初始化EGL12345678910111213EGLint majorVersion;EGLint minorVersion;EGLDisplay display = eglGetDisplay(EGL_DEFAULT_DISPLAY);if (display == EGL_NO_DISPLAY)&#123; // Unable to open connection to local windowinng system&#125;if (!eglInitialize(display,&amp;majorVersion,&amp;minorVersion))&#123; // Unable to initialize EGL; handle and recover&#125; 调用如何函数打开与EGL显示服务器的连接：EGLDisplay eglGetDisplay(EGLNativeDisplayType displayId)displayId 指定显示连接，默认连接为EGL_DEFAULT_DISPLAY 检查错误EGL中的大部分函数在成功时返回EGL_TRUE，否则返回EGL_FALSE。但是，EGL所做的不仅是告诉你调用是否失败—它将记录错误，指示故障原因。不过，这个错误代码不会直接返回给你；你需要明确地查询EGL错误代码，为此可以调用如何函数完成：EGLint eglGetError() 初始化EGL成功地打开连接之后，需要初始化EGL，这通过调用如何函数完成：EGLBoolean eglInitialize(EGLDisplay display,EGLint *majorVersion,EGLint *minorVersion)display 指定EGL显示连接majorVersion 指定EGL实现返回的主版本号，可能为NULLminorVersion 指定EGL实现返回的次版本号，可能为NULL 确定可用的表面配置一旦初始化了EGL，就可以确定可用渲染表面的类型和配置，这有两种方法： 查询每个表面配置，找出最好的选择。 指定一组需求，让EGL推荐最佳匹配。 查询EGLConfig属性现在，我们说明与EGLConfig相关的EGL值，并说明如何检索这些值。EGLConfig包含关于EGL启用的表面的所有信息。这包括关于可用颜色、与配置相关的其他缓冲区（如后面将要讨论的深度和模版缓冲区）、表面类型和许多其他特性。下面是可以从EGLConfig中查询的属性的一个列表。在本章中我们只讨论一个子集，表3-1中列出了完整的列表作为参考。使用如何函数可以查询与EGLConfig相关的特定属性：EGLBoolean eglGetConfigAttrib(EGLDisplay display,EGLConfig config,EGLint attribute,EGLint *value)display 指定EGL显示连接config 指定要查询的配置attribute 指定返回的特定属性value 指定返回值上述函数在调用成功时返回EGL_TRUE，失败时返回EGL_FALSE，如果attribute不是有效的属性，则还要返回EGL_BAD_ATTRIBUTE错误。 创建屏幕上的渲染区域：EGL窗口12345EGLSurface eglCreateWindowSurface(EGLDisplay display, // 指定EGL显示连接 EGLConfig config, // 指定配置 EGLNativeWindowType window, // 指定原生窗口 const EGLint * attribList // 指定窗口属性列表；可能为NULL ); 下表是eglCreatePbufferSurface失败时可能的错误 错误代码 描述 EGL_BAD_ALLOC pbuffer因为缺乏资源而无法分配时发生这种错误 EGL_BAD_CONFIG 如果提供的EGLConfig不是系统支持的有效配置，则发生这种错误 EGL_BAD_PARAMETER 如果属性列表中提供的EGL_WIDTH或EGL_HEIGHT是负值，则产生这种错误 同步渲染你可能会碰到一些情况，即需要协调多个图形API在单个窗口中的渲染。例如，你可能发现使用OpenVG更容易找到比OpenGL ES 3.0更适于窗口绘制字符的原生窗口系统字体渲染函数。在这种情况下，需要让应用程序允许多个库渲染到共享窗口。EGL有几个函数有助于同步任务。 着色器和程序需要创建两个基本对象才能用着色器进行渲染：着色器对象和程序对象。理解着色器对象和程序对象的最佳方式是将它们比作C语言的编译器和链接程序。C编译器为一段源代码生成目标代码（例如，.obj或者.o文件）。在创建目标文件之后，C链接程序将对象文件链接为最后的程序。编译之后，着色器对象可以连接到一个程序对象。程序对象可以连接多个着色器对象。在OpenGL ES中，每个程序对象必须连接一个顶点着色器和一个片段着色器（不多也不少），这和桌面OpenGL不同。程序对象被链接为用于渲染的最后“可执行程序”。获得链接后的着色器对象的一般过程包括6个步骤： 创建一个顶点着色器对象和一个片段着色器对象。 将源代码连接到每个着色器对象。 编译着色器对象。 创建一个程序对象。 将编译后的着色器对象连接到程序对象。 链接程序对象。 创建和编译一个着色器使用着色器对象的第一步是创建着色器，着用glCreateShader完成。12GLuint glCreateShader(GLenum type//创建的着色器类型可以是GL_VERTEX_SHADER或者GL_FRAGMENT_SHADER ); 调用glCreateShader将根据传入的type参数创建一个新的顶点或者片段着色器。返回值是指向新着色器对象的句柄。当完成着色器对象时，可以用glDeleteShader删除。12void glDeleteShader(GLuint shader // 要删除的着色器对象的句柄 ); 如果一个着色器链接到一个程序对象，那么调用glDeleteShader不会立刻删除着色器，而是将着色器标记为删除，在着色器不再连接到任何程序对象时，它的内存将被释放。一旦创建了着色器对象，下一件事通常时用glShaderSource提供着色器源代码。1234glShaderSource(GLuint shader,// 指向着色器对象的句柄 GLsizei count,//着色器源字符串的数量。着色器可以由多个源字符串组成，但是每个着色器只能有一个main函数。 const GLchar* const *string,// 指向保存数量为count的着色器源字符串的数组指针。 const GLint *length);//指向保存每个着色器字符串大小且元素数量为count的整数数组指针。如果length为NULL，着色器字符串被认定为空。如果length不为NULL，则它的每个元素保存对应于string数组的着色器的字符数量。如果任何元素的length值均小于0，则该字符串被认定以null结束。 12void glLinkProgram(GLuint program//指向程序对象的句柄 ); 链接操作负责生成最终的可执行程序。链接程序将检查各种对象的数量，确保成功链接。链接程序之后，你必须检查链接是否成功，可以使用glGetProgramiv检查链接状态。1234void glGetProgramiv(GLuint program, // 需要获取信息的程序对象句柄 GLenum pname, GLint *params // 指向查询结果整数存储位置的指针 ); pname 获取信息的参数，可以是：123456789101112131415GL_ACTIVE_ATTRIBUTESGL_ACTIVE_ATTRIBUTE_MAX_LENGTHGL_ACTIVE_UNIFORM_BLOCKGL_ACTIVE_UNIFORM_BLOCK_MAX_LENGTHGL_ACTIVE_UNIFORMSGL_ACTIVE_UNIFORM_MAX_LENGTHGL_ATTACHED_SHADERSGL_DELETE_STATUSGL_INFO_LOG_LENGTHGL_LINK_STATUSGL_PROGRAM_BINARY_RETRIEVABLE_HINTGL_TRANSFORM_FEEDBACK_BUFFER_MODEGL_TRANSFORM_FEEDBACK_VARYINGSGL_TRANSFORM_FEEDBACK_VARYING_MAX_LENGTHGL_VALIDATE_STATUS 统一变量和属性一旦链接了程序对象，就可以在对象上进行许多查询。首先，你可能需要找出程序中的活动统一变量。统一变量（uniform）—— 在关于着色语言的下一章中详细介绍——是存储应用程序通过OpenGL ES 3.0 API传递给着色器的只读常数值的变量。统一变量被组合成两类统一变量块。第一类是命名统一变量块，统一变量的值由所谓的统一变量缓冲区对象（下面将详细介绍）支持。命名统一变量块被分配一个统一变量块索引。下面的例子声明一个名为TransformBlock并包含3个统一变量（matViewProj、matNormal和matTexGen）的统一变量块：123456uniform TransformBlock&#123; mat4 matViewProj; mat3 matNormal; mat3 matTexGen;&#125;; 第二类是默认的统一变量块，用于在命名块统一变量块之外声明的统一变量。和命名统一变量块不同，默认统一变量块没有名称或者统一变量块索引。下面的例子在命名统一变量块之外生命同样的3个统一变量：123uniform mat4 matViewProj;uniform mat3 matNormal;uniform mat3 matTexGen; 我们将在5.14节更详细地说明统一变量块。如果统一变量在顶点着色器和片段着色器中均有声明，则声明的类型必须相同，且在两个着色器中的值也需相同。在链接阶段，链接程序将为程序中与默认统一变量块相关的活动统一变量指定位置。 获取和设置统一变量要查询程序中活动统一变量的列表，首先要用GL_ACTIVE_UNIFORMS参数调用glGetProgramiv。这样可以获得程序中活动统一变量的数量。这个列表包含命名统一变量块中的统一变量、着色器代码中生命的默认统一变量块中统一变量以及着色器代码中使用的内建统一变量。如果统一变量被程序使用，就认为它是“活动”的。换言之，如果你在一个着色器中声明了一个统一变量，但是从未使用，链接程序可能会在优化时将其去掉，不在活动统一变量列表中饭回。你还可能发现程序中最大统一变量名称的字符数量（包括null终止符）；这可以用GL_ACTIVE_UNIFORM_MAX_LENGTH参数调用glGetProgramiv获得。知道活动统一变量和存储统一变量名称所需的字符数之后，我们可以用glGetActiveUniform和glGetActiveUniformsiv找出每一个统一变量的细节。void glGetActiveUniform(GLuint program, GLuint index, GLsizei bufSize, GLsizei *length, GLint *size, GLenum *type, GLchar *name);program 程序对象句柄index 查询的统一变量索引bufSize 名称数组中的字符数length 如果不是NULL，则是名称数组中写入的字符数（不含null终止符）size 如果查询的统一变量时个数组，这个变量便将写入程序中使用的最大数组元素（加1）；如果查询的统一变量不是数组，则该值为1type 将写入统一变量类型；可以为：123456789101112GL_FLOAT,GL_FLOAT_VEC2,GL_FLOAT_VEC3,GL_FLOAT_VEC4,GL_INT,GL_INT_VEC2,GL_INT_VEC3,GL_INT_VEC4,GL_UNSIGNED_INT,GL_UNSIGNED_INT_VEC2,GL_UNSIGNED_INT_VEC3,GL_UNSIGNED_INT_VEC4,GL_BOOL,GL_BOOL_VEC2,GL_BOOL_VEC3,GL_BOOL_VEC4,GL_FLOAT_MAT2,GL_FLOAT_MAT3,GL_FLOAT_MAT4,GL_FLOAT_MAT2x3,GL_FLOAT_MAT2x4,GL_FLOAT_MAT3x2,GL_FLOAT_MAT3x4,GL_FLOAT_MAT4x2,GL_FLOAT_MAT4x3,GL_SAMPLER_2D,GL_SAMPLER_3D,GL_SAMPLER_CUBE,GL_SAMPLER_2D_SHADOW,GL_SAMPLER_2D_ARRAY,GL_SAMPLER_2D_ARRAY_SHADOW,GL_SAMPLER_CUBE_SHADOW,GL_INT_SAMPLER_2D,GL_INT_SAMPLER_3D,GL_INT_SAMPLER_CUBE,GL_INT_SAMPLER_2D_ARRAY,GL_UNSIGNED_INT_SAMPLER_2D,GL_UNSIGNED_INT_SAMPLER_3D,GL_UNSIGNED_INT_SAMPLER_CUBE,GL_UNSIGNED_INT_SAMPLER_2D_ARRAY name 写入统一变量名称，最大字符数为bufSize,这是一个null终止的字符串。void glGetActiveUniformsiv(GLuint program, GLsizei count, const GLuint *indeices, GLenum pname, GLint *params);program 程序对象句柄count 索引（indices）数组中的元素数量indices 统一变量索引列表pname 统一变量索引中每个统一变量的属性，将被写入params元素；可以是： GL_UNIFORM_TYPE, GL_UNIFORM_SIZE， GL_UNIFORM_NAME_LENGTH,GL_UNIFORM_BLOCK_INDEX, GL_UNIFORM_OFFSET, GL_UNIFORM_ARRAY_STRIDE， GL_UNIFORM_MATRIX_STRIDE, GL_UNIFORM_IS_ROW_MAJORparams 将被写入由对应统一变量的pname所指定的结果 统一变量缓冲区对象可以使用缓冲区对象存储统一变量数据，从而在程序中的着色器之间甚至程序之间共享统一变量。这种缓冲区对象乘坐统一变量缓冲区对象。使用统一变量缓冲区对象，你可以在更新大的统一变量块时降低API开销。此外，这种方法增加了统一变量的可用存储，因为你的可以不受默认统一变量块大小的限制。要更新统一变量缓冲区对象中的统一变量数据，你可以用glBufferData、glBufferSubData、glMapBufferRange和glUnmapBuffer等命令修改缓冲区对象的内容。在统一变量缓冲区对象中，统一变量在内存中以如下形式出现： 类型为bool、int、uint和float的成员保存在内存的特定偏移，分别作为单个unity、int、unit和float类型的分量。 基本数据类型bool、int、uint或者float的向量保存在始于特定便宜的连续内存位置中，第一个分量在最低偏移处。 C列R行的列优先矩阵被当成C浮点列向量的一个数组对待，每个向量包含R个分量。相类似，R行C列的行优先矩阵被当成R浮点行向量的一个数组，每个向量包含C个分量。列向量或者行向量连续存储，但是有些实现的存储中可能有缺口。矩阵中两个向量之间的偏移量被称作列跨距或者行跨距（GL_UNIFORM_MATRIX_STRIDE），可以在链接的程序中用glGetActiveUniformsiv查询。 标量、向量和矩阵的数组按照元素的顺序存储与内存中，成员0放在最低偏移处。数组中每个元素之间的偏移量时一个常熟，称作数组跨距（GL_UNIFORM_ARRAY_STRIDE），可以在链接的程序中用glGetActiveUniformsiv查询。 着色器编译器当你要求OpenGL ES编译和链接着色器时，光花一点时间思考OpenGL ES实现必须做到的事。着色器代码通常解析为某种中间表现形式，这和大部分编译语言相同（例如，抽象语法树）。编译器必须将抽象表现形式转化为硬件的机器指令。理想状态下，这个编译器还应该进行大量的优化，例如无用代码删除、常量传播等。进行这些工作需要付出代价——主要是CPU时间和内存。OpenGL ES 3.0实现必须支持在线着色器编译（用glGetBooleanv检索的GL_SHARDER_COMPILER值必须是GL_TRUE）。你可以指定着色器使用glShaderSource，就像我们在示例中所做的那样。你还可以尝试缓解着色器编译对资源的影响。也就是说，一旦完成了应用程序中着色器的编译，就可以调用glReleaseShaderCompiler。这个函数提示OpenGL ES实现你已经完成了着色器编译器的工作，可以释放它的资源了。注意，这个函数只是一个提示，如果决定用glCompileShader编译更多的着色器，那么OpenGL ES实现需要重新为编译器分配资源。void glReleaseShaderCompiler(void)提示OpenGL ES实现可以释放着色器编译器使用的资源。因为这个函数只是个提示，所以有些实现可能忽略对这个函数的调用。 程序二进制码程序二进制码是完全编译和链接的程序的二进制表现形式。它们很有用，因为可以保存到文件系统供以后使用，从而避免在线编译的代价。你也可以使用程序二进制码，这样就没有必要在实现中分发着色器源代码。 OpenGL ES着色语言在前面几章中你已经看到，着色器是OpenGL ES 3.0API的一个基础和兴概念。每个OpenGL ES 3.0程序都需要一个顶点着色器和片段着色器，以渲染有意义的图片。考虑到着色器是API概念的核心，我们希望确保你在深入了解图形API的更多细节之前，掌握编写着色器的基础知识。本章的目标是确保你理解着色语言中的如下概念： 变量和变量类型 向量和矩阵的构造及选择 常量 结构和数组 运算符、控制流和函数 输入/输出变量、统一变量、统一变量块和布局限定符 预处理器和指令 统一变量和插值器打包 精度限定符和不变性 我们在第2章中的例子里已经介绍了这些概念的少数细节。现在，我们将用更多的细节来充实这些概念，确保你理解如何编写和阅读着色器。 OpenGL ES着色语言基础知识在阅读本书时，你会看到许多着色器。如果你开始开发自己的OpenGL ES 3.0应用程序，则很有可能编写许多着色器。目前，你应该已经理解了着色器作用的基本概念以及它融入管线的方式。如果还不理解，可以复习第1张，在那里我们介绍了管线，并且描述了顶点着色器和片段着色器融入其中的方式。现在我们要关注的是着色器究竟是由什么组成的。你可能已经观察到，着色器的语法和C编程语言有很多相似之处。如果你能够理解C代码，理解着色器的语法就没有太大的难度。但是，两种语言之间当然有一些重大的区别，首先是版本规范和所支持的原生数据类型。 着色器版本规范#version 300 es没有声明版本号的着色器被认定使用OpenGL ES着色语言的1.00版本。着色语言的1.00版本用于OpenGL ES 2.0。对于OpenGL ES 3.0，规范的作者决定匹配API和着色语言的版本号。 变量和变量类型在计算机图形中，两个基本数据类型组成了变换的基础：向量和矩阵。这两种数据类型在OpenGL ES着色语言中也是核心。表5-1具体描述了着色语言中存在的基于标量、向量和矩阵的数据类型。 表 5-1 OpenGL ES 着色语言中的数据类型 变量分类 类型 描述 标量 float,int,uint,bool 用于浮点、整数、无符号整数和布尔值的基于标量的数据类型 浮点向量 float,vec2,vec3,vec4 有1、2、3、4个分量的基于浮点的向量类型 整数向量 int,ivec2,ivec3,ivec4 有1、2、3、4个分量的基于整数的向量类型 无符号整数向量 uint,uvec2,uvec3,uvec4 有1、2、3、4个分量的基于无符号整数的向量类型 布尔向量 bool,bvec2,bvec3,bvec4 有1、2、3、4个分量的基于无符号整数的向量类型 矩阵 mat2（或mat2x2),mat2x3,mat2x4,mat3x2,mat3(或mat3x3),mat3x4,mat4x2,mat4x3,mat4(或mat4x4) 2x2,2x3,2x4,3x2,3x3,3x4,4x2,4x3或4x4的基于浮点的矩阵 变量构造器OpenGl ES着色语言在类型转换方面有非常严格的规则。也就是说，变量只能赋值为相同类型的其他变量或者相同类型的变量进行运算。在语言不允许隐含类型转换的原因是，这样可以避免着色器作者遇到可能导致难以跟踪的缺陷的意外转换。 对于矩阵的构造，着色语言很灵活。下面是构造的一些基本规则： 如果只为矩阵构造器提供一个标量参数，则该值被放在矩阵的对角线上。例如，mat4(1.0)将创建一个4x4的单位矩阵。 矩阵可以从多个向量参数构造。例如，mat2可以从两个vec2构造。 矩阵可以从多个标量参数构造，每个参数代表矩阵中的一个值，从左到右使用。 OpenGL ES中的矩阵以列优先顺序存储。使用矩阵构造器时，参数按列填充矩阵。下面的例子中的注释说明了矩阵构造参数如何映射到列中。123mat3 myMat3 = mat3(1.0,0.0,0.0,// First column 0.0,1.0,0.0,//Second column 0.0,1.0,1.0);// Third column 常量可以将任何基本类型声明为常数变量。常数变量是着色器中不变的值。声明常量时，在声明中加入const限定符。常数变量必须在声明时初始化。下面是const声明的一些例子：1234const float zero = 0.0f;const float pi = 3.14159;const vec4 red = vec4(1.0,0.0,0.0,1.0);const mat4 identity = mat4(1.0); 正如在C或者C++中那样，声明为const的变量是只读的，不能在源代码中修改。 结构除了使用语言中提供的基本类型之外，还可以和C语言一样将变量聚合成结构。OpenGL ES着色语言中声明结构的语言如下例所示：123456struct fogStruct&#123; vec4 color; float start; float ent;&#125;fogVar; 上述定义的结果是一个名为fogStruct的新用户类型和一个新变量fogVar。结构可以用构造器初始化。在定义新的结构类型之后，也用与类型相同的名称顶一个新的结构构造器。 函数函数的声明方法和C语言相通。 限定符 描述 in （没有指定时的默认限定符）这个限定符指定参数按值传送，函数不能修改 inout 这个限定符规定变量按照引用传入函数，如果该值被修改，它将在函数退出后变化 out 这个限定符表示该变量的值不被传入函数，但是在函数返回时将被修改 统一变量OpenGL ES着色语言中的变量类型限定符之一是统一变量。统一变量存储应用程序通过OpenGL ES 3.0 API传入着色器的只读值，对于保存着色器所需的所有数据类型（如变化矩阵、照明参数和颜色）都很有用。本质上，一个着色器的任何参数在所有顶点或者片段中都应该以统一变量的形式传入。在编译时已知值的变量应该是常量，而不是统一变量，这样可以提供效率。 限定符 描述 shared shared限定符指定多个着色器或者多个程序中统一变量块的内存布局相同。要使用这个限定符，不同定义中的row_major/column_major值必须相等。覆盖std140和packed（默认） packet packet布局限定符指定编译器可以优化统一变量块的内存布局。使用这个限定符时必须查询偏移位置，而且统一变量块无法在顶点/片段着色器或者程序见共享。覆盖std140和shared std140 std140布局限定符指定统一变量块的布局基于OpenGL ES 3.0规范的“标准统一变量快布局”中定义的一组标准规则。 raw_major 矩阵在内存中以行优先顺序布局 column_major 矩阵在内存中以列优先顺序布局（默认） 顶点和片段着色器输入/输出这个着色的两个顶点输入变量a_position和a_color的数据由应用程序加载。本质上，应用程序将为每个顶点创建一个顶点数组，该数组包含位置和颜色。1234567891011121314151617181920212223// Vector Shader#version 300 esuniform mat4 u_matViewProjection;layout(location = 0) in vec4 a_position;layout(location = 1) in vec3 a_colorout vec3 v_colorvoid main(void)&#123; gl_Position = u_matViewProjection * a_position; v_color = a_color;&#125;// Fragment Shader#version 300 esprecision mediump float // Input from vertex shaderin vec3 v_color;// Output of fragment shaderlayout(location = 0) out vec4 o_fragColor;void main()&#123; o_fragColor = vec4(v_color, 1.0);&#125; layout限定符用于指定顶点属性的索引。布局限定符是可选的，如果没有指定，链接程序将自动为顶点输入变量分配位置。和统一变量一样，底层硬件通常可在输入顶点着色器的属性变量数目上有限制。OpenGL ES实现支持的最大属性数量由内建变量gl_MaxVertexAttribs给出（也可以使用glGetIntegerv查询GL_MAX_VERTEX_ATTRIBS得到）。OpenGL ES 3.0实现可支持的最小属性为16个。不同的实现可以支持更多变量，但是如果想要编写保证能在任何OpenGL ES 3.0实现上运行的着色器，则应该将属性限制为不多于16个。 插值限定符在没有限定符时，默认的插值行为是执行平滑着色。也就是说，来自顶点着色器的输出变量在图元中线性插值，片段着色器接受线性插值之后的数值作为输入。我们可以明确的请求平滑着色，而不是依赖默认行为，如下：1234567// ...Vertex shader...// Vertex shader outputsmooth out vec3 v_color;// ..Fragment shader// Input from vertex shadersmooth in vec3 v_color; OpenGL ES 3.0引入了平面着色。在平面着色中，图元的值没有进行插值，而是将一个顶点设为驱动顶点(Provoking Vertex)，该顶点的值被用于图元中的所有片段。我们可以声明如下的平面着色输出/输入：1234567// ...Vertex Shader...// Vertex shader outputflat out vec3 v_color;// ...Fragment shader...// Input from fragment shaderflat in vec3 v_color; 最后，可以用centroid关键字在插值器中添加另一个限定符。质心采样(centroid sampling)1234567// ..Vertex shader// Vertex shader outputsmooth centroid out vec3 v_color;// ...Fragment shader// Input from vertex shadersmooth centroid in vec3 v_color; 预处理器和指令12345678#define#undef#if#ifdef#ifndef#else#elif#endif 注意，宏不能定义为带有参数(在C++的宏中可以这样)。#if、#else和#elif指令可以使用defind测试来查看宏是否已经定义。下面的宏是预先定义的，接下来将作说明：1234__LINE__ // Replaced with the current line number in a shader__FILE__ // Always 0 in OpenGL ES 3.0__VERSION__ // The OpenGL ES shading language versionGL_ES // This will be defind for ES shaders to a value of 1 扩展行为 描述 require 扩展是必须的，因为预处理器在扩展不受支持时将抛出错误。如果指定了all，将总是抛出错误 enable 扩展被启用，因为扩展不受支持时预处理将抛出警告。如果扩展被启用，该语言将被处理。如果指定all，将总是抛出错误 warn 对于扩展的任何使用均提出警告，除非这种使用时另一个已经启用扩展所必需的。如果指定all，则在使用扩展时都将抛出警告。而且，如果扩展不受支持，将抛出警告 disable 扩展被禁用，因此如果使用扩展将被抛出错误。如果指定all（默认），则不启用任何扩展 统一变量和插值器打包统一变量通常保存在所谓的“常量存储”中，这可以看作向量的物理数组。顶点着色器输出/片段着色器输入一般保存在插值器中，这通常也保存为一个向量数组。在OpenGL ES 3.0中，定义插值器和统一变量映射到物理存储空间的方式。打包规则基于物理存储空间被组织为一个每个存储位置4列（每个向量分量一列）和1行的网格的概念。打包规则寻求打包变量，使生成代码的复杂度保持不变。换言之，打包规则不景行重排序操作（这种操作需要编译器生成合并打包数据的额外指令），而是试图在部队运行时性能产生负面影响的情况下，优化物理地址空间的使用。我们来看一组统一变量声明的例子，看看如何打包它们：123uniform mat3 m;uniform float f[6];uniform vec3 v; 如果完全不进行打包，你可能发现许多常量存储空间将被浪费。矩阵m将占据3行，数组f占据6行，向量v占据1行，共需要10行才能存储这些变量。下表展示了任何不进行任何打包的结果。 位置 X Y Z W 0 m[0].x m[0].y m[0].z - 1 m[1].x m[1].y m[1].z - 2 m[2].x m[2].y m[2].z - 3 f[0] - - - 4 f[1] - - - 5 f[2] - - - 6 f[3] - - - 7 f[4] - - - 8 f[5] - - - 9 v.x v.y v.z -6 下表表示打包之后的结果 位置 X Y Z W 0 m[0].x m[0].y m[0].z f[0] 1 m[1].x m[1].y m[1].z f[1] 2 m[2].x m[2].y m[2].z f[2] 3 v.x v.y v.z f[3] 4 - - - f[4] 5 - - - f[5] 在使用打包规则时，只需硧6个物理常量位置。你将会注意到，数组f的元素会跨越行的边界，原因是GPU通常会按照向量位置索引对常量存储进行索引。打包必须时数组跨域行边界，这样索引才能够起作用。所有打包对OpenGL ES着色语言的用户都是完全透明的，除了一个细节：打包影响统一变量和顶点着色器输出/片段着色器输入的计数方式。如果你想要编写保证能够在所有OpenGL ES 3.0实现上运行的机器，就不应该使用打包之后超过最小运行存储大小的统一变量或者插值器。 精度限定符精度限定符使着色器创作者可以指定着色器变量的计算精度。变量可以声明为低、中高。这些限定符用于提示编译器允许在较低的范围和精度上执行变量计算。在较低的精度上，有些OpenGL ES实现在运行着色器时可能更快，或者电源效率更高。当然，这种效率的提升是以精度为代价的，在没有正确使用精度限定符时可能造成伪像。注意，OpenGL ES规范中没有规定底层硬件中必须支持多种精度，所以某个OpenGL ES实现在最高精度上进行所有运算并见到那地忽略限定符是完全正常地。不过，在某些是线上，使用较低地精度可能带来好处。精度限定符可以用于指定任何基于浮点数或者整数的变量的精度。指定精度的关键字是lowp、mediump和highp。下面是一些带有精度限定符的声明示例：123highp vec4 position;varying lowp vec4 color;mediump float specularExp; 除了精度限定符之外，还有默认精度的概念。也就是说，如果变量声明时没有使用精度限定符，它将拥有该类型的默认精度。默认精度限定符在顶点或者片段着色器的开头用如下语法指定：12precision highp float;precision mediump int; 在顶点着色器中，如果没有指定默认精度，则int和float的默认精度都为highp。也就是说，顶点着色器中所有没用精度限定符声明的变量都使用最高的精度。片段着色器的规则与此不同。在片段着色器中，浮点值没有默认的精度值：每个着色器必须声明一个默认的float精度，或者为每个float变量指定精度。 不变性OpenGL ES着色语言中引入的invariant关键字可以用于任何可变的顶点着色器输出。不变性是什么意思，为什么它很必要呢？问题在于着色器需要编译，而编译器可能进行导致指令重新排序的优化。这种指令重排意味着两个着色器之间等价计算不能保证产生完全相同的结果。这种不一致性在多遍着色器特效时尤其可能称为问题，在这种情况下，相同的对象Alpha混合绘制在自身上方。如果用于计算输出位置的数值的精度不完全一样，精度差异就会导致伪像。这个问题通常表现为“深度冲突”(Z fighting)，每个像素的Z（深度）精度差异导致不同遍着色相互之间有微小的偏移。invariant关键字可以用于变量声明，或者用于已经声明的变量。下面是一些例子：12invariant gl_Position;invariant texCoord; 一旦某个输出变量声明了不变性，编译器便保证相同的计算和着色器输入条件下结果相同。例如，两个顶点着色器通过将视图投影矩阵和输入位置位置相乘计算输出位置，你可以保证这些位置不变。123456789#version 300 esuniform mat4 u_viewProjMatrix;layout(location = 0) in vec4 a_vertex;invariant gl_Position;void main()&#123; // Will be the same value in all shaders with the same viewProjMatrix and vertex gl_Position = u_viewProjMatrix * a_vertex;&#125; 也可以用#pragma指定让所有变量全都不变：#pragma STDGL invariant(all)警告：因为编译器需要保证不变性，所以可能限制它所做的优化。因此，invariant限定符应该只在必要时使用；否则可能导致性能下降。由于这个原因，全局启用不变性的#pragma指令之应该在不变性对于所有变量都必需的时候使用。还要注意，虽然不变性表示在指定GPU上计算会得到相同的结果，但是并不意味着计算在任何OpenGL ES实现之间保持不变。 复制缓冲区对象迄今为止，我们已经说明如何用glBufferData、glBufferSubData和glMapBufferRange加载缓冲区对象。所以这些技术都涉及从应用程序到设备的数据传输。OpenGL ES 3.0还可以从一个缓冲区对象将数据完全复制到设备，这可用glCopyBufferSubData函数完成。void glCopyBufferSubData(GLenum readTarget,GLenum writeTarget,GLintptr readoffset,GLinptr writeoffset,GLsizeptr size)readtarget 读取的缓冲区对象目标writetarget 写入的缓冲区对象目标。readtarget和writetarget都可以设置为如下目标中的任何一个（尽管它们不必设置为同一个目标）GL_ARRAY_BUFFERGL_ELEMENT_ARRAY_BUFFERGL_COPY_READ_BUFFERGL_COPY_WRITE_BUFFERGL_PIXEL_PACK_BUFFERGL_PIXEL_UNPACK_BUFFERGL_TRANSFORM_FEEDBACK_BUFFERGL_UNIFORM_BUFFERreadoffset 需要复制的读缓冲区数据中的偏移量，以字节表示writeoffset 需要复制的写缓冲区数据中的偏移量，以字节表示size 从读缓冲区数据复制到写缓冲区数据的字节数 调用glCopyBufferSubData将从绑定到readtarget的缓冲区复制指定的字节到writetarget。缓冲区绑定根据每个目标的最后一次glBindBuffer调用确定。任何类型的缓冲区对象（数组、元素数组、变化反馈等）都可以绑定到GL_COPY_READ_BUFFER或GL_COPY_WRITE_BUFFER目标。这两个目标是一种方便的措施，使得应用程序在执行缓冲区的复制不改变任何真正的缓冲区绑定。 小结本章探索了OpenGL ES3.0中指定顶点属性和数据的方法，特别是介绍了如下主题： 如何使用glVertexAttrib*函数指定常量顶点属性和用glVertexAttrib[I]Point函数指定顶点数组。 如何在顶点数组状态在顶点数组对象中如何封装，以及如何使用VAO改进性能。 加载缓冲区对象数组的各种方法：glBuffer[Sub]Data、glMapBufferRange和glCopyBufferSubData。现在我们知道了指定顶点数据的方法，下一章将介绍在OpenGL ES中可以使用顶点数据的各种图元。 图元装配和光栅化本章描述OpenGL ES支持的图元和几何形状和对象的类型，并说明绘制它们的方法。然后描述发生在顶点着色器处理图元处理顶点之后的图元装配阶段。在这一阶段，执行裁剪、透视分割和视口变换操作，对这些操作将做详细的讨论。本章以光栅化阶段的描述作为结束。光栅化是将图元转换为一组二维片段的过程，这些片段由片段着色器处理，代表可以在屏幕上绘制的像素。 图元图元是可以用OpenGL ES中的glDrawArrays、glDrawElements、glDrawRangeElements、glDrawArraysInstanced和glDrawElementsInstanced命令绘制的几何形状对象。图元由一组表示顶点位置的顶点描述。其他如颜色、纹理坐标和几何法线等信息也作为通用属性和每个顶点关联。OpenGL ES3.0可以绘制如下图元： 三角形 直线 点精灵 三角形三角形代表着描述由3D应用程序渲染的几何形状对象时最常用的办法。OpenGL ES支持的三角形图元有GL_TRIANGLES、GL_TRIANGLE_STRIP和GL_TRIANGLE_FAN。图7-1展示了支持的三角形图元类型示例。GL_TRIANGLES绘制一系列单独的三角形。在图7-1中，绘制了顶点为$(v_0,v_1,v_2)$和$(v_3,v_4,v_5)$的两个三角形。总共绘制了n/3个三角形，其中n是前面提到的glDrawAPI中的Count指定的索引。GL_TRIANGLE_STRIP绘制一系列相关连接的三角形。在图7-1的例子中，绘制了3个顶点为$(v_0,v_1,v_2)$、$(v_2,v_1,v_3)$（注意顺序）和$(v_2,v_3,v_4)$的三角形。总共绘制了n-2个三角形，其中n是glDrawAPI中的Count指定的索引。GL_TRIANGLE_FAN也绘制了一系列相连的三角形。 纹理过滤和mip贴图到目前为止，我们对2D纹理的介绍仅限于单个2D图像。尽管这使得我们能够解释纹理的概念，但是OpenGL ES纹理的指定和使用还有一些其他的方法。这种复杂性与使用单个纹理贴图时发生的视觉危象和性能问题有关。正如我们到目前为止所描述的那样，纹理坐标用于生成一个2D索引，以从纹理贴图中读取。当缩小和放大过滤器设置为GL_NEAREST时，就会发生这样的情况：一个纹素将在提供的纹理坐标位置上读取。这称作点采样或者最近采样。但是，最近采样可能产生严重的视觉危象，这是因为三角形在屏幕空间中变得较小，在不同像素间的插值中，纹理坐标有很大的跳跃。结果是，从一个大的纹理贴图中取得少量样本，造成 纹理坐标包装纹理包装模式用于指定纹理坐标超出[0.0,1.0]范围是所发生的的行为，用glTexParamter]]></content>
      <categories>
        <category>OpenGL ES 3.0</category>
      </categories>
      <tags>
        <tag>OpenGL ES 3.0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菲涅尔反射]]></title>
    <url>%2F2019%2F05%2F12%2Ffresnelreflection%2F</url>
    <content type="text"><![CDATA[在实时渲染中，经常会使用菲涅耳反射（Fresnel reflection）来根据视角方向控制反射程度。菲涅耳反射描述了一种光学现象，即当光线照射到物体表面上时，一部分发生反射，一部分进入物体内部，发生折射或散射。被反射的光和入射光之间存在一定的比率关系，这个比率关系可以通过菲涅耳等式进行计算。一个经常使用的例子是，当你站在湖边，直接低头看脚边的水面时，你会发现水几乎是透明的，你可以直接看到水底的小鱼和石子；但是，当你抬头看远处的水面时，会发现几乎看不到水下的情景，而只能看到水面反射的环境。这就是所谓的菲涅耳效果。事实上，不仅仅是水、玻璃这样的反光物体具有菲涅耳效果，几乎任何物体都或多或少包含了菲涅耳效果，这是基于物理的渲染中非常重要的一项高光反射计算因子。那么，如何计算菲涅耳反射呢？这就需要使用菲涅耳等式。真实世界的菲涅耳等式是非常复杂的，但在实时渲染中，通常会使用一些近似公式来计算。其中一个著名的近似公式就是Schlick 菲涅耳近似等式： $F_{Schlick}(v,n) = F_{0}+(1-F_{0})(1-v \cdot n)^5$ 其中，$F_{0}$是一个反射系数，用于控制菲涅耳反射的强度， v 是视角方向， n 是表面法线。另一个应用比较广泛的等式是Empricial菲涅耳近似等式： $F_{Empricial}(v,n) = max(0,min(1,bias+scale x (1-v \cdot n)^power))$ 其中，bias、scale和power是控制项。使用上面的菲涅尔近似等式，可以在边界处模拟反射光强和折射光强/漫反射光强之间的变化。在许多车漆、水面等材质的渲染中，会经常用到菲涅尔反射来模拟更加真实的反射。]]></content>
      <categories>
        <category>Graphics</category>
      </categories>
      <tags>
        <tag>Graphics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斯涅尔定律]]></title>
    <url>%2F2019%2F05%2F12%2Fsnell%2F</url>
    <content type="text"><![CDATA[描述当光波从一种介质传播到另一种具有不同折射率的介质时，会发生折射现象，其入射角与折射角之间的关系，可以用斯涅尔定律（Snell’s Law）来描述。解释如下：入射光和折射光位于同一平面上，并且与界面法线的夹角满足如下关系：${n_1}sin\theta_1={n_2}sin\theta_2$，其中，$n_1$和$n_2$分别是两个介质的折射率，$\theta_1$和$\theta_2$分别是入射光（或折射光）与界面法线的夹角，叫做入射角和折射角。 特殊情况在折射定律中，若令$n1$和$n_2$，则得到反射定律，因此，可以将反射定律看做折射定律的一个特例。当光由光密介质（折射率$n_1$比较大的介质）射入光疏介质（折射率$n_2$比较小的介质）时（比如由水入射到空气中），如果入射角$\theta_1$等于某一个角$\theta_c$时，折射光线会沿折射界面的切线进行，即折射角$\theta_2=90$°,此时会有$sin\theta_2=1$，则可推出$sin\theta c=sin\theta_1={n2\over n1}$。但如果入射角$\theta_1$大于$\theta_c$时，入射角的正弦$sin\theta_1&gt;{n2\over n1}$，会推出$sin\theta_2&gt;1$。这在物理上是没有意义的，所以此时，不存在折射光，而只存在反射光，于是便发生全反射。而使得全反射发生的最小入射角$\theta_c$叫做临界角，它的值取决于两种介质的折射率的比值，即 $\theta_c=sin^{-1}{({n_2\over n_1})}$例如：水的折射率为1.33，空气的折射率近似等于1.00001，临界角$\theta_c$等于48.8°。]]></content>
      <categories>
        <category>光学</category>
      </categories>
      <tags>
        <tag>光学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[别离]]></title>
    <url>%2F2019%2F05%2F12%2Ffiction-1%2F</url>
    <content type="text"><![CDATA[芩站在府门外面，此时门口的护卫已经回去了，剩下门上挂着的两盏不算很明亮的灯笼，还有门口的两个石狮子。谁也看不出他是想进去还是想在外面等什么人，手握着挂在腰上的剑，头上戴着斗笠。就这样站在门口，似乎是有些奇怪，平日里，他总是在勤于练习他的剑法。虽然芩不是特别有天赋的人，但是却特别的努力。当别人问起他为什么要这么勤于练习的时候，他却说，“哦，也就无聊的时候练练。”。给人一种木讷的感觉。大概在等了有一刻钟的时候，徐娘回来了，原来今天是徐娘去王爷府给王妃请安去了。“哟，芩，你在这里干嘛呢？”，徐娘有些兴奋的说道。“徐娘，和总管说一声，我打算明天离开秦淮。”，芩淡淡的说道。“不是吧？这么快就要走了吗？还有点舍不得你呢。不过你还是自己进去和总管大人说吧，来都来了，顺便进去和总管好好道别一下吧。”，徐娘恢复了正常的神态。“不了，今晚回去收拾收拾，明天天一亮就动身了。”，芩说道。“这么急？”，徐娘说。“嗯。”，芩说。“好吧，那我替你和总管大人禀报一下，也祝你一路顺风。”，徐娘说。“嗯。”，芩说完转身离开。在回来的路上，芩缓慢的走在路上，其实也不算慢了，但是和之前比起来，确实慢了许多。月亮早已高高挂在天上了，由于今天是满月，可以比较清楚的看到周围的建筑和道路，虽然晚上一个人都没有。走这么慢在想什么呢？想着自己马上要离开了吗？要去一个可以让自己的武力和剑术更上一层楼的地方了吗？想以后的日子会变成什么样子的呢？谁也不知道，总之选择了，也只能按照选择的方式去生活吧。]]></content>
      <tags>
        <tag>混沌</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶变换]]></title>
    <url>%2F2019%2F05%2F11%2Ffouriertransform%2F</url>
    <content type="text"><![CDATA[什么是频域从我们出生，我们看到的世界都以时间贯穿，股票的走势、人的身高、汽车的轨迹都会随着时间发生改变。这种以时间作为参照物来观察动态世界的方法我们称其为时域分析。而我们也想当然的认为，世间万物都在随时间不停的改变，并且永远不会静止。但如果我告诉你，用另一种方法来观察世界的话，你会发现世界是永恒不变的，这个静止的世界就叫做频域。 我们眼中的世界就像皮影戏中的大幕步，幕布的候面有无数的齿轮，大齿轮带动小齿轮，小齿轮在带动更小的。在最外面的小齿轮上有个小人，那就是我们自己。我们只看到这个小人毫无规律的在幕布前表演，却无法预测他下一步去哪。而幕布候面的齿轮却永远一直那样不停的旋转，永不停歇。 离散傅里叶变换(DFT)定义离散傅里叶变换，是傅里叶变换在时域和频域上都呈现离散的形式，将时域信号的采样变换为离散时间傅里叶变换(DTFT)频域的采样。在形式上，变换两端（时域和频域上）的时序是有限长的，而实际上这两组序列应当被认为离散周期信号的主值序列。即使对有现场的离散信号做DFT，也应当将其看作经过周期延拓成为周期信号再做变换。在实际应用中通常采用快速傅里叶变换以高效计算DFT。 快速傅里叶变换(FFT)]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZBrush Manual]]></title>
    <url>%2F2019%2F05%2F11%2Fzbrush%2F</url>
    <content type="text"><![CDATA[常用快捷键空格键 激活鼠标指针下的菜单（按住不放再拖拉鼠标指针可定位文档）左键在空白处单击并拖动＝旋转视角alt建＋左键在空白处单击并拖动＝平移视角alt键＋左键然后放开alt键在空白处拖动并平移＝缩放视角 放大文档 缩小文档0（零） 查阅文档的实际大小旋转中配合 shift ，捕捉在正交视点处旋转中配合 ALT ，以相对平滑方式旋转视图按下 DEL ，可以将物体在画布中最大化显示Ctrl+0 查阅文档实际大小的一半，抗锯齿（还影响输出）ctrl+shift+拖动=未选中的部分将隐藏。ctrl+shift+点击空白处=恢复显示ctrl+shift+拖动+释放（ctrl、shift）=选中的部分将隐藏Ctrl+f 用当前texture填充canvas当前layerCtrl 遮罩功能Ctrl+d 细份一次Tab 隐藏/显示浮动调控板H 隐藏/显示Zscript窗口C 在指针下面拾取颜色S 绘图大小I RGB强度Shift+I Z强度Shift+d 绘制贴图的时候让模型上的网格线隐藏Q 绘图指示器（默认为所有工具）W 移动模式E 缩放模式R 旋转模式T 编辑模式Shift+s 备份物体M 标记物体点中marker ctrl+M 取消标记Ctrl+Z 撤销Shift+Ctrl+Z 重做Alt/Option 影响转换大多数工具G 打开Projection MasterAlt+A Alpha调控板Alt+C Color颜色调控板Alt+T tool调控板Alt+T Transform调控板Alt+R Render调控板Alt+鼠标左 绘图模式下可以删除Z求点 Shift+crease———————crease everythingShift_uncrease——————uncrease everythingA —————————zSphere to Z meshctrl+N ————————- clear the layer 笔刷 Standard(标准笔刷):使用Standard笔刷进行雕刻的时候,我们可以塑造出截面为半椭圆形的突起,如图所示 Smooth(光滑笔刷):在选择任何笔刷的情况下,按住Shift键,都会切换到Smooth笔刷,该笔刷可以使物体避免的形状进行融合,进而雕刻出较为平滑三维表面,如图所示 Move(移动笔刷):Move和Standard不同,不能对物体表面进行连续的形变,每次只能对不大于笔刷大小的区域进行锥拉操作,如图所示,但是Move在对形体进行调整时,有非常良好的表现 Clay(粘土笔刷):Clay与ClayTubes和ClayBuildup笔刷一样,属于粘土类型的笔刷,该中类型的笔刷雕刻起来感觉类似传统的泥塑,就像用泥巴一层一层的添加结构,它是应用最广发的笔刷之一. Clay Tubes(粘土管笔刷):此笔刷可以作为Clay的变种笔刷,由于加载了方形的Alpha,所以在塑造形体的时候,边缘更清晰,而且有层次感. Clay Buildup(粘土堆积笔刷):同ClayTubes笔刷相比,ClayBuildup笔刷更细腻,凹起程度也更高.不同的是,Clay和ClayTubes在雕刻时会使形体产生平坦的突起,但是ClayBuildup会产生边界较为锐利但表面弧状的突起. Dam Standard:给人感觉用刀雕刻的感觉。 HPolish Brush可以画出坚硬的牙齿效果。 Slash3 Tray是用来放置菜单的.CanvasLight BoxShelfBrushProject位于上面的File菜单中.也可以通过快捷键Ctrl+S访问这个选项,这样就可以保存好一个Project了,Project中可以保存全部的Tools.可以将其中所有的Tools都保存好.也可以保存好对材质面板的改变.以及Render面板中的一些设置和Light面板中的一些设置.一定要记住Project中保存了所有的ToolsTool 快捷键操作摁住Alt鼠标左键点击空白处移动,可以移动画面.默认外拉面数,Alt内推面数Zadd,ZsubZadd是所有笔刷默认使用的模式,不是所有的笔刷,你只要按Alt就可以切换到Zsub模式,向内雕刻模型,摁住Shift你会注意到,鼠标光标会变成蓝色,现在处于Smooth Brush模式,你可以使模型表面变得平滑Smoothey IntelligentlyClay笔刷不用理会拓扑结构是怎样的.无论是光滑的还是凹陷的结构.它与拓扑结构无关.Ctrl添加Mask，Ctrl+Alt消除Mask做耳朵技巧：先用Mask画出一个耳朵，然后更改画刷为Move，然后修改细分，然后拉出一只耳朵来。单独按D键，可以向上移动一个层级DeformationSmart ReSym 设置快捷键1键切换到标准笔刷，2键切换到Move笔刷，3键表示Clay4，4键表示Tray Dynamic，5键表示Clay Buildup在Deformation(变形工具)中可以调整Inflate（充气）选项。让模型变得臃肿。Inflate Balloon(快速充气)注意这个选项运算量很大，所以最好修改一下细分。 Polish：磨光 Polish Grisp Edge Masking(遮罩工具) Mask By Cavity对内向的地方进行了遮罩。 Sub ToolSphere3D制作头发GeometryDynaMeshResolution 128TransparencyGhost Can’t adjust divideTry use Dynamesh,but this operator may be make your mode have a few of triangle. |快捷键|说明||Ctrl+Shift+Alt然后框选物体|剪切掉框选的物体||Ctrl+Shitf然后框选物体|剪切掉除了框选之外的物体|]]></content>
      <categories>
        <category>ZBrush</category>
      </categories>
      <tags>
        <tag>ZBrush</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3DMAX Manual]]></title>
    <url>%2F2019%2F05%2F11%2F3dmax%2F</url>
    <content type="text"><![CDATA[工具栏主工具栏（Main Toolbars）:按ALT+6可以进行隐藏/显示，其他工具栏可以选择菜单Customize\Show UI(自定义\显示用户界面)进行显示在屏幕上。 工作视图 视图切换可直接按快捷键的有： T—Top（顶视图）、B—Bottom（底视图）、F—Front（前视图）L—Left（左视图）、U—User（用户视图）、P—Perspective（透视图）C—Camara（摄像机视图，只有建立摄像机后才有用）Shift+移动——复制MAX安全框 快捷键 显示/隐藏安全框 Shitf+F, 防止相机打出去的Shift+Q——渲染当前视图Alt+X使选中物体透明 其他不能按快捷键的操作如下： 激活视图，按V键，从快捷菜单中进行选择 在视图名称处按右键选择Views(查看)命令后面的相应视图 视图中的物体显示方式Wireframe（网格）：以物体颜色显示网格，材质不显示Smooth+HighLights（实体）以上两种可以按F3进行切换Other后面的有Smooth（光滑）：只进行光滑显示，不会显示高光Facets+Highlights：显示面状+高光，不进行光滑显示Facets:只按面状显示Lit Wireframe：以材质标准方式显示网格，与物体颜色设置无关Bounding Box：边界盒子，按物体最大体积边界方盒显示，这种方式视图刷新最快Facets Edges:按网格和实体同时显示，可按F4进行切换Alt+X—将物体按透明方式显示 改变视图大小将鼠标置于视图窗口交界出拖动即可任意改变视图大小，还原时在窗口边界处按右键，选择Rest Layout（重新恢复布局）命令即可。单独放大某个视图：按Alt+W键，再次使用还原。 隐藏/显示视图网格—按G键 视图布局选择菜单Customize\Viewport Configration(自定义\视图配置)命令，选择Layout（布局）选项 视图布局风格选择菜单Customize\Lode Custom UI Scheme(自定义\装载自定义用户界面方案)命令鼠标操作:直接按”中键”—平移视图Alt+”中键”—按任意角度旋转视图Ctrl+Alt+”中键”—缩放视图Shift+Alt+”中键”—水平或垂直旋转视图五、命令面板（Command Panal）最顶上一排图标分别表示Create(创建)、Modify（修改）、Hiaracher（层级）、Motion（运动）、Display（显示）、Utilities（实用程序）六、其他（轨迹栏、状态栏、提示栏、动画播放区等）略先左键后右键，取消当前选择。复制，整列复制。Ctrl+V：复制，实例，参考。复制：复制出来的物体与原物体没有任何关系实例：相互影响，不管是修改实例。参考：参考物体时不具有属性的，无法修改参考属性。Z键：将选择物体最大化显示修改器列表:Bend中心:修改弯曲轴弯曲角度,弯曲多少度方向:弯曲轴:以哪个方向为弯曲轴限制:某一部分不进行弯曲.上限:轴心0点以上下线:轴心0点以下显示最终结果打开Show end result锥化命令(Taper)数量(Amount)如果为整数上面放大曲线(Curve)中间凸起锥化轴(Taper Axis)主轴(Primary)效果(Effect)限制(Limits)限制效果(Limit Effect)扭曲()-制作冰激凌 晶格(Lattice)-制作纸篓:运用边生成三维模型应用整个对象(Apply to Entire Object)忽略隐藏边(Ignore Hidden Edges)末端封口(End Caps)基点面类型(Geodeisic Base Type)四面体(Tetra)八面体(Octa)二十面体(Icosa) 选择操作1、多选物体：A:按Ctrl键增加物体选择，按Alt键减少物体选择B：框选，有矩形、圆形、多边形、套索四种范围2、编辑菜单中的几个选择命令：Select Invert(反选)（ctrl+i）、Select by Color(按颜色选择)、Select by name(按名称选择)3、工具菜单中的选择命令：Isolate Selection:单独显示被选择的物体（alt+q ），自动隐藏其他物体（非选择）关闭Isolate Selection警告对话框进行还原。4、命名选择集合实例：台球桌物体的操作 复制操作 使用菜单Edit\Clone（编辑\克隆）命令。2、使用变换工具进行复制（移动、旋转、缩放）3、使用镜向工具复制三、变换操作1、移动：移动控制轴由两两垂直的三个单向轴组成，显示为红、绿、篮颜色的三个轴向分别代表X、Y、Z方向，操作时既可单独锁定控制轴进行单轴方向上的移动，也可将 鼠标定在靠近两轴交点的黄色平面区域内按平面的方式进行任意移动。2、旋转：旋转物体时，其外围会出现三个球形控制轴，显示为红、绿、蓝圆弧线条的为单向旋转轴，分别代表X、Y、Z三个轴向，当前操纵的轴向会显示为黄色；内圈的灰色圆弧可以进行空间上的旋转，可将物体在三个轴向上同时进行旋转；外圈的灰白色圆弧可以在当前视图角度的平面上进行旋转。3、缩放：5.0版对缩放控制轴做了很大改进，可以直接在控制轴上实现等比和非等比操作，其控制轴呈三角形，显示为红、绿、蓝箭头轴向为单向缩放轴，分别代表X、Y、Z三个轴向。操作时拖动内部中心的三角区域可以进行等比例缩放；拖动单个轴向，可以进行单方向上缩放；拖动外侧的三角平面可以进行双方向上的同时缩放。四、实例：1、使用局布（Local）坐标系统移动斜波物体。2、复制西餐椅子（可使用移动、旋转、镜向工具完成）3、复制石凳（使用旋转工具）要点：A：移动和对齐轴心点；B：捕捉角度 第三讲一、复习二、群组操作Group（成组）：将多个选择的物体组成一个组Ungroup（解组）：将群组解散，一次只能解散一个组Open（打开组）：打开的组仍然存在，可以对组中的单个成员进行编辑Close（关闭组）：将打开的组关闭，保持原来的组名Detach（分离组）：将选择的组从当前的组中分离出去 Attach（合并组）：对两个或两个以上的组组合成一个新的组。Explode（炸开组）：对当前选择的组进行炸开操作，可将多个组一次解散。三、阵列操作1、阵列对话框参数解释Incremental（增量）：表示每两个物体之间的变换量，使用Move表示为距离，使用Rotate则表示角度，使用Scale表示缩放变比。Tatols（总量）：表示所有物体之和的总量，使用Move表示为距离，使用Rotate则表示角度，使用Scale表示缩放变比。Uniform:勾选此项，将锁定Scale变比设置，只能等比缩放。1D、2D、3D分别表示在一维、二维、三维空间上产生阵列，Count表示物体的复制数目。Incremental Row Offsets:制作二维、三维阵列时相对于一维阵列X、Y、Z轴上的偏移量。Reset all parameters可以恢复对话框中的默认参数设置2、实例：A：制作圆形环绕的石凳 B：制作旋转台阶（特别注意台阶物体的轴心点位置）四、对齐操作先选择被对齐的原物体，单击工具栏中的对齐按钮，在视图中点击目标对齐物体， 依据对话框可以实现原物体与目标物体以下几种对齐方式：Minimum（最小对齐）:在正交视图物体的最左端和最下端分别定义X、Y轴的最小值。Center(中心)：以物体的重心位置进行对齐Pivot Point（轴心点）：以物体的坐标轴位置进行对齐Maximum（最大值）：在正交视图物体的最右端和最上端分别定义X、Y轴的最大值。第四讲 Box（方体）Length、Width和Height分别定义方体的长度、宽度和高度，Length Segs、 Width Segs和Height Segs分别定义长度、宽度和高度的分段划分，增加它们的值则产生栅格方体，配合修改器的使用可以使方体更易于变形，从而产生形态各异的几何物体2.Sphere(球体）Radius（半径）：定义球体的大小。Segments（分段数）：该值越大，球越圆滑。Smooth（光滑）：控制球体表面是否光滑。Hemisphere（半球）：值域为0-1，值为0时，表示一个完整的球体，值为1时，整个球体收缩成一个点，值介于0-1之间，球体变为球冠，仅当值为0.5时为半球。Chop（剪切）：在半球或球冠时，将整个球体的水平分段数切掉一半Squash（挤压）：在半球或球冠时，可将下半球被切掉的球体水平分段数挤压到上半球，仍保持完整的分段数。Slice On（切片）：打开它可以在下面的设置中调节球体局部切片大小。Slice From/Slice To（切片开始/切片结束）：分别设置切片两端切除的幅度Base To Pivot：设置球体的轴心点在球体的底部还是在球心位置。 Generate Mapping Coordinates（产生贴图坐标）：自动产生贴图坐标。3.Geosphere(几何球体）Tetra（四面体）/Octa（八面体）/Icosa（二十面体）：这三个参数分别控制该球体的基本类型，它们与Segments参数值的平方值相乘正好是几何球体的所有三角面的个数，直接在选择的物体上按数字键7，视图中会显示物体所有面的数量 Cylinder(柱体)Radius（半径）：控制圆柱体的粗细。Height（高度）：可以控制圆柱体的高矮。Height Segments（高度分段数）：分段越多，物体精度越高，表面则越光滑Cap Segments（端面分段数）：定义圆柱体截面圆形的分段数，从顶端截面看就是一个个同心圆。Sides（边数）：定义圆柱体侧面的分段划分，值越大，圆柱体越圆。 Cone(锥体)Radius 1/Radius 2分别控制锥体的上下两个端面的半径大小，当其中的一个值为0时即为锥体，当两个半径值不为0且不相等时为圆台物体，当两个半径不为0且相等时则变为柱体。 Tube(圆管)Radius 1/Radius 2分别控制圆管的内径和外径的大小。 Torus(圆环)Radius 1：表示自圆环的中心至截面正多边形的中心距离。Radius 2：表示圆环截面正多边形的内径大小，用它可定义圆环的粗细。Rotation（旋转）：设置每一片段截面沿圆环轴旋转的角度Twist（扭曲）：设置每个截面扭曲的角度，产生扭曲的表面。扭曲角度,扭曲偏移Bias扭曲轴,限制,上下限制扭曲.Segments：沿着圆环长度上的分段数，值越大，得到的圆形越光滑。Sides：圆环截面的边数，值越大，圆环越圆滑。Smooth：设置圆环光滑范围，有All（全部光滑）、Sides（边光滑）、None（所有不光滑）和Segments（沿着长度光滑）四种类型。 Teaport（茶壶）Radius（半径）：用于控制茶壶的大小。Segments（分段数）：增加此值，可使茶壶变得更加圆滑。Teapot Parts：该选项中的四个参数分别控制是否要茶壶的Body（壶身）、Handle（壶柄）、Spout（壶嘴）和Lid（壶盖） Pyramid（四棱锥） 产生类似金字塔状的四棱锥体，调节Width、 Depth和 Height参数可以改变四棱锥的宽度、深度和高度。 Plane(平面)Length和Width确定平面的大小。Scale（比例）:控制平面在渲染时可以按一定的比例倍数进行放大或缩小；Density（密度）:参数可以使平面增加更多面的划分，当加大此值时，可以从Total Faces（总面）参数中获得相关信息。FFD-制作苹果通过控制点FFD222控制点(Control Points)晶格(Lattice)设置体积(Set Volume):这个晶格点是放在哪个位置上 第五讲 Hedra（异面体）Family（类型）：即Tetra（四面体）、Cube/Octa（立方体/八面体）、Dodec/Octa（十二面体/二十面体）、Star1（星形1）和Star2（星形2）。Family Parameters（类型参数）：参数P和Q，取值范围从0.0到1.0，修改它们的值可以控制组成异面体的多边形的形状。Axis Scaling（轴向比率）：P、Q、R分别调节各种多边形的轴向比率。如果异面体只有一种或两种类型的面，那么轴向比率参数也只有一项或两项有效无效的比率不产生效果。Reset（重设置）:单击此按钮恢复轴向的初始设置。Vertices（顶点）：确定异面体内部顶点的分布情况，从而决定异面体的内部结构。其中Basic表示超过最小值的面不再进行细划分；Center表示在面的中心位置添加一顶点，按中心点到面的各个顶点所形成的边进行细划分；Center &amp; Sides表示在面的中心位置添加一枯点，按中心点到面的各个顶点和边中心所形成的边进行细划分，所产生的面比Center方式多一倍。 Turus Knot（环形节）Base Curve（基本曲线）：提供两种基本曲线类型：Knot（节）和Circle（圆形）。当选择Knot类型时，激活其下的P和Q参数；当选择Circle类型时，激活Warp Count和WarpHeight参数。Radius：定义环形节物体的半径大小，在Cross Section子面板中也有一个Radius，它是定义环形节物体的截面半径大小。P和Q：表示在水平方向和垂直方向产生打节的数目，当这两个值相等时，均为一个不打节的圆环，当其中的一个值为小数时，是一个断裂的圆环。Warp Count（扭曲数目）：表示在环形物体上突出的扭曲角的数目，最大值为100。Warp Height（扭曲高度）：表示扭曲角突出的程度，最大值为4。Cross Section（横截面）：定义环形节物体横截面的形态。Sides（边）：环形节截面的段数，值越大越圆滑。Eccentricity（偏心率）：设置环形节压扁的程度，该值越接近1，其截面就越接近圆形。Twist（扭曲）：设置截面沿路径扭曲旋转的程度，一般取消Smooth（光滑）选项后观察比较明显。Lumps（肿块）：设置此值，可以使环形节产生一定数量的肿块效果。Lumps Height：设置肿块的高度，最大值为4。Lumps Offset：设置肿块在路径上移动的偏移量。Smooth（光滑）：设置环形节表面按哪种方式进行光滑，All、Sides和None分别表示对整个造型进行光滑、沿路径方向的面进行光滑和不进行光滑处理。Mapping Coordinates（贴图坐标）：设置贴图坐标及贴图图像在当前物体U、V方向的偏移量和平辅次数。 ChamferBox（倒角方体）有两个参数用于设置倒角值，Fillet设置倒角的大小，当值为0时，就变为Box了；Fillet Segments用于设置倒角的分段数。这两个值要配合使用，如果Fillet Segments值设置过小，很难体现倒角的圆滑度。 ChamferCyl（倒角圆柱体）与标准几何体中的圆柱体相似，所不同的是在圆柱体的两个端面与侧面之间可以产生圆滑的倒角效果,Fillet和Fillet Segments，含义与ChamferBox中的参数含义相同 OilTank（油罐）、Capsule（胶囊体）、Spindle（纺锤体）这三个扩展几何体工具属于同类型的，共同点是中间都是圆柱体，只是顶端形状不一样，控制参数也大同小异，大部分参数项与圆柱体相同。Blend（融合）参数设置油罐圆柱部分与其顶盖部分的倒角程度，使其互相交融，产生圆滑效果。Overall与Center用来定义油罐的高度，使用Overall包括上下两个顶盖的高度和油罐中间圆柱的高度，使用Center仅指中间圆柱部分的高度。 Gengon（多边形棱体）使用Gengon（多边形棱体）命令可以创建多边形柱体，修改Fillet参数值还可以使多边形柱体的每个侧面交界处产生光滑的倒角。 L-Ext（L型物体）与C-Ext（C型物体）使用L-Ext和C-Ext命令可以创建表现L型和C型实体模型，主要用来表现建筑中的墙体效果 RingWave（环形波）Radius（半径）：设置环形波的外沿半径。Radius Segs（半径分段数）：设置内沿半径与外沿半径之间的分段数。Radius Width（环形宽度）：设置从外沿半径向内的环形宽度的平均值。RingWave Timing（环形波定时）：主要用于设置环形波的运动形式，主要有三种：No Growth（没有增长）：环形波在生成过程始终以静态方式显示出来，不能形成动画。Grow and Stay（增长并保持）：环形波生长过程中逐渐放大，到达最大时就停止放大，直至运动到最后一帧，其放大及停留的时间可以通过Start Time和Grow Time参数控制。Cyclic Growth（循环增长）：将使环形波在运动过程中以循环方式进行放大显示，循环的次数可以通过Start Time和Grow Time参数进行设置，例如要在100帧的动画中循环5次，可将Start Time设置为0，Grow Time设置为20。Outer Edge Breakup与Inner Edge Breakup：它们的参数项是一样的，修改这些参数可以设置环形波内部和外部波浪的变化形状和大小幅度。分别有一个On复选项，控制其下参数设置是否有效，系统默认激活Inner Edge Breakup控制项，取消该复选项，环形波内部为一圆形，主要参数含义如下。Major Cycles（主圆周期）：定义环形波内部或外部边缘产生波纹的数目。Width Flux（宽度流束）：定义波纹伸展的幅度，以百分比的形式表示。Crawl Time（运动时间）：该值为正值时，环形波按顺时针方向运动，为负值时，按逆时针方向运动。Minor Cycles（次圆周期）：设置此值可以在主圆的外围再产生若干个次圆波纹。 Hose（软管）Hose是一种可以连接两个物体之间的可变形物体，它会随着两端物体的运动而做出相应的反应，从外形看很像一根软管，有圆形、矩形和D形三种外观。软管分自由软管和绑定软管两种，作为捆绑软管可以在其顶部和底部与任何物体进行绑定操作，被绑定物体的轴心点将是软管模型两端的定位点。 第六讲 复合物体(COMPOUND OBJECTSOBJECTS))*注意: 1.要有二个或二个以上的物体才能用其命令一.BOOLEAN(布尔计算)1.PICK OPERAND B（拾取操作对象B）1)REFERENCE(将对象B参考复制一个,来进行布尔计算)2)COPY (将对象B复制一个,来进行布尔计算)3)MOVE (将对象B直接来进行布尔计算)4)INSTANCE (将对象B关联复制一个,来进行布尔计算)2.Operation（操作）Union（相加）Intersection（相交）Subtraction（A-B）/Subtraction（B-A）:相减Cut（剪切）Refine（细化，插入一条对象B与对象A相交部分的轮廓线）Split（割裂，把相交部分分为单独的一个次元素对象）Remove Inside（出除里面，删除相交部分，使对象A里面挖空）Remove Outside（出除外面，删除对象A与对象B不相交的部分，相交部分只保留一个面，里面挖空）3.DISPLAYRESULT（显示结果）OPERAND（显示操作对象）RESULT+HIDDEN OPERAND（结果+隐藏的操作对象）4.如何修改原物体参数在OPERAND中选原始物体A或B(MODIFY-OPERANDS A或B)5.几个物体同时挖要求：几个物体用ATTACH(合并)命令使它们作为一个物体第1种：EDIT MESH（编辑网格）-ATTACH LIST第2种：按右键-CONVERT TO-CONVERT TO EDITABLE MESH-ATTACH LIST）例:烟灰缸，TWO-17，TWO-7，TWO-8，TWO-10三.MORPH(变形)四.SCATTER(离散)五.CONFORM(包裹)六.CONNECT(连接)七.SHAPEMERGE(形体合并)八.BOOLEAN(布尔运算)九.TERRAIN(地形)十.LOFT(放样)（针对于二维图形SHAPES）十一.MESHER(网格化)涡轮平滑(TurboSmooth) 第七讲 创建二维图形（SHAPES）一.二维图形1.LINE（线）1)直线2）曲线（1）点的类型（CORNER角点SMOOTH圆滑BAZIER贝赛尔BAZIER CORNER贝赛尔角点）3)画一条笔直的线(SHIFT+LINE画)4)线的连接(用2D捕捉命令)2.RECTANGLE（矩形）3.CIRCLE（圆）二.二维渲染RENDERING-RENDERABLE（可渲染的）THICHNESS（线变粗变细）渲染圆滑如何提高INTERPOLATION（插补值）STEPS（插入多少个点）-点越多越圆滑OPTIMIZE（优化圆滑）ADAPTIVE（适配圆滑，自动生成圆滑，不需要你填插入多少个点）三.二维变成面(extrude)例如:楼梯,圆形台阶(BEND)四.ARC（弧）1.PIE SLICE(将圆心与弧的两端点连接)2.REVERSE(端点对调)五.DONUT（双圆）(双形在一起为复合形)1.双形在一起为复合形,单形为一形2.START NEW SHAPE(开始新形)六.STAR（星形）七.NGON（多边形）八.ELLIPSE（椭圆）九.TEXT(文本)(多行文字,按回车键)十.HELIX（螺旋线）(motion-trajectories使球沿着螺旋线运动)十一.SECTION(剖面)截取一个三维物体的剖面挤出(Extrude)Amount:挤出多少 第八讲 二维编辑命令（EDIT SPLINE(样条曲线) 二维样条线Renderer(渲染)在渲染中启用(Enable In Renderer)在视口中启用(Enable In Viewport)使用视口设置(User Viewport Settings)生成贴图坐标(Generte Mapping Coords)真实世界贴图大小(Real-World Map Size)视口(Viewport) 渲染(Renderer)径向(Radial)厚度(Thickness) EDIT SPLINE(编辑样条曲线)注：EDIT SPLINE是斜体—针对了多个物体EDIT SPLINE是正体—针对单个物体EDIT SPLINE包括VERTEX(点)SEGMENT(线段)SPLINE(曲线)三个次对象(一)点,线段,曲线所共有的命令1.CREATE LINE（创建线）2.ATTACH(合并)没有对话框合并使二个或多个独立的二维图形变成复合形）3.ATTACH MULT(合并)有对话框合并使二个或多个独立的二维图形变成复合形）4.INSERT（插入）(二)VERTEX(点)1.点的不同类型（CORNER，SMOOTH，BAZIER，BAZIER CORNER）LOCK HANDLES（锁定控制柄）ALIKE （选定相似的手柄，才移动）ALL （所有选定了的手柄都移动）例：雨伞（SQUEEZE(挤压)(1.5,-2,50,1)）2.点的编辑命令1）REFINE（细化，增加点）不改变原线的位置2）INSERT（插入点）会改变原线的位置3）BREAK（断开点）4）CONNECT（将断开的点连接起来）5）WELD(焊接)先选定点,再点击WELD(不考虑点是否断开)6）CROSSINSERT(在交叉处插入点)(注意:CROSSINSERT只针对复合形)7）FILLET（倒圆角）8）CHAMFER（倒直角）9）HIDE (隐藏)10）UNHIDE ALL（取消隐藏）11）DELETE （删除）12）MAKE FIRST（使某一个做为起点）（1）是一个封闭型的二维图形，任何一个都可做为起点（2）如果不是一个封闭型的二维图形只有断开的两个端点才可以做为起点(三)SEGMENT(线段)1.REFINE2.BREAK3.DIVIDE(匀分)（先选定线段，后填数学，点DIVIDE）4.DETACH(分离)1）SAME SHAPES(同一图形)使分离出来的部分仍是源对象的一部分2）REORIENT(重定向)使分离出来的部分独立3）COPY(复制)创建分离次对象的一个新的复制品5.线段 焊接（针对复合形）（选定一段，移动回来，如有多段要移动多次）6.HIDE7.UNHIDE8.DELETE(四)SPLINE(曲线)1.BOOLEAN(只针对复合形)（如果不是复合形，请用ATTACH或ATTACH MULT做成复合形）2.OUTLINE例:茶杯（LATHE）3.TRIM （修剪）（一般最好针对复合形4.MIRROR5.EXTEND6.HIDE7.UNHIDE8.DELETE9.SPLINE 焊接（针对复合形）（选定一段，移动回来，如有多段只要移动一次） 第九讲 LOFT(放样)一.基本概念一个截面(SHAPE)沿着一条路径(PATH)不断的复制注意:1.路径(PATH)只能是一条（可以是LINE，CIRCLE或者其它的二维图形）2.截面(SHAPE)可是一个,也可以是多个(但是多个截面都要是同一类型的（单形，复合形）) 3.路径(PATH)和截面(SHAPE)只能是二维图形例:镜框,吧台,沙发二.LOFT的参数1.SURFACE PARAMETERS(表面参数)(主要针对LENGTH,WIDTH是否光滑)* 2.PATH PARAMETERS (路径参数)(主要针对在路径什么地方放什么形)3.SKIN PARAMETERS (表皮参数)(主要针对加盖,增减分格数,是否显示表皮)4.DEFORMATIONS (变形)(SCALE,TWIST,TEETER,BEVEL,FIT)三.LOFT的修改1.PATH（可以使路径变长或变短）2.SHAPE（可以改变形的位置，旋转，缩放）例:盆,窗帘3.SHAPE对齐COMPARE(1)MODIFIERS-SHAPE-COMPARE-PICK SHAPE(2)进入次对象:SPLINE进行旋转例:上面是一个圆,下面是一个矩形的放样放样如果图形放反了怎么办1.如果路径是不封闭的我们用MAKE FIRST改变路径起点的位置点是断开的两个端点2.如果路径是封闭的我们是改变SHAPE(形状)的位置用ROTATE命令第十讲 LOFT(放样)的修改一.DEFORAMTIONS(变形)1.SCALE(缩放)1）截面形放大,缩小2）界面介绍例:FOUR-8,FOUR-9,蹋陷的易拉罐,FOUR-16,SEVEN-22.TWIST(扭曲)1）截面扭曲例:FOUR-113.TEETER(倾斜)2）界面介绍例:圆珠笔4.BEVEL(倒角)1）截面倒角2）界面介绍3）优点:圆滑4）缺点:值不能大5）修改器中的BEVEL(1)优点:能很大(2)缺点:不圆滑5.FIT(拟合,适配)1）界面介绍2）物体的厚度感,深度感,高度感用Y轴（LEFT的截面）3）物体的宽度用X轴 （TOP的截面）例:FOUR-18,FOUR-17, FOUR-19,FOUR-20二.模型精度不能太高(因为会影响渲染时间) 第十一讲 CAMERA（照相机）一.改变物体大小1.CAMERA离物体远,物体小,离物体近,物体大2.PARAMETERS(参数)1)LENS(焦距)单位：MM（毫米）(1)焦距值大——离物体近——物体大—-物体越清晰相应的视野也就越小 ——看到的物体也就越少(2)焦距值小——离物体远——物体小—-物体也不很清晰相应的视野也就越大 ——看到的物体也就越多2)FOV(视野)（FIELD OF VIEW）单位：DEGREE（度）(1)视野大——离物体远——物体小 ——看到的物体也就越多(2)视野小——离物体近——物体大——看到的物体也就越少3）LENS(焦距)与FOV(视野)之间是相反的。二.SHOW CONE（显示锥形）（无论是否选定照相机，照相机的视野都会显示）三.SHOW HORIZON(显示水平线)照相机的水平线四.ENVIRONMENT RANGES(环境范围)要以环境挂上钩1.RENDERING—ENVIRONMENT—ATMOSPHERE(大气)—FOG(雾)1)ACTIVE(激活雾)2) MERGE(合并另外一个场景的特效,如没特效,只是合并场景)3)TYPE(类型)STANDARD(标准雾)(均匀分布,沿水平方向分布)LAYERED(层雾)(沿垂直方向分布)2.NEAR RANGE(近距离范围)(弱,密度没有)3.FAR RANGE(远距离范围)(强,密度最大)4.NEAR RANGE到FAR RANGE之间的雾越来越多五.CLIPPING PLANES(剪切平面)1.CLIPPING MANUALLY(从NEAR到FAR两者间的物体显示,不在两者间的物体不显示)第十二讲 MATERIAL EDITOR（材质编辑器） 一.概念1.材质:是指物体外表信息的表现(包括:颜色,高光,光泽度,透明度等等)2.贴图:是指带有图案,纹理的图像信息,它附于材质之上注意:物体一定有材质,可以没有贴图3.热材质（同步材质）:赋给了物体的材质球(边有白框)4.冷材质（不同步材质）:没有赋给物体的材质球二.SHADER(阴影) BASIC（基础） PARAMETERS1.渲染模式2.WIRE（网格）1)网格与物体的分格数（SEGMENTS）有关2)用一步修改网格(1)加粗(EXTENDED PARAMETERS-WIRE-PIXELS(远近一样粗细)UNITS(远细,近粗 )3）二维物体网格—没有分格数插入EDIT SPLINE-SEGMENT-DEVIDE（注：顶盖，顶底没有）3.2-SIDED（内外所赋的材质是一样）4.FACE MAP5.FACETED三.不同渲染模式的基本参数( XXXXXX BASIC PARAMETERS)1.AMBIENT(背光区)2.DIFFUSE(主光区)3.SPECULAR(高光区,高光在什么地方与灯有必然的联系)1)SPECULAR LEVEL (高光级别)2)GLOSSINESS (光泽度,控制高光的面积)3)SOFTEN (柔和0~1,高光与非高光之间的过渡)4.SELF-ILLUMINATION (自发光,可以用数字表示,也可以用颜色表示)5.OPACITY (不透明度)1)值越低,越透明,物体越不亮2)可以进一步对透明进行修改EXTENDED PARAMETERS-ADVANCED TRANSPARENCYFALL OFF(衰减) TYPE(1)FILTER(过滤,在物体上留下一种颜色)(2)SUBTRACTIVE(当前物体颜色减去背景色)使物体更暗(3)ADDITIVE(当前物体颜色加上背景色)使物体更亮例:杯子,矿泉水瓶注意:玻璃作透明不能太厚3)INDEX OF REFRACTION(折射率)水(1.3)玻璃(1.5)高光固体(2.0)四.改变背景色的颜色(RENDERING-ENVIRONMENT)第十三讲 材质(二) 一.渲染模式1.METAL(金属)1)SPECULAR(高光度) 最佳的取值范围（60~70）2)GLOSSINESS(光泽度) 最佳的取值范围（60~70）2.ANISOTROPIC(各向异形)主要控制高光的形状1)ANISOTROPIC(0,圆形高光,50,椭圆高光,100,线形高光)2)ORIENTATION(控制高光的方向)3.MULTI-LAYER(多层)在ANISOTROPIC基础上再增加一层来控制高光4.STRAUSS(金属加强)(金属渲染方式一种)渲染粗糙,不光滑,有凹凸感**5.BLINN(反射)柔和一点,低光照射的效果6.PHONG(多面)与BLINN相似7.OREN-NAYER-BLINN(明暗处理器)适合于制作表现物体模糊的”材质”二.图标介绍1.GET MATERIAL(获取材质)(注:只能获取材质,不能获取贴图)1)MTLIBARY (从材质库中获取材质)(C:\3DMAX4.0\MATLIBS\.MAT)2)MTL EDITOR (从材质编辑器中获取材质)(一共有24个)3)ACTIVE (从激活的样本球(白框)中获取材质)4)SELECTED (从选定的物体中获取材质)5)SCENCE (从场景中获取材质)6)NEW (获取新的材质)2.PUT MATERIAL TO SCENE (将修改了的材质,重新赋给场景)3.ASSIGN MATERIAL TO SELECTION (将指定的材质赋给选定的对象)4.RESET MAP/MTL TO DEFAULT SETTINGS (恢复到默认的设置)5.MAKE MATERIAL COPY (将热材质进行复制)(注:1)当是热材质时,才有用 2)热材质变成冷材质,没有热材质标志)6.PUT TO LIBRARY(将编辑好的材质保存到材质库中,从材质库中可获取此材质)第十四讲 材质（三） 一.贴图（是指带有图案,纹理的图像信息,它附于材质之上）1.如何贴图1)通过选择MAPS(贴图)中的通道来贴图例:DIFFUSE COLOR(主光区颜色通道)2.图的来源方式1)自带的程序图(例如:BRICK,CELLULAR等等)**2)拾取外面的图(通过BITMAP)（注意：当你拾取外面的图时，注意图片格式图片格式是PSD的话是能拾取的）3.图的修改1)COORDINATES(贴图极坐标)(偏移,平铺,旋转)2)BITMAP PARAMETERS(位图参数)（只有拾取外面的图才有）4.有些图贴不上去,是因为贴图坐标的问题1)创建一个物体都带有GENERATE MAPPING COORDS(贴图坐标)(1)BOX5.贴图坐标的修改器MODIFIERS—UV COORDINATE—UVW MAP（针对于解决MISSING MAP COORDINATES（丢失贴图坐标）的问题）1)PLANAR (平面)2)CYLINDRICAL(圆柱体)3)SPHERICAL (球体) 4)SHRINK WRAP(收缩包裹) 5)BOX (盒子)6)FACE (面状)（与分格数有关）7)XYZ TO UVW (物体本身具有的坐标 到 图贴的方向) 对齐 1)FIT （适配） 2)CENTER （使图居中）3)BITMAP FIT （根据你所选的位图对齐）4)NORMAL ALIGN（法线对齐，只能在透视图中进行可任意移动图片在任意面上5)VIEW ALIGN （以当前正交视图对齐）**6)REGION FIT （画一个区域进行贴，会产生重复贴， 想不重复贴回到材质编辑器，取消TILE钩）7)RESET （恢复原始值）8)ACQUIRE （从其它物体获取一个贴图坐标）（相对，绝对）（1-W的值）/2=U的值（图水平放在中间）（1-H的值）/2=V的值（图垂直放在中间）.jpg .bmp .tif .tga .png .psd（在3DMAX5.0中支持） g键关闭网格，右键对象菜单，选择对象属性，勾选以灰色显示冻结。摁住Shift可以画出直线。 Bones和Biped的区别用bones需要自己创建骨骼系统（比如人、动物、怪物等的骨骼），会使用到很多的约束、参数关键等；如果只是简单的机械臂，或者简单的几根骨骼动画，用这个还是比较方便的。而biped是系统自带的适合于两足动物的骨骼系统（当然也可以调节适合马、虎等动物），各种骨骼约束关联创建好了，直接可以蒙皮使用。 蒙皮： http://yuntv.letv.com/bcloud.html?uu=ejtjj0ntox&amp;vu=4b9dd28064&amp;pu=75346142bf&amp;auto_play=0&amp;gpcflag=1&amp;width=100%&amp;height=100%&amp;isPlayerAd=0先确定旋转方向，然后在确定高度。视图操作栏，命令面板，创建面板，四大键：Q,W,E,RQ选择工具，点选，点击视图中的物体。按住鼠标左键不放，框选。减选：Alt键，加选：Ctrl键，点击物体或者框选物体。Alt+A全选Q：改变框选方式。窗口和交叉：如果交叉，表示必须将物体完全的框住。W:是一个双重工具。选择并且移动。X键可以放大或者缩小。E：旋转功能R：缩放功能，放在中心区域，三个轴同时缩放。Zomm Extends All SelectedOrbit Subobject:旋转视图。 烘培法线首先创建一个正方体复制一个出来，改成其他颜色，接下来白色模型卡线，加涡轮平滑或者网格平滑命令。选中线少的正方体，打开UVW展开编辑器接下来开始烘培法线，先选中底模，先按大键盘的0键打开烘培面板，然后选取高模。重置一下，然后数量给2或者3然后点击渲染，这里法线贴图得到所在文件夹去查找。]]></content>
      <categories>
        <category>3DMax</category>
      </categories>
      <tags>
        <tag>3DMax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vspathmacro]]></title>
    <url>%2F2019%2F05%2F11%2Fvspathmacro%2F</url>
    <content type="text"><![CDATA[$(SolutionDir) 解决方案的目录（定义形式：驱动器+路径）；包括尾部的反斜杠”\”，和sln同级目录]]></content>
      <categories>
        <category>VS</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>VS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[marshal]]></title>
    <url>%2F2019%2F05%2F10%2Fmarshal%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[C#结构体字节对齐方式]]></title>
    <url>%2F2019%2F05%2F10%2Fcsharpstructbytealignment%2F</url>
    <content type="text"><![CDATA[12345678[StructLayout(LayoutKind.Sequential, CharSet=CharSet.Ansi)]internal struct DllInvoices&#123; [MarshalAs(UnmanagedType.ByValArray, SizeConst=8)] public byte[] serial; public byte Type; public uint Sum;&#125; 调用Marshal.SizeOf(typeof(DllInvoices))得到的大小为16，为什么不是13？这其实是体系结构和汇编的问题。在内存里特定类型数据的起始地址通常有一定的对齐要求，比如说32位机器上的int起始地址必须是4的整数倍，结构通常也是如此。如果一个结构包含一个char和一个int，那么char作为结构体的第一个字段，需要在4的整数倍地址开始，而int有同样的要求，所以char之后必须空出3个字节来，才能使int的地址满足对齐的要求。.NET的CLR是基于32位的，所以也是4字节对齐的。在byte之后，必须空出3个字节。所以结果就是16字节了。可以通过StructLayout的Pack属性改变这种对齐设置。 [StructLayout(LayoutKind.Sequential, CharSet=CharSet.Ansi, Pack=1)] MarshalAs属性指示如何在托管代码和非托管代码之间封送数据。 当MarshalAsAttribute.Value设置为ByValArray时，必须设置SizeConst以指示数组中的元素数。当需要区分字符串类型时，ArraySubType字段可以选择包含数组元素的UnmanagedType。此UnmanagedType只可用于作为结构中的字段的数组。而SizeConst则是指数组的元素个数。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[quaternion]]></title>
    <url>%2F2019%2F05%2F10%2Fquaternion%2F</url>
    <content type="text"><![CDATA[三维空间中的旋转在讨论四元数之前，我们先来研究一下三维空间中旋转。表示三维空间中旋转的方法有很多种，但我们这里关注的是轴角式（Axis-angle）的旋转。虽然使用欧拉角的旋转很常用，但是我们知道欧拉角的表示方法不仅会导致Gimbal Lock而且依赖于三个坐标轴的选定，使用四元数正是为了解决这个问题。我们这里所要讨论的轴角式旋转是旋转更加普遍的情况：假设我们有一个经过原点的（如果旋转轴不经过原点我们可以先将旋转轴平移到原点，进行旋转，在平移回原处）旋转轴$u=(x,y,z)^T$，我们希望将一个向量v，沿着这个旋转轴旋转$\theta$度，变换到v’： 注意，在这篇教程中我们将使用右手坐标系统，并且我们将使用右手定则来定义旋转的正方向。 四元素终于，我们可以开始讨论四元数与旋转之间的关系了。四元数的定义和复数非常类似，唯一的区别就是四元数一共有三个虚部，而复数只有一个。所有的四元数都可以协程下面这种形式：$q=a+bi+cj+dk (a,b,c,d \in R)$其中：$i^2=j^2=k^2=ijk=-1$]]></content>
  </entry>
  <entry>
    <title><![CDATA[jobsystemnativecontainer]]></title>
    <url>%2F2019%2F05%2F10%2Fjobsystemnativecontainer%2F</url>
    <content type="text"><![CDATA[Allocator.Temp has the fastest allocation.It is for allocations with a lefespan(寿命) of one frame or fewer. Allocator.TempJob is a slower allocation than Temp but is faster than Persistent.It is for allocations within a lifespan of four frames and is thread-safe. Allocator.Persistent is the slowest allocation but can last as long as you need it to,]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EventSource]]></title>
    <url>%2F2019%2F05%2F10%2FEventSource%2F</url>
    <content type="text"><![CDATA[原则上不会出现托管堆数据，不会List接口，数据统一申请，按需释放。 充分利用CPU，防止让线程之间切换时间片的发生。]]></content>
      <categories>
        <category>GameFramework</category>
      </categories>
      <tags>
        <tag>GameFramework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSharp Thread]]></title>
    <url>%2F2019%2F05%2F10%2Fcsharp-thread%2F</url>
    <content type="text"><![CDATA[IsBackgroundA thread is either a background thread or a foreground thread.Background threads are identical to foreground threads,except that background threads do not prevent a process from terminating.通过Thread类新建线程默认为前台线程。当所有前台线程关闭时，所有的后台线程也会被直接终止，不会抛出异常。 Thread.sleep(0)在Java或者C#中，都会用到Thread.Sleep()来使线程挂起一段时间。那么你有没有正确的理解这个方法的用法呢？思考下面这两个问题： 假设现在2019-5-13 17:00:00.000，如果我调用一下Thread.Sleep(1000)，在2019-5-13 17:00:01.000的时候，这个线程会不会被唤醒？ 代码中添加：Thread.Sleep(0)。既然是Sleep 0毫秒，那么和去掉这句代码相比，有什么区别？ 首先回顾一下操作系统原理在操作系统中，CPU竞争有很多种策略。Unix系统使用的是时间片算法，而Windows则属于抢占式的。在时间片算法中，所有的进程拍成一个队列。操作系统按照他们顺序，给每个进程分配一段时间，即该进程允许运行的时间。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。调度程序所要做的就是维护一张就绪进程列表，当进程用完它的时间片后，它被移到队列的末尾。所谓抢占式操作系统，就是说如果一个进程得到了CPU时间，除非它自己放弃使用CPU，否则将完全霸占CPU。因此可以看出，在抢占式操作系统中，操作系统假设所有的进程都会主动退出CPU。在抢占式操作系统中，假设有若干进程，操作系统会根据他们的优先级、饥饿时间（已经多长时间没有使用过CPU了），给他们算出一个总的优先级来。操作系统就会把CPU交给总优先级最高的这个进程。当进程执行完毕或者自己主动挂起后，操作系统就会重新计算一次所有进程的总优先级，然后在挑一个优先级最高的把CPU控制权交给他。我们用分蛋糕的场景来描述这两种算法。假设有源源不断的蛋糕（源源不断的时间），一副刀叉（一个CPU），10个等待吃蛋糕的人（10个进程）。如果是Unix操作系统来负责分蛋糕，那么他会这样顶规定：每个人上来吃1分钟，时间到了换下一个。最后一个人吃完了就再从头开始。于是，不管这10个人是不是优先级不同、饥饿成都不同、饭量不同，每个人上来的时候都可以吃1分钟。当然，如果有人本来不太饿，或者饭量小，吃了30秒中之后就吃饱了，那么也可以跟操作系统说：我已经吃饱了（挂起）。于是操作系统就会让下一个人接着吃。如果是Windows操作系统来负责分蛋糕的，那么场面就很有意思了。他会这样顶规矩：我会根据你们的优先级、饥饿程序会给你们每个人计算一个优先级。优先级最高的那个人，可以上来吃蛋糕，吃到你不想吃为止。等这个人吃完了，我再重新根据优先级、饥饿程序来计算每个人的优先级，然后再分给优先级最高的那个人。这样看来，这个场面就很意思了，可能有些人是MM，因此具有高优先级，于是她就可以经常来吃蛋糕。可能另外一个人优先级特别低，于是好半天了才轮到他一次（因为随着时间的推移，他会越来越饥饿，因此算出来的总优先级就会越来越高，因此总有一天会轮到他）。而且，如果一不小心让一个大胖子得到了刀叉，因为他饭量大，可能他会霸占着蛋糕连续吃很久很久。而且，还可能会有这种情况出现：操作系统现在计算出来的结果，5号MM总优先级最高，而且高出别人一大截。因此就叫5号来吃蛋糕。5号吃了一小会儿，觉得没那么饿了，于是说“我不吃了”（挂机）。因此操作系统就会重新计算所有人的优先级。因为5号刚刚吃过，因此她的饥饿程序变小了，于是总优先级变小了；而其他人因为多等了一会儿，饥饿程度都变大了，所以总优先级也变大了。不过这时候仍然有可能5号的优先级比别的都搞，只不过现在只比其他的高一点点，但她仍然是总优先级最高的呀。因此操作系统就会说：5号MM上来吃蛋糕….（5号MM心里郁闷，这不刚吃过嘛，人家要减肥。。谁叫你长那么漂亮，获得了那么高的优先级）。那么，Thread.Sleep()是干吗的呢？还用刚才的分蛋糕的场景来描述。上面的场景里面，5号MM再吃了一次蛋糕之后，觉得已经有8分饱了，她觉得再未来半个小时之内不想再来吃蛋糕了，那么她就会跟操作系统说：再未来的半小时之内不要叫我上来吃蛋糕了。这样，操作系统再随后的半小时里面重新计算所有人总优先级的时候，就会忽略5号MM。Sleep函数就是干这事的，他告诉操作系统“在未来的多少毫秒内我不参与CPU竞争”。看完了Thread.Sleep()的作用，再来考虑前面的两个问题。对于第一个问题，答案是：不一定，因为你只是告诉操作系统：在未来的1000毫秒内我不想再参与到PU竞争。那么1000毫秒过去之后，这时候也许另外一个线程正在使用CPU。那么这时候操作系统是不会重新分配CPU的，直到那个线程挂起或结束；况且，即使这个时候恰巧轮到操作系统进行CPU分配，那么当前线程也不一定就是总优先级最高的那个，CPU还是可能被其他线程抢占去。与此相似的，Thread有个Resume()，用来唤醒挂起的线程。当然，这个函数只是“告诉操作系统我从现在开始参与CPU竞争了”，这个函数的调用并不能马上使得这个线程获得CPU的控制权。不过，因为具有死锁倾向，JDK1.6以后已经不赞成是使用Thread.stop、Thread.suspend、Thread.resume。对于第二个问题，答案是：有，而且区别很明显，假如我们刚才的分蛋糕场景里面，有另外一个MM7号，而且饭量也很大。不过7号人品很好，她很善良，她没吃几口就会想：如果现在有别人比我更需要吃蛋糕，那么我就让他。因此，她可以每吃几口就跟操作系统说：我们来重新计算一下所有人的总优先级吧。不过，操作系统不接受这个建议，因为操作系统不提供这个接口。于是7号就换了个说法：“再未来0毫秒之内不要再叫我上来吃蛋糕了”。这个指令时操作系统接受的，于是此时操作系统就会重新计算大家的总优先级，注意这个时候是连7号一起计算的，因为“0毫秒已经过去了”嘛。因此如果没有比7号更需要吃蛋糕的人出现，那么下一次7号还是会被叫上来吃蛋糕。因此，Thread.Sleep(0)的作用，就是“触发操作系统立刻重新进行一次CPU竞争”。竞争的结果也许是当前线程仍然获得CPU控制权，也许会换成别的线程获得CPU控制权。这也是我们再大循环里面经常会写一句Thread.Sleep(0)，因为这样就给了其他线程比如Paint线程获得CPU控制的权力，这样界面就会不会假死再那里。另外，虽然上面提到说“除非它自己放弃使用CPU，否则将完全霸占CPU”但这个行为仍然是收到制约的，操作系统会监控你霸占CPU的情况，如果发现某个线程长时间霸占CPU，会强制使用这个线程挂起。因此实际上不会出现“一个线程一直霸占着CPU不放”的情况。其实再Windwos原理层面，CPU竞争都是线程级的，本文中把这里的线程、进程看成一个东西就可以了。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LoadFromFileAsync和Yield的问题探究]]></title>
    <url>%2F2019%2F05%2F10%2Floadfromfileasyncandyield%2F</url>
    <content type="text"><![CDATA[问题提出昨晚临下班的时候在同时讨论到Unity的资源异步加载接口是否是多线程的时候，然后自己发了一份源自网上的测试文档，地址：https://github.com/zentia/UnityDemo然后群里开始讨论这个问题，根据文档出现两个分歧 LoadFormFileAsync是否是多线程实现的？ yield 即协程是否是多线程实现的？ 带着上述两个问题，我们开始分析和验证。 验证与分析LoadFormFileAsync是否是多线程？测试环境：Unity 2018.3测试平台：Windows(由于没有Android打包环境和设备，暂时选Windows)测试工程：https://github.com/zentia/UnityDemo好吧，是图片不具有代表性吗？那我们换大点的图片。 从结果来看，我认为LoadFromFileAsync内部是多线程实现的。协程不具备多线程的功能。我们来分析协程，下面是4.7的源码 Coroutine123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379#include "UnityPrefix.h"#include "Coroutine.h"#if ENABLE_SCRIPTING#include "Runtime/Misc/AsyncOperation.h"#include "Runtime/Mono/MonoBehaviour.h"#include "Runtime/Mono/MonoScript.h"#include "Runtime/Mono/MonoIncludes.h"#include "Runtime/Mono/MonoManager.h"#include "Runtime/GameCode/CallDelayed.h"#include "Runtime/Export/WWW.h"#include "Runtime/Scripting/ScriptingUtility.h"#include "Runtime/Scripting/Backend/ScriptingBackendApi.h"#include "Runtime/Scripting/ScriptingObjectWithIntPtrField.h"#if UNITY_IPHONE_API# include "Runtime/Input/OnScreenKeyboard.h"#endif#include "Runtime/Scripting/Backend/ScriptingBackendApi.h"// copied from MonoBehaviour.cpp// if they should be synced - blame the author not me ;-)#define DEBUG_COROUTINE 0#define DEBUG_COROUTINE_LEAK 0Coroutine::Coroutine() : m_DoneRunning(false)&#123; #if DEBUG_COROUTINE static int coroutineCounter = 0; coroutineCounter++; printf_console("Allocating coroutine %d --- %d : 0x%x\n", this, coroutineCounter, &amp;m_RefCount); #endif&#125;Coroutine::~Coroutine()&#123; Assert(m_CoroutineEnumeratorGCHandle == 0); #if DEBUG_COROUTINE printf_console("Deconstructor coroutine %d\n", this); #endif&#125;void Coroutine::SetMoveNextMethod(ScriptingMethodPtr method)&#123; m_MoveNext = method;&#125;void Coroutine::SetCurrentMethod(ScriptingMethodPtr method)&#123; m_Current = method;&#125;void Coroutine::ContinueCoroutine (Object* o, void* userData)&#123; Coroutine* coroutine = (Coroutine*)userData; Assert(coroutine-&gt;m_RefCount &gt; 0 &amp;&amp; coroutine-&gt;m_RefCount &lt; 1000000); if ((Object*)coroutine-&gt;m_Behaviour != o) &#123; ErrorString("Coroutine continue failure"); #if DEBUG_COROUTINE if ((Object*)coroutine-&gt;m_Behaviour != o) &#123; printf_console ("continue Coroutine fuckup %d refcount: %d behaviour: %d \n", coroutine, coroutine-&gt;m_RefCount, coroutine-&gt;m_Behaviour); printf_console ("continue Coroutine fuckup name: %s methodname\n", ((MonoBehaviour*)(o))-&gt;GetScript()-&gt;GetName()); if (coroutine-&gt;m_CoroutineMethod) printf_console ("continue Coroutine methodname: %s\n", scripting_method_get_name(coroutine-&gt;m_CoroutineMethod)); &#125; #endif return; &#125; coroutine-&gt;Run ();&#125;void Coroutine::CleanupCoroutine (void* userData)&#123; Coroutine* coroutine = (Coroutine*)userData; AssertIf(coroutine-&gt;m_RefCount &lt;= 0); AssertIf(coroutine-&gt;m_RefCount &gt; 1000000); coroutine-&gt;m_RefCount--; #if DEBUG_COROUTINE printf_console("decrease refcount %d - active: %d \n", coroutine, coroutine-&gt;m_RefCount); #endif if (coroutine-&gt;m_RefCount &gt; 0) return; coroutine-&gt;m_DoneRunning = true; #if DEBUG_COROUTINE printf_console ("CleanupCoroutine %d\n", coroutine); if (coroutine-&gt;m_Behaviour &amp;&amp; GetDelayedCallManager().HasDelayedCall(coroutine-&gt;m_Behaviour, Coroutine::ContinueCoroutine, CompareCoroutineMethodName, coroutine)) &#123; printf_console ("FUCKUP is still in delayed call manager%d!\n", coroutine-&gt;m_Behaviour); &#125; #endif if (coroutine-&gt;m_ContinueWhenFinished) &#123; CleanupCoroutine (coroutine-&gt;m_ContinueWhenFinished); coroutine-&gt;m_ContinueWhenFinished = NULL; &#125; if (coroutine-&gt;m_WaitingFor) coroutine-&gt;m_WaitingFor-&gt;m_ContinueWhenFinished = NULL; coroutine-&gt;RemoveFromList(); if (coroutine-&gt;m_AsyncOperation) &#123; coroutine-&gt;m_AsyncOperation-&gt;SetCoroutineCallback(NULL, NULL, NULL, NULL); coroutine-&gt;m_AsyncOperation-&gt;Release(); coroutine-&gt;m_AsyncOperation = NULL; &#125; Assert(coroutine-&gt;m_CoroutineEnumeratorGCHandle != 0); scripting_gchandle_free (coroutine-&gt;m_CoroutineEnumeratorGCHandle); coroutine-&gt;m_CoroutineEnumeratorGCHandle = 0; if (!coroutine-&gt;m_IsReferencedByMono) &#123; delete coroutine; #if DEBUG_COROUTINE_LEAK gCoroutineCounter--; #endif &#125;&#125;void Coroutine::CleanupCoroutineGC (void* userData)&#123; Coroutine* coroutine = (Coroutine*)userData; if (!coroutine-&gt;m_IsReferencedByMono) return; if (coroutine-&gt;m_RefCount != 0) &#123; coroutine-&gt;m_IsReferencedByMono = false; return; &#125; ErrorIf(coroutine-&gt;IsInList()); delete coroutine; #if DEBUG_COROUTINE printf_console ("GC free coroutine: %d\n", coroutine); #endif #if DEBUG_COROUTINE_LEAK gCoroutineCounter--; #endif&#125;bool Coroutine::CompareCoroutineMethodName (void* callBackUserData, void* cancelUserdata)&#123; Coroutine* coroutine = (Coroutine*)callBackUserData; if (!coroutine-&gt;m_CoroutineMethod) return false; return strcmp(scripting_method_get_name(coroutine-&gt;m_CoroutineMethod), (const char*)cancelUserdata) == 0;&#125;bool Coroutine::InvokeMoveNext(ScriptingExceptionPtr* exception)&#123; ScriptingInvocation invocation(m_MoveNext); invocation.object = m_CoroutineEnumerator; invocation.classContextForProfiler = m_Behaviour-&gt;GetClass(); invocation.objectInstanceIDContextForException = m_Behaviour-&gt;GetInstanceID(); bool result = invocation.Invoke&lt;bool&gt;(exception); return result &amp;&amp; *exception==NULL;&#125;void Coroutine::Run ()&#123; Assert(m_RefCount != 0); Assert(m_Behaviour != NULL); #if DEBUG_COROUTINE AssertIf(GetDelayedCallManager().HasDelayedCall(m_Behaviour, Coroutine::ContinueCoroutine, CompareCoroutineMethodName, this)); if (m_Behaviour == NULL) &#123; printf_console ("Coroutine fuckup %d refcount: %d behaviour%d\n", this, m_RefCount, m_Behaviour); &#125; #endif // - Call MoveNext (This processes the function until the next yield!) // - Call Current (This returns condition when to continue the coroutine next.) // -&gt; Queue it based on the continue condition // Temporarily increase refcount so the object will not get destroyed during the m_MoveNext call m_RefCount++; ScriptingExceptionPtr exception = NULL; bool keepLooping = InvokeMoveNext(&amp;exception); AssertIf(m_RefCount &lt;= 0 || m_RefCount &gt; 10000000); bool coroutineWasDestroyedDuringMoveNext = m_RefCount == 1; // Decrease temporary refcount so the object will not get destroyed during the m_MoveNext call CleanupCoroutine(this); // The coroutine has been destroyed in the mean time, probably due to a call to StopAllCoroutines, stop executing further if (coroutineWasDestroyedDuringMoveNext) &#123; Assert(m_ContinueWhenFinished == NULL); return; &#125; if (exception != NULL) return; // Are we done with this coroutine? if (!keepLooping) &#123; // If there is a coroutine waiting for this one to finish Run it! if (m_ContinueWhenFinished) &#123; AssertIf (this != m_ContinueWhenFinished-&gt;m_WaitingFor); Coroutine* continueWhenFinished = m_ContinueWhenFinished; m_ContinueWhenFinished-&gt;m_WaitingFor = NULL; m_ContinueWhenFinished = NULL; // The coroutine might have been stopped inside of the last coroutine invokation if (continueWhenFinished-&gt;m_Behaviour) continueWhenFinished-&gt;Run (); CleanupCoroutine (continueWhenFinished); &#125; return; &#125; if (m_Behaviour == NULL) return; ProcessCoroutineCurrent();&#125;void Coroutine::ProcessCoroutineCurrent()&#123; ScriptingExceptionPtr exception = NULL;#if !UNITY_FLASH ScriptingInvocation invocation(m_Current); invocation.object = m_CoroutineEnumerator; invocation.objectInstanceIDContextForException = m_Behaviour-&gt;GetInstanceID(); invocation.classContextForProfiler = m_Behaviour-&gt;GetClass(); ScriptingObjectPtr monoWait = invocation.Invoke(&amp;exception);#else ScriptingObjectPtr monoWait = Ext_Flash_getProperty(m_CoroutineEnumerator,"IEnumerator_Current"); #endif AssertIf(m_RefCount &lt;= 0 || m_RefCount &gt; 10000000); if (exception != NULL) return; if (monoWait == SCRIPTING_NULL) &#123; m_RefCount++; CallDelayed (ContinueCoroutine, m_Behaviour, 0.0F, this, 0.0F, CleanupCoroutine, DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kWaitForNextFrame); return; &#125; HandleIEnumerableCurrentReturnValue(monoWait);&#125;void Coroutine::HandleIEnumerableCurrentReturnValue(ScriptingObjectPtr monoWait)&#123; AsyncOperation* async = NULL; ScriptingClassPtr waitClass = scripting_object_get_class (monoWait, GetScriptingTypeRegistry()); const CommonScriptingClasses&amp; classes = GetMonoManager ().GetCommonClasses (); // Continue the coroutine in 'wait' seconds if (scripting_class_is_subclass_of (waitClass, classes.waitForSeconds)) &#123; m_RefCount++; float wait; MarshallManagedStructIntoNative(monoWait,&amp;wait); CallDelayed (ContinueCoroutine, m_Behaviour, wait, this, 0.0F, CleanupCoroutine, DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kWaitForNextFrame); return; &#125; // Continue the coroutine on the next fixed update if (scripting_class_is_subclass_of (waitClass, classes.waitForFixedUpdate)) &#123; m_RefCount++; CallDelayed (ContinueCoroutine, m_Behaviour, 0.0F, this, 0.0F, CleanupCoroutine, DelayedCallManager::kRunFixedFrameRate); return; &#125; // Continue the coroutine at the end of frame if (scripting_class_is_subclass_of (waitClass, classes.waitForEndOfFrame)) &#123; m_RefCount++; CallDelayed (ContinueCoroutine, m_Behaviour, 0.0F, this, 0.0F, CleanupCoroutine, DelayedCallManager::kEndOfFrame); return; &#125; // Continue after another coroutine is finished if (scripting_class_is_subclass_of (waitClass, classes.coroutine)) &#123; Coroutine* waitForCoroutine; MarshallManagedStructIntoNative(monoWait,&amp;waitForCoroutine); if (waitForCoroutine-&gt;m_DoneRunning) &#123; // continue executing. ContinueCoroutine(m_Behaviour, this); return; &#125; if (waitForCoroutine-&gt;m_ContinueWhenFinished != NULL) &#123; LogStringObject ("Another coroutine is already waiting for this coroutine!\nCurrently only one coroutine can wait for another coroutine!", m_Behaviour); return; &#125; m_RefCount++; waitForCoroutine-&gt;m_ContinueWhenFinished = this; m_WaitingFor = waitForCoroutine; return; &#125; #if ENABLE_WWW // Continue after fetching an www object is done if (classes.www &amp;&amp; scripting_class_is_subclass_of (waitClass, classes.www )) &#123; WWW* wwwptr; MarshallManagedStructIntoNative(monoWait,&amp;wwwptr); if(wwwptr != NULL) &#123; m_RefCount++; wwwptr-&gt;CallWhenDone (ContinueCoroutine, m_Behaviour, this, CleanupCoroutine); &#125; return; &#125;#endif // Continue after fetching an www object is done if ((scripting_class_is_subclass_of (waitClass, classes.asyncOperation)) &amp;&amp; (async = ScriptingObjectWithIntPtrField&lt;AsyncOperation&gt; (monoWait).GetPtr()) != NULL) &#123; m_RefCount++; if (async-&gt;IsDone()) &#123; CallDelayed (ContinueCoroutine, m_Behaviour, 0.0F, this, 0.0F, CleanupCoroutine, DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kWaitForNextFrame); return; &#125; // Use AysncOperation ContinueCoroutine - default path if (async-&gt;HasCoroutineCallback ()) &#123; ////@TODO: Throw exception? ErrorString("This asynchronous operation is already being yielded from another coroutine. An asynchronous operation can only be yielded once."); CallDelayed (ContinueCoroutine, m_Behaviour, 0.0F, this, 0.0F, CleanupCoroutine, DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kWaitForNextFrame); return; &#125; async-&gt;SetCoroutineCallback(ContinueCoroutine, m_Behaviour, this, CleanupCoroutine); m_AsyncOperation = async; m_AsyncOperation-&gt;Retain(); return; &#125; // Continue the coroutine on the next dynamic frame update m_RefCount++; CallDelayed (ContinueCoroutine, m_Behaviour, 0.0F, this, 0.0F, CleanupCoroutine, DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kRunDynamicFrameRate | DelayedCallManager::kWaitForNextFrame); //Ext_MarshalMap_Release_ScriptingObject(monoWait);//RH TODO : RELEASE THE MONOWAIT OBJECTS SOMEWHERE&#125;#endif MonoBehaviour.cpp1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556Coroutine* MonoBehaviour::CreateCoroutine(ScriptingObjectPtr userCoroutine, ScriptingMethodPtr method)&#123; ScriptingMethodPtr moveNext = scripting_object_get_virtual_method(userCoroutine, MONO_COMMON.IEnumerator_MoveNext, GetScriptingMethodRegistry());#if !UNITY_FLASH ScriptingMethodPtr current = scripting_object_get_virtual_method(userCoroutine, MONO_COMMON.IEnumerator_Current, GetScriptingMethodRegistry());#else //todo: make flash use generic path. set a bogus value for flash here right now so it passes current != NULL check, flash path will never use this value for now. ScriptingMethodPtr current = (ScriptingMethodPtr)1;#endif if (current == SCRIPTING_NULL || moveNext == SCRIPTING_NULL) &#123; std::string message = (method != SCRIPTING_NULL) ? Format ("Coroutine '%s' couldn't be started!", scripting_method_get_name(method)) : "Coroutine couldn't be started!"; LogStringObject (message, this); return NULL; &#125; Coroutine* coroutine = new Coroutine (); coroutine-&gt;m_CoroutineEnumeratorGCHandle = scripting_gchandle_new (userCoroutine); coroutine-&gt;m_CoroutineEnumerator = userCoroutine; coroutine-&gt;m_CoroutineMethod = method; coroutine-&gt;SetMoveNextMethod(moveNext); coroutine-&gt;SetCurrentMethod(current); coroutine-&gt;m_Behaviour = this; coroutine-&gt;m_ContinueWhenFinished = NULL; coroutine-&gt;m_WaitingFor = NULL; coroutine-&gt;m_AsyncOperation = NULL; coroutine-&gt;m_RefCount = 1; coroutine-&gt;m_IsReferencedByMono = 0; #if DEBUG_COROUTINE printf_console ("Allocate coroutine %d\n", coroutine); AssertIf(GetDelayedCallManager().HasDelayedCall(coroutine-&gt;m_Behaviour, Coroutine::ContinueCoroutine, CompareCoroutine, coroutine)); #endif #if DEBUG_COROUTINE_LEAK printf_console ("Active coroutines %d\n", gCoroutineCounter); gCoroutineCounter++; #endif m_ActiveCoroutines.push_back (*coroutine); AssertIf(&amp;m_ActiveCoroutines.back() != coroutine); m_ActiveCoroutines.back ().Run (); AssertIf(coroutine-&gt;m_RefCount == 0); if (coroutine-&gt;m_RefCount &lt;= 1) &#123; Coroutine::CleanupCoroutine(coroutine); return NULL; &#125; Coroutine::CleanupCoroutine(coroutine); return coroutine; &#125; 好了，入口我们找到了，那么它是运行的呢？我们跟踪run的时候会发现有一个CallDelaye函数，而这个函数是一个定时器函数，内部最终在Update上执行，那么我们的目标转而它的Update在哪里执行的呢？我们继续看。我们发现它最终是在场景的中Tick执行的，但是我目前并未发现Tick是多线程执行的，而且在个人的理解中，Tick也不太会或者不敢用多线程。 结论通过Unity2018上测试发现LoadFromFileAsync是使用多线程，协程在主线程上跑，这看上去符合我们的实验结果。而从Unity4.7源码发现协程是在主线程中运行。]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[边缘检测]]></title>
    <url>%2F2019%2F05%2F09%2Fedgedetection%2F</url>
    <content type="text"><![CDATA[边缘检测是描边效果的一种实现方法，在本节结束后，我们可以得到类似下图中的效果。边缘检测的原理是利用一些边缘检测算子对图像进行卷积（convolution）操作，我们首先来了解什么是卷积。 什么是卷积在图像处理中，卷积操作指的就是使用一个卷积核（kernel）对一张图像中的每个像素进行一系列操作。卷积核通常是一个四方形网格结果（例如2x2、3x3的方形区域），该区域内每个方格都有一个权重值。当对图像中的某个像素进行卷积时，我们会把卷积核的中心放置于该像素上，如下图所示，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到的结构就是该位置的新像素值。卷积核和卷积。使用一个3x3大小的卷积核对一张5x5大小的图像进行卷积操作，当计算图中红色方法对应的像素的卷积结果时，我们首先把卷积核的中心放置在该像素位置，翻转核之后在依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到新的像素值。这样的计算过程虽然简单，但可以实现很多常见的图像处理效果，例如图像模糊、边缘检测等。例如，如果我们想要对图像进行均值模糊，可以使用一个3x3的卷积核，核内每个元素的值均为1/9。 常见的边缘检测算子卷积操作的神奇之处在于选择的卷积核。那么，用于边缘检测的卷积核（也被称为边缘检测算子）应该长什么样子呢？在回答这个问题前，我们可以首先回想一下边到底是如何形成的。如果相邻像素之间存在差别明显的颜色、亮度、纹理等属性，我们就会认为它们之间应该有一条边界。这种相邻像素之间的插值可以用梯度（gradient）来表示，可以想象得到，边缘处的梯度绝对值会比较大。基于这样的理解，有几种不同的边缘检测算子被先后提出来。3中常见的边缘检测算子如上图所示，它们都包含了两个方向的卷积核，分别用于检测水平方向和竖直方向上的边缘信息。在进行边缘检测时，我们需要对每个像素分别进行一次卷积计算，得到这两个方向上的梯度值$G_x$和$G_y$，而整体的梯度可按下面的公式计算而得： $G = \sqrt{G_x^2 + G_y^2}$ 由于上述计算包含了开根号操作，出于性能的考虑，我们有时会使用绝对值操作来代替开根号操作： $G = |G_x| + |G_y|$当得到梯度G后，我们就可以据此来判断哪些像素对应了边缘（梯度值越大，越有可能是边缘点）。 实现本节将会使用Sobel算子进行边缘检测，实现描边效果。（4）在顶点着色器的代码中，我们计算了边缘检测时需要的纹理坐标：1234567891011121314151617181920212223struct v2f &#123; float4 pos : SV_POSITION; half2 uv[9] : TEXCOORD0;&#125;;v2f vert(appdata_img v) &#123; v2f o; o.pos = mul(UNITY_MATRIX_MVP, v.vertex); half2 uv = v.texcoord; o.uv[0] = uv + _MainTex_TexelSize.xy * half2(-1, -1); o.uv[1] = uv + _MainTex_TexelSize.xy * half2(0, -1); o.uv[2] = uv + _MainTex_TexelSize.xy * half2(1, -1); o.uv[0] = uv + _MainTex_TexelSize.xy * half2(-1, 0); o.uv[1] = uv + _MainTex_TexelSize.xy * half2(0, 0); o.uv[2] = uv + _MainTex_TexelSize.xy * half2(1, 0); o.uv[0] = uv + _MainTex_TexelSize.xy * half2(-1, 1); o.uv[1] = uv + _MainTex_TexelSize.xy * half2(0, 1); o.uv[2] = uv + _MainTex_TexelSize.xy * half2(1, 1); return o;&#125; 我们在v2f结构体中定义了一个维数为9的纹理数组，对应了使用Sobel算子采样时需要的9个领域纹理坐标。通过把计算采样纹理坐标的代码从片元着色器中转移到顶点着色器中，可以减少运算，提高性能。由于从顶点着色器到片元着色器的插值是线性的，因此这样的转移并不会影响纹理坐标的计算结果。（5）片元着色器是我们的重点，它的代码如下：1234567fixed4 fragSobel(v2f i) : SV_Target &#123; half edge = Sobel(i); fixed4 withEdgeColor = lerp(_EdgeColor,tex2D(_MainTex, i.uv[4]), edge); fixed4 onlyEdgeColor = lerp(_EdgeColor, _BackgroundColor,edge); return lerp(withEdgeColor,onlyEdgeColor,_EdgeOnly);&#125; 我们首先调用Sobel函数计算当前像素的梯度值edge，并利用该值分别计算了北京为原图和纯色下的颜色值，然后利用_EdgeOnly在两者之间插值得到最终的像素值。Sobel函数将利用Sobel算子对原图进行边缘检测，它的定义如下：12345678910111213141516171819202122232425fixed luminance(fixed4 color) &#123; return 0.2125 * color.r + 0.7154 * color.g + 0.0721 * color.b;&#125;half Sobel(v2f i) &#123; const half Gx[9] = &#123; -1,-2,-1, 0, 0, 0, 1, 2, 1 &#125;; const half Gy[9] = &#123; -1, 0, 1, -2, 0, 2, -1, 0, 1 &#125;; half texColor; half edgeX = 0; half edgeY = 0; for (int it = 0; it &lt; 9; it++) &#123; texColor = luminance(tex2D(_MainTex, i.uv[it]); edgeX += texColor * Gx[it]; edgeY += texColor * Gy[it]; &#125; half edge = 1 - abs(edgeX) - abs(edgeY); return edge;&#125;]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interlocked]]></title>
    <url>%2F2019%2F05%2F09%2Finterlocked%2F</url>
    <content type="text"><![CDATA[Interlocked可以为多个线程共享的变量提供原子操作。 Interlocked.Increment 以原子操作的形式递增指定变量的值并存储结果。 Interlocked.Decrement 以原子操作的形式递减制定变量的值并存储结果。 Interlocked.Add(ref int src, int val) 以原子操作的形式，添加两个整数并用两者的和替换第一个整数。 Interlocked.CompareExhange(ref target, desiredVal, startVal); 将target的值和startVal比较，相等则用desiredVal替换target，否则不操作。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AutoResetEvent]]></title>
    <url>%2F2019%2F05%2F09%2Fautoresetevent%2F</url>
    <content type="text"><![CDATA[ManualResetEvent和AutoResetEvent主要负责多线程编程中的线程同步；那在讲这个之前我们先说说线程同步： 线程同步共享数据首先，死记住，在C#中被标记static的变量就是共享数据，然后在探讨为什么静态变量是共享数据呢？首先静态变量的生命周期是从程序开始到程序结束。但是static变量的作用并不等同于它的生命周期，它的作用域决定于它被定义的位置。可以认为static变量的作用域&lt;=生存周期。static的数据是存储在静态存储区的，这块数据不同线程之间是可以共享的。 线程同步的目的很简单，为了防止共享数据被破坏，那么共享数据是如何被破坏的呢？同时进行写操作的时候会发生共享数据被破坏。 AutoResetEvent允许线程通过信号互相通信，通常，此通信涉及线程需要独占访问的资源。 AutoResetEvent与ManualResetEvnet的区别他们的用法声明都很类似，Set方法将信号置为发送状态，Reset方法将信号设置为不发送状态，WaitOne等待信号的发送。其实，从名字就可以看出一个手动，一个自动，这个手动和自动实际指的是在Reset方法的处理上，如下面的例子：12public AutoResetEvent autoEvent = new AutoResetEvent(true);public ManualResetEvent manualEvent = new ManualResetEvent(true); 默认信号都处于发送状态autoEvent.WaitOne();manualEvent.WaitOne();如果某个线程调用上面方法，则当信号处于发送状态时，该线程会得到信号，得以继续执行。差别就在调用后，autoEvent.WaitOne()每次只允许一个线程进入，当某个线程得到信号（也就是说有其他线程调用了autoEvnet.Set()方法后），autoEvent会自动又将信号设置为不发送状态，则其他调用WaitOne的线程只有继续等待，也就是说，autoEvent一次只唤醒一个线程。而manualEvent则可以唤醒多个线程，因为当某个线程调用了set方法后，其他调用waitone的线程获得信号得以继续执行，而manualevent不会自动将信号置为不发送，也就是说，除非手动调用了manualEvent.Reset()方法，否则manualEvent将一直保持有信号状态，manualEvent也就可以同时唤醒多个线程继续执行。如果上面的程序换成ManualResetEvent的话，就需要在waitone后面做下reset。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ManualResetEvent]]></title>
    <url>%2F2019%2F05%2F09%2Fmanualresetevent%2F</url>
    <content type="text"><![CDATA[ManualResetEvent用于线程间通信，实现一种类似信号量的功能。1public ManualResetEvent(bool initalState); initState为true表示有信号，为false表示无信号WaitOne起到线程阻塞的作用Set将ManualResetEvent对象的信号设为有信号状态，这个时候WaitOne如果正在阻塞中的话，将会立即终止阻塞，向下继续执行。而且这个状态一直不变的话，每次执行到WaitOne都将五任何阻塞。Reset将ManualResetEvent对象的信号设置为无信号状态，当下次执行到WaitOne时，又将重新开始阻塞。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解.NET中的GC(译文)]]></title>
    <url>%2F2019%2F05%2F09%2Funderstanding-garbage-colllection%2F</url>
    <content type="text"><![CDATA[原文链接: https://www.red-gate.com/simple-talk/dotnet/.net-framework/understanding-garbage-collection-in-.net/ 一旦你理解了.NET的垃圾收集器是如何工作的，那么一些复杂的.NET应用程序问题的原因就会变得更加清晰。.NET已承诺结束显式内存管理，但如果您希望避免与内存相关的错误和一些性能问题，则在开发.NET应用程序时仍需要分析内存的使用情况。 在应用程序中，.NET的垃圾收集器被认为是显式内存管理和内存泄漏的结束，在后台运行垃圾收集器时，开发人员不再需要担心需要管理他们创建的对象的生命周期，一旦应用程序完成它们，垃圾收集器将处理它们。 然而，现实比这更复杂。垃圾收集器解决了非托管程序中最常见的泄漏，那些由开发人员在完成后忘记释放内存而导致的泄漏。它还解决了过早释放内存的相关问题，但是当垃圾收集器对开发人员关于对象是否仍然“live”并且能够具有不同意见时，解决此问题的方式会导致内存泄漏要使用的。在解决这些问题之前，您需要了解收集器的工作原理。 GC的工作原理那么，垃圾收集器如何实现呢？基本思想非常简单：它检查对象如何在内存中布局，并通过遵循一系列引用来识别正在运行的程序可以引用的所有对象。 当GC开始时，它会查看一组称为“GC Roots”的引用。这些内存位置由于某种原因被指定为始终可访问，并且包含对程序创建的对象的引用。它将这些对象标记为“live”，然后查看它们引用的任何对象; 它标志着这些也是“live”。它以这种方式继续，遍历它所知道的所有“live”对象。它标记它们引用的任何内容，直到它找不到其他对象为止。 GC将对象标识为引用另一个对象（如果它或其中一个超类具有包含另一个对象的字段）。 一旦知道了所有这些活动对象，就可以丢弃任何剩余的对象，并将空间重新用于新对象。.NET压缩内存使得没有冗余（有效地压缩丢弃的对象） - 这意味着空闲内存总是位于堆的末尾并且非常快速地分配新对象。 GC roots 本身不是对象，而是对象的引用。GC roots 引用的任何对象将自动在下一个垃圾回收中存活。.NET中有四种主要的root用户： 当前正在运行的方法中的局部变量被视为GC root。这些变量引用的对象始终可以通过声明它们的方法立即访问，因此必须保留它们。这些root的生命周期可能取决于程序的构建方式。在调试版本中，只要方法在堆栈上，局部变量就会持续。在发布版本中，JIT能够查看程序结构，以计算出该方法可以使用变量的执行中的最后一点，并在不再需要时将其丢弃。此策略并不总是使用，可以关闭，例如，通过在调试器中运行程序。 静态变量也始终被视为GC root。它们引用的对象可以由声明它们的类（或程序的其余部分，如果它们是公共的）随时访问，因此.NET将始终保留它们。声明为“thread static”的变量只会持续该线程运行的时间。 如果通过interop将托管对象传递给非托管COM +library，那么它也将成为具有引用计数的GC root。这是因为COM +不进行垃圾收集：它使用引用计数系统; 一旦COM +library通过将引用计数设置为0来完成对象，它就不再是GC root，可以再次收集。 如果一个对象有一个finalizer，当垃圾收集器决定它不再“live”时，它不会被立即删除。相反，它在.NET调用终结器方法之前成为一种特殊的root。这意味着这些对象通常需要从内存中删除多个垃圾收集，因为它们将在第一次被发现未使用时存活。 The Object Graph总的来说，.NET中的内存形成了一个复杂的，打结的引用和交叉引用图。这可能使得难以确定特定对象使用的内存量。例如，List对象使用的内存非常小，因为List类只有几个字段。但是，其中一个是List中的对象数组如果有许多节点，这可能会非常大。这几乎总是由List所拥有，因此关系非常简单：List的总大小是小的初始对象和它引用的大型数组的大小。但是，数组中的对象可能完全是另一回事：可能存在一些通过内存的其他路径，通过它们可以到达它们。在这种情况下，当循环引用发挥作用时，事情变得更加混乱。 在开发代码时，通常会将内存视为一个更容易理解的结构：从单个root开始的tree： 事实上，以这种方式思考确实可以更容易（或确实可能）思考如何在内存中布置对象。这也是编写程序或使用调试器时数据的表示方式，但这样可以很容易地忘记对象可以附加到多个root。.NET中的内存泄漏通常是来自开发人员忘记或者从未意识到对象被附加到多个root。考虑这里显示的情况：将GC root 2设置为null（看下图，不要看上图）实际上不会允许垃圾收集器删除任何对象，这可以从查看完整图形而不是从树中看到。 内存分析器使得可以从另一个角度查看图形，作为以单个对象为根的树并向后跟随引用以将GC root放在叶子上。对于root 2引用的ClassC对象，我们可以向后跟随引用以获取以下图形： 以这种方式思考表明ClassC对象有两个最终的归属者，两者都必须在垃圾收集器移除它之前放弃它。GC root 3与对象之间的任何链接都可以被破坏，以便在GC root 2设置为null后将其删除。 在实际的.NET应用程序中很容易出现这种情况。最常见的一个是数据对象由用户界面中的元素引用，但在数据完成后不会被删除。这种情况并不是很严重：使用新数据更新UI控件时将回收内存，但这可能意味着应用程序使用的内存比预期的多得多。事件处理程序是另一个常见原因：很容易忘记一个对象将至少与它接收事件的对象一样长，这在某些全局事件处理程序（例如Application类中的那些事件处理程序）的情况下永远存在。 真实应用程序，尤其是那些具有用户界面组件的应用程序，具有比这更复杂的图形 甚至像对话框中的标签这样简单的东西也可以从大量不同的地方引用…… 很难查找对象的引用关系。 垃圾收集器的限制Unused objects.NET中垃圾收集器的最大限制：虽然它找到了未引用的对象，但是它仍然可能无法删除。而这个对象永远不会被程序再次引用; 虽然它有一些路径导致可能仍然使用的对象，但它永远不会从内存中释放出来。这会导致内存泄漏; 在.NET中，当不再使用的对象仍然被引用时会发生这种情况。 虽然内存使用量上升的症状很明显，但这些泄漏的来源很难被发现。有必要确定哪些未使用的对象保留在内存中，然后跟踪引用以找出它们未被收集的原因。内存分析器对于此任务至关重要：通过在发生泄漏时比较内存状态，可以找到麻烦的未使用对象，但是无法向后跟踪对象引用。 垃圾收集器旨在处理丰富的资源，也就是说，何时释放对象无关紧要。在现代系统中，内存属于该类别（只要它及时完成以防止新分配失败，它就会被回收。仍然存在不属于此类别的资源：例如，需要快速关闭文件句柄以避免导致应用程序之间的共享冲突。这些资源不能由垃圾收集器完全管理，因此.NET为管理这些资源的对象提供了Dispose()方法和using()构造。在这些情况下，对象使用的稀缺资源通过实现快速释放Dispose 方法，这比垃圾收集器稍后释放的关键内存要少得多。 Dispose对.NET来说没有什么特别之处，因此必须仍然取消引用已处理的对象。这使得已经处理但尚未被回收的对象成为内存泄漏源的良好候选者。 堆的碎片GC堆GC堆用来分配小对象实例，他是由GC完全控制内存的分配和回收。 LOH堆LOH堆是为大对象实例准备的，它不会被压缩且只在GC完全回收时才会被回收。成为LOH堆的一部分的对象永远不会被运行时移动，这可能导致程序过早地耗尽内存。当某些对象比其他对象生命周期更长时，这会导致堆在以前对象所在的位置生成碎片。当程序申请大块内存但堆已经因为碎片以至于没有足够大的单个内存区域来容纳它时，就会出现问题。内存分析器可以估计程序可以分配的最大对象，如果分配失败，那么这很可能是因为碎片导致的。一个OutOfMemoryException当程序显然拥有大量可用内存时，通常会发生碎片导致在32位系统上，进程应该能够使用至少1.5Gb，但由于碎片导致的故障通常会在使用之前开始发生很多记忆。在IL中可以看到newobj、ldstr(创建string对象)、newarr(用于分配新的数组对象)、box(装箱)等常见的创建对象的指令。当然在堆上也存在值类型，比如值类型作为类的字段时，他将存储在堆的实例对象空间，还有装箱时也会让堆上存在值类型。 碎片的另一个症状是.NET通常必须保留分配给应用程序的空洞所使用的内存。这使得它显然使用比在任务管理器中查看时所需的内存更多的内存。这种效果通常相对无害：Windows非常擅长于意识到漏洞所占用的内存未被使用并将其分页，如果碎片没有恶化，那么程序将不会耗尽内存。但是，对用户而言，这看起来并不好，他们可能认为该应用程序是浪费和“臃肿”。这通常是当分析器显示程序分配的对象仅使用少量内存但任务管理器显示该进程占用大量空间时发生的情况。 垃圾收集器的性能在性能方面，垃圾收集系统最重要的特征是垃圾收集器可以随时开始执行。这使得它们不适合于时序非常关键的情况，因为任何操作的时序都可以通过收集器的操作而被抛弃。 .NET收集器有两种主要的操作模式：并发和同步（有时称为工作站和服务器）。并发垃圾收集在桌面应用程序中使用，并且默认情况下在ASP.NET等服务器应用程序中使用同步。 在并发模式下，.NET将尝试避免在集合正在进行时停止正在运行的程序。这意味着应用程序在给定时间内完成的总量较少，但应用程序不会暂停。对于交互式应用程序而言，这对于向用户提供应用程序立即响应的印象非常重要。 在同步模式下，.NET将在垃圾收集器运行时挂起正在运行的应用程序。这实际上比并发模式更有效 - 垃圾收集花费相同的时间，但它不必与继续运行的程序竞争 - 但意味着当必须完成完整集合时可能会有明显的暂停。 如果默认值不合适，可以在应用程序的配置文件中设置垃圾收集器的类型。当应用程序具有高吞吐量而不是显示响应更重要时，选择同步收集器会很有用。 分代机制在大型应用程序中，垃圾收集器需要处理的对象数量会变得非常大，这意味着访问和重新排列所有这些对象可能需要很长时间。为了解决这个问题，.NET使用“世代”垃圾收集器，它试图优先考虑较小的一组对象。我们的想法是，最近创建的对象更有可能被弃用，因此当尝试释放内存时，分代垃圾收集器会优先考虑它们，因此所有新创建的对象都会放在第0代堆上，直到回收器进行了一次清理动作后仍存在的对象会被移动到另一片连续的地址空间中，即第1代堆上。而之前第1代上剩余的对象会被移动到第2代堆上，此时第0代堆空闲，等待新创建的对象。每一次回收动作都重复此过程。新的对象被回收的几率更大，将这些对象分阶段存放，回收过程速度加快。注：在创建新对象时，如果所需空间超出了第0代对应的空闲区域，回收器会进行垃圾回收，将第0代区域空闲出来。 如果.NET可以选择收集时间本身，并且if GC.Collect()被调用会中断，这个系统效果最好，因为这通常会导致新对象过早老化，这增加了在不久的将来另一个昂贵的完整收集的可能性。 具有终结器的类也可以破坏垃圾收集器的平稳操作。这些类的对象不能立即删除：它们转到终结器队列，并在终结器运行后从内存中删除。这意味着它们引用的任何对象（以及那些引用的任何对象，等等）必须至少保留在内存中，直到此时为止，并且在内存再次可用之前需要两次垃圾收集。如果图形包含许多带有终结器的对象，这可能意味着垃圾收集器需要多次传递才能完全释放所有未引用的对象。 有一种简单的方法可以避免这个问题：IDisposable在可finalizable的类上实现，将最终化对象所需的操作移动到Dispose()方法中并GC.SuppressFinalize()在最后调用。然后可以修改终结器以调用该Dispose()方法。GC.SuppressFinalize()告诉垃圾收集器该对象不再需要最终确定，并且可以立即进行垃圾收集，这可以更快地回收内存。 结论如果您花时间了解垃圾收集器的工作原理，那么理解应用程序中的内存和性能问题会变得更容易。它揭示了，虽然.NET使内存管理的负担更轻，但并不能完全消除跟踪和管理资源的需要。但是，使用内存分析器来诊断和修复.NET中的问题会更容易。考虑到.NET在开发早期管理内存的方式可以帮助减少问题，但即使这样，由于框架或第三方库的复杂性，仍然可能出现这样的问题。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RectTransform]]></title>
    <url>%2F2019%2F05%2F09%2Frecttransform%2F</url>
    <content type="text"><![CDATA[123456789// 改变RectTransform的top和RightGetComponent&lt;RectTransform&gt;().offsetMax = new Vector2(left, top);// bottom leftrectTransform.offsetMin = new Vector2(right, bottom);// width heightrectTransform.sizeDelta = new Vector2(width, height);// posrectTransform.anchoredPosition3D = new Vector3(posx,posy,posz);rectTransform.anchoredPosition = new Vector2(posx,posy);]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>UGUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ParticleSystem]]></title>
    <url>%2F2019%2F05%2F09%2FParticleSystem%2F</url>
    <content type="text"><![CDATA[1234ParticleSystem ps = GetComponent&lt;ParticleSystem&gt;();var main = ps.main;main.startDelay = 5.0f;main.startLifeTime = 2.0f;]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UnityWebRequest]]></title>
    <url>%2F2019%2F05%2F08%2Funitywebrequests%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930public class Network : MonoBehaviour&#123; void Start() &#123; StartCoroutine(Get()); StartCoroutine(Post()); &#125; IEnumerator Get() &#123; UnityWebRequest webRequest = UnityWebRequest.Get("http://www.baidu.com"); yield return webRequest.SendWebRequest(); if (webRequest.isHttpError || webRequest.isNetworkError) Debug.Log(webRequest.error); else Debug.Log(webRequest.downloadHandler.text); &#125; IEnumerator Post() &#123; WWWForm form = new WWWForm(); form.AddField("key", "value"); form.AddField("name", "mafanwei"); form.AddField("blog","qwe25878"); UnityWebRequest webRequest = UnityWebRequest.Post("http://www.baidu.com", form); yield return webRequest.SendWebRequest(); if (webRequest.isHttpError || webRequest.isNetworkError) Debug.Log(webRequest.error); else Debug.Log(webRequest.downloadHandler.text); &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[decompiler]]></title>
    <url>%2F2019%2F05%2F08%2Fdecompiler%2F</url>
    <content type="text"><![CDATA[https://github.com/Zhentar/ILSpy/releases/tag/0.1 一款优秀的反编译产品，作者修复了Mono Iterator的问题。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unity的阴影]]></title>
    <url>%2F2019%2F04%2F30%2FUnity-Shadow%2F</url>
    <content type="text"><![CDATA[阴影是如何实现的在实时渲染中，我们最长用的是一种名为Shadow Map技术。这种技术理解起来非常简单，它会首先把摄像机的位置放在与光源重合的位置上，那么场景中该光源的阴影区域就是那些摄像机看不到的地方。而Unity就是使用的这种技术。在前向渲染路径中，如果场景中最重要的平行光开启了阴影，Unity就会为该光源计算它的阴影映射纹理（shadowmap）。这张阴影隐射纹理本质也是一张深度图，它记录了从该光源的位置触发、能看到的场景中距离它最近的表面位置（深度信息）。那么，在计算阴影映射纹理时，我们如何判定距离它最近的表面位置呢？一种方法是，先把摄像机放置到光源的位置上，然后按正常的渲染流程，即调用Base Pass和Additional Pass来更新深度信息，得到阴影映射纹理。但这种方法会对性能造成一定的浪费，因为我们实际上仅仅需要深度信息而已，而Base Pass和Additional Pass中往往涉及很多复杂的光照模型计算。因此，Unity选择使用一个额外的Pass来专门更新光源的阴影映射纹理，这个Pass就是LightMode标签被设置为ShadowCaster的Pass。这个Pass的渲染目标不是帧缓存，而是阴影映射纹理（或深度纹理）。Unity首先把摄像机放置到光源的位置上，然后调用该Pass，通过对顶点变换后得到光源空间下的位置，并据此来输出深度信息到阴影映射纹理中。因此，当开启了光源的阴影效果后，底层渲染引擎首先会在当前渲染物体的Unity Shader中找到LightMode为ShadowCaster的Pass，如果没有，它就会在Fallback指定的Unity Shader中继续寻找，如果仍然没有找到，该物体就无法向其他物体投射阴影（但它仍然可以接受来自其他物体的阴影）。当找到了一个LightMode位ShadowCaster的Pass后，Unity会使用该Pass来更新光源的阴影映射纹理。在传统的阴影映射纹理的实现中，我们会在正常渲染的Pass中把顶点位置变换到光源空间下，以得到它在光源空间中的三维位置信息。然后，我们使用xy分量对阴影映射纹理进行采样，得到阴影映射纹理中该位置的深度信息。如果该深度值小于该顶点的深度值（通常由z分量得到），那么说明该点位于阴影中。但在Unity5中，Unity使用了不同于这种传统的阴影采样技术，即屏幕空间的阴影映射技术（Screenspace Shadow Map）。屏幕空间的阴影映射原本是延迟渲染中产生阴影的方法。需要注意的是，并不是所有的平台Unity都会使用这种技术。这是因为，屏幕空间的阴影映射需要显卡支持MRT，而有些移动平台不支持这种特性。当使用了屏幕空间的阴影映射技术时，Unity首先会通过调用LightMode为ShadowCaster的Pass来得到可投射阴影的光源的阴影映射纹理以及摄像机的深度纹理。然后，根据光源的阴影映射纹理和摄像机的深度纹理来得到屏幕空间的阴影图。如果摄像机的深度图中记录的表面深度大于转换到阴影隐射纹理中的深度值，就说明该表面虽然是可见的，但是却处于该光源的阴影中。通过这样的方式，阴影图就包含了屏幕空间中所有阴影的区域。如果我们想要一个物体接受来自其他物体的阴影，只需要在Shader中对阴影图进行采样。由于阴影图是屏幕空间下的，因此，我们首先需要把表面坐标从模型空间变换到屏幕空间中，然后使用这个坐标对阴影图进行采样即可。总结一下，一个物体接受来自其他物体的阴影，以及它像其他物体投射阴影是两个过程。 如果我们想要一个物体接受来自其他物体的阴影，就必须在Shader中对阴影映射纹理（包括屏幕空间的阴影图）进行采样，把采样结果和最后的光照结果相乘来产生阴影效果。 如果我们想要一个物体向其他物体投射阴影，就必须把该物体加入到光源的阴影映射纹理的计算中，从而让其他物体在对阴影映射纹理采样时可以得到该物体的相关信息。在Unity中，这个过程是通过为该物体执行LightMode为ShadowCaster的Pass来实现的。如果使用了屏幕空间的投影映射技术，Unity还会使用这个Pass产生一张摄像机的深度纹理。 不透明物体的阴影]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【spine】快速入门]]></title>
    <url>%2F2019%2F04%2F30%2Fspine-base%2F</url>
    <content type="text"><![CDATA[Spine 不限于角色动画，但角色动画是最常见也是最好的例子。在 Spine 中角色使用 的不是一张完整的图片，而是将各个部分切片成一系列的小图。比如：头、躯干、胳膊和腿。 这些小图片被附加到骨骼上，然后用骨骼自由的设置角色动作。这些切片会随着骨骼运动而 产生流畅的动画。 装配模式 Setup Mode使用 Spine 从装配模式开始，在此模式中创建骨骼，附加切片。在编辑区的左上角显 示着 Setup（装配）或 Animate（动画）来指示当前的模式，可以通过点击进行切换。 切片 Images层级树中的 Images 节点定义了 Spine 从哪里为你找到这副骨架要用的图片。图片的路 径 path 默认使用当前项目的相对路径。也支持绝对路径。设置完成后，路径下的图片会被加 载到图片 Images 节点中。Spine 实时监控图片所在路径，如果图片发生改变，立刻更新到项目中。 参考图片 Template Image通过将一张完整的角片作为参考，能更简单准确的创建骨骼和放置图片。操作如 下：把 template 图片从 Images 节点拖到编辑区域，它会被附加到 root 骨骼点上。在层 级树底部的属性面板勾选背景 Background ，被设置成背景后它将不可选，也不会被输出。可以改变参考图片的颜色，这样更容易辨认。 角色切片 Character Images在 Images 节点下，点选切片，然后 shift + 左键或 ctrl+左键把其它切片全部选中。 把它们拖放到编辑区，Spine 会为它们创建切片插槽 slots 并全部放在 root 骨骼点下。对照参考图片把所有肢体切片对位。切片不是直接附加到骨骼上的，而是附加到一个切片插槽中，插槽再附加到骨骼上。一 个切片插槽中可以放置多个切片，但一次只能显示一个。切片插槽对复杂骨骼的绘制顺序提 供更多控制权限。在层级树的 Draw Order 节点中拖拽改变绘制顺序。在列表上方的切片插槽会显示在 前面，而下方的插槽会显示在后面。你还可以用+或-号键来调整顺序，按住 Shift 可以一次 移动5个单位。当参考图用完后，可以点击层级树的中的显示点隐藏它。 Photoshop如果在使用 Photoshop，那架设骨骼时可以使用 Spine 提供的“LayersToPNG.jsx” PS 脚本。在 Spine 安装目录下的 scripts/photoshop/LayersToPNG.jsx 能找到。此脚本能 导出图层为 PNG 文件和 Spine 的 JSON 文件。点击 Spine 左上角的 Spine 标志，然后 Import Data, Skeleton。导入的骨架包含一个骨骼点和所有的图片，这些图片位置和显示绘制顺序 都和 PS 中的图层一至。留给你的工作就只有创建骨骼了。这在后面会介绍。 另一个提高工作效率的方案是使用 Adobe Generator . 它能让 PNG 文件与 PSD 同步， 妈妈再也不用担心我手动导图几万张图而发飙了。而 Spine 也是实时同步文件夹中的 PNG 的，这也就相当于 Spine 中的切片素材可以和 PSD 保持同步了。 创建骨骼 Creating Bones使用创建 Create 工具，创建新骨骼时，首先要选中一个骨骼作为它的父级，然后再拖 拽创建出新骨骼。 当创建新骨骼时，按 shift（不用按住不放）选择光标下的图片。当拖出新骨骼后，被 选中的图片将会变成新骨骼的子物体。使用这个功能来创建骨骼能更高效，因为你同时创建了新骨骼，并改变了图片的父级。 最后你可能要想改变某个骨头，插槽，图片或其它东西的父级。方法如下：选中要改变 父级的对象，按 P 键或 Set Parent 按钮，然后在层级树中选择新的父级。如果目前是骨骼 的话，比起在层级树中选，在编辑区域选可能更方便。要改变骨骼的长度，选中任意一个变换工具 Rotate, Translate 或 Scale。然后拖动骨 骼的末端。另外骨骼长度也可以在层级树下方的属性面板中调整。如果骨骼长度为0，在编 辑区它将显示为一个特殊的图标。而在别的地方和其它骨骼没什么不同。骨骼可以在层级树底部的属性面板中设置颜色。这将便于区分各个不同的骨骼。在 Compensation 面板中 Image 和 Bone 按钮用于调整骨骼但保持它的子物体，如附 加在它下面的骨骼和图片不受影响。别一个调整已经创建好的骨骼的方法，用 Create 工具选要调整的骨骼，按住 Alt 键， 然后点击拖拽。这样可以在新的位置重画骨骼，而不影响它的子物体。 动画模式 Animate Mode点击编辑区左上角的 Setup 切换到动画模式。在动画模式下，层级树会显示动画 Animations 节点，其中包含所有可编辑和查看的 动画。 用骨骼摆出姿势，然后设置关键帧创建动画。当动画播放时，骨骼会自动在关键帧之间 添加中间帧以实现平滑的运动。 摄影表 DopesheetDopesheet 按钮可以点击以展开摄影表，它提供更详细的关键帧视图。可以在摄影表 中拖动关键帧调整动画。 设置关键帧 Setting Keyframes通常第一个关键帧设置在0帧上。通过点击位移、缩放、旋转（Translate, Scale, and Rotate）工具后的关键帧图标，设置关键帧。绿色表示当前没关键帧，*表示值已经发 生变化，但是没有再次添加关键帧，红色表示已经添加关键帧。热键 K 可以为所有发生改变的值设置关键帧。 热键 L 可以为当前激活工具设置关键帧。 如果 AutoKey 按钮被按下，所有发生改变的值都会自动被设置关键帧。 接着，在时间轴上选到下一个位置，调整骨骼摆出姿势，添加关键帧。点击并拖动时间 线就能看到流畅的骨骼动画了。 动画工作流程 Animation Workflow常见的动画工作流程，先 K 出关键 pose 然后再回头细化润色动作。点击时间轴上方 的 Playback 按钮，在打开的面板中激活“步进 Stepped”按钮来实现关键 pose 预览。它能够禁用补间帧，从而更容易观察关键 pose。一旦所有大动作都创建完成，关闭 Stepped，添加更多 key 优化过度的效果。 曲线编辑器 Graph曲线 Graph 按钮可以展开曲线编辑器。在摄影表中选择一个关键帧，这里会显示它与 下一帧之间的补间插值曲线。通过点击贝塞尔 Bezier Curve 曲线图标，启动非线性插值，要想 K 出栩栩如生的动画 这是关键所在。在曲线编辑器中拖动 Bezier 手柄改变插值。X 轴代表当前帧到下一帧之间的时间，Y 轴代表值。]]></content>
      <categories>
        <category>Spine</category>
      </categories>
      <tags>
        <tag>Spine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【spine】反向动力学 Inverse Kinematics (IK)]]></title>
    <url>%2F2019%2F04%2F30%2Fspine-IK%2F</url>
    <content type="text"><![CDATA[通常情况下，我们使用FK工具设置动画，它是正向动力学的缩写。当设置手部位置动画时，FK从上至下驱动，先转动大臂，再转动小臂来实现。大多数情况下它能很好的达到我们想要的效果。但某些特殊情况比如：一个坐着的角色手扶桌面，慢慢起身，这时FK需要不段的调整手部的位置，以使其能保持按在桌面上。这将需要创建大量关键帧来实现。IK对于这种情况会更合适，它是反向动力学的缩写。IK从下至上驱动。设置好手部的位置后，角色起身时，手部保持不动，小臂和大臂的骨骼会自动旋转到合适角度。IK也适合于完成其它一些任务，比如脚部会踩进地面的行走动画（例如游戏场景中有一关沼泽地），可以在运行时通过调整IK目标（IK target）实现角色在不平坦的地面上行走的效果，等等。在Spine中对骨骼的控制可以是FK，可以是IK，可以是FK/IK两者混合的效果。当然也可以在动画中实现FK和IK之间的平滑过度。（传说中的FK/IK无缝转换） 装配 Setup要使用IK（IK约束）需要三个骨骼：父骨骼、子骨骼、目标骨骼。子骨骼必须是父骨骼的子级，但可以不是直接的父子关系。目标骨骼不能是父骨骼的子级。开始创建IK约束，选中父骨骼、子骨骼，在层级树目录中点击约束(Constraints)，点击创建新IK约束(New IK Constraint)，然后选择一个已经存在的骨骼(父骨骼的子级不能选)作为目标，或是点击场景中空白区创建一个新骨骼作为目标。IK约束会不断的调整父骨骼、子骨骼的旋转值，以使子骨骼的末端钉在目标骨骼上。父骨骼与子骨骼的弯曲方向可以通过IK约束(IK constraint)的属性来改变。当一个骨骼的旋转属性被IK约束(IK constraint)所控制时，它将显示为一个中空的骨骼，以表明某些变换操作，现在不能手动控制了。 FK/IK融合 Mixing FK/IKIK的混合(Mix)滑动条，用于控制骨骼受影响的程度。当值为0表示当前骨骼完全处于FK控制，当值为100表示当前骨骼完全处于IK控制。当值为0到100之间，表示骨骼同时受到FK和IK的控制。两条辅助线分别表示，FK的位置和IK的位置。通常在一个动画中只需要为FK/IK做0到100之间的简单过渡。总之在某些情况下使用FK/IK混合功能比直接K帧要方便的多。例如：用IK做了一段手臂上下挥动的动画，接着要用FK做另一部分。这时关掉IK约束的显示开关，IK的控制效果就会被停用，这样更方便将FK对齐到IK的位置。当IK约束被停用，骨骼将完全处于FK状态，并且可以像通常那样进行变换制作。注意：当IK约束停用时，此约束影响的骨骼下的附属资源将变为不可编辑。 设置动画 Animating当在动画模式下改变了弯曲(bend)或混合(mix)属性的值，约束节点前的小钥匙就会变成*。点击小钥匙图标，将同时为弯曲(bend)和混合(mix)属性创建关键帧，它们默认是同时创建的没法分开。设置混合(mix)属性的关键帧，通常用于在动画中控制IK的起效和失效。在曲线编辑器中，可以通过一根曲线来控制它，因此混合(mix)属性的过渡效果是可以自定义的。]]></content>
      <categories>
        <category>Spine</category>
      </categories>
      <tags>
        <tag>Spine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Spine 源码解析]]></title>
    <url>%2F2019%2F04%2F28%2Fspine%2F</url>
    <content type="text"><![CDATA[概念先来介绍下 spine 中的一些术语和概念 Bone 骨骼spine 是骨骼编辑器,所以骨骼是基础。每个骨骼都会有旋转，缩放，位移的属性。然后骨骼可以有子节点，最终形成了一个树型结构。可以对应2dx 里面的 node Slot 插槽骨骼上的一个挂载点。不是所有的骨骼上都能放置东西的，因为很多骨骼其实只参与计算，真正重要的骨骼，也就是需要挂载其他东西的骨骼上必须放置插槽。slot 只是用来标记特殊的骨骼位置，本身只有一个颜色属性，也可以说，重要的骨骼节点可以称为 slot。 Attachment 附件挂在插槽上的内容，可以是图片，也可以是判定区域，只要是你能想到的东西，都可以当成附件。 Draw order 描画顺序骨架上插槽的一个顺序列表。用来控制描画的先后顺序。 Animation 动画基于时间轴的一个骨骼状态列表。 Skin 皮肤一套附件的集合，类似于换装。 Bounding Box 边界框用来指定骨骼上的边界的多边形的区域。 atlas 图集贴图集合，小图片合并在一起，就成了图集。 实现上面大致介绍了一些基本概念，然后我们从实现角度上来说下为啥这么设计。首先，假设我们需要一个骨骼系统。于是，我们就设计了一个树状的骨架，每个节点就是（Bone）。很简单啊，再想下，骨骼上要放图片啥的，于是我们就要能访问到特定的骨骼，遍历太傻了，好吧，我们给这些骨骼加个名字，这样就能访问到具体 骨骼了，那这些名字就叫 slot。好吧，可能有些人觉得，slot 和 bone 本质上一样，为啥需要分开呢，没必要的。我只能说事情其实并不简单，来想下，我们已经有了一个完美的骨架，图片也在应该在的骨骼上了。那我们该如何显示图片么？遍历么，从根结点开始，一直到最下层的节点，不管你用啥排序，这个顺序是固定的，但是现实总是很残酷，很多时候，我们需要不停调整图片描画的顺序，也就是调整树的节点排序，啊，好麻烦。那怎么办，我们指定下骨骼描画的顺序吧（Draw order），这些特定的骨骼也就是 slot。你看，这下完美了，也就是 bone 用来计算位置，slot 用来控制描画。完美的骨骼系统，一定要有碰撞区域（bounding box），这和图片差不多,一个用于显示,一个用于边界判断,好吧,那就抽象成一个概念叫（p_w_upload），于是，slot 上就可以附加不同的 p_w_upload 了。终于可以换附件了，但是一个一个换好累。于是，我们把一组附件合在一起，组成了 skin。这下简单了，一换 skin，整个世界就变样了。啊，做着做着，就发现图片太多了，要优化啊。怎么办，简单，把小图片合在一起，每个图片对应了一个大图里面的一个区域，这就是 atlas。Spine-Unity使用Unity的MeshRenderer和MeshFiter组建，还有材质资源进行渲染。SkeletonRenderer类（SkeletonAnimation和SkeletonAnimator均继承与它），在它的LateUpdate中构建Mesh。生成顶点，颜色，三角形索引和UV然后把这些放入Mesh中。以下讲解主要说明如何构建Mesh。Spine一般使用alpha混合的方式来渲染模型，在一个网格中，它根据网格中三角形的顺序去渲染物体，然后绘制一个东西在另一个东西上面。该顺序是在Spine中控制槽的绘制顺序来决定的。为了让大家更好的理解本文，先讲述涉及到的一些数据结构：12345678910public class ExposedList&lt;T&gt;: IEnumerable&lt;T&gt;&#123; public void Clear (bool clearArray = true) &#123; if (clearArray) Array.Clear(Items, 0, Items.Length); Count = 0; version++; &#125;&#125; 暴露的链表，原理和List是一样的，但是扩展了一些方法，比如Clear(bool clearArray = true)，List只能Clear()，尝试在多找一些对比，但是代码中大部分是foreach,add,clear由于时间有限，暂时不对其进入深入了解。 TransformMode123456789// 转换模式public enum TransformMode &#123; //0000 0 Flip Scale Rotation Normal = 0, // 0000 正常，平移，旋转，缩放 OnlyTranslation = 7, // 0111 只平移 NoRotationOrReflection = 1, // 0001 不旋转或映像 NoScale = 2, // 0010 不缩放 NoScaleOrReflection = 6, // 0110 不缩放或映像&#125; BoneData12345678public class BoneData &#123; internal int index; // 骨骼索引，第几根骨骼 internal string name;// 骨骼名，具有唯一性 internal BoneData parent;//父亲骨骼 internal float length; // 骨骼长度，不太理解 internal float x, y, rotation, scaleX = 1, scaleY = 1, shearX, shearY;// 位移，旋转，缩放，裁剪 internal TransformMode transformMode = TransformMode.Normal;//变换模式&#125; BlendMode1234567// 混合模式public enum BlendMode &#123; Normal, Additive,// 加法 Multiply, // 乘法 Screen // 屏幕&#125; SlotData1234567891011// 槽数据class SlotData &#123; internal int index; internal string name; internal BoneData boneData; internal float r = 1, g = 1, b = 1, a = 1; internal float r2 = 0, g2 = 0, b2 = 0; internal bool hasSecondColor = false; internal string attachmentName; // 附件名 internal BlendMode blendMode;&#125; IKContraintData123456789// IK约束(动力学)class IkConstraintData &#123; internal string name; internal int order; internal List&lt;BoneData&gt; bones = new List&lt;BoneData&gt;(); internal BoneData target; internal int bendDirection = 1; internal float mix = 1;&#125; TransformConstraintData12345678910// 变换约束数据class TransformConstraintData &#123; internal string name; internal int order; // 命令 internal ExposedList&lt;BoneData&gt; bones = new ExposedList&lt;BoneData&gt;(); internal BoneData target; internal float rotateMix, translateMix, scaleMix, shearMix; internal float offsetRotation, offsetX, offsetY, offsetScaleX, offsetScaleY, offsetShearY; internal bool relative, local;//坐标系&#125; PathConstraintData123456789101112// 路径约束class PathConstraintData &#123; internal string name; internal int order; internal ExposedList&lt;BoneData&gt; bones = new ExposedList&lt;BoneData&gt;(); internal SlotData target; internal PositionMode positionMode; internal SpacingMode spacingMode; internal RotateMode rotateMode; internal float offsetRotation; internal float position, spacing, rotateMix, translateMix;&#125; SkeletonData123456789101112131415// 骨架数据class SkeletonData &#123; internal string name; internal ExposedList&lt;BoneData&gt; bones = new ExposedList&lt;BoneData&gt;(); // Ordered parents first internal ExposedList&lt;SlotData&gt; slots = new ExposedList&lt;SlotData&gt;(); // S装配绘制顺序 internal ExposedList&lt;Skin&gt; skins = new ExposedList&lt;Skin&gt;(); // 附件集合 internal Skin defaultSkin; internal ExposedList&lt;EventData&gt; events = new ExposedList&lt;EventData&gt;(); internal ExposedList&lt;Animation&gt; animations = new ExposedList&lt;Animation&gt;(); // 动画列表 internal ExposedList&lt;IkConstraintData&gt; ikConstraints = new ExposedList&lt;IkConstraintData&gt;(); internal ExposedList&lt;TransformConstraintData&gt; transformConstraints = new ExposedList&lt;TransformConstraintData&gt;(); internal ExposedList&lt;PathConstraintData&gt; pathConstraints = new ExposedList&lt;PathConstraintData&gt;(); internal float width, height; internal string version, hash;&#125; Skeleton(骨架)1234567891011121314151617// 骨架，总感觉数据有冗余，在看看吧class Skeleton &#123; internal SkeletonData data; internal ExposedList&lt;Bone&gt; bones; internal ExposedList&lt;Slot&gt; slots; internal ExposedList&lt;Slot&gt; drawOrder; // 画的命令槽 internal ExposedList&lt;IkConstraint&gt; ikConstraints; internal ExposedList&lt;TransformConstraint&gt; transformConstraints; internal ExposedList&lt;PathConstraint&gt; pathConstraints; internal ExposedList&lt;IUpdatable&gt; updateCache = new ExposedList&lt;IUpdatable&gt;(); internal ExposedList&lt;Bone&gt; updateCacheReset = new ExposedList&lt;Bone&gt;(); internal Skin skin; internal float r = 1, g = 1, b = 1, a = 1; internal float time; internal bool flipX, flipY; internal float x, y;&#125; Bone(骨头)12345678910111213class Bone : IUpdatable &#123; static public bool yDown; internal BoneData data; internal Skeleton skeleton; internal Bone parent; internal ExposedList&lt;Bone&gt; children = new ExposedList&lt;Bone&gt;(); internal float x, y, rotation, scaleX, scaleY, shearX, shearY; internal float ax, ay, arotation, ascaleX, ascaleY, ashearX, ashearY; internal bool appliedValid; internal float a, b, worldX; // 权重，坐标 internal float c, d, worldY; internal bool sorted;&#125; SubmeshInstruction12345678910111213141516171819202122// 子网格约束struct SubmeshInstruction &#123; public Skeleton skeleton; public int startSlot; public int endSlot; public Material material; public bool forceSeparate; // 强制分离 public int preActiveClippingSlotSource; #if SPINE_TRIANGLECHECK // 缓存的值，因为它们是在生成指令的过程中确定的， // but could otherwise be pulled from accessing attachments, checking materials and counting tris and verts. public int rawTriangleCount; public int rawVertexCount; public int rawFirstVertexIndex; public bool hasClipping; #endif /// &lt;summary&gt;The number of slots in this SubmeshInstruction's range. Not necessarily the number of attachments.&lt;/summary&gt; public int SlotCount &#123; get &#123; return endSlot - startSlot; &#125; &#125;&#125; RegionAttachment(显示纹理区域的附件)123456789101112131415class RegionAttachment : Attachment, IHasRendererObject &#123; public const int BLX = 0; // bottom left x public const int BLY = 1; // bottom left y public const int ULX = 2; // upper left x public const int ULY = 3; // upper left y public const int URX = 4; // upper right x public const int URY = 5; // upper right y public const int BRX = 6; // bottom right x public const int BRY = 7; // bottom right y internal float x, y, rotation, scaleX = 1, scaleY = 1, width, height; internal float regionOffsetX, regionOffsetY, regionWidth, regionHeight, regionOriginalWidth, regionOriginalHeight; internal float[] offset = new float[8], uvs = new float[8]; internal float r = 1, g = 1, b = 1, a = 1;&#125; MeshAttachment(使用网格显示纹理区域的附件)123456789class MeshAttachment : VertexAttachment, IHasRendererObject &#123; internal float regionOffsetX, regionOffsetY, regionWidth, regionHeight, regionOriginalWidth, regionOriginalHeight; private MeshAttachment parentMesh; internal float[] uvs, regionUVs; internal int[] triangles; internal float r = 1, g = 1, b = 1, a = 1; internal int hulllength; internal bool inheritDeform;&#125; BuildMeshWithArrays(构建顶点等数据，渲染帧中只负责渲染)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266// 当不涉及剪切时，使用这种更快的方法。public void BuildMeshWithArrays(SkeletonRendererInstruction instruction, bool updateTriangles)&#123; var settings = this.settings; int totalVertexCount = instruction.rawVertexCount; // 扩容 &#123; if (totalVertexCount &gt; vertexBuffer.Items.Length) &#123; // Manual ExposedList.Resize() Array.Resize(ref vertexBuffer.Items, totalVertexCount); Array.Resize(ref uvBuffer.Items, totalVertexCount); Array.Resize(ref colorBuffer.Items, totalVertexCount); &#125; vertexBuffer.Count = uvBuffer.Count = colorBuffer.Count = totalVertexCount; &#125; // Populate Verts Color32 color = default(Color32); int vertexIndex = 0; var tempVerts = this.tempVerts; Vector3 bmin = this.meshBoundsMin; Vector3 bmax = this.meshBoundsMax; var vbi = vertexBuffer.Items; var ubi = uvBuffer.Items; var cbi = colorBuffer.Items; int lastSlotIndex = 0; // drawOrder[endSlot] is excluded for (int si = 0, n = instruction.submeshInstructions.Count; si &lt; n; si++) &#123; var submesh = instruction.submeshInstructions.Items[si]; // 通过骨骼的[startSlot,endSlot)来渲染网格 var skeleton = submesh.skeleton; // 骨骼 var skeletonDrawOrderItems = skeleton.drawOrder.Items; // 骨骼命令槽 float a = skeleton.a * 255, r = skeleton.r, g = skeleton.g, b = skeleton.b; int endSlot = submesh.endSlot; int startSlot = submesh.startSlot; lastSlotIndex = endSlot; if (settings.tintBlack) &#123; // 是不是浅黑色效果，增加两倍顶点来实现的 Vector2 rg, b2; int vi = vertexIndex; b2.y = 1f; &#123; if (uv2 == null) &#123; uv2 = new ExposedList&lt;Vector2&gt;(); uv3 = new ExposedList&lt;Vector2&gt;(); &#125; if (totalVertexCount &gt; uv2.Items.Length) &#123; // Manual ExposedList.Resize() Array.Resize(ref uv2.Items, totalVertexCount); Array.Resize(ref uv3.Items, totalVertexCount); &#125; uv2.Count = uv3.Count = totalVertexCount; &#125; var uv2i = uv2.Items; var uv3i = uv3.Items; for (int slotIndex = startSlot; slotIndex &lt; endSlot; slotIndex++) &#123; var slot = skeletonDrawOrderItems[slotIndex]; var attachment = slot.attachment; rg.x = slot.r2; //r rg.y = slot.g2; //g b2.x = slot.b2; //b var regionAttachment = attachment as RegionAttachment; if (regionAttachment != null) &#123; uv2i[vi] = rg; uv2i[vi + 1] = rg; uv2i[vi + 2] = rg; uv2i[vi + 3] = rg; uv3i[vi] = b2; uv3i[vi + 1] = b2; uv3i[vi + 2] = b2; uv3i[vi + 3] = b2; vi += 4; &#125; else &#123; var meshAttachment = attachment as MeshAttachment; if (meshAttachment != null) &#123; int meshVertexCount = meshAttachment.worldVerticesLength; for (int iii = 0; iii &lt; meshVertexCount; iii += 2) &#123; uv2i[vi] = rg; uv3i[vi] = b2; vi++; &#125; &#125; &#125; &#125; &#125; for (int slotIndex = startSlot; slotIndex &lt; endSlot; slotIndex++) &#123; var slot = skeletonDrawOrderItems[slotIndex]; var attachment = slot.attachment; float z = slotIndex * settings.zSpacing; var regionAttachment = attachment as RegionAttachment; if (regionAttachment != null) &#123; regionAttachment.ComputeWorldVertices(slot.bone, tempVerts, 0); // 根据权重上一位置，计算当前顶点 float x1 = tempVerts[RegionAttachment.BLX], y1 = tempVerts[RegionAttachment.BLY]; float x2 = tempVerts[RegionAttachment.ULX], y2 = tempVerts[RegionAttachment.ULY]; float x3 = tempVerts[RegionAttachment.URX], y3 = tempVerts[RegionAttachment.URY]; float x4 = tempVerts[RegionAttachment.BRX], y4 = tempVerts[RegionAttachment.BRY]; vbi[vertexIndex].x = x1; vbi[vertexIndex].y = y1; vbi[vertexIndex].z = z; vbi[vertexIndex + 1].x = x4; vbi[vertexIndex + 1].y = y4; vbi[vertexIndex + 1].z = z; vbi[vertexIndex + 2].x = x2; vbi[vertexIndex + 2].y = y2; vbi[vertexIndex + 2].z = z; vbi[vertexIndex + 3].x = x3; vbi[vertexIndex + 3].y = y3; vbi[vertexIndex + 3].z = z; // 混合颜色 if (settings.pmaVertexColors) &#123; color.a = (byte)(a * slot.a * regionAttachment.a); color.r = (byte)(r * slot.r * regionAttachment.r * color.a); color.g = (byte)(g * slot.g * regionAttachment.g * color.a); color.b = (byte)(b * slot.b * regionAttachment.b * color.a); if (slot.data.blendMode == BlendMode.Additive) color.a = 0; &#125; else &#123; color.a = (byte)(a * slot.a * regionAttachment.a); color.r = (byte)(r * slot.r * regionAttachment.r * 255); color.g = (byte)(g * slot.g * regionAttachment.g * 255); color.b = (byte)(b * slot.b * regionAttachment.b * 255); &#125; cbi[vertexIndex] = color; cbi[vertexIndex + 1] = color; cbi[vertexIndex + 2] = color; cbi[vertexIndex + 3] = color; // 阈值 float[] regionUVs = regionAttachment.uvs; ubi[vertexIndex].x = regionUVs[RegionAttachment.BLX]; ubi[vertexIndex].y = regionUVs[RegionAttachment.BLY]; ubi[vertexIndex + 1].x = regionUVs[RegionAttachment.BRX]; ubi[vertexIndex + 1].y = regionUVs[RegionAttachment.BRY]; ubi[vertexIndex + 2].x = regionUVs[RegionAttachment.ULX]; ubi[vertexIndex + 2].y = regionUVs[RegionAttachment.ULY]; ubi[vertexIndex + 3].x = regionUVs[RegionAttachment.URX]; ubi[vertexIndex + 3].y = regionUVs[RegionAttachment.URY]; if (x1 &lt; bmin.x) bmin.x = x1; // 潜在的第一个附件边界初始化。初始最小值不应阻止初始最大值。下面的Y也是一样。 if (x1 &gt; bmax.x) bmax.x = x1; if (x2 &lt; bmin.x) bmin.x = x2; else if (x2 &gt; bmax.x) bmax.x = x2; if (x3 &lt; bmin.x) bmin.x = x3; else if (x3 &gt; bmax.x) bmax.x = x3; if (x4 &lt; bmin.x) bmin.x = x4; else if (x4 &gt; bmax.x) bmax.x = x4; if (y1 &lt; bmin.y) bmin.y = y1; if (y1 &gt; bmax.y) bmax.y = y1; if (y2 &lt; bmin.y) bmin.y = y2; else if (y2 &gt; bmax.y) bmax.y = y2; if (y3 &lt; bmin.y) bmin.y = y3; else if (y3 &gt; bmax.y) bmax.y = y3; if (y4 &lt; bmin.y) bmin.y = y4; else if (y4 &gt; bmax.y) bmax.y = y4; vertexIndex += 4; &#125; else &#123; var meshAttachment = attachment as MeshAttachment; if (meshAttachment != null) &#123; int meshVertexCount = meshAttachment.worldVerticesLength; if (tempVerts.Length &lt; meshVertexCount) this.tempVerts = tempVerts = new float[meshVertexCount]; meshAttachment.ComputeWorldVertices(slot, tempVerts); if (settings.pmaVertexColors) &#123; color.a = (byte)(a * slot.a * meshAttachment.a); color.r = (byte)(r * slot.r * meshAttachment.r * color.a); color.g = (byte)(g * slot.g * meshAttachment.g * color.a); color.b = (byte)(b * slot.b * meshAttachment.b * color.a); if (slot.data.blendMode == BlendMode.Additive) color.a = 0; &#125; else &#123; color.a = (byte)(a * slot.a * meshAttachment.a); color.r = (byte)(r * slot.r * meshAttachment.r * 255); color.g = (byte)(g * slot.g * meshAttachment.g * 255); color.b = (byte)(b * slot.b * meshAttachment.b * 255); &#125; float[] attachmentUVs = meshAttachment.uvs; // 潜在的第一个附件边界初始化。参见区域连接逻辑中的条件。 if (vertexIndex == 0) &#123; // 初始最小值不应阻止初始最大值。 // vi == vertexIndex does not always mean the bounds are fresh. It could be a submesh. Do not nuke old values by omitting the check. // Should know that this is the first attachment in the submesh. slotIndex == startSlot could be an empty slot. float fx = tempVerts[0], fy = tempVerts[1]; if (fx &lt; bmin.x) bmin.x = fx; if (fx &gt; bmax.x) bmax.x = fx; if (fy &lt; bmin.y) bmin.y = fy; if (fy &gt; bmax.y) bmax.y = fy; &#125; for (int iii = 0; iii &lt; meshVertexCount; iii += 2) &#123; float x = tempVerts[iii], y = tempVerts[iii + 1]; vbi[vertexIndex].x = x; vbi[vertexIndex].y = y; vbi[vertexIndex].z = z; cbi[vertexIndex] = color; ubi[vertexIndex].x = attachmentUVs[iii]; ubi[vertexIndex].y = attachmentUVs[iii + 1]; if (x &lt; bmin.x) bmin.x = x; else if (x &gt; bmax.x) bmax.x = x; if (y &lt; bmin.y) bmin.y = y; else if (y &gt; bmax.y) bmax.y = y; vertexIndex++; &#125; &#125; &#125; &#125; &#125; this.meshBoundsMin = bmin; this.meshBoundsMax = bmax; this.meshBoundsThickness = lastSlotIndex * settings.zSpacing; int submeshInstructionCount = instruction.submeshInstructions.Count; submeshes.Count = submeshInstructionCount; // 添加三角形 if (updateTriangles) &#123; // Match submesh buffers count with submeshInstruction count. if (this.submeshes.Items.Length &lt; submeshInstructionCount) &#123; this.submeshes.Resize(submeshInstructionCount); for (int i = 0, n = submeshInstructionCount; i &lt; n; i++) &#123; var submeshBuffer = this.submeshes.Items[i]; if (submeshBuffer == null) this.submeshes.Items[i] = new ExposedList&lt;int&gt;(); else submeshBuffer.Clear(false); &#125; &#125; var submeshInstructionsItems = instruction.submeshInstructions.Items; // This relies on the resize above. // Fill the buffers. int attachmentFirstVertex = 0; for (int smbi = 0; smbi &lt; submeshInstructionCount; smbi++) &#123; var submeshInstruction = submeshInstructionsItems[smbi]; var currentSubmeshBuffer = this.submeshes.Items[smbi]; &#123; //submesh.Resize(submesh.rawTriangleCount); int newTriangleCount = submeshInstruction.rawTriangleCount; if (newTriangleCount &gt; currentSubmeshBuffer.Items.Length) Array.Resize(ref currentSubmeshBuffer.Items, newTriangleCount); else if (newTriangleCount &lt; currentSubmeshBuffer.Items.Length) &#123; // Zero the extra. var sbi = currentSubmeshBuffer.Items; for (int ei = newTriangleCount, nn = sbi.Length; ei &lt; nn; ei++) sbi[ei] = 0; &#125; currentSubmeshBuffer.Count = newTriangleCount; &#125; var tris = currentSubmeshBuffer.Items; int triangleIndex = 0; var skeleton = submeshInstruction.skeleton; var skeletonDrawOrderItems = skeleton.drawOrder.Items; for (int a = submeshInstruction.startSlot, endSlot = submeshInstruction.endSlot; a &lt; endSlot; a++) &#123; var attachment = skeletonDrawOrderItems[a].attachment; if (attachment is RegionAttachment) &#123; tris[triangleIndex] = attachmentFirstVertex; tris[triangleIndex + 1] = attachmentFirstVertex + 2; tris[triangleIndex + 2] = attachmentFirstVertex + 1; tris[triangleIndex + 3] = attachmentFirstVertex + 2; tris[triangleIndex + 4] = attachmentFirstVertex + 3; tris[triangleIndex + 5] = attachmentFirstVertex + 1; triangleIndex += 6; attachmentFirstVertex += 4; continue; &#125; var meshAttachment = attachment as MeshAttachment; if (meshAttachment != null) &#123; int[] attachmentTriangles = meshAttachment.triangles; for (int ii = 0, nn = attachmentTriangles.Length; ii &lt; nn; ii++, triangleIndex++) tris[triangleIndex] = attachmentFirstVertex + attachmentTriangles[ii]; attachmentFirstVertex += meshAttachment.worldVerticesLength &gt;&gt; 1; // length/2; &#125; &#125; &#125; &#125;&#125; 上述是构造Mesh方法。 SpineMesh.cs123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#region Step 3 : Transfer vertex and triangle data to UnityEngine.Meshpublic void FillVertexData (Mesh mesh) &#123; var vbi = vertexBuffer.Items; var ubi = uvBuffer.Items; var cbi = colorBuffer.Items; // Zero the extra. &#123; int listCount = vertexBuffer.Count; int arrayLength = vertexBuffer.Items.Length; var vector3zero = Vector3.zero; for (int i = listCount; i &lt; arrayLength; i++) vbi[i] = vector3zero; &#125; // Set the vertex buffer. &#123; mesh.vertices = vbi; mesh.uv = ubi; mesh.colors32 = cbi; if (float.IsInfinity(meshBoundsMin.x)) &#123; // meshBoundsMin.x == BoundsMinDefault // == doesn't work on float Infinity constants. mesh.bounds = new Bounds(); &#125; else &#123; //mesh.bounds = ArraysMeshGenerator.ToBounds(meshBoundsMin, meshBoundsMax); Vector2 halfSize = (meshBoundsMax - meshBoundsMin) * 0.5f; mesh.bounds = new Bounds &#123; center = (Vector3)(meshBoundsMin + halfSize), extents = new Vector3(halfSize.x, halfSize.y, meshBoundsThickness * 0.5f) &#125;; &#125; &#125; &#123; int vertexCount = this.vertexBuffer.Count; if (settings.addNormals) &#123; int oldLength = 0; if (normals == null) normals = new Vector3[vertexCount]; else oldLength = normals.Length; if (oldLength &lt; vertexCount) &#123; Array.Resize(ref this.normals, vertexCount); var localNormals = this.normals; for (int i = oldLength; i &lt; vertexCount; i++) localNormals[i] = Vector3.back; &#125; mesh.normals = this.normals; &#125; if (settings.tintBlack) &#123; if (uv2 != null) &#123; mesh.uv2 = this.uv2.Items; mesh.uv3 = this.uv3.Items; &#125; &#125; &#125;&#125;// 通过上面设置的三角形，在这里设置(lateUpdate)public void FillTrianglesSingle (Mesh mesh) &#123; mesh.SetTriangles(submeshes.Items[0].Items, 0, false);&#125; SkeletonRenderer.cs1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798// Generates a new UnityEngine.Mesh from the internal Skeleton.public virtual void LateUpdate () &#123; if (!valid) return; #if SPINE_OPTIONAL_RENDEROVERRIDE bool doMeshOverride = generateMeshOverride != null; if ((!meshRenderer.enabled) &amp;&amp; !doMeshOverride) return; #else const bool doMeshOverride = false; if (!meshRenderer.enabled) return; #endif var currentInstructions = this.currentInstructions; var workingSubmeshInstructions = currentInstructions.submeshInstructions; var currentSmartMesh = rendererBuffers.GetNextMesh(); // Double-buffer for performance. bool updateTriangles; if (singleSubmesh) &#123; // STEP 1. Determine a SmartMesh.Instruction. Split up instructions into submeshes. ============================================= MeshGenerator.GenerateSingleSubmeshInstruction(currentInstructions, skeleton, skeletonDataAsset.atlasAssets[0].materials[0]); // STEP 1.9. Post-process workingInstructions. ================================================================================== #if SPINE_OPTIONAL_MATERIALOVERRIDE if (customMaterialOverride.Count &gt; 0) // isCustomMaterialOverridePopulated MeshGenerator.TryReplaceMaterials(workingSubmeshInstructions, customMaterialOverride); #endif // STEP 2. Update vertex buffer based on verts from the attachments. =========================================================== meshGenerator.settings = new MeshGenerator.Settings &#123; pmaVertexColors = this.pmaVertexColors, zSpacing = this.zSpacing, useClipping = this.useClipping, tintBlack = this.tintBlack, calculateTangents = this.calculateTangents, addNormals = this.addNormals &#125;; meshGenerator.Begin(); updateTriangles = SkeletonRendererInstruction.GeometryNotEqual(currentInstructions, currentSmartMesh.instructionUsed); if (currentInstructions.hasActiveClipping) &#123; meshGenerator.AddSubmesh(workingSubmeshInstructions.Items[0], updateTriangles); &#125; else &#123; meshGenerator.BuildMeshWithArrays(currentInstructions, updateTriangles); &#125; &#125; else &#123; // STEP 1. Determine a SmartMesh.Instruction. Split up instructions into submeshes. ============================================= MeshGenerator.GenerateSkeletonRendererInstruction(currentInstructions, skeleton, customSlotMaterials, separatorSlots, doMeshOverride, this.immutableTriangles); // STEP 1.9. Post-process workingInstructions. ================================================================================== #if SPINE_OPTIONAL_MATERIALOVERRIDE if (customMaterialOverride.Count &gt; 0) // isCustomMaterialOverridePopulated MeshGenerator.TryReplaceMaterials(workingSubmeshInstructions, customMaterialOverride); #endif #if SPINE_OPTIONAL_RENDEROVERRIDE if (doMeshOverride) &#123; this.generateMeshOverride(currentInstructions); if (disableRenderingOnOverride) return; &#125; #endif updateTriangles = SkeletonRendererInstruction.GeometryNotEqual(currentInstructions, currentSmartMesh.instructionUsed); // STEP 2. Update vertex buffer based on verts from the attachments. =========================================================== meshGenerator.settings = new MeshGenerator.Settings &#123; pmaVertexColors = this.pmaVertexColors, zSpacing = this.zSpacing, useClipping = this.useClipping, tintBlack = this.tintBlack, calculateTangents = this.calculateTangents, addNormals = this.addNormals &#125;; meshGenerator.Begin(); if (currentInstructions.hasActiveClipping) meshGenerator.BuildMesh(currentInstructions, updateTriangles); else meshGenerator.BuildMeshWithArrays(currentInstructions, updateTriangles); &#125; if (OnPostProcessVertices != null) OnPostProcessVertices.Invoke(this.meshGenerator.Buffers); // STEP 3. Move the mesh data into a UnityEngine.Mesh =========================================================================== var currentMesh = currentSmartMesh.mesh; meshGenerator.FillVertexData(currentMesh); rendererBuffers.UpdateSharedMaterials(workingSubmeshInstructions); if (updateTriangles) &#123; // Check if the triangles should also be updated. meshGenerator.FillTriangles(currentMesh); meshRenderer.sharedMaterials = rendererBuffers.GetUpdatedSharedMaterialsArray(); &#125; else if (rendererBuffers.MaterialsChangedInLastUpdate()) &#123; meshRenderer.sharedMaterials = rendererBuffers.GetUpdatedSharedMaterialsArray(); &#125; meshGenerator.FillLateVertexData(currentMesh); // STEP 4. The UnityEngine.Mesh is ready. Set it as the MeshFilter's mesh. Store the instructions used for that mesh. =========== meshFilter.sharedMesh = currentMesh; currentSmartMesh.instructionUsed.Set(currentInstructions);&#125; 左图是默认的mesh，右图是设置关键帧的状态，三角形数量和顶点数量没有改变，只是改变的顶点位置。类似蒙皮的原理123456public static void DrawBoundingBoxes (Transform transform, Skeleton skeleton) &#123; foreach (var slot in skeleton.Slots) &#123; var bba = slot.Attachment as BoundingBoxAttachment; if (bba != null) SpineHandles.DrawBoundingBox(slot, bba, transform); &#125;&#125; 为什么写这个东西为了支持SkeletonAnimation在编辑状态下预览，最后查到的问题是，渲染没有刷新，然后在每帧做强制刷新EditorUtility.SetDirty(action.gameObject);]]></content>
      <categories>
        <category>Spine</category>
      </categories>
      <tags>
        <tag>Spine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非真实感渲染]]></title>
    <url>%2F2019%2F04%2F28%2FNon-photorealistic-rendering%2F</url>
    <content type="text"><![CDATA[卡通风格的渲染实现方式：基于色调的着色技术（tone-based shading）高光：一块块分界明显的纯色区域 渲染轮廓线 基于观察者角度和表面法线的轮廓线渲染。使用视角方向和表面法线的点乘结果得到轮廓线信息。优点可以在一个Pass中得到渲染结果，但效果不好。 过程式几何轮廓线渲染，使用两个Pass渲染。第一个Pass渲染背面的面片，第二个Pass渲染正面的面片，适用于绝大多数表面平滑的模型，缺点不适合类似立方体这样平整的模型。 基于图像处理的轮廓线渲染，利用边缘检测，缺点是深度和法线变化很小的轮廓无法被检测出来 基于轮廓边检测的轮廓线渲染，检查是否是轮廓边的公式：$(n_0 \cdot v &gt; 0) \neq (n_1 \cdot v &gt; 0)$其中，$n_0$和$n_1$分别表示两个相邻三角面片的法线，v是从视角到该边上任意顶点的方向。上述公式的本质在与检查两个相邻面片是否一个朝正面、一个朝背面。 添加高光Blinn-Phong使用法线点乘光照方向以及视角方向和的一半，再和另一个参数指数操作得到高光反射系数。代码如下：1float spec = pow(max(0, dot(normal, halfDir)), _Gloss) 对于卡通渲染需要的高光反射光照模型，我们同样需要计算normal和halfDir的点乘结果，但不同的是，我们把该值和一个阈值进行比较，如果小于该阈值，则高光反射系数为0，否则返回1。12float spec = dot(worldNormal, worldHalfDir);spec = step(threshold, spec); 但是，这种粗暴的判断方法会在高光区域的边界造成锯齿。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140Shader "Zenita/Non-photo"&#123; Properties &#123; _Color ("Color Tint", Color) = (1,1,1,1) _MainTex("Main Tex", 2D) = "white"&#123;&#125; _Ramp ("Ramp Texture", 2D) = "white" &#123;&#125; // 漫反射色调的渐变纹理 _Outline("Outline", Range(0, 1)) = 0.1 // 用于控制轮廓线宽度 _OutlineColor ("Outline Color", Color) = (0,0,0,1) // 轮廓线颜色 _Specular("Specular", Color)=(1,1,1,1) // 高光反射颜色 _SpecularScale("Specular Scale", Range(0, 0.1)) = 0.01 // 高光反射的阈值 &#125; SubShader &#123; Tags &#123; "RenderType"="Opaque" &#125; LOD 100 Pass &#123; NAME "OUTLINE" Cull Front CGPROGRAM #pragma vertex vert #pragma fragment frag // make fog work #pragma multi_compile_fog #include "UnityCG.cginc" #include "Lighting.cginc" struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal : NORMAL; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; float3 normal : NORMAL; &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _Ramp; float4 _Ramp_ST; fixed4 _Specular; float _Gloss; float _Outline; float4 _OutlineColor; v2f vert (appdata v) &#123; v2f o; o.vertex = mul(UNITY_MATRIX_MV, v.vertex); float3 normal = mul((float3x3)UNITY_MATRIX_IT_MV, v.normal); normal.z = -0.5; o.vertex = o.vertex + float4(normalize(normal), 0) * _Outline; o.vertex = mul(UNITY_MATRIX_P, o.vertex); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; return fixed4(_OutlineColor.rgb, 1); &#125; ENDCG &#125; Pass &#123; Tags &#123;"LightMode"="ForwardBase"&#125; Cull Back CGPROGRAM #pragma vertex vert #pragma fragment frag #include "UnityCG.cginc" #include "Lighting.cginc" #include "AutoLight.cginc" #pragma multi_compile_fwdbase struct a2v &#123; float4 vertex : POSITION; float3 texcoord : TEXCOORD0; float3 normal : NORMAL; &#125;; struct v2f &#123; float4 pos : POSITION; float2 uv : TEXCOORD0; float3 worldNormal : TEXCOORD1; float3 worldPos : TEXCOORD2; SHADOW_COORDS(3) &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _Ramp; float4 _Ramp_ST; fixed4 _Specular; float _Gloss; float _Outline; float4 _OutlineColor; float4 _Color; float _SpecularScale; v2f vert (a2v v)&#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.uv = TRANSFORM_TEX(v.texcoord, _MainTex); o.worldNormal = mul(v.normal, (float3x3)unity_WorldToObject); o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz; TRANSFER_SHADOW(o); return o; &#125; float4 frag(v2f i) : SV_Target&#123; fixed3 worldNormal = normalize(i.worldNormal); fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos)); fixed3 worldViewDir = normalize(UnityWorldSpaceViewDir(i.worldPos)); fixed3 worldHalfDir = normalize(worldLightDir + worldViewDir); fixed4 c = tex2D(_MainTex, i.uv); fixed3 albedo = c.rgb * _Color.rgb; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo; UNITY_LIGHT_ATTENUATION(atten, i, i.worldPos); fixed diff = dot(worldNormal, worldLightDir); diff = (diff*0.5+0.5)*atten; fixed3 diffuse = _LightColor0.rgb * albedo * tex2D(_Ramp, float2(diff, diff)).rgb; fixed spec = dot(worldNormal, worldHalfDir); fixed w = fwidth(spec) * 2.0; fixed3 specular = _Specular.rgb * lerp(0, 1, smoothstep(-w, w, spec + _SpecularScale - 1)) * step(0.0001, _SpecularScale); return fixed4(ambient + diffuse + specular, 1.0); &#125; ENDCG &#125; &#125;&#125; 抗锯齿处理：1specular = lerp(0,1,smoothstep(-0.0001, 0.0001, specular - _Threshold)); 首先，我们计算了光照模型中需要的各个方向矢量，并对它们进行了归一化处理。然后我们计算了材质的反射率albedo和环境光照ambient。接着，我们使用内置的UNITY_LIGHT_ATTENUATION宏来计算当前世界坐标下的阴影值。随后，我们计算了半兰伯特漫反射系数，并和阴影值相乘得到最终的漫反射系数。我们使用这个漫反射系数对渐变纹理_Ramp进行采样，并将结果和材质的反射率、光照颜色颜色相乘，作为最后的漫反射光照。高光反射使用fwidth对高光区域的边界进行抗锯齿处理，并将计算得到的高光反射系数和高光反射颜色相乘，得到高光反射的光照部分。值得注意的是，我们在最后还使用了step(0.0001,_SpecularScale)，这是为了在_SpecularScale为0时，可以完全消除高光反射的光照。最后，返回环境光照、漫反射光照和高光反射光照叠加的结果。最后，我们为Shader设置了合适的Fallback:1Fallback "Diffuse" 这对产生正确的阴影投射效果很重要。 素描风格的渲染另一个非常流行的非真实感渲染是素描风格的渲染。1234567891011Properties&#123; _Color("Color Tint", Color)=(1,1,1,1) _TitleFactor("Tile Factor", Float) = 1 _Outline("Outline", Range(0, 1))=0.1 _Hatch0("Hatch 0", 2D)="white"&#123;&#125; _Hatch1("Hatch 1", 2D)="white"&#123;&#125; _Hatch2("Hatch 2", 2D)="white"&#123;&#125; _Hatch3("Hatch 3", 2D)="white"&#123;&#125; _Hatch4("Hatch 4", 2D)="white"&#123;&#125; _Hatch5("Hatch 5", 2D)="white"&#123;&#125;&#125; 其中，_Color是用于控制模型颜色的属性。_TileFactor是纹理的平铺系数，_TileFactor越大，模型上的素描线条越密。_Hatch0至_Hatch5对应了渲染时使用的6张素描纹理，它们的线条密度依次增大。由于素描风格往往也需要在物体周围渲染轮廓线，因此我们直接使用上面的渲染轮廓线的Pass：12345SubShader&#123; Tags&#123;"RenderType"="Opaque" "Queue"="Geometry"&#125; UsePass "Zentia/Toon Shading/OUTLINE"&#125; 我们使用UsePass命令调用了轮廓线渲染的Pass下面，我们需要定义光照模型所在的Pass。为了能够正确获取各个光照变量，我们设置了Pass的标签和相关的编译指令：12345678Pass &#123; Tags &#123;"LightMode"="ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase&#125; 由于我们需要在顶点着色器中计算6张纹理的混合权重，我们首先需要在v2f结构体中添加相应的变量：1234struct &#123; &#125;;]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[commandbuffer]]></title>
    <url>%2F2019%2F04%2F27%2Fcommandbuffer%2F</url>
    <content type="text"><![CDATA[CommandBuffer 上图是摄像机渲染的两个路径。这两种通用的方法，能很好的解决常用物体的渲染的光影效果。但一些特效会需要在此基础上进行改动。CommandBuffer可以在上图任意的绿点插入式渲染。为了解决此问题常规的方法是使用后效。但是这种方法操作麻烦，而且性能不是很好。 CommandBuffer类的常规操作1234567891011// 声明CommandBuffer commandBuffer = new CommandBuffer();// 设置渲染目标commandBuffer.SetRenderTarget(renderTexture);commandBuffer.ClearRenderTarget(true, true, Color.black);// 设置渲染数据commandBuffer.DrawRenderer(targetRenderer, material);// 将commandBuffer的渲染进行后处理commandBuffer.Bilt(renderTexture,DestTexture,material);// 向主camera中插入CommandBuffercommandBuffer.AddCommandBuffer(CameraEvent.BeforeForwardOpaque,commandBuffer); 描边思路实现]]></content>
      <categories>
        <category>Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移动平台的AlphaTest效率问题]]></title>
    <url>%2F2019%2F04%2F25%2Falphatest%2F</url>
    <content type="text"><![CDATA[为什么AlphaTest应该比AlphaBlend更慢？AlphaTest在渲染时实际上和不透明物体类型，与其说是一种“透明物体”，不如说是一种“可以在上面打洞的不透明物体”。在Unity里，也可以允许AlpahTest和Opaque混合绘制。光照，是否可接受投影，在渲染管线的位置，AlphaTest的物体都是完全按Opaque处理的。AlphaTest实际上就是一种特殊的Opaque，只是允许在像素阶段discard像素，让某些像素不绘制到屏幕上，从这个角度看，甚至还应该比Opaque更节约性能猜对。而AlphaBlend则是纯粹的透明物体。透明物体多=效率低也是常见的“经验结论”，主要原因是ALphaBlend会在Blend的时候读取屏幕缓冲区，以及必须重复计算每个像素的多层内容，高overdraw会很快烧光fillrate。 但为什么会有人说移动平台AlphaTest比AlphaBlend更慢呢？是因为移动平台上广泛使用了early-DT（提前的Depth Test）只做移动平台的会产生一种误解：认为先画了一个物体，在某个区域写上了深度，然后在之后再画一个深度比它低的物体，因为被遮挡所以画不上去，那GPU就不应该花时间去画然而事实上，之前的GPU并没有那么“聪明”。这个技术本身就是early-DT。虽然只有苹果自己在吹，实际上所有移动平台的GPU都使用这个技术。也只有使用了这个技术的GPU，才能实现刚才说的这种“绘制优化”。而其他的GPU由于没有这个技术，DepthTest阶段都是在Frag Shader之后的（也就是later-DT），因此屏幕内的物体并不存在遮挡剔除。PC和移动平台拥有ealy-DT，它的功能和Deferred Shading的功能部分重叠的，所以才不建议使用Deferred Shading，因为获得的收益很可能会反倒不如Deffed技术新增的成本。了解了early-DT和later-DT后，还需要在谈一个东西： 并行化和串行化硬件进行计算时，并不是一个像素一个像素地执行，而是同时多个像素同时进行，这就是并行化。但是在这个并行化的多个线程中，他们并不总能保持齐头并进，在Frag阶段，总会由于各种原因导致他们结束的时间点出现不一致，有可能出现先画的像素反而后绘制的情况。并不是所有的像素都按要求顺序完成，但是假如我们强行设置了他们的绘制顺序，GPU也必须遵守，所以只能这样：当然，在这个Wait的阶段如果GPU能够找到什么别的不需要操作Frame Buffer的工作，它也不会闲着，但假如确实找不到任何“可以干的活”，它也就只能闲着了。这就是串行化，显然，会造成性能下降。然而，GPU其实也没有这么蠢。一个显而易见的优化是：其实我只需要保证绘入Frame Buffer时的顺序是一致的，那么我把Frag Shader的结果堆起来放在一个队列里，保证这个队列顺序是一致的，那前面Frag Shader什么时候结束也就无所谓了。在later-DT的时候确实是这样的：很容易被忽略掉的一点是，这个Depth Test过程，其实是一个读+写的过程，不透明物体在读取Depth之后，还需要马上把自己的Depth写回去，这样上一个像素把Depth写进去后，下一个才能读出来，所以Depth Test的顺序同样必须争取的。所以换成early-DT之后虽然Frame Depth和Frame Color Buffer操作的时间点被错开了，但是分别的顺序还是一致的，并没有问题。那么AlphaTest到底用的是later-DT还是early-DT呢？ PowerVR目前和别的GPU的主要区别是：它在TBR的DT阶段多了一次寻址最顶端三角形的操作（别人是TBR，它是TBDR）。在全部移动平台上，有一种可能性，AlpahtTest只走later-DT，导致它自身无法被“遮挡（而AlphaBlend可以）”，这是效率比AlphaBlend低的主要原因。所以，只要AlphaTest较少被遮挡，劣势就并不存在，反而因为AlphaTest可以“遮挡”其它物体的原因，导致AlphaTest效率更高（但这必须让AlphaTest先于不透明物体绘制）。]]></content>
      <categories>
        <category>Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Photon-TrueSync]]></title>
    <url>%2F2019%2F04%2F24%2FPhoton-TrueSync%2F</url>
    <content type="text"><![CDATA[git仓库：https://github.com/zentia/TrueSync优点： 支持回滚 支持UDP 完整的解决方案 缺点： lockstep模式，目前不太需要 不适合扩展ECS模型 代码整体性能应该不是最优，不过可以调整 封装的比较完整，但是要适配到项目中，可能会对项目改的东西比较多。 反射和Lambda使用的情况比较多 1234567public enum ConnectionProtocol : byte&#123; Udp = 0, Tcp = 1, WebSocket = 4, WebSocketSecure = 5,&#125; 貌似都支持，但是我们不需要这么多。或者说我们PVP部分和大厅部分都走一套。目前不考虑大厅的设计。 TrueSyncConfig帧同步配置 TrueSyncManager123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244管理、驱动帧同步 //同步全局配置static TrueSyncConfig TrueSyncGlobalConfig;// 配置static TrueSyncConfig Config;TrueSyncConfig ActiveConfig;// 锁帧private AbstractLockstep lockstep;// 协程调度CoroutineScheduler scheduler;// 玩家预设列表GameObject[] playerPrefabs;// private Dictionary&lt;int, List&lt;GameObject&gt;&gt; gameOjectsSafeMap = new Dictionary&lt;int, List&lt;GameObject&gt;&gt;();// 非哪个玩家拥有的行为，叫做普通行为List&lt;TrueSyncManagedBehaviour&gt; generalBehaviours = new List&lt;TrueSyncManagedBehaviour&gt;();// 对应玩家所拥有的行为Dictionary&lt;byte, List&lt;TrueSyncManagedBehaviour&gt;&gt; behaviorsByPlayer;// 一个临时缓存池，用在后面注册行为的时候占存。在帧更新的时候OnStepUpdate调用CheckQueuedBehaviours。分配玩家拥有者和调OnSyncedStart。然后就清理该列表List&lt;TrueSyncManagedBehaviour&gt; queuedBehaviours = new List&lt;TrueSyncManagedBehaviour&gt;();// 保存了所有行为的字典Dictionary&lt;ITrueSyncBehaviour, TrueSyncManagedBehaviour&gt; mapBehaviorToManagedBehavior = new Dictionary&lt;ITrueSyncBehaviour, TrueSyncManagedBehaviour&gt;();// 时间FP time = 0;static FP Time;// 帧时间static FP DeltaTime;// 帧static int Ticks;static int LastSafeTick;// 重力static TSVector Gravity;// 玩家列表static List&lt;TSPlayerInfo&gt; Players；// 本地玩家static TSPlayerInfo LocalPlayer；// 启动状态, 在Update决定什么时候运行lockstep.RunSimulation(true);private enum StartState &#123; BEHAVIOR_INITIALIZED, FIRST_UPDATE, STARTED &#125;;private StartState startState;void Awake() &#123; TrueSyncConfig currentConfig = ActiveConfig; lockedTimeStep = currentConfig.lockedTimeStep; // 初始化状态跟踪 StateTracker.Init(currentConfig.rollbackWindow); // 初始化随机数 TSRandom.Init(); // 初始化物理管理器 if (currentConfig.physics2DEnabled || currentConfig.physics3DEnabled) &#123; PhysicsManager.New(currentConfig); PhysicsManager.instance.LockedTimeStep = lockedTimeStep; PhysicsManager.instance.Init(); &#125; // 跟踪 时间 StateTracker.AddTracking(this, "time");&#125;void Start() 做了什么?设置instance = this;设置Application.runInBackground = true;初始化通信PhotonTrueSyncCommunicator 创建lockstep检测是否是录像模式, 如果是就加载录像如果配置了显示TrueSyncStats，那就初始化创建协程调度 scheduler = new CoroutineScheduler(lockstep);非录像模式下 初始化帧的玩家列表初始化场景中现有的帧同步行为 TrueSyncBehaviour实例化玩家预设playerPrefabs和同步其行为的拥有者 initBehaviors初始化行为拥有者，并分配给对于玩家。没有继承TrueSyncBehaviour的就继续放到普通行为列表。initGeneralBehaviors添加物理对象移除监听 PhysicsManager.instance.OnRemoveBody(OnRemovedRigidBody);设置启动状态 startState = StartState.BEHAVIOR_INITIALIZED;// 创建ITrueSyncBehaviour的TrueSyncManagedBehaviour，是对ITrueSyncBehaviour的一层包装private TrueSyncManagedBehaviour NewManagedBehavior(ITrueSyncBehaviour trueSyncBehavior)// 初始化玩家预设和他们的同步行为。行为设置拥有者，并其添加到对应玩家的行为字典里behaviorsByPlayerprivate void initBehaviors()// 对行为列表分配拥有者， 在Start(), CheckQueuedBehaviours()里调用private void initGeneralBehaviors(IEnumerable&lt;TrueSyncManagedBehaviour&gt; behaviours, bool realOwnerId)// 将注册行为占存列表列queuedBehaviours的行为调initGeneralBehaviors分配拥有者。调SetGameInfo和OnSyncedStart两个方法private void CheckQueuedBehaviours()// 只做一件事，检测启动状态，如果是第一次启动就调lockstep.RunSimulation(true);void Update()// 在帧同步调暂停后 恢复继续运行。instance.lockstep.RunSimulation(false);public static void RunSimulation()// 暂停游戏 调instance.lockstep.PauseSimulation();public static void PauseSimulation() // 结束游戏 调instance.lockstep.EndSimulation();public static void EndSimulation()// 更新一次协程， 主要是物理里调用了。默认的协程更新在 帧更新里OnStepUpdatepublic static void UpdateCoroutines()// 添加一个协程public static void SyncedStartCoroutine(IEnumerator coroutine)// 实例化一个预设// 先势力化一个GameObject// 非录像模式将该对象添加到帧记录里。AddGameObjectOnSafeMap(go);// 将该对象的帧行为添加到queuedBehaviours，等待帧更新的时候分配拥有者和调度初始化方法// 调该对象上组件的初始化方法（ICollider注册到物理管理器里PhysicsManager, TSTransform, TSTransform2D）。InitializeGameObjectpublic static GameObject SyncedInstantiate(GameObject prefab)public static GameObject SyncedInstantiate(GameObject prefab, TSVector position, TSQuaternion rotation)public static GameObject SyncedInstantiate(GameObject prefab, TSVector2 position, TSQuaternion rotation)// 将势力化的GameObject添加到当前的帧+1列表里private static void AddGameObjectOnSafeMap(GameObject go)// 在帧更新OnStepUpdate的时候掉, 清理销毁掉当前 Ticks + 1里的GameObject。猜测估计是帧回滚的时候把预处理的对象销毁private static void CheckGameObjectsSafeMap()// 调该对象上组件的初始化方法（ICollider注册到物理管理器里PhysicsManager, TSTransform, TSTransform2D）private static void InitializeGameObject(GameObject go, TSVector position, TSQuaternion rotation)// 销毁GameObject// 第一步调SyncedDisableBehaviour, 停止更新该对象上的ITrueSyncBehaviour// 第二步调 TSCollider和TSCollider2D 调 DestroyTSRigidBodypublic static void SyncedDestroy(GameObject gameObject)// 将GameObject的ITrueSyncBehaviour的disabled设置为true, 停止对他调帧更新方法 OnSyncedInput，OnSyncUpdate。public static void SyncedDisableBehaviour(GameObject gameObject)// 设置 tsColliderGO.gameObject.SetActive(false);// 将物理对象从lockstep销毁 instance.lockstep.Destroy(body);private static void DestroyTSRigidBody(GameObject tsColliderGO, IBody body)// 注册ITrueSyncBehaviour, 将他添加到queuedBehaviours。在下次CheckQueuedBehaviours的时候，也就是在下次帧更新的时候OnStepUpdate，对他分配拥有者，调SetGameInfo和OnSyncedStart两个方法public static void RegisterITrueSyncBehaviour(ITrueSyncBehaviour trueSyncBehaviour)// 注册游戏是否继续的委托。 调委托会返回一个bool值。 true游戏可以继续运行。lockstep里会调该方法检测是否可以继续CheckGameIsReady（）public static void RegisterIsReadyChecker(TrueSyncIsReady IsReadyChecker)// 移除玩家// 第一步将该玩家的 行为全部禁止帧更新behaviorsByPlayer[(byte)playerId],disabled = true;// 第二步将这些行为的GameObject上拥有TSCollider、TSCollider2D的物理全部掉DestroyTSRigidBodypublic static void RemovePlayer(int playerId)// 检测帧更新时间，时间到就调instance.scheduler.UpdateAllCoroutines();和lockstep.Update();// lockedTimeStep，帧同步一帧的时间// JitterTimeFactor, 为了避免浮动点数比较造成误差。if (tsDeltaTime &gt;= (lockedTimeStep - JitterTimeFactor))// tsDeltaTime, 用的时间还是用Unity的 tsDeltaTime += UnityEngine.Time.deltaTime;void FixedUpdate()// 里面创建一个输入数据结构 return new InputData(); 是在lockstep创建的时候传这个方法给他InputDataBase ProvideInputData()// 这个方法会调本地玩家所有帧行为的OnSyncedInput方法// 这这个方法生命周期内 TrueSyncInput.CurrentInputData = playerInputData// 是在lockstep创建的时候传这个方法给他void GetLocalData(InputDataBase playerInputData)// 帧更新// 添加当前时间 time += lockedTimeStep;// 非录像模式， 检测GameObject CheckGameObjectsSafeMap();// 遍历generalBehaviours普通行为列表，调行为的OnPreSyncedUpdate()。还会调协程更新instance.scheduler.UpdateAllCoroutines();// 遍历allInputData,和对应玩家的行为列表behaviorsByPlayer。 调行为的OnPreSyncedUpdate()。还会调协程更新instance.scheduler.UpdateAllCoroutines();// 遍历generalBehaviours普通行为列表，调行为的OnSyncedUpdate()。还会调协程更新instance.scheduler.UpdateAllCoroutines();// 遍历allInputData,和对应玩家的行为列表behaviorsByPlayer。 调行为的OnSyncedUpdate()。还会调协程更新instance.scheduler.UpdateAllCoroutines();// 检测占存行为列表CheckQueuedBehaviours（）。给他们分配拥有者和调同步开始方法// 是在lockstep创建的时候传这个方法给他void OnStepUpdate(List&lt;InputDataBase&gt; allInputData)// 玩家离线消息处理// 调TrueSyncManagedBehaviour.OnPlayerDisconnection(generalBehaviours, behaviorsByPlayer, playerId);// 是在lockstep创建的时候传这个方法给他 void OnPlayerDisconnection(byte playerId)// 游戏开始消息处理// 是在lockstep创建的时候传这个方法给他 void OnGameStarted() &#123; TrueSyncManagedBehaviour.OnGameStarted(generalBehaviours, behaviorsByPlayer); instance.scheduler.UpdateAllCoroutines(); CheckQueuedBehaviours(); &#125;// 游戏暂停消息处理// 是在lockstep创建的时候传这个方法给他 void OnGamePaused() &#123; TrueSyncManagedBehaviour.OnGamePaused(generalBehaviours, behaviorsByPlayer); instance.scheduler.UpdateAllCoroutines(); &#125;// 游戏继续消息处理 void OnGameUnPaused() &#123; TrueSyncManagedBehaviour.OnGameUnPaused(generalBehaviours, behaviorsByPlayer); instance.scheduler.UpdateAllCoroutines(); &#125;// 游戏结束消息处理 void OnGameEnded() &#123; TrueSyncManagedBehaviour.OnGameEnded(generalBehaviours, behaviorsByPlayer); instance.scheduler.UpdateAllCoroutines(); &#125;// 移除物理对象事件处理// 会移除该对象的GameObject上所有同步行为 调RemoveFromTSMBList// PhysicsManager.instance.OnRemoveBody(OnRemovedRigidBody); 在这里注册private void OnRemovedRigidBody(IBody body) // 从tsmbList列表中，移除behavioursprivate void RemoveFromTSMBList(List&lt;TrueSyncManagedBehaviour&gt; tsmbList, List&lt;TrueSyncBehaviour&gt; behaviours)// 清理// 清理对象池 ResourcePool.CleanUpAll();// 清理状态跟踪 StateTracker.CleanUp();// 去除实例变量引用 instance = null;public static void CleanUp()// Unity的消息。退出应用 void OnApplicationQuit() &#123; EndSimulation(); &#125; 支持lockstep模式，但是目前我们是不会用到这个的。并且不是可配置的，改造起来可能会比较麻烦一些。 ICommunicator12345678910public interface ICommunicator&#123; // 通信器，在TrueSync管理器中创建 // 往返时间 int RoundTripTime(); // 操作时间 void OpRaiseEvent(byte eventCode, object message, bool reliable, int[] toPlayers); // 添加监听 void AddEventListener(OnEventReceived onEventReceived); &#125; PhotonTrueSyncCommunicator123456789帧同步 通信器， 实现ICommunicator接口// 往返时间int RoundTripTime();// 操作时间void OpRaiseEvent(byte eventCode, object message, bool reliable, int[] toPlayers);// 添加监听void AddEventListener(OnEventReceived onEventReceived); OnEventReceived123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354代理事件， 接收消息// byte eventCode 消息编号// object content 消息内容private void OnEventDataReceived(byte eventCode, object content)&#123; if (eventCode == 0xc7) &#123; byte[] data = content as byte[]; SyncedData[] dataArray = SyncedData.Decode(data); if (dataArray.Length &gt; 0) &#123; TSPlayer player = this.players[dataArray[0].inputData.ownerID]; if (!player.dropped) &#123; this.OnSyncedDataReceived(player, dataArray); if ((dataArray[0].dropPlayer &amp;&amp; (player.ID != localPlayer.ID)) &amp;&amp; !this.players[dataArray[0].dropFromPlayerId].dropped) &#123; player.dropCount++; &#125; &#125; &#125; &#125; else if (eventCode == 0xc6) &#123; byte[] infoBytes = content as byte[]; OnChecksumReceived(SyncedInfo.Decode(infoBytes)); &#125; else if (eventCode == 0xc5) &#123; byte[] buffer3 = content as byte[]; if (buffer3.Length &gt; 0) &#123; if (buffer3[0] == 0) &#123; this.Pause(); &#125; else if (buffer3[0] == 1) &#123; this.Run(); &#125; else if (buffer3[0] == 3) &#123; this.End(); &#125; &#125; &#125; else if (eventCode == 0xc4) &#123; byte[] buffer4 = content as byte[]; SyncedInfo info = SyncedInfo.Decode(buffer4); players[info.playerId].sentSyncedStart = true; &#125;&#125; 接口的实现有一次GC，并未实测 TrueSyncBehaviour1234567891011121314151617帧同步行为，继承自 MonoBehaviour, 实现接口 ITrueSyncBehaviourGamePlay, ITrueSyncBehaviourCallbacks// 该行为的拥有者玩家public TSPlayerInfo owner;// 本地玩家，相当于快捷访问本地玩家，此处会被序列化，放到项目中应该要去掉public TSPlayerInfo localOwner;// 快捷访问TSTransform tsTransformTSTransform2D tsTransform2DTSRigidBody tsRigidBodyTSRigidBody2D tsRigidBody2DTSCollider tsColliderTSCollider2D tsCollider2D// 基本上就是上面这些属性，实现的接口都是空的没有写业务逻辑，在Mono上层封装了一层，基于多组件的方式，不利于ECS扩展 TrueSyncManagedBehaviour12345678910帧同步行为管理器，实现接口 ITrueSyncBehaviourGamePlay, ITrueSyncBehaviour, ITrueSyncBehaviourCallbacks主要是包装了TrueSyncBehaviour/ITrueSyncBehaviour, 实现的接口方法直接掉TrueSyncBehaviour的放方法，TrueSyncBehaviour的OnSyncedStartLocalPlayer 方法该行为是本地用户时才调// 有一个属性, true是，不会参与帧更新 [AddTracking] public bool disabled;后面就是一些全局静态方法，用管理处理列表的事件管理主要是管理这个的。 CoroutineScheduler1234协程调用在TrueSyncManager.SyncedStartCoroutine 调 StartCoroutine(IEnumerator coroutine) 启动一个协程在TrueSyncManager驱动UpdateAllCorutines()内部协程使用链表来维护，但是链表操作会有GC，比如Remove的时候直接舍弃了，并没有使用池处理 ITrueSyncBehaviour1234接口 帧同步行为就只有一个方法// 设置游戏信息 (本地玩家， 玩家数量)void SetGameInfo(TSPlayerInfo localOwner, int numberOfPlayers); ITrueSyncBehaviourGamePlay123456789接口 玩家操作帧同步行为, 继承自ITrueSyncBehaviour，Mono上层的封装接口// 同步 玩家输入操作void OnSyncedInput();// 同步 读取玩家操作void OnSyncedUpdate();void OnPreSyncedUpdate(); ITrueSyncBehaviourCallbacks12345678910111213141516171819接口 回调同步行为, 继承自ITrueSyncBehaviourTrueSyncBehaviour实现：表示在连接到游戏的每台机器上模拟的每个玩家的行为。// 开始void OnSyncedStart();// 开始 -- 只调本地玩家的void OnSyncedStartLocalPlayer();// 游戏暂停void OnGamePaused();// 游戏继续void OnGameUnPaused();// 游戏结束的时候调用void OnGameEnded();// 有玩家离线时调用void OnPlayerDisconnection(int playerId); TSRandom123456随机数http://www.codeproject.com/Articles/164087/Random-Number-Generationhttps://github.com/ihaiucom/learn.PhotonTrueSync/blob/master/PhotonGame/Assets/TrueSync/Engine/Math/TSRandom.cs原理是，传一个因素进去，然后里面生成N数量的数组。每个数有一个公式计算来生成。所以传相同的因素生成的结果是一样的。获取随机数的时候根据当前索引mti依次读取数组里面的数。当mti大于N时，内部重新生成默认因素是5489U Random-Number-GenerationTrueSync/Engine/Math/TSRandom.cs StateTracker.TrackedInfo123456状态跟踪信息， 用来保存对象引用，和对象的成员属性信息MemberInfointernal class TrackedInfo&#123; public object relatedObj; // 保存对象 public MemberInfo propInfo; // 对象的成员属性信息&#125; 效率略低 StateTracker.State12345678910111213141516171819202122232425262728293031323334353637383940414243// 状态跟踪信息， 持有TrackedInfo跟踪信息internal class State&#123; private StateTracker.TrackedInfo trackedInfo; private object value; public void SetInfo(StateTracker.TrackedInfo trackedInfo) &#123; this.trackedInfo = trackedInfo; this.SaveValue(); &#125; // 保存值到value变量 public void SaveValue() &#123; object obj = this.trackedInfo.propInfo.GetValue(this.trackedInfo.relatedObj); if (obj != null) &#123; if (obj.GetType().IsArray) &#123; this.value = (object) Array.CreateInstance(obj.GetType().GetElementType(), ((Array) obj).Length); Array.Copy((Array) obj, (Array) this.value, ((Array) obj).Length); &#125; else this.value = obj; &#125; else this.value = (object) null; &#125; // 将保存的值用反射赋值给对象 public void RestoreValue() &#123; if (this.trackedInfo.relatedObj == null) return; if (this.value is Array) &#123; Array instance = Array.CreateInstance(this.value.GetType().GetElementType(), ((Array) this.value).Length); Array.Copy((Array) this.value, instance, ((Array) this.value).Length); this.trackedInfo.propInfo.SetValue(this.trackedInfo.relatedObj, (object) instance); &#125; else this.trackedInfo.propInfo.SetValue(this.trackedInfo.relatedObj, this.value); &#125;&#125; StateTracker12345678910111213141516171819// 状态跟踪// TSRandom 用到StateTracker.AddTracking(r, "mt"); // 字符串拼接StateTracker.AddTracking(r, "mti");//TrueSyncManager 用到StateTracker.AddTracking(this, "time");//TSTransform 用到 配合 [AddTracking] Attribute 使用, StateTracker.AddTracking(object obj)通过反射获取obj的成员变量StateTracker.AddTracking(this);// TrueSyncManagedBehaviour 用到StateTracker.AddTracking(this);StateTracker.AddTracking(trueSyncBehavior);// 这个是核心了， 里面保存了 rollbackWindow 数量的列表，AddTracking的时候回把StateTracker.State 添加到所有列表里// SaveState 的时候就保存GenericBufferWindow当前列表的, 保存完后就GenericBufferWindow的索引移动下一个// RestoreState 从GenericBufferWindow当前的列表把值恢复StateTracker.instance.states = new GenericBufferWindow&lt;List&lt;StateTracker.State&gt;&gt;(rollbackWindow); GenericBufferWindow12345678// 通用缓存窗口，和list相比多了一个前驱，需要自己调用Resize(会有GC消耗)，是一个泛型数据结构// StateTracker 用到StateTracker.instance.states = new GenericBufferWindow&lt;List&lt;StateTracker.State&gt;&gt;(rollbackWindow);// CompoundStats 用到this.bufferStats = new GenericBufferWindow&lt;Stats&gt;(10);// AbstractLockstep 用到 this.bufferSyncedInfo = new GenericBufferWindow&lt;SyncedInfo&gt;(3);// 构造方法： 会创建一个T[size] 的数组buffer，并且实例化T ResourcePool 对象池123456789101112131415161718//ResourcePool 内部使用Stack实现//是一个抽象对象池,他有一个静态对象池列表。他管理所有对象池的清理CleanUpAll();ResourcePool&lt;T&gt; 是ResourcePool派生类。里面有一个对象栈存储空闲的对象。// 还回对象GiveBack(T obj)// 获取对象, 如果T是ResourcePoolItem的派生类就会调对象的CleanUp()方法T GetNew()// 实例化对象T NewInstance()ResourcePoolItem 是对象池对象接口，实现该接口的对象在获取对象时会调CleanUp()方法【使用】internal class ResourcePoolListSyncedData : ResourcePool&lt;List&lt;SyncedData&gt;&gt;internal class ResourcePoolStateTrackerState : ResourcePool&lt;StateTracker.State&gt;internal class ResourcePoolSyncedData : ResourcePool&lt;SyncedData&gt; SerializableDictionary1234567891011public class SerializableDictionary&lt;TKey, TValue&gt; : Dictionary&lt;TKey, TValue&gt;, ISerializationCallbackReceiver其实就是一个Dictionary, 然后实现了Unity的接口ISerializationCallbackReceiver。OnBeforeSerialize、OnAfterDeserialize派生类public class SerializableDictionaryByteByte : SerializableDictionary&lt;byte, byte&gt;public class SerializableDictionaryByteByteArray : SerializableDictionary&lt;byte, byte[]&gt;public class SerializableDictionaryByteInt : SerializableDictionary&lt;byte, int&gt;public class SerializableDictionaryBytePlayer : SerializableDictionary&lt;byte, TSPlayer&gt;public class SerializableDictionaryByteString : SerializableDictionary&lt;byte, string&gt;public class SerializableDictionaryIntSyncedData : SerializableDictionary&lt;int, SyncedData&gt; InputData123456789拥有各个基本类型序列化字典序列化和解析都是对这些解绑类型字典每个值的序列化:key, valueType, value数组的: key, valueType, length, value[]字符串的用char[] 也就是数组然后有各个类型的AddXX和GetXX SyncedInfo12345678910111213141516171819同步信息，保存了3个属性 // 玩家ID public byte playerId; // 帧 public int tick; // 校验码 public string checksum;2 个方法// 序列化public static byte[] Encode(SyncedInfo info)// 解析public static SyncedInfo Decode(byte[] infoBytes) SyncedData1234567891011121314151617181920// 同步数据// 主要就序列化下面两个方法的数据public void GetEncodedHeader(List bytes)&#123; // 帧 Utils.GetBytes(this.tick, bytes); // 拥有者玩家ID bytes.Add(this.inputData.ownerID); // 从哪个玩家掉线 bytes.Add(this.dropFromPlayerId); // 是否掉线 bytes.Add(this.dropPlayer ? 1 : 0);&#125;public void GetEncodedActions(List bytes)&#123; this.inputData.Serialize(bytes);&#125; TSPlayerInfo123456789//玩家信息,保存2个属性// 玩家ID[SerializeField]internal byte id;// 玩家名称[SerializeField]internal string name; TSPlayer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174// 玩家// 玩家信息[SerializeField]public TSPlayerInfo playerInfo;// 掉线次数[NonSerialized]public int dropCount;//是否掉线[NonSerialized]public bool dropped;// 开始发送同步数据[NonSerialized]public bool sentSyncedStart;// 保存玩家整个战斗的操作同步数据, 他是一个字典SerializableDictionary&lt;int, SyncedData&gt;[SerializeField]internal SerializableDictionaryIntSyncedData controls;// 最后一次 同步操作数据的帧, AddData(SyncedData data)private int lastTick;internal TSPlayer(byte id, string name)&#123; // 创建玩家信息 playerInfo = new TSPlayerInfo(id, name); dropCount = 0; dropped = false; // 创建玩家操作字典存储器 controls = new SerializableDictionaryIntSyncedData();&#125;// 获取某帧是否有真实同步操作数据public bool IsDataReady(int tick)&#123; return controls.ContainsKey(tick) &amp;&amp; !controls[tick].fake;&#125;// 获取某帧是否有模拟同步操作数据, 客户端先行，是客户端预测的操作, 回滚添加的。public bool IsDataDirty(int tick)&#123; bool flag = this.controls.ContainsKey(tick); return flag &amp;&amp; this.controls[tick].dirty;&#125;// 获取该帧的同步操作数据public SyncedData GetData(int tick)&#123; if (!controls.ContainsKey(tick)) &#123; // 如果不存在，就查找上一帧是否存在 SyncedData data = null; if (controls.ContainsKey(tick - 1)) &#123; // 如果存在上一帧，就克隆上一帧的同步数据 data = controls[tick - 1].clone(); data.tick = tick; &#125; else &#123; // 否则就新建一个同步数据 data = new SyncedData(ID, tick); &#125; // 设置为伪造的 data.fake = true; // 保存到帧字典 this.controls[tick] = data; return data; &#125; // 如果存在该,就返回该帧数据 return controls[tick];&#125;// 添加存在帧同步数据public void AddData(SyncedData data)&#123; int tick = data.tick; bool flag = this.controls.ContainsKey(tick); if (flag) &#123; // 如果已经存在，就还给对象池 SyncedData.pool.GiveBack(data); &#125; else &#123; // 否则 添加到存储里 this.controls[tick] = data; // 设置最后存储的帧 this.lastTick = tick; &#125;&#125;ReplayRecord录像负责记录游戏是所有玩家的SynceData序列化: 各个玩家的所有操作AbstractLockstep.SimulationState帧同步模拟器状态private enum SimulationState&#123; // 没启动 NOT_STARTED, // 等待玩家 WAITING_PLAYERS, // 运行中 RUNNING, // 暂停 PAUSED, // 结束 ENDED&#125;AbstractLockstep帧同步抽象基类// 玩家初始容量 private const int INITIAL_PLAYERS_CAPACITY = 4;// 同步游戏开始编码 private const byte SYNCED_GAME_START_CODE = 196;// 模拟器编码 (0 暂停, 1 第一次启动, 3 End) private const byte SIMULATION_CODE = 197;// 验证码编码 private const byte CHECKSUM_CODE = 198;// 发送编码 private const byte SEND_CODE = 199;// 模拟器时间--暂停 private const byte SIMULATION_EVENT_PAUSE = 0;// 模拟器时间--运行 private const byte SIMULATION_EVENT_RUN = 1;// 模拟器时间--结束 private const byte SIMULATION_EVENT_END = 3;// 游戏结束前 最大等待所有玩家输入的帧 private const int MAX_PANIC_BEFORE_END_GAME = 5;// 同步信息 缓存窗口 private const int SYNCED_INFO_BUFFER_WINDOW = 3;// 添加玩家// internal Dictionary&lt;byte, TSPlayer&gt; players;// internal List activePlayers;// this.localPlayer = tSPlayer;public void AddPlayer(byte playerId, string playerName, bool isLocal)// 更新在线的其他玩家ID列表internal void UpdateActivePlayers()// 运行模拟器// TrueSyncStats的Update里检测调 lockstep.RunSimulation(true);// CheckGameStart() 里调 RunSimulation(false);public void RunSimulation(bool firstRun)// 更新设置simulationState模拟器状态, 和调对应的回调(OnGameStarted, OnGameUnPaused)// RunSimulation() 里调// private void OnEventDataReceived(byte eventCode, object content) 里调private void Run()// 发送操作// 调通信器 this.communicator.OpRaiseEvent(eventCode, message, reliable, toPlayers);private void RaiseEvent(byte eventCode, object message)private void RaiseEvent(byte eventCode, object message, bool reliable, int[] toPlayers) ThreadManager123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113using System;using System.Collections.Generic;using System.Threading;namespace EventSource&#123; public class ThreadManager &#123; private static ThreadManager instance; private volatile List&lt;Action&lt;object&gt;&gt; tasks = new List&lt;Action&lt;object&gt;&gt;(); private volatile List&lt;object&gt; parameters = new List&lt;object&gt;(); private ManualResetEvent waitHandleA; private ManualResetEvent waitHandleB; private ManualResetEvent currentWaitHandle; private Thread[] threads; private int currentTaskIndex; private int waitingThreadCount; internal int threadCount; public int ThreadCount &#123; private set &#123; threadCount = value; &#125; get &#123; return threadCount; &#125; &#125; public static ThreadManager Instance &#123; get &#123; if (instance == null) &#123; instance = new ThreadManager(); instance.Initialize(); &#125; return instance; &#125; &#125; private ThreadManager() &#123; &#125; // 下面这种写法感觉没有切换时间的概念呀，该进程内部不会发送切换时间片呀 private void Initialize() &#123; threadCount = Environment.ProcessorCount; threads = new Thread[threadCount]; waitHandleA = new ManualResetEvent(false); waitHandleB = new ManualResetEvent(false); currentWaitHandle = waitHandleA; var initWaitHandle = new AutoResetEvent(false); for (var index = 1; index &lt; threads.Length; index++) &#123; threads[index] = new Thread(() =&gt; &#123; initWaitHandle.Set(); ThreadProc(); &#125;) &#123; IsBackground = true &#125;; threads[index].Start(); initWaitHandle.WaitOne(); &#125; &#125; public void Execute() &#123; currentTaskIndex = 0; waitingThreadCount = 0; currentWaitHandle.Set(); PumpTasks(); while (waitingThreadCount &lt; threads.Length - 1) &#123; Thread.Sleep(0); &#125; currentWaitHandle.Reset(); currentWaitHandle = currentWaitHandle == waitHandleA ? waitHandleB : waitHandleA; tasks.Clear(); parameters.Clear(); &#125; public void AddTask(Action&lt;object&gt; task, object param) &#123; tasks.Add(task); parameters.Add(param); &#125; private void ThreadProc() &#123; while (true) &#123; Interlocked.Increment(ref waitingThreadCount); waitHandleA.WaitOne(); PumpTasks(); Interlocked.Increment(ref waitingThreadCount); waitHandleB.WaitOne(); PumpTasks(); &#125; &#125; private void PumpTasks() &#123; var count = tasks.Count; while (currentTaskIndex &lt; count) &#123; var curTaskIndex = currentTaskIndex; if (curTaskIndex == Interlocked.CompareExchange(ref currentTaskIndex, curTaskIndex + 1, curTaskIndex) &amp;&amp; currentTaskIndex &lt; count) tasks[currentTaskIndex](parameters[currentTaskIndex]); &#125; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity3D游戏GC优化总结---protobuf-net无GC版本优化实践]]></title>
    <url>%2F2019%2F04%2F24%2Fprotobuf-net-no-gc%2F</url>
    <content type="text"><![CDATA[protobuf-net优化效果图protobuf-net是Unity3D游戏开发中被广泛使用的Google Protocol Buffer库的c#版本，之所以c#版本被广泛使用，是因为c++版本的源代码不支持Unity3D游戏在各个平台上的动态库构建。它是一个网络传输层协议，对应的lua版本有两个可用的库：一个是proto-gen-lua，由tolua作者开发，另外一个是protoc，由云风开发。protobuf-net在GC上有很大的问题，在一个高频率网络通讯的状态同步游戏中使用发现GC过高，所以对它进行了一次比较彻底的GC优化。下面是优化前后的对比图： Unity3D游戏GC优化概述有关Unity3D垃圾回收的基本概念和优化策略Unity官网有发布过文章：Optimizing garbage collection in Unity games&gt;。这篇文章讲述了Unity3D垃圾回收机制，和一些简单的优化策略，讨论的不是特别深入，但是广度基本上算是够了。 C#变量分为两种类型：值类型和引用类型，值类型分配在栈区，引用类型分配在堆区，GC关注引用类型 GC卡顿原因：堆内存垃圾回收，向系统申请新的堆内存 GC触发条件：堆内存分配而当内存不足时、按频率自动触发、手动强行触发（一般用在场景切换） GC负面效果：内存碎片（导致内存变大，GC触发更加频繁）、游戏顿卡 GC优化方向：减少GC次数、降低单次GC运行时间、场景切换时主动GC GC优化策略：减少对内存分配次数和引用次数、降低堆内存分配和回收频率 善用缓存：对有堆内存分配的函数，缓存其调用结果，不要反复去调用 清除列表：而不要每次都去new一个新的列表 用对象池：必用 慎用串拼接：缓存、Text组件拆分、使用StringBuild、Debug.Log接口封装（打Conditional标签） 警惕Unity函数调用：GameObject.name、GameObject.tag、FindObjectsOfType()等众多函数都有堆内存分配，实测为准 避免装箱：慎用object形参、多用泛型版本（如List）等，这里的细节问题很多，实测为准 警惕协程：StartCoroutine有GC、yield return带返回值有GC、yield return new xxx有GC（最好自己做一套协程管理） foreach：unity5.5之前版本有GC，使用for循环或者获取迭代器 减少引用：建立管理类统一管理，使用ID作为访问token 慎用LINQ：这东西最好不用，GC很高 结构体数组：如果结构体中含有引用类型变量，对结构体数组进行拆分，避免GC时遍历所有结构体成员 在游戏空闲（如场景切换时）强制执行GC protobuf-net GC分析protobuf-net序列化先分析下序列化GC，deep profile如下： 打开PropertyDecorator.cs脚本，找到Write函数如下： 123456public override void Write(object value, ProtoWriter dest)&#123; Helpers.DebugAssert(value != null); value = property.GetValue(value, null); if(value != null) Tail.Write(value, dest);&#125; 可以看到这里MonoProperty.GetValue产生GC的原因是因为反射的使用；而ListDecorator.Write对应于代码Tail.Write，继续往下看：找到对应源代码：12345678910111213141516171819202122232425public override void Write(object value, ProtoWriter dest)&#123; SubItemToken token; bool writePacked = WritePacked; if (writePacked) &#123; ProtoWriter.WriteFieldHeader(fieldNumber, WireType.String, dest); token = ProtoWriter.StartSubItem(value, dest); ProtoWriter.SetPackedField(fieldNumber, dest); &#125; else &#123; token = new SubItemToken(); // default &#125; bool checkForNull = !SupportNull; foreach (object subItem in (IEnumerable)value) &#123; if (checkForNull &amp;&amp; subItem == null) &#123; throw new NullReferenceException(); &#125; Tail.Write(subItem, dest); &#125; if (writePacked) &#123; ProtoWriter.EndSubItem(token, dest); &#125;&#125; 可以看到这里的GC是由list遍历的foreach引起的。继续往内展开，产生GC的点全部是这两个原因上。 protobuf-net反序列化找到第一个产生GC的分支： 同上述分析，MonoProperty.GetValue、MonoProperty.SetValue产生GC原因是反射。而Int32Serializer.Read()代码如下：12345public object Read(object value, ProtoReader source)&#123; Helpers.DebugAssert(value == null); // since replaces return source.ReadInt32();&#125; 可见产生GC的原因是因为装箱。继续往下展开ListDecorateor.Read函数：由Activator.CreateInstance得出这里产生GC的原因是实例的创建。继续往下展开：反射和装箱产生GC上面已经提到，看ProtoReader.AppendBytes代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static byte[] AppendBytes(byte[] value, ProtoReader reader)&#123; if (reader == null) throw new ArgumentNullException("reader"); switch (reader.wireType) &#123; case WireType.String: int len = (int)reader.ReadUInt32Variant(false); reader.wireType = WireType.None; if (len == 0) return value == null ? EmptyBlob : value; int offset; if (value == null || value.Length == 0) &#123; offset = 0; value = new byte[len]; &#125; else &#123; offset = value.Length; byte[] tmp = new byte[value.Length + len]; Helpers.BlockCopy(value, 0, tmp, 0, value.Length); value = tmp; &#125; // value is now sized with the final length, and (if necessary) // contains the old data up to "offset" reader.position += len; // assume success while (len &gt; reader.available) &#123; if (reader.available &gt; 0) &#123; // copy what we *do* have Helpers.BlockCopy(reader.ioBuffer, reader.ioIndex, value, offset, reader.available); len -= reader.available; offset += reader.available; reader.ioIndex = reader.available = 0; // we've drained the buffer &#125; // now refill the buffer (without overflowing it) int count = len &gt; reader.ioBuffer.Length ? reader.ioBuffer.Length : len; if (count &gt; 0) reader.Ensure(count, true); &#125; // at this point, we know that len &lt;= available if (len &gt; 0) &#123; // still need data, but we have enough buffered Helpers.BlockCopy(reader.ioBuffer, reader.ioIndex, value, offset, len); reader.ioIndex += len; reader.available -= len; &#125; return value; default: throw reader.CreateWireTypeException(); &#125;&#125; 可见，这里产生GC的原因是因为new byte[]操作。 Protobuf-net GC优化方案protobuf-net在本次协议测试中GC产生的原因总结如下： 反射 forearch 装箱 创建新的pb对象 创建新的字节数组 去反射用过lua的人都知道，不管是tolua还是xlua，去反射的方式是生成wrap文件，这里去反射可以借鉴同样的思想。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566using CustomDataStruct;using ProtoBuf.Serializers;namespace battle&#123; public sealed class NtfBattleFrameDataDecorator : ICustomProtoSerializer &#123; public void SetValue(object target, object value, int fieldNumber) &#123; ntf_battle_frame_data data = target as ntf_battle_frame_data; if (data == null) &#123; return; &#125; switch (fieldNumber) &#123; case 1: data.time = ValueObject.Value&lt;int&gt;(value); break; case 3: data.slot_list.Add((ntf_battle_frame_data.one_slot)value); break; case 5: data.server_from_slot = ValueObject.Value&lt;int&gt;(value); break; case 6: data.server_to_slot = ValueObject.Value&lt;int&gt;(value); break; case 7: data.server_curr_frame = ValueObject.Value&lt;int&gt;(value); break; case 8: data.is_check_frame = ValueObject.Value&lt;int&gt;(value); break; default: break; &#125; &#125; public object GetValue(object target, int fieldNumber) &#123; ntf_battle_frame_data data = target as ntf_battle_frame_data; if (data == null) &#123; return null; &#125; switch (fieldNumber) &#123; case 1: return ValueObject.Get(data.time); case 3: return data.slot_list; case 5: return ValueObject.Get(data.server_from_slot); case 6: return ValueObject.Get(data.server_to_slot); case 7: return ValueObject.Get(data.server_curr_frame); &#125; return null; &#125; &#125;&#125; 反射产生的地方在protobuf-net的装饰类中，具体是PropertyDecorator，我这里并没有去写工具自动生成Wrap文件，而是对指定的协议进行了Hook。 foreachforeach对列表来说改写遍历方式就好了，我这里没有对它进行优化，因为Unity5.5以后版本这个问题就不存在了。篇首优化后的效果图中还有一点残留就是因为这里捣鬼。 无GC装箱要消除这里的装箱操作，需要重构代码，而protobuf-net内部大量使用了object进行参数传递，这使得用泛型编程来消除GC变得不太现实。我这里是自己实现了一个无GC版本的装箱拆箱类ValueObject，使用方式十分简单，类似： 123456789public object Read(object value, ProtoReader source)&#123; Helpers.DebugAssert(value == null); // since replaces return ValueObject.Get(source.ReadInt32());&#125;public void Write(object value, ProtoWriter dest)&#123; ProtoWriter.WriteInt32(ValueObject.Value&lt;int&gt;(value), dest);&#125; 其中ValueObject.Get是装箱，而ValueObject.Value是拆箱，装箱和拆箱的步骤必须一一对应。 使用对象池对于protobuf-net反序列化的时候会创建pb对象这一点，最合理的方式是使用对象池，Hook住protobuf-net创建对象的地方，从对象池中取对象，而不是新建对象，用完以后再执行回收。池接口如下：1234567891011121314151617181920212223/// &lt;summary&gt;/// 说明：proto网络数据缓存池需要实现的接口/// /// @by wsh 2017-07-01/// &lt;/summary&gt;public interface IProtoPool&#123; // 获取数据 object Get(); // 回收数据 void Recycle(object data); // 清除指定数据 void ClearData(object data); // 深拷贝指定数据 object DeepCopy(object data); // 释放缓存池 void Dispose();&#125; 使用字节缓存池对于new byte[]操作的GC优化也是一样的，只不过这里使用的缓存池是针对字节数组而非pb对象，我这里是自己实现了一套通用的字节流与字节buffer缓存池StreamBufferPool，每次需要字节buffer时从中取，用完以后放回。 protobuf-net GC优化实践以上关键的优化方案都已经有了，具体怎么部署到protobuf-net的细节问题这里不再多说，有兴趣的朋友自己去看下源代码。这里就优化以后的protobuf-net使用方式做下介绍，首先是目录结构： CustomDatastruct：自定义的数据结构 Protobuf-extension/Protocol：测试协议 Protobuf-extension/ProtoFactory：包含两个部分，其中ProtoPool是pb对象池，而ProtoSerializer是对protobuf-net装饰器的扩展，用于特定协议的去反射 ProtoBufSerializer：Protobuf-net对外接口的封装。 主要看下ProtoBufSerializer脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172using battle;using CustomDataStruct;using ProtoBuf.Serializers;using System.IO;/// &lt;summary&gt;/// 说明：ProtoBuf初始化、缓存等管理；序列化、反序列化等封装/// /// @by wsh 2017-07-01/// &lt;/summary&gt;public class ProtoBufSerializer : Singleton&lt;ProtoBufSerializer&gt;&#123; ProtoBuf.Meta.RuntimeTypeModel model; public override void Init() &#123; base.Init(); model = ProtoBuf.Meta.RuntimeTypeModel.Default; AddCustomSerializer(); AddProtoPool(); model.netDataPoolDelegate = ProtoFactory.Get; model.bufferPoolDelegate = StreamBufferPool.GetBuffer; &#125; public override void Dispose() &#123; model = null; ClearCustomSerializer(); ClearProtoPool(); &#125; static public void Serialize(Stream dest, object instance) &#123; ProtoBufSerializer.instance.model.Serialize(dest, instance); &#125; static public object Deserialize(Stream source, System.Type type, int length = -1) &#123; return ProtoBufSerializer.instance.model.Deserialize(source, null, type, length, null); &#125; void AddCustomSerializer() &#123; // 自定义Serializer以避免ProtoBuf反射 CustomSetting.AddCustomSerializer(typeof(ntf_battle_frame_data), new NtfBattleFrameDataDecorator()); CustomSetting.AddCustomSerializer(typeof(ntf_battle_frame_data.one_slot), new OneSlotDecorator()); CustomSetting.AddCustomSerializer(typeof(ntf_battle_frame_data.cmd_with_frame), new CmdWithFrameDecorator()); CustomSetting.AddCustomSerializer(typeof(one_cmd), new OneCmdDecorator()); &#125; void ClearCustomSerializer() &#123; CustomSetting.CrearCustomSerializer(); &#125; void AddProtoPool() &#123; // 自定义缓存池以避免ProtoBuf创建实例 ProtoFactory.AddProtoPool(typeof(ntf_battle_frame_data), new NtfBattleFrameDataPool()); ProtoFactory.AddProtoPool(typeof(ntf_battle_frame_data.one_slot), new OneSlotPool()); ProtoFactory.AddProtoPool(typeof(ntf_battle_frame_data.cmd_with_frame), new CmdWithFramePool()); ProtoFactory.AddProtoPool(typeof(one_cmd), new OneCmdPool()); &#125; void ClearProtoPool() &#123; ProtoFactory.ClearProtoPool(); &#125;&#125; 其中： AddCustomSerializer：用于添加自定义的装饰器到protobuf-net AddProtoPool：用于添加自定义对象池到protobuf-net Serialize：提供给逻辑层使用的序列化接口 Deserialize：提供给逻辑层使用的反序列化接口 使用示例：123456789101112131415161718192021222324252627282930const int SENF_BUFFER_LEN = 64 * 1024;const int REVIVE_BUFFER_LEN = 128 * 1024;MemoryStream msSend = new MemoryStream(sendBuffer, 0, SENF_BUFFER_LEN, true, true);;MemoryStream msRecive = new MemoryStream(reciveBuffer, 0, REVIVE_BUFFER_LEN, true, true);;msSend.SetLength(SENF_BUFFER_LEN);msSend.Seek(0, SeekOrigin.Begin);ntf_battle_frame_data dataTmp = ProtoFactory.Get&lt;ntf_battle_frame_data&gt;();ntf_battle_frame_data.one_slot oneSlot = ProtoFactory.Get&lt;ntf_battle_frame_data.one_slot&gt;();ntf_battle_frame_data.cmd_with_frame cmdWithFrame = ProtoFactory.Get&lt;ntf_battle_frame_data.cmd_with_frame&gt;();one_cmd oneCmd = ProtoFactory.Get&lt;one_cmd&gt;();cmdWithFrame.cmd = oneCmd;oneSlot.cmd_list.Add(cmdWithFrame);dataTmp.slot_list.Add(oneSlot);DeepCopyData(data, dataTmp);ProtoBufSerializer.Serialize(msSend, dataTmp);ProtoFactory.Recycle(dataTmp);//*************回收，很重要msSend.SetLength(msSend.Position);//长度一定要设置对msSend.Seek(0, SeekOrigin.Begin);//指针一定要复位//msRecive.SetLength(msSend.Length);//同理，但是如果Deserialize指定长度，则不需要设置流长度msRecive.Seek(0, SeekOrigin.Begin);//同理Buffer.BlockCopy(msSend.GetBuffer(), 0, msRecive.GetBuffer(), 0, (int)msSend.Length);dataTmp = ProtoBufSerializer.Deserialize(msRecive, typeof(ntf_battle_frame_data), (int)msSend.Length) as ntf_battle_frame_data;PrintData(dataTmp);ProtoFactory.Recycle(dataTmp);//*************回收，很重要 Unity3D游戏GC优化实践protobuf-net的GC优化实践要说的就这么多，其实做GC优化的大概步骤就是这些：GC分析，优化方案，最后再重构代码。这里再补充一些其它的内容，CustomDatastruct中包含了： BetterDelegate：泛型委托包装类，针对深层函数调用树中使用泛型委托作为函数参数进行传递时代码编写困难的问题。 BetterLinkedList：无GC链表 BetterStringBuilder：无GC版StrigBuilder StreamBufferPool：字节流与字节buffer缓存池 ValueObject：无GC装箱拆箱 ObjPool：通用对象池 其中protobuf-net的无GC优化用到了StreamBufferPool、ValueObject与ObjPool，主要是对象池和免GC装箱，其它的在源代码中有详细注释。TestScenes下包含了各种测试场景：这里对其中关键的几个结论给下说明： LinkedList当自定义结构做链表节点，必须实现IEquatable、IComparable接口，否则Roemove、Cotains、Find、FindLast每次都有GC产生。 123456789101112131415161718192021222324252627282930313233343536373839// 重要：对于自定义结构一定要继承IEquatable&lt;T&gt;接口并实现它// 此外：对于Sort，实现IComparable&lt;T&gt;接口，则在传入委托的时候可以和系统简单值类型一样public struct CustomStruct : IEquatable&lt;CustomStruct&gt;, IComparable&lt;CustomStruct&gt;&#123; public int a; public string b; public CustomStruct(int a, string b) &#123; this.a = a; this.b = b; &#125; public bool Equals(CustomStruct other) &#123; return a == other.a &amp;&amp; b == other.b; &#125; public int CompareTo(CustomStruct other) &#123; if (a != other.a) &#123; return a.CompareTo(other.a); &#125; if (b != other.b) &#123; return b.CompareTo(other.b); &#125; return 0; &#125; // 说明：测试正确性用的，不是必须 public override string ToString() &#123; return string.Format("&lt;a = &#123;0&#125;, b = &#123;1&#125;&gt;", a, b); &#125;&#125; 所有委托必须缓存，产生GC的测试一律是因为每次调用都生成了一个新的委托 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class TestDelegateGC : MonoBehaviour&#123; public delegate void TestDelegate(GameObject go, string str, int num); public delegate void TestTDelegate&lt;T,U,V&gt;(T go, U str, V num); Delegate mDelegate1; Delegate mDelegate2; TestDelegate mDelegate3; TestTDelegate&lt;GameObject, string, int&gt; mDelegate4; TestDelegate mDelegate5; Comparison&lt;int&gt; mDelegate6; Comparison&lt;int&gt; mDelegate7; int mTestPriviteData = 100; List&lt;int&gt; mTestList = new List&lt;int&gt;(); // Use this for initialization void Start () &#123; mDelegate1 = (TestDelegate)DelegateFun; mDelegate2 = Delegate.CreateDelegate(typeof(TestDelegate), this, "DelegateFun"); mDelegate3 = DelegateFun; mDelegate4 = TDelegateFun; //static mDelegate5 = new TestDelegate(StaticDelegateFun); mDelegate6 = SortByXXX; mDelegate7 = TSortByXXX&lt;int&gt;; mTestList.Add(1); mTestList.Add(2); mTestList.Add(3); &#125; // Update is called once per frame void Update () &#123; // 不使用泛型 TestFun(DelegateFun); TestFun(mDelegate1 as TestDelegate); //无GC TestFun(mDelegate2 as TestDelegate); //无GC TestFun(mDelegate3); //无GC，推荐 TestFun(mDelegate5); //无GC // 使用泛型，更加通用 TestTFun(TDelegateFun, gameObject, "test", 1000);//每次调用产生104B垃圾 TestTFun(mDelegate4, gameObject, "test", 1000);// 无GC，更通用，极力推荐*********** // Sort测试 mTestList.Sort();//无GC TestSort(SortByXXX);//每次调用产生104B垃圾 TestSort(mDelegate6);//无GC TestSort(TSortByXXX);//每次调用产生104B垃圾 TestSort(TSortByXXX);//每次调用产生104B垃圾 TestSort(mDelegate7);//无GC &#125; private void TestFun(TestDelegate de) &#123; de(gameObject, "test", 1000); &#125; private void TestTFun&lt;T, U, V&gt;(TestTDelegate&lt;T, U, V&gt; de, T arg0, U arg1, V arg2) &#123; de(arg0, arg1, arg2); &#125; private void TestSort&lt;T&gt;(List&lt;T&gt; list, Comparison&lt;T&gt; sortFunc) &#123; list.Sort(sortFunc); &#125; private void TestSort(Comparison&lt;int&gt; sortFunc) &#123; mTestList.Sort(sortFunc); &#125; private void DelegateFun(GameObject go, string str, int num) &#123; &#125; private void TDelegateFun&lt;T, U, V&gt;(T go, U str, V num) &#123; &#125; private static void StaticDelegateFun(GameObject go, string str, int num) &#123; &#125; private int SortByXXX(int x, int y) &#123; return x.CompareTo(y); &#125; private int TSortByXXX&lt;T&gt;(T x, T y) where T : IComparable&lt;T&gt; &#123; return x.CompareTo(y); &#125;&#125; List对于自定义结构做列表项，必须实现IEquatable、IComparable接口，否则Roemove、Cotains、IndexOf、sort每次都有GC产生；对于Sort，需要传递一个委托。这两点的实践上面都已经说明。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KCP C#版]]></title>
    <url>%2F2019%2F04%2F22%2FKCP-CSharp-README%2F</url>
    <content type="text"><![CDATA[KCP C#版支持目标框架: dotnetstandard2.0 dotnetstandard1.1 开箱即用。也可以使用Nuget 搜索KCP。 链接c: skywind3000 KCPgo: xtaci kcp-go 用法请参考C版本文档。 说明 内部使用了unsafe代码和非托管内存，所以kcpsegment运行时不会alloc，不会对gc造成压力。 对于output回调和TryRecv函数。使用RentBuffer回调，从外部分配内存。请参考IMemoryOwner用法。 支持Span&lt;byte&gt; 测试[已修复]同一个进程两个Kcp echo测试，至少使用3个线程，否则可能死锁。 在UnitTestProject1路径下执行 dotnet test 可进行多框架测试。（需要安装notnetcoreSDK） 相对C版的一些变化 差异变化 C版 C#版 数据结构 acklist 数组 ConcurrentQueue snd_queue 双向链表 ConcurrentQueue snd_buf 双向链表 LinkedList rcv_buf 双向链表 LinkedList rcv_queue 双向链表 List ——————— ——————— ——————— 回调函数 增加了RentBuffer回调，当KCP需要时可以从外部申请内存。 多线程 增加了线程安全。 流模式 由于数据结构变动，移除了流模式。 interval最小间隔 10ms 0ms(在特殊形况下允许CPU满负荷运转) ——————— ——————— ——————— API变动 增加大小端编码设置。默认小端编码。 增加TryRecv函数，当可以Recv时只peeksize一次。 ikcp_ack_push 删除了此函数（已内联） ikcp_ack_get 删除了此函数（已内联）]]></content>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KCP - A Fast and Reliable ARQ Protocol]]></title>
    <url>%2F2019%2F04%2F22%2FKCP-README%2F</url>
    <content type="text"><![CDATA[README in English 简介KCP是一个快速可靠协议，能以比 TCP浪费10%-20%的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果。纯算法实现，并不负责底层协议（如UDP）的收发，需要使用者自己定义下层数据包的发送方式，以 callback的方式提供给 KCP。 连时钟都需要外部传递进来，内部不会有任何一次系统调用。 整个协议只有 ikcp.h, ikcp.c两个源文件，可以方便的集成到用户自己的协议栈中。也许你实现了一个P2P，或者某个基于 UDP的协议，而缺乏一套完善的ARQ可靠协议实现，那么简单的拷贝这两个文件到现有项目中，稍微编写两行代码，即可使用。 技术特性TCP是为流量设计的（每秒内可以传输多少KB的数据），讲究的是充分利用带宽。而 KCP是为流速设计的（单个数据包从一端发送到一端需要多少时间），以10%-20%带宽浪费的代价换取了比 TCP快30%-40%的传输速度。TCP信道是一条流速很慢，但每秒流量很大的大运河，而KCP是水流湍急的小激流。KCP有正常模式和快速模式两种，通过以下策略达到提高流速的结果： RTO翻倍vs不翻倍： TCP超时计算是RTOx2，这样连续丢三次包就变成RTOx8了，十分恐怖，而KCP启动快速模式后不x2，只是x1.5（实验证明1.5这个值相对比较好），提高了传输速度。 选择性重传 vs 全部重传： TCP丢包时会全部重传从丢的那个包开始以后的数据，KCP是选择性重传，只重传真正丢失的数据包。 快速重传： 发送端发送了1,2,3,4,5几个包，然后收到远端的ACK: 1, 3, 4, 5，当收到ACK3时，KCP知道2被跳过1次，收到ACK4时，知道2被跳过了2次，此时可以认为2号丢失，不用等超时，直接重传2号包，大大改善了丢包时的传输速度。 延迟ACK vs 非延迟ACK： TCP为了充分利用带宽，延迟发送ACK（NODELAY都没用），这样超时计算会算出较大 RTT时间，延长了丢包时的判断过程。KCP的ACK是否延迟发送可以调节。 UNA vs ACK+UNA： ARQ模型响应有两种，UNA（此编号前所有包已收到，如TCP）和ACK（该编号包已收到），光用UNA将导致全部重传，光用ACK则丢失成本太高，以往协议都是二选其一，而 KCP协议中，除去单独的 ACK包外，所有包都有UNA信息。 非退让流控： KCP正常模式同TCP一样使用公平退让法则，即发送窗口大小由：发送缓存大小、接收端剩余接收缓存大小、丢包退让及慢启动这四要素决定。但传送及时性要求很高的小数据时，可选择通过配置跳过后两步，仅用前两项来控制发送频率。以牺牲部分公平性及带宽利用率之代价，换取了开着BT都能流畅传输的效果。 基本使用 创建 KCP对象： 123// 初始化 kcp对象，conv为一个表示会话编号的整数，和tcp的 conv一样，通信双// 方需保证 conv相同，相互的数据包才能够被认可，user是一个给回调函数的指针ikcpcb *kcp = ikcp_create(conv, user); 设置回调函数： 123456789// KCP的下层协议输出函数，KCP需要发送数据时会调用它// buf/len 表示缓存和长度// user指针为 kcp对象创建时传入的值，用于区别多个 KCP对象int udp_output(const char *buf, int len, ikcpcb *kcp, void *user)&#123; ....&#125;// 设置回调函数kcp-&gt;output = udp_output; 循环调用 update： 123// 以一定频率调用 ikcp_update来更新 kcp状态，并且传入当前时钟（毫秒单位）// 如 10ms调用一次，或用 ikcp_check确定下次调用 update的时间不必每次调用ikcp_update(kcp, millisec); 输入一个下层数据包： 12// 收到一个下层数据包（比如UDP包）时需要调用：ikcp_input(kcp, received_udp_packet, received_udp_size); 处理了下层协议的输出/输入后 KCP协议就可以正常工作了，使用 ikcp_send 来向远端发送数据。而另一端使用 ikcp_recv(kcp, ptr, size)来接收数据。 协议配置协议默认模式是一个标准的 ARQ，需要通过配置打开各项加速开关： 工作模式： 1int ikcp_nodelay(ikcpcb *kcp, int nodelay, int interval, int resend, int nc) nodelay ：是否启用 nodelay模式，0不启用；1启用。 interval ：协议内部工作的 interval，单位毫秒，比如 10ms或者 20ms resend ：快速重传模式，默认0关闭，可以设置2（2次ACK跨越将会直接重传） nc ：是否关闭流控，默认是0代表不关闭，1代表关闭。 普通模式： ikcp_nodelay(kcp, 0, 40, 0, 0); 极速模式： ikcp_nodelay(kcp, 1, 10, 2, 1); 最大窗口： 1int ikcp_wndsize(ikcpcb *kcp, int sndwnd, int rcvwnd); 该调用将会设置协议的最大发送窗口和最大接收窗口大小，默认为32. 这个可以理解为 TCP的 SND_BUF 和 RCV_BUF，只不过单位不一样 SND/RCV_BUF 单位是字节，这个单位是包。 最大传输单元： 纯算法协议并不负责探测 MTU，默认 mtu是1400字节，可以使用ikcp_setmtu来设置该值。该值将会影响数据包归并及分片时候的最大传输单元。 最小RTO： 不管是 TCP还是 KCP计算 RTO时都有最小 RTO的限制，即便计算出来RTO为40ms，由于默认的 RTO是100ms，协议只有在100ms后才能检测到丢包，快速模式下为30ms，可以手动更改该值： 1kcp-&gt;rx_minrto = 10; 文档索引协议的使用和配置都是很简单的，大部分情况看完上面的内容基本可以使用了。如果你需要进一步进行精细的控制，比如改变 KCP的内存分配器，或者你需要更有效的大规模调度 KCP链接（比如 3500个以上），或者如何更好的同 TCP结合，那么可以继续延伸阅读： Wiki Home KCP 最佳实践 同现有TCP服务器集成 传输数据加密 应用层流量控制 性能评测 开源案例 kcptun: 基于 kcp-go做的高速远程端口转发(隧道) ，配合ssh -D，可以比 shadowsocks 更流畅的看在线视频。 dog-tunnel: GO开发的网络隧道，使用 KCP极大的改进了传输速度，并移植了一份 GO版本 KCP v2ray：著名代理软件，Shadowsocks 代替者，1.17后集成了 kcp协议，使用UDP传输，无数据包特征。 asio-kcp: 使用 KCP的完整 UDP网络库，完整实现了基于 UDP的链接状态管理，会话控制，KCP协议调度等 kcp-java：Java版本 KCP协议实现。 kcp-netty：kcp的Java语言实现，基于netty。 kcp-go: 高安全性的kcp的 GO语言实现，包含 UDP会话管理的简单实现，可以作为后续开发的基础库。 kcp-csharp: kcp的 csharp移植，同时包含一份回话管理，可以连接上面kcp-go的服务端。 kcp-csharp: 新版本 Kcp的 csharp移植。线程安全，运行时无alloc，对gc无压力。 kcp-rs: KCP的 rust移植 kcp-rust：新版本 KCP的 rust 移植 tokio-kcp：rust tokio 的 kcp 集成 lua-kcp: KCP的 Lua扩展，用于 Lua服务器 node-kcp: node-js 的 KCP 接口 nysocks: 基于libuv实现的node-addon，提供nodejs版本的代理服务，客户端接入支持SOCKS5和ss两种协议 shadowsocks-android: Shadowsocks for android 集成了 kcptun 使用 kcp协议加速 shadowsocks，效果不错 kcpuv: 使用 libuv开发的kcpuv库，目前还在 Demo阶段 Lantern：更好的 VPN，Github 50000 星，使用 kcpgo 加速 rpcx ：RPC 框架，1000+ 星，使用 kcpgo 加速 RPC xkcptun: c语言实现的kcptun，主要用于OpenWrt, LEDE开发的路由器项目上 et-frame: C#前后端框架(前端unity3d)，统一用C#开发游戏，实现了前后端kcp协议 商业案例 明日帝国：Game K17 的 《明日帝国》 （Google Play），使用 KCP 加速游戏消息，让全球玩家流畅联网 仙灵大作战：4399 的 MOBA游戏，使用 KCP 优化游戏同步 CC：网易 CC 使用 kcp 加速视频推流，有效提高流畅性 BOBO：网易 BOBO 使用 kcp 加速主播推流 云帆加速：使用 KCP 加速文件传输和视频推流，优化了台湾主播推流的流畅度 欢迎告知更多案例 协议比较如果网络永远不卡，那 KCP/TCP 表现类似，但是网络本身就是不可靠的，丢包和抖动无法避免（否则还要各种可靠协议干嘛）。在内网这种几乎理想的环境里直接比较，大家都差不多，但是放到公网上，放到3G/4G网络情况下，或者使用内网丢包模拟，差距就很明显了。公网在高峰期有平均接近10%的丢包，wifi/3g/4g下更糟糕，这些都会让传输变卡。 感谢 asio-kcp 的作者 zhangyuan 对 KCP 与 enet, udt做过的一次横向评测，结论如下： ASIO-KCP has good performace in wifi and phone network(3G, 4G). The kcp is the first choice for realtime pvp game. The lag is less than 1 second when network lag happen. 3 times better than enet when lag happen. The enet is a good choice if your game allow 2 second lag. UDT is a bad idea. It always sink into badly situation of more than serval seconds lag. And the recovery is not expected. enet has the problem of lack of doc. And it has lots of functions that you may intrest. kcp’s doc is chinese. Good thing is the function detail which is writen in code is english. And you can use asio_kcp which is a good wrap. The kcp is a simple thing. You will write more code if you want more feature. UDT has a perfect doc. UDT may has more bug than others as I feeling. 具体见：横向比较 和 评测数据，为犹豫选择的人提供了更多指引。 欢迎捐赠 欢迎使用支付宝手扫描上面的二维码，对该项目进行捐赠。捐赠款项将用于持续优化 KCP协议以及完善文档。 感谢：明明、星仔、进、帆、颁钊、斌铨、晓丹、余争、虎、晟敢、徐玮、王川、赵刚强、胡知锋、万新朝、何新超、刘旸、侯宪辉、吴佩仪、华斌、如涛、胡坚。。。（早先的名单实在不好意思没记录下来）等同学的捐助与支持。 欢迎关注 KCP交流群：364933586（QQ群号），KCP集成，调优，网络传输以及相关技术讨论Gitter 群：https://gitter.im/skywind3000/KCP blog: http://www.skywind.me zhihu: https://www.zhihu.com/people/skywind3000 ContributorsThis project exists thanks to all the people who contribute.]]></content>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[帧锁定同步(frame lock sync)按帧同步（frame sync）状态同步(state sync)]]></title>
    <url>%2F2019%2F04%2F22%2Fframe-sync%2F</url>
    <content type="text"><![CDATA[帧锁定同步(frame lock sync)lockstep这个概念大家的理解基本都是一致的。准确的说，应该叫frame lockstep sync。但因为lockstep sync基本都是针对帧的（至少我现在想不出其他用法），把lockstep sync和frame lock sync直接画等号也没啥问题。lockstep sync这个东西，最大的特点则是： 每一帧的运算都要依赖上一帧的数据，也就是所谓的上下文强相关。 每帧的数据，都是通过上一帧的数据通过相同的输入参数再次计算出来的，只要上一帧有一点点的不同，后面的结果就会完全不同。所以导致了lockstep在获得它的唯一优点（同步数据少）的同时，有了一些闹心的缺点： 对误差极度敏感，任何差错都会因为产生蝴蝶效应被放大 所有逻辑都必须计算（包括视野外的），导致客户端运算量增加 因为整个游戏状态都必须存在于客户端，数据对“外挂”透明。 当本地状态遗失后（断网或应用崩溃），必须获得一个非常大的数据包来恢复状态，因为必须包含视野外，以及一些客户端本不需要关心的内容。 当然，上述缺点在特定情况并不算是缺点，比如对于Moba类游戏而言，场景小，物体数量少，那么整个场景的总数据量也不是很大，增加的运算量也可以接受。对于2v2的格斗游戏就更不用说了，这些都是原本lockstep的标准应用样例。 但这时候肯定就有人说了，“帧同步的优点”并不是只有“数据量少”这一个啊，他还有帕拉啪啦啪啦…… 没错“按帧同步”(frame sync)的优点确实没有帧锁定同步(frame lock sync)这么少。 当然，事实上其实并没有frame sync这样一个词在流传。但是从“帧同步”这个词的字面意思，正常人都会往这边理解成frame sync好吧？ 把帧锁定同步(frame lock sync)缩写成帧同步(frame sync)，便是一切恶的根源。而按帧同步（frame sync），按字面就是以一帧数据为单位进行同步，按照分词结构，帧锁定同步(frame lock sync)必定是按帧同步（frame sync），也就是这样的关系。 lockstep是用来交换流畅性的特性是公平性，这个特性其实和一致性有所类似。我们和其他玩家一起游戏的时候，有时候不希望对方因为电脑速度比较快，网络比较好，而能比我们更早的看到游戏的运行结果，从而提早作出操作。这一点在格斗对打游戏（如《街霸》）里面非常关键，在一些RTS（《星际争霸》）里面，提早看到游戏运行结果也是很有竞争优势的。因此我们为了让网络、硬件不一样的玩家能公平游戏，往往会使用一种叫“锁步”的策略：就好像一串绑着脚镣的囚犯，他们只能一起抬起左脚，然后再一起抬起右脚的走路，谁也不能走的更快。技术上的实现，就是每个客户端都定时（每N个渲染帧）发送一个网络帧到服务器上，就算玩家没操作，也类似心跳的这样发送空数据帧，所有客户端都要完整的收到所有的其他客户端的“心跳帧”才能开始运算一次游戏逻辑。这就是让所有的客户端，都互相等待，如果任何一个客户端卡了，其他的客户端都立刻就能知道，然后弹出界面让玩家停止输入来等待。因此在很多场合，帧同步的技术也被成为“锁步”技术，事实上，在没有统一的Relay Server服务器的时代（IPX局域网连机对战的时代），帧同步的网络帧其实就是上面所说的某个客户端的“心跳帧”，是由某个客户端产生并广播的（比如以前的局域网游戏，都会由一个客户端充当Host主机）。在《星际争霸》连机游戏中，如果有一个玩家掉线了，所有其他玩家就会发现有一个界面弹出来挡住画面，表示在等某某某。这种做法实际上是牺牲了流畅度的，因为你会发现一旦有网络、硬件卡的玩家加入游戏，所有其他玩家都受他的影响。为了减少这种对流畅度的影响，我们可以在需要“锁步”的时候，尽量少锁一点，比如不是发现缺了一帧就停下来，而是缺了若干帧，还是可以以“不公平”的方式继续玩一会儿（比如几秒），如果这段时间内还是没有补齐所缺的帧，才宣布锁住游戏等待。当然这个“容忍”的帧数我们可以调节到“最大”——就是没有。那么一个完全不锁步的游戏，肯定不是一个公平的游戏，但是也会在流畅性产生最大的好处，就是完全不受其他玩家影响。在那些不是PVP（玩家对战）的帧同步游戏中，不公平这个往往问题不大。我们完全可以在游戏的不同玩法里，打开、调整、甚至关闭这个“锁步”的机制，从而让游戏最大程度的平衡公平性和流畅性。 也就是一个包含关系。帧锁定同步(frame lock sync)一定包含lock sync的所有优点和缺点，但帧同步未必包含lockset的优缺点——假如，帧同步仅仅是按帧同步frame sync，而不是帧锁定同步的“简称”的话。 优点 它的开发效率比较高。如果你开发思路的整体框架是验证可行的，如果你把它的缺点解决了，那么你的开发思路完全就跟写单机一样，你只需要遵从这样的思路，尽量保证性能，程序该怎么写就怎么写。比如我们以前要在状态同步下面做一个复杂的技能，有很多段位的技能，可能要开发好几天，才能有一个稍微过得去的结果，而在帧同步下面，英雄做多段位技能很可能半天就搞定了。 它能实现更强的打击感，打击感强除了我们说的各种反馈、特效、音效外，还有它的准确性。利用帧同步，游戏里面看到这些挥舞的动作，就能做到在比较准确的时刻产生反馈，以及动作本身的密度也可以做到很高的频率，这在状态同步下是比较难做的。 它的流量消耗是稳定的。大家应该看过《星级争霸》的录像，它只有几百K的大小，这里面只有驱动游戏的输入序列。帧同步只会随着玩家数量的增多，流量才会增长，如果玩家数量固定的话，不管你的游戏有多复杂，你的角色有多少，流量消耗基本上都是稳定的。这点延伸开来还有一个好处，就是可以更方便地实现观战，录像的存储、回放，以及基于录像文件的后续处理。 缺点 最致命的缺点是网络要求比较高，帧同步是锁帧的，如果有网络的抖动，一段时间调用次数不稳定，网络命令的延迟就会挤压，引起卡顿。 它的反外挂能力很弱，帧同步的逻辑都在客户端里面，你可以比较容易的修改它。但为什么《王者荣耀》敢用帧同步，一方面是因为当时立项的时候开发周期很短，半年时间要做上线，要有几十个英雄，存在时间的压力，另一方面，MOBA类游戏不像数值成长类的游戏，它的玩法是基于单局的，单局的作弊修改，顶多影响这一局的胜负，不会存档，不会出现刷多少钱刷多少好的装备的问题，而且作弊之后我们也很容易监测到，并给予应有的惩罚，所以我们认为这不是致命的缺点。 它的断线重回时间很长，相信台下也有很多王者玩家，也曾碰到过闪退以后重回加载非常长的情况，甚至加载完以后游戏也快结束了，这是帧同步比较致命的问题。 它的逻辑性能优化有很大的压力。大家应该没有见到哪一款大型游戏是用帧同步来做的，因为这些游戏的每一个逻辑对象都是需要在客户端进行运算的。如果你做一个主城，主城里面有上千人，上千人虽然玩家看不到它，但游戏仍然需要对他们进行有效的逻辑运算，所以帧同步无法做非常多的对象都需要更新的游戏场景。 三座大山同步问题帧同步的技术原理相当简单，从一个相同初始的状态开始，获得一个相同的输入，往下一帧一帧执行，执行时所有代码的流程走得都是一样的，这个结果调用完了以后，又有一个新状态，完成循环。相同的状态，相同的流程，不停的这样循环下去。这个原理虽然简单，但是你要去实现它的时候，还是会有很多坑。右边写的是实现要点，这是我们在解决第一座大山经验的总结，也是我们实际开发过程当中做的事情。 首先，我们所有的运算都是基于整数，没有浮点数。浮点数是用分子分母表达的。 其次，我们还会用到第三方的组件，帧组件也要需要进行一个比较严格的甄别。我们本身用的公司里面关于时间轴的编辑器里面，最初也是是浮点数，我们都是进行重写改造的。 再次，很多人初次接触帧同步里面的问题，就是在写逻辑的时候和本地进行了关联、和“我”相关，这样就导致不同客户端走到了不同的分支。实际上，真正客户端跟逻辑的话，要跟我这样一个概念无关。 接下来还有随机数，这个要严格一致。这是实现的要点，严格按照这上面的规则写代码还是有可能不同步，本身就很难杜绝这样的问题。最后，真正重要的是开发者要提升自己发现不同步问题的能力，什么时候不同步了，不同步你还要知道不同步在什么点，这是最关键的。你需要通过你的经验和总结提升这样的能力。这个能力还是通过输出来看不同客户端不同输出，找到发生在什么点。 比如在《王者荣耀》里，我们看到不同步的现象应该是这样，有人对着墙跑，你看到的和别人玩的游戏是不一样的，就像进入平行世界。 最开始测试《王者荣耀》的，我们希望不同步率达到1%，就是100局里面有1局出现不同步，我们就算游戏合格，但实际上对于这么大体量游戏来说，这个比率是有问题的，经过我们不停的努力，现在已经控制在万分之几，一万局游戏里面，可能有几局是不同步的。这个问题不一定是代码原因或者没有遵循这些要点才出现的，有可能是你去修改内存，你去加载资源的时候，本地资源有损害或者缺失，或者是异常。说白了，你没有办法往下执行，大家走了不同分支，这都可能引起最终是不同步的。 如果你不同步概率比较低，到了这种万分之几概率的时候，很难通过测试来去还原，去找到这样不同步的点。 最开始我们游戏出现不同步的时候，就是在周末玩家开黑多的时候，随着你的概率越来越低，基本上你就自己就还原不出这些问题了，只能依靠玩家帮你还原这样的场景，来分析这样的不同步问题。同步性遵循这样的要点，按照这样的思路来写，加上你不同步定位的能力，有了监控手段能够去发现，这个问题其实就解决了。解决之后，你就可以好好享受帧同步的开发优势。 网络《王者荣耀》技术测试版本出台的时候，延迟非常大，而且还是卡顿，现在看一下帧同步里面比较特别的地方。帧同步有点像在看电影，它传统的帧同步需要有buffer，每个玩家输入会转发给所有客户端，互相会有编号，按顺序输入帧。 比如我现在已经收到第N帧，只有当我收到第N+1帧的时候，第N这一帧我才可以执行。服务器会按照一定的频率，不同的给大家同步帧编号，包括这一帧的输入带给客户端，如果带一帧给你的数据你拿到之后就执行，下一帧数据没来就不能执行，它的结果就是卡顿。 网络绝对理想的情况下还好，但现实的网络环境不是这样的。帧同步要解决问题就是调试buffer，以前有动态的buffer，它有1到n这样的缓冲区，根据网络抖动的情况，收入然后放到队列里面。 这个buffer的大小，会影响到延迟和卡顿。如果你的buffer越小，你的延迟就越低，你拿到以后你不需要缓冲等待，马上就可以执行。但是如果下一帧没来，buffer很小，你就不能执行，最终导致的结果你的延迟还好，但是卡顿很明显。 如果调到帧同步的buffer，假如我们认为网络延迟是1秒，你抖动调到1秒，那得到的结果虽然你画面不抖动了，但是你的延迟极其高。如果连最坏的网络情况都考虑进去，buffer足够大，那么记过就跟看视频是一样的，平行的东西，看你调大条小。一些局部的措施我们都做过，都是一样的问题。 具体我们怎么优化卡顿的问题呢？ 刚才提到该帧同步与buffer，这个buffer可以是1也可以到n，我们要解决我们的延迟问题，我们就让buffer足够小。事实上《王者荣耀》最后做到的buffer是零，它不需要buffer，服务器给了我n，马上知道是n，我收到n，我知道下一次肯定是n+1，所以我收到n之后马上就把n这一帧的输入执行了。 那么为什么不卡顿了，画面不抖动了？ 最后一个关键点，是本地插值平滑加逻辑与表现分离。客户端只负责一些模型、动画、它的位置，它会根据绑定的逻辑对象状态、速度、方向来进行一个插值，这样可以做到我们的逻辑帧率和渲染帧率不一样，但是做了插值平滑和逻辑表现分离，画面不抖了，延迟感也是很好的。 做了这些后，我们还把TCP换成UDP，在手机环境下，弱网的情况下，TCP很难恢复重连，所以最后用了UDP来做。整体来说，在网络好的情况下，它延迟也是很好的，在网络比较差的情况下做插值，也是传统CS的表现。 我们经常见到角色A和B，有些客户端A在左B在右，有些是A在右B在左，帧同步逻辑上面AB之间的距离和坐标都是完全一样，但是画面上看到他们可能会不重合，那就是你把它们分离之后的表现。网络极其好的情况下，它应该是重合的，但是在网络差的情况下，可能会有些偏差。这里面是最重要的一块优化。 性能的优化本身帧同步逻辑上面在优化上面存在一些缺点，所有的角色都需要进行运算。这方面我们也是借助Unity的特性，如果你想追求性能上的极致，有些东西你需要寻求好的方式。 第一点是热点的处理。 我们是不用反射的，它都有GC性能开销，我们的做法里面，会把对象的显示隐藏放在不同的渲染层里面，尽量让整个游戏帧率是平滑的过程。还有我们本身有自己的系统，比如AI，在《王者荣耀》这样的多角色游戏中，你如果想要做出比较好的体验，那么AI就要做得比较复杂。 而要去优化热点，我觉得就只有这三个步骤可以走。 首先，从程序的结构上面能找到更优的，它的优化效果就是最明显的；其次，如果你的结构都是用的最好，就去挖掘局部的算法，调整你代码的一些写法。最后，如果局部的算法都已经调到最优还是没有什么办法，那只有一条路，就是牺牲整个质量，就是分帧降频。 第二点是GC，这块刚才说不用反射，还有装箱和拆箱的行为也是尽量少用。Unity指导过我们的优化，从GC上面的考虑，他们建议每一帧应该在200个字节以内是比较好的状态，其实很难做到，王者也是每一帧在1k左右，很难做到200。 第三点是Drawcall，这些传统的优化手段大家都用的很熟了。 第四点是裁剪，帧同步里面是不能裁剪的，表现里面我看不到的可以降低频率或者不更新它，这在表现里面可以做的。 第五点是3DUI的优化，比如《王者荣耀》的血条、小地图上面叠的元素等等，这些UI都比较丰富，这块我们用了31UI的方式来优化，没有用UGUI里面进行血条方面的处理。 我们也牺牲了一些东西，我们把所有东西都加载了，在游戏过程当中，我们希望不要有任何IO行为，包括输出我们都是要布局的。你处理的决策和复杂度，如果在一帧里面放出100颗子弹，在放100颗子弹的时候一定要掉帧的，一定要在力所能及的时候把这些东西做到极致。上面提的是我们的第一代，也是在去年5月份以前做的优化方案。5月份以后，我们还做了另外一件事情：GameCore。 首先，为什么我们觉得iOS比安卓的优化效率高一些，一方面是iOS的CPU架构包括系统确实都优化的比较好，另一方面我们用的Unity4.6，在IOS下面它本身效率高一些，在安卓端的机器各种各样，性能也是千差万别，我们只能用性能比较差的方式。 因为我们已经做到逻辑和表现的分离，那么我们能不能把逻辑独立出来，做成一个C++的东西，实际上我们在去年开始已经在这样做了。做之前也测试过C++和Mono性能的差别，大概是2.5左右，本身我们的逻辑占比游戏消耗20%多，逻辑不是一个大头，我们做了这件事情之后，还是有效的，帧率提升了2到3帧，花的时间很长。 其次，做GameCore以后最明显的变化是我们以前逻辑上的GC没有了，我们有自己内存的管理、对象的管理，包括里面所有的容器类这些东西都是我们自己实现的，包括反射整个一套。它有了自己的内存管理，本身的效率就会比较高，这就已经是一个比较明显的优势了。 再次，有了GameCore之后，又多了很多应用场景，这个东西就是玩法的服务器版本，应用场景运行服务器要做很多的分析，还有第三方使用都是可以的。 最后，GameCore还有可以扩展多线程的潜力。 status sync这时候咱们再来谈谈状态同步（status sync）。怎么说呢，其实状态同步并非字面上的意思，而是以前一个标准化的网络同步方案。毕竟按字面意思的话，帧同步/帧锁定同步，人家同步的操作数据难道就不是状态了？游戏中了包含各种状态，状态同步会在“合适”的时间，”合适”的间隔，”合适”的数据切分下，将一个客户机的状态同步到其他客户机上。所谓“合适”，即是没谱，也就是不定时不定期，有数据就算没数据就算了，所以，无法保证每个客户机上看到的画面是一致的，只能保证他们看到的内容不会差别特别大。另外，为了减少同步的数据量，它通常只会将变化的数据进行同步，所以需要对数据进行切分以判断哪些有变化，哪些需要同步。因此，ECS自带的数据切分就对“状态同步天生亲和”，只要给Component写一个Dirty机制，然后同步所有Dirty的Component就好了，不需要重新设计同步规则。但是，即使是这个狭义的状态同步（status sync），它其实和按帧同步（frame sync）也是不矛盾的。只要服务端先集齐一帧所有客户端发送的状态，再统一归结成一个数据包广播到所有客户端，它就可以拥有和frame sync完全一致的特性。也就是说，status sync和frame sync其实是不冲突的，你完全可以搞出frame status sync（以帧为单位的状态同步）来。所以，我个人建议大家舍弃掉“帧同步”“状态同步”这种词，而改成更少歧义的“帧锁定同步”和“非帧锁定同步”（或者lockstep同步和非lockstep同步）。如果提到了我上面定义的这种不是lockstep的frame sync（其实LOL就是这样的），就干脆直接说“不是lockstep的按帧同步”。 状态同步的优点 它的安全性非常高，外挂基本上没有什么能力从中收益。 状态同步对于网络的带宽和抖动包有更强的适应能力，即便出现了200、300的输入延迟再恢复正常，玩家其实也感受不到不太舒服的地方。 在开发游戏过程中，它的断线重连比较快，如果我的游戏崩溃了，客户端重启之后只需要服务器把所有重要对象的状态再同步一次过来，重新再创建出来就可以了。 它的客户端性能优化优势也比较明显，比如优化时可以做裁剪，玩家看不到的角色可以不用创建，不用对它进行运算，节省消耗。 缺点第一，它的开发效率相对帧同步而言要差一些，很多时候你需要保证服务器与客户端的每一个角色对象的状态之间保持一致，但事实上你很难做到一致。 比如客户端和服务器端更新的频率，对优化的一些裁剪，网络的抖动等等，你要让每一个状态在客户端同步是比较难的，而你要想调试这些东西，来优化它带来的漏洞、不一致的现象，花费的周期也会比较长，想要达到优化好的水平也比较难。 第二，它比较难做出动作类游戏打击感和精确性。比如说你要做一个射击类角色，他的子弹每秒钟要产生几十颗，基于状态同步来做是比较难的，因为系统在很短时间内，会产生很多数据，要通过创建、销毁、位置运算来同步。 第三，它的流量会随着游戏的复杂度，而逐渐增长，比如角色的多少。我们做《王者荣耀》时，希望在3G、4G的网络条件下也能够玩PvP，所以我们希望它对付费流量的消耗能控制在比较合理的水平，不希望打一局游戏就消耗几十兆的数据流量。 lockstep无法降低游戏延迟，反而还会增加延迟。lockstep或者说按帧同步frame sync，保证的是画面的一致性。延迟只能靠优化网络速度和本地预测降低。 同步精度和同步方式无关，只和服务器帧的频率和同步频率有关。频率越高精度自然就越高，就越不容易出现暂时性的画面错误。是否能通过录像文件重放，只需要“伪随机数”和“固定间隔运行”即可，和“同步”无关。以前的FC模拟器就有完整的录像功能，难不成那也是lockstep了？ “lockstep（步调一致）”缩写成”lock（锁）”这个缩写本身就是错的这件事，就不用提了。毕竟这个缩写错误只会导致迷惑，并不会导致歧义。 lockstep不是MOBA游戏的唯一解，本来也不是。但是按帧同步确实是必须的。 帧同步的几个难点保证客户端独自计算的正确，即一致性帧同步的基础，是不同的客户端，基于相同的操作指令顺序，各自执行逻辑，能得到相同的效果。就如大家所知道的，在unity下，不同的调用顺序，时序，浮点数计算的偏差，容器的排序不确定性，coroutine内写逻辑带来的不确定性，物理浮点数，随机数值带来的不确定性等等。有些比较好解决，比如随机数值，只需要做随机种子即可。有些注意代码规范，比如在帧同步的战斗中，逻辑部分不使用Coroutine，不依赖类似Dictionary等不确定顺序的容器的循环等。还有最基础的，要通过一个统一的逻辑tick入口，来更新整个战斗逻辑，而不是每个逻辑自己去Update。保证每次tick都从上到下，每次执行的顺序一致。浮点数计算无法保证一致性，我们需要转换为定点数。关于定点数的实现，比较简单的方式是，在原来浮点数的基础上乘1000或10000，对应地方除以1000或10000，这种做法最为简单，再辅以三角函数查表，能解决一些问题，减少计算不一致的概率，但是，这种做法是治标不治本的方式，存在一些隐患（举个例子，例如一个int和一个float做乘法，如果原数值就要*1000，那最后算出来的数值，可能会非常大，有越界的风险。）。是使用实现更加精确和严谨，并经过验证的定点数数学库。对于计算的不确定性，我们也有一些小的隐患，就是，我们用到了Physics.Raycast来检测地面和围墙，让人物可以上下坡，走楼梯等高低不平的路，也可以有形状不规则的墙。这里会获得一个浮点数的位置，可能会导致不确定性，这里，我们用了数值截断等方式，尽量规避，经过反复测试，没有出现过不一致。 帧同步游戏中，由于需要“每一帧”都要广播数据，所以广播的频率非常高，这就要求每次广播的数据要足够的小。最好每一个网络帧，能在一个MTU以下，这样才能有效降低底层网络的延迟。同样的理由，我们为了提高实时性，一般也倾向于使用UDP而不是TCP协议，这样底层的处理会更高效。但是，这样也会带来了丢包、乱序的可能性。因此我们常常会以冗余的方式——比如每个帧数据包，实际上是包含了过去2帧的数据，也就是每次发3帧的数据，来对抗丢包。也就是说三个包里面只要有一个包没丢，就不影响游戏。另外我们还会在RelayServer上保存大量的客户端上传的数据，如果客户端发现丢了包（如果乱序了也认为是丢包），那么就发起一次“下载”请求，从服务器上重新下载丢失了的帧数据包（这个可能会使用TCP）。这一切，都依赖于每个帧数据要足够的小。所以我们一般要求，每次客户端发送的数据，应该小于128字节。你可以大概计算一下，如果我们的游戏有4个玩家，我们的冗余是3帧，那么一个下行的网络帧数据包大小会到128x4x3=1536字节，而每秒我们发15个网络帧，那么占用的带宽会到1536x15=23,040字节/秒，加上一些底层协议包头也就是24kB/s，这个速度看起来已经要求手机是3G网络才能支持了（实测中GPRS一般很难稳定到这个速度）。另外一个降低广播数据量的做法就是自己编写序列化函数：一般现代编程语言，特别是面向对象的语言，都带有把对象序列化和反序列化的功能。我们要广播游戏操作的时候，这些操作往往也是一个个的“对象”，因此最简单的方法就是使用编程语言自带的序列化库来把对象转换成字节数组去广播。但是这些编程语言的默认序列化功能，为了实现诸如反射等高级功能，会把很多游戏逻辑所“不必要”的数据也序列化了，比如对象的类名、属性名什么的。如果我们自己去针对特定的数据对象来编写序列化函数，就没有这个问题了，我们可以仅仅提取我们想要的数据，甚至能合并和裁剪一些数据项，达到最小化数据长度的目的。 在网络游戏中，各个客户端的运行条件和环境往往千差万别，有的硬件好一些，有的差一些，各方的网络情况也不一致；时不时玩家的网络还会在游戏过程中，发生临时的拥堵，我们称之为“网络抖动”。网络游戏有时候还会需要有中途加入游戏的需求（乱入），有游戏录像和观看、快进录像的功能。这些功能，都可能导致客户端收到“过去时间”里的一堆网络帧，因此，客户端必须要有处理这些堆积起来的网络数据的能力。最简单的做法就是加速播放（快进）——如果收到网络数据处理完游戏逻辑后，然后在同一个渲染帧（同一次Update()函数里）内，马上继续收下一个网络数据，然后又立刻处理。这样往往能在一个渲染帧的时间内，加速赶上服务器广播的最新游戏进度。但是这样做也会有副作用，如果客户端积累的包太多（比如游戏已经开始玩了10分钟，新的用户中途加入），会导致这个用户长时间卡住，因为程序正在疯狂的下载积累的帧同步包和运算快进。为了解决这个问题，有些程序员会限制每一个渲染帧中所快进的操作次数，这样用户还是能看到画面有活动。如果实在要快进的进度太多，就要采用“快照”技术，通过定时保存的游戏状态数据，来减少快进的进度了。这个快照功能这里就不展开了。 一般来说，我们的客户端的渲染帧率都会大大高于网络帧的接收频率。如果我们每个渲染帧都去发送一次玩家操作（比如触摸屏上的手指位置），那么可能会导致发送的游戏操作远远大于收到的操作，这样做要么会让游戏操作堆积在服务器上，导致操作的严重延迟，要么导致下行的网络包非常大（服务器每次都把收到的所有操作一次下发），这样会让网络带宽占满，同样是会感觉延迟。不管怎么处理，都是不太好的结果。正确的做法应该是控制发包频率，最好是至少收到一个网络下行帧，才发送一个上行的游戏操作，避免堆积。另外，刚刚讲到的“快进”，如果我们在快速播放游戏逻辑的时候，每次播放同时也采集玩家输入去发送，那么同样会导致短时间内发送一大堆上行数据给服务器，而这些数据很可能客户端接收时产生大量的延迟。所以最好是在快进的时候不采集玩家的输入，因为玩家在看到快进过程中，实际上也很难有效的做出合理的反应，一个常见的做法，就是快进的时候，给游戏覆盖一个“等待”或“Loading”的蒙皮层，让玩家不可以输入操作。 关于流畅度的优化实时同步游戏最重要的是流畅，然而影响游戏流畅的因素很多，网络带宽的限制，CPU运算和渲染效率的限制，都是很大的问题。所幸游戏本身还是有很多可以取舍的因素，这让我们可以牺牲一些游戏不太重要的特性，去提高流畅度。 第一个可以用来交换流畅度的是“一致性”特性。我们做帧同步的目标是各个客户端都能看到一致的显示。但是游戏内容有很多，有一部分内容是可以容忍“不一致”的，比如我们做飞行射击弹幕游戏，满屏幕有很多子弹，而每一颗子弹本身的存在的时间很短，如果我们不是做对打的游戏（而是一起打电脑），那么这些子弹是可以不一致的。又比如我们做一个横版过关的配合游戏，几个玩家一起打电脑控制的怪物，大家关心的是怪物是怎么被打死的，而玩法本身又比较容忍不一致（横版动作游戏的攻击范围往往比较大），所以就算有些不一致问题也不大。在以上的条件下，我们就可以尝试，把更多的游戏逻辑，从网络帧的UpdateByNet()函数里面拿出去，放回到单机游戏中的Update()函数里去。这样就算网络有点卡，起码整个画面里还是有很多东西是不会被“卡住”的。但是必须注意的是，一般玩家控制的角色的动作，包括当前客户端控制的角色，还是应该从网络帧里面获得行为数据，因为如果玩家爱控制角色不一致的太多，整个游戏场面就会差更多。很多游戏中的怪物AI都是根据玩家角色来设定的，所以一旦玩家角色的行为是同步的，那么大多数的怪物的表现还是一致的。 第二个可以用来交换流畅度的特性是实时性。一般来说，我们都希望游戏中的角色控制是灵敏的，实时的。我们的游戏角色往往在会玩家输入操作后的几十分之一秒内，就开始显示变化。在帧同步游戏中，我们可以让玩家一输入完操作，就立刻发包，然后尽快在下一个收到的网络帧中收到这个操作，从而尽快的完成显示。然而，网络并不是那么稳定，我们常常会发现一会快一会慢，这样玩家的操作体验就非常奇怪，无法预测输入动作后，角色会在什么时候起反应。这对于一些讲求操作实时性的游戏是很麻烦的。比如球类游戏，控制的角色跑的一会儿快一会儿慢，很难玩好“微操”。要解决这个问题，我们一般可以学习传输语音业务的做法，就是接收网络数据时，不立刻处理，而是给所有的操作增加一个固定的延迟，后在延迟的时间内，搜集多几个网络包，然后按固定的时间去播放（运算）。这样相当于做了一个网络帧的缓冲区，用来平滑那些一会儿快一会儿慢的数据包，改成匀速的运算。这种做法会让玩家感觉到一个固定延迟：输入操作后，最少要隔一段时间，才会起反应。但是起码这个延迟是固定的，可预计的，这对于游戏操作就便捷很多了，只要掌握了提前量，这个操作的感觉就好像角色有一定的“惯性”一样：按下跑并不立刻跑，松开跑不会立刻停，但这个惯性的时间是固定的。 首先，是网络协议的选择。TCP和UDP的选择，我就不多说了，帧同步肯定要基于UDP才能保证更低的延迟。在UDP的选择上，我看网上有些文章，容易导入一个误区，即，我们是要用可靠传输的UDP，还是冗余信息的UDP。 基于可靠传输的UDP，是指在UDP上加一层封装，自己去实现丢包处理，消息序列，重传等类似TCP的消息处理方式，保证上层逻辑在处理数据包的时候，不需要考虑包的顺序，丢包等。类似的实现有Enet，KCP等。 冗余信息的UDP，是指需要上层逻辑自己处理丢包，乱序，重传等问题，底层直接用原始的UDP，或者用类似Enet的Unsequenced模式。常见的处理方式，就是两端的消息里面，带有确认帧信息，比如客户端（C）通知服务器（S）第100帧的数据，S收到后通知C，已收到C的第100帧，如果C一直没收到S的通知（丢包，乱序等原因），就会继续发送第100帧的数据给S，直到收到S的确认信息。有些文章介绍的时候，没有明确这两者的区别，但是这两种方式，区别是巨大的。可靠传输的UDP，在帧同步中，个人认为是不合适的，因为他为了保证包的顺序和处理丢包重传等，在网络不佳的情况下，delay很大，将导致收发包处理都会变成类似tcp的效果，只是比TCP会好一些。必须要用冗余信息的UDP的方式，才能获得好的效果。并且实现并不复杂，只要和服务器商议好确认帧和如何重传即可，自己实现，有很大的优化空间。例如，我们的协议定义类似如下： 这里简单说一下，对于这种收发频繁的消息，如果使用protobuf，会造成每个逻辑帧的GC，这是非常不好的，解决方案，要么对protobuf做无GC改造&gt;，要么就自己实现一个简单的byte[]读写。无GC改造工程太大，感觉无必要，我们只是在战斗的几个频繁发送的消息，需要自己处理一下byte[]读写即可。 此处补充一下，kcp+fec的模式，可以比冗余方式，有更好的效果，我之前并没有仔细研究过这个模式，不过可以推荐大家看一下，如果有用过朋友分享下结论就更好了。 因为我们项目早期，服务器定下了使用enet，我评估了一下，反正使用冗余包的方式，所以没有纠结enet或kcp，后续其实想改成kcp，服务器不想再动，也就放下了。 enet麻烦的地方是，enet的ipv6版本，是一个不成熟的pull request，enet作者没有merge（并且存在好几个ipv6的pull request），我不确定稳定性，还好看了下commit，加上测试下来，没有太大问题。KCP我没有评估过ipv6的问题，不过github上有C#版本，改一下ipv6支持应该很简单。 逻辑和显示的分离这块很多讲帧同步的文章都提过了。我在前面讲技能编辑器的时候，也提过，配置的数据和显示要分离，在战斗中，战斗的逻辑，也要和显示做到分离。 例如，最基本，我们动作切换的逻辑，是基于自己抽象的逻辑帧，而不是基于animator中一个clip的播放。比如一个攻击动作，当第10帧的时候，开始出现攻击框，并开始检测和敌人受击框的碰撞，这个时候的第10帧，必须是独立的逻辑，不能依赖于animator播放的时间，或者AnimatorStateInfo的normalizedTime等。甚至，当我们不加载角色的模型，一样可以跑战斗的逻辑。如果抽离得好，还可以放到服务器跑，做为战斗的验证程序，王者荣耀就是这样做的。 联机如何做到流畅战斗前面所有的准备，最终的目的，都是为了战斗的流畅。特别是我们这种Act游戏，或者格斗类游戏，对按键以后操作反馈的即时性，要求非常高，一点点延迟，都会影响玩家的手感，导致玩家的连招操作打断，非常影响体验。我们对延迟的敏感性，甚至比MOBA类游戏还要高，我们要做到好的操作手感，还要联机战斗（PVP，组队PVE），都需要把帧同步做到极致，不能因为延迟卡住或者操作反馈出现变化。 我们也不能用缓存服务器确认操作的方式，也就是一些游戏做的指令buffer。具体描述，王者荣耀的分析文章，讲得很具体了。这也是他们说的模式，这个模式能解决一些小的网络波动，对一些操作反馈不需要太高的游戏，例如有些游戏攻击前会有一个比较长的前摇动作，这类游戏，用这种方式，应该就能解决大部分问题。但是这种方式还是存在隐患，即使通过策略能很好地动态调整buffer，也还是难以解决高延迟下的卡顿和不流畅。王者荣耀优化得很好，他们说能让buffer长度为0，文章只提到通过平滑插值和逻辑表现分离来优化，更细节的没有提到，我不确定他们是否只是基于这个方式来优化的。目前也没有看到更具体的分析。 指令buffer的方式，也不能满足我们的需求，或者说，我没有找到基于此方式，能优化到王者荣耀的效果的办法。我也测试过其他moba和act，arpg类游戏的联机，在高延迟，网络波动情况下，没有比王者表现更好的了。 最后，在仔细研究了我们的需求后，找到一篇指导性的文章，非常适合我们。]]></content>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3dmax利用视口画布在窗口中绘制贴图]]></title>
    <url>%2F2019%2F04%2F21%2Fdraw-texture%2F</url>
    <content type="text"><![CDATA[打开场景文件场景中创建了5个球体。单机打开材质编辑器，单机一个材质球，将材质名称我们命名为黄色，然后将它的材质类型设置为VR材质单机漫反射后面的通道，添加一张黄色的贴图（选择位图可以自定义），选择贴图，单机打开添加完成，需要设置下面的参数单击转到父对象，设置一下它的反射颜色为白色，并且要勾选菲涅尔反射，设置细分的数值为20。可以打开它的背景显示。假如渲染的更加清晰一点，可以设置一下模糊为0.01。这样黄色材质就制作完成了，然后可以制作下一个材质，蓝色材质。为了操作方便，我们可以直接将它拖动复制，并将它命名为蓝色。我们需要在菜单中进行工具，需要将视口画布的工具找到。选择视口画布，并单击。此时会单击这样一个对话框。 然后看到有这样一些画笔可以进行设置。选择一个黄色的球体，接着单击绘制按钮。此时弹出这样一个对话框。选择第一项漫反射-贴图，选择完成，此时弹出层的对话框，在这个对话框可以单击添加新层的按钮。也就是说我们后面绘制的贴图都会呈现在新层上面这个时候设置一下画笔基本的参数。首先设置它的颜色为黑色，半径数值设置为10，设置硬度设置为25左右，设置完成。最后可以取消使用选项。并且设置它的遮罩。在这里可以单击选择它的遮罩，我们选择第三个。设置完成，然后在该球体上单击鼠标左键就可以进行绘制了当然我们现在是用鼠标进行绘制，我们也可以使用手写板进行绘制。设置我们在绘制进行中也可以调整。这样就制作完成。当然也可以更换它的遮罩等选项，这个绘制完成以后。这时候可以单击选择并移动工具。这样会弹出保存纹理层的对话框。这时候可以单击另存为PSD文件，并且将它进行保存。在这里我们可以将它保存为黄色.psd就可以了。同样的方法我们可以将另外的四个球体绘制出来。方法是一样的。都绘制完成以后，我们可以查看此时的绘制效果。我们看到已经出现5个卡通的球体。]]></content>
      <categories>
        <category>3DMax</category>
      </categories>
      <tags>
        <tag>3DMax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flash-effect]]></title>
    <url>%2F2019%2F04%2F17%2Fflash-effect%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[特性（Attribute）]]></title>
    <url>%2F2019%2F04%2F17%2Fattribute%2F</url>
    <content type="text"><![CDATA[特性（Attribute）是用于在运行时传递程序中各种元素（比如类、方法、结构、枚举、组件等）的行为信息的声明性标签。可以通过使用特性向程序添加声明性信息。一个声明性标签是通过放置在它所应用的元素前面的方括号（[ ]）来描述的。 特性（Attribute）用于添加元数据，如编译器指令和注释、描述、方法、类等其他信息。.Net 框架提供了两种类型的特性：预定义特性和自定义特性。 规定特性（Attribute）规定特性（Attribute）的语法如下：12[attribute(positional_parameters, name_parameter = value, ...)]element 特性（Attribute）的名称和值是在方括号内规定的，放置在它所应用的元素之前。positional_parameters 规定必需的信息，name_parameter 规定可选的信息。 预定义特性（Attribute）.Net 框架提供了三种预定义特性： AttributeUsage Conditional Obsolete AttributeUsage预定义特性 AttributeUsage 描述了如何使用一个自定义特性类。它规定了特性可应用到的项目的类型。 规定该特性的语法如下：12345[AttributeUsage( validon, AllowMultiple=allowmultiple, Inherited=inherited)] 其中： 参数 validon 规定特性可被放置的语言元素。它是枚举器 AttributeTargets 的值的组合。默认值是 AttributeTargets.All。 参数 allowmultiple（可选的）为该特性的 AllowMultiple 属性（property）提供一个布尔值。如果为 true，则该特性是多用的。默认值是 false（单用的）。 参数 inherited（可选的）为该特性的 Inherited 属性（property）提供一个布尔值。如果为 true，则该特性可被派生类继承。默认值是 false（不被继承）。 例如：123456[AttributeUsage(AttributeTargets.Class |AttributeTargets.Constructor |AttributeTargets.Field |AttributeTargets.Method |AttributeTargets.Property, AllowMultiple = true)] Conditional这个预定义特性标记了一个条件方法，其执行依赖于指定的预处理标识符。 它会引起方法调用的条件编译，取决于指定的值，比如 Debug 或 Trace。例如，当调试代码时显示变量的值。 规定该特性的语法如下：123[Conditional( conditionalSymbol)] Obsolete这个预定义特性标记了不应被使用的程序实体。它可以让您通知编译器丢弃某个特定的目标元素。例如，当一个新方法被用在一个类中，但是您仍然想要保持类中的旧方法，您可以通过显示一个应该使用新方法，而不是旧方法的消息，来把它标记为 obsolete（过时的）。 规定该特性的语法如下：1234[Obsolete( message)][Obsolete( message, iserror)] 其中： 参数 message，是一个字符串，描述项目为什么过时的原因以及该替代使用什么。 参数 iserror，是一个布尔值。如果该值为 true，编译器应把该项目的使用当作一个错误。默认值是 false（编译器生成一个警告）。 创建自定义特性（Attribute）.Net 框架允许创建自定义特性，用于存储声明性的信息，且可在运行时被检索。该信息根据设计标准和应用程序需要，可与任何目标元素相关。创建并使用自定义特性包含四个步骤： 声明自定义特性 构建自定义特性 在目标程序元素上应用自定义特性 通过反射访问特性 最后一个步骤包含编写一个简单的程序来读取元数据以便查找各种符号。元数据是用于描述其他数据的数据和信息。该程序应使用反射来在运行时访问特性。 声明自定义特性一个新的自定义特性应派生自 System.Attribute 类。例如：123456789// 一个自定义特性 BugFix 被赋给类及其成员[AttributeUsage(AttributeTargets.Class |AttributeTargets.Constructor |AttributeTargets.Field |AttributeTargets.Method |AttributeTargets.Property,AllowMultiple = true)]public class DeBugInfo : System.Attribute 在上面的代码中，我们已经声明了一个名为 DeBugInfo 的自定义特性。 构建自定义特性让我们构建一个名为 DeBugInfo 的自定义特性，该特性将存储调试程序获得的信息。它存储下面的信息： bug 的代码编号 辨认该 bug 的开发人员名字 最后一次审查该代码的日期 一个存储了开发人员标记的字符串消息 我们的 DeBugInfo 类将带有三个用于存储前三个信息的私有属性（property）和一个用于存储消息的公有属性（property）。所以 bug 编号、开发人员名字和审查日期将是 DeBugInfo 类的必需的定位（ positional）参数，消息将是一个可选的命名（named）参数。 每个特性必须至少有一个构造函数。必需的定位（ positional）参数应通过构造函数传递。下面的代码演示了 DeBugInfo 类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657using System;using System.Reflection;// 一个自定义特性 BugFix 被赋给类及其成员[AttributeUsage(AttributeTargets.Class |AttributeTargets.Constructor |AttributeTargets.Field |AttributeTargets.Method |AttributeTargets.Property,AllowMultiple = true)]public class DeBugInfo : Attribute&#123; private int bugNo; private string developer; private string lastReview; public string message; public DeBugInfo(int bg, string dev, string d) &#123; bugNo = bg; developer = dev; lastReview = d; &#125; public int BugNo &#123; get &#123; return bugNo; &#125; &#125; public string Developer &#123; get &#123; return developer; &#125; &#125; public string LastReview &#123; get &#123; return lastReview; &#125; &#125; public string Message &#123; get &#123; return message; &#125; set &#123; message = value; &#125; &#125;&#125; 应用自定义特性通过把特性放置在紧接着它的目标之前，来应用该特性：1234567891011121314151617181920212223242526[DeBugInfo(45, "Zara Ali", "12/8/2012", Message = "Return type mismatch")][DeBugInfo(49, "Nuha Ali", "10/10/2012", Message = "Unused variable")]class Rectangle&#123; // 成员变量 protected double length; protected double width; public Rectangle(double l, double w) &#123; length = l; width = w; &#125; [DeBugInfo(55, "Zara Ali", "19/10/2012", Message = "Return type mismatch")] public double GetArea() &#123; return length * width; &#125; [DeBugInfo(56, "Zara Ali", "19/10/2012")] public void Display() &#123; Console.WriteLine("Length: &#123;0&#125;", length); Console.WriteLine("Width: &#123;0&#125;", width); Console.WriteLine("Area: &#123;0&#125;", GetArea()); &#125;&#125; 通过反射访问特性注意：只有在调用GetCustomAttributes才开始创建特性实例。123456789101112131415161718192021222324252627282930313233343536373839class ExecuteRectangle&#123; static void Main(string[] args) &#123; Rectangle r = new Rectangle(4.5, 7.5); r.Display(); Type type = typeof(Rectangle); foreach (Object attributes in type.GetCustomAttributes(false)) &#123; DeBugInfo dbi = (DeBugInfo)attributes; if (null != dbi) &#123; Console.WriteLine("Bug no: &#123;0&#125;", dbi.BugNo); Console.WriteLine("Developer: &#123;0&#125;", dbi.Developer); Console.WriteLine("Last Reviewed: &#123;0&#125;", dbi.LastReview); Console.WriteLine("Remarks: &#123;0&#125;", dbi.Message); &#125; &#125; foreach (MethodInfo m in type.GetMethods()) &#123; foreach (Attribute a in m.GetCustomAttributes(true)) &#123; if (a is DeBugInfo) &#123; DeBugInfo dbi = (DeBugInfo)a; if (null != dbi) &#123; Console.WriteLine("Bug no: &#123;0&#125;, for Method: &#123;1&#125;", dbi.BugNo, m.Name); Console.WriteLine("Developer: &#123;0&#125;", dbi.Developer); Console.WriteLine("Last Reviewed: &#123;0&#125;", dbi.LastReview); Console.WriteLine("Remarks: &#123;0&#125;", dbi.Message); &#125; &#125; &#125; &#125; Console.ReadLine(); &#125;&#125;]]></content>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[houdini]]></title>
    <url>%2F2019%2F04%2F14%2Fhoudini%2F</url>
    <content type="text"><![CDATA[entagma免费的教程都是教基础的 程序化生成树 master class全集 https://cgpersia.com https://www.anastasiaopara.com/houdini-hive-siggraph-17 http://www.tokeru.com/cgwiki/index.php?title=Main_Page# https://www.bilibili.com/video/av29099924 很渣 空格键+数字键1：透视图空格键+数字键2：顶视图空格键+数字键3：前视图空格键+数字键4：左视图空格键+鼠标左键：旋转视图空格键+鼠标中键：移动视图空格键+鼠标右键：缩放视图空格键+F键：选中当前对象空格键+G键：选中当前对象并还原视口D键打开Display Option感觉最右边的那个按钮表示激活。]]></content>
      <categories>
        <category>Houdini</category>
      </categories>
      <tags>
        <tag>Houdini</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遮挡显示]]></title>
    <url>%2F2019%2F04%2F13%2Fshader-xray%2F</url>
    <content type="text"><![CDATA[3D游戏中主角会经常被墙壁之内的东西挡住，此时为了达到突出主角的效果，会做一些特殊处理让主角显示出来。光栅化阶段的后期，会有一个深度测试和颜色混合的过程，此效果就是针对这个过程进行的一种特殊处理。 深度就是该像素点在3D世界中距离摄像机的距离，离摄像机越近，深度值越小。 深度测试：在屏幕上每一个点，都存放在一个缓存列表。如果启用深度缓存Zwrite On，那么在绘制每个像素钱，底层会将当前点的深度值和已经存储在这个位置的点的深度值进行比较。如果新的点的深度值小于原来点的深度值，则新的点会代替原来的点。反之新的点会被遮挡，其颜色值和深度值会被丢弃。 实现步骤： 定义了2个pass，一个输出纯色，一个输出模型色 当对象没有被遮挡是，先执行的纯色pass输出了纯色，然后模型的pass输出了模型色，最终纯色被替换显示正常模型。 当对象被墙壁挡住是，如果我们什么也不做，纯色pass输出的颜色和模型pass输出的颜色都会被墙壁代替，因为它们的深度值逗逼墙壁深度值大 当对象被墙壁遮挡住时，我们想要的效果是显示纯色，那么我们可以关闭纯色的ZWrite，就是不将它的深度值写入深度缓存，此时它的深度测试参数ZTest默认是LEqual，而它的深度值是大于墙壁的，所以也不会显示。 被挡住时，模型色已经被剔除了，最终的颜色混合为Blend SrcAlpha OneMinusSrcAlpha最终色 = 纯色rgb纯色a + 墙壁rgb(1-纯色a) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182Shader "Custome/XRay"&#123; Properties &#123; _Color("Color", Color)=(1,1,1,1) _MainTex ("Texture", 2D) = "white" &#123;&#125; _AfterColor("After Color", Color)=(0.435,0.851,1,0.419) &#125; SubShader &#123; Tags&#123;"Queue"="Geometry+1" "RenderType"="Opaque"&#125; LOD 300 Blend SrcAlpha OneMinusSrcAlpha Pass &#123; ZTest GEqual // 深度测试，大于等于当前最小中的值就会显示 ZWrite Off CGPROGRAM #pragma vertex vert #pragma fragment frag #include "UnityCG.cginc" struct appdata &#123; float4 vertex : POSITION; &#125;; struct v2f &#123; float4 vertex : SV_POSITION; &#125;; v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); return o; &#125; fixed4 _AfterColor; fixed4 frag (v2f i) : SV_Target &#123; return _AfterColor; &#125; ENDCG &#125; Pass &#123; ZTest LEqual CGPROGRAM #pragma vertex vert #pragma fragment frag #include "UnityCG.cginc" struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; &#125;; struct v2f &#123; float4 vertex: SV_POSITION; float2 uv : TEXCOORD0; &#125;; v2f vert(appdata i) &#123; v2f o; o.vertex = UnityObjectToClipPos(i.vertex); o.uv = i.uv; return o; &#125; sampler2D _MainTex; fixed4 _Color; fixed4 frag(v2f i):SV_Target &#123; fixed4 c = tex2D(_MainTex, i.uv) + _Color; return c; &#125; ENDCG &#125; &#125;&#125;]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用静态分析优化Unity代码]]></title>
    <url>%2F2019%2F04%2F13%2Fstatic-analyze-unity-code%2F</url>
    <content type="text"><![CDATA[UnityEngineAnalyzerUnityEngineAnalyzer is a set of Roslyn analyzers that aim to detect common problems in Unity3D C# code. Unity3D makes it easy for us to make cross platform games, but there are hidden rules about performance and AOT, which might only come with experience, testing or reading the forums. It is hoped that such problems can be caught before compilation. Building CLI executableCLI requires .NET Core 2.1 1dotnet publish -c Release -r win10-x64 or1dotnet publish -c Release -r ubuntu.16.10-x64 Comand Line InterfaceIn order to use the Command Line Interface (CLI), download the latest release of UnityEngineAnalyzer then unzip the archive (https://github.com/vad710/UnityEngineAnalyzer/releases). Open a Command Prompt or Powershell Window Run Linty.CLI.exe &lt;project path&gt; Observe the analysis results (Optional) In the same location as the project file are report.json and UnityReport.html files containig the results of the analysis Use command -e customexporter exporter2 ... to load custom exporters (Optional) configuration file path. Use command -c configureFilePath.json to load custom configurations Configuration json, allows to enable / disable analyzers (Optional) minimal severity for reports Use command -s Info/Warning/Error to defined used minimal severity for reporting Default is Warning (Optional) Unity version for check Use command -v UNITY_2017_1/UNITY_5_5/UNITY_4_0/... to Unity version For default analyzer will try to find ProjectVersion.txt file and parse version automatically. Example: &gt; Linty.CLI.exe C:\Code\MyGame.CSharp.csproj Visual Studio IntegrationIn Visual Studio 2017, go to Tools &gt; Nuget Package Manager &gt; Manage Nuget Packages for Solution.... Search for and install UnityEngineAnalyzer ConfigurationRight-click Analyzers to modify the severity or to disable the rule completely. Limitations HTML Report requires FireFox or XOR (Corss Origin Request) enabled in other browsers It doesn’t have rules for all of Mono’s AOT Limitations IL2CPP might change the limitations of AOT compilation Below is a sample of all the rules available in this analyzer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// AOT0001: System.Runtime.Remoting is not suppportedusing System.Runtime.Remoting;// AOT0002: System.Reflection.Emit is not supportedusing System.Reflection.Emit;using UnityEngine;class FooBehaviour : MonoBehaviour &#123; void Start() &#123; // AOT0003: Reflection only works for looking up existing types Type.GetType(""); // UEA0002: Using string methods can lead to code that is hard to maintain SendMessage(""); // UEA0006: Use of coroutines cause some allocations StartCoroutine(""); &#125; // UEA0001: Using OnGUI causes allocations and GC spikes void OnGUI() &#123; &#125; // UEA0003: Empty MonoBehaviour methods are executed and incur a small overhead void FixedUpdate() &#123; &#125; void OnTriggerEnter(Collider other) &#123; // UEA0004: Using CompareTag for tag comparison does not cause allocations if (other.tag == "") &#123; &#125; &#125; void Update() &#123; // UEA0005: Warning to cache the result of find in Start or Awake GameObject.Find(""); &#125;&#125; LicenseSee LICENSE]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RTR 4th Chapter2 图形渲染管线]]></title>
    <url>%2F2019%2F04%2F12%2FRTR-4th-Chapter2%2F</url>
    <content type="text"><![CDATA[整个渲染流水线的目标是实时地通过一个虚拟的camera，把光源，3D物体（包括上面的纹理）等渲染到2D图像上，流水线是并行化执行的，但是会出现stall，直到流水线中最慢的一个阶段完成它的任务整条流水线的架构，主要依次分为四个阶段：Application,Geometry Processing,Rasterization和Pixel Processing 每个阶段内部也有自己的pipeline的。我们要区别“阶段（functional stage）”和具体的实现结构，也就是说具体的某个实现结合可能合并了几个stage的内容到一个单元（unit），使得其过程时间消耗更短。 简要介绍Application阶段主要是在CPU上完成的，可以利用现代CPU的多和特性进行多线程优化，这一部分通常包括碰撞检测，全局加速算法，动画，物理模拟等待，这些取决于application的类型。Geometry Processing阶段主要处理转换（transforms），投影（projections）等等其他所有类型的几何操作，这个阶段计算了什么将会被渲染，怎样被渲染，在哪里被渲染，主要在GPU上完成。Rasterization阶段一般接受三个顶点，构建出一个三角形，找到所有被这个三角形包含着的像素点，然后把这些像素点传递给Pixel Processing阶段，这部分完全在GPU上完成。Pixel Processing阶段执行逐像素的程序，计算每个像素的color，也许会进行Z-Test等进行可见性判断，也许会进行blend操作等，这部分也完全在GPU上完成。 具体介绍每个阶段Application Stage这部分是开发者完全控制的阶段，因为这部分通常是基于CPU执行的，对于这部分的改变会影响后续阶段的performance（比如这里可以通过算法减低要被渲染的三角形的数量）但是现在在这部分平台上也可以使用计算着色器来借GPU的力量加速。这个阶段的最后，渲染图元（点、线、三角形）传入到Geometry Procssing阶段。这个部分是不能被分割成子部分的，因为这个是基于软件的实现方式，我们最多只能借助CPU的多核编写多线程程序来提升性能这个阶段也是用来处理外接设备的输入，两个物体的碰撞检测，加速算法（比如部分剔除算法） Geometry Processing用来负责逐三角形和逐顶点的操作。这部分可以被分为4个阶段：Vertex Shading，Projection，Clipping和Screen Mapping，下面逐一介绍：Vertex Shading：这个子阶段主要处理两个任务：1.计算顶点位置 2.计算每个顶点包含的其他性质，如发现，纹理坐标等以前会在这里实现逐顶点的光照，所以叫顶点着色器，现在顶点着色器变成了一个更加通用的用来设定与操作每个顶点相关的数据的计算单元（比如可以实现顶点动画等）这个阶段同时是转换坐标的阶段，把坐标从模型空间转换到世界空间，为了便于后续的投影和裁剪，在使用view transform转换到相机空间，同时保存每个顶点对应的material，normal等信息，接下来把它转换到一个单位(-1,-1,-1)(1,1,1)中进行投影（z也可能是[0,1]），首先是进行投影，投影可分为正交投影和透视投影，在进行顶点着色器的操作这个子阶段的输出（包含颜色，纹理坐标等）被送到Rasterization和Pixel Processing阶段被插值，用来计算表面的shading，这一步结束后，z-轴坐标不再存储在image中，而是z-buffer内，也就是说，这一步把3D-&gt;2D。 Optional Vertex Processing：这个阶段是可选的，而且不同的GPU对这部分的硬件支持程度也是不同的。简单来说依次是曲面细分，几何着色和流输出。 Clipping：只有那些全部部分在view volume中的渲染图元才能够pass这个阶段进入后续的阶段，使用投影矩阵意味着把transform后的图元裁剪单位立方体中。 Screen Mapping：把还是3D的坐标转换成屏幕坐标（屏幕坐标原点取决于API） Rasterization目标：找到所有被渲染图元包含或覆盖的像素点这部分分为两个部分：三角形建立和三角形遍历。把2D的顶点在屏幕空间转换到屏幕上的像素，在这里，三角形通过传入的3个点得以简历，最后把所有图元的像素点传递到Pixel Processing中。这个阶段通常是由硬件实现的。 Pixel Processing这个阶段通常分为2个子阶段，分别是Pixel Shading和MergeingPixel Shading：所有逐像素的计算都在这里完成，这里的输入是通过shading data的插值得到的。这里是基本上完全可编程的，通过自定义片元着色器（或者叫像素着色器）在GPU上完成光照，纹理等计算Mergeing：每个像素存储来一个叫颜色缓冲的地方，我们需要一个Merge阶段处理片元着色器出来的颜色和buffer中本来存着的颜色之间的关系，这部分也用来负责可见性问题（使用z-buffer算法）模版缓冲是一个离屏缓冲用来记录渲染图元的位置，每个像素通常为8bit，可以用来控制后续图元的渲染情况（通过模版测试的方式）]]></content>
      <categories>
        <category>RTR-4th</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity中的渲染优化技术]]></title>
    <url>%2F2019%2F04%2F11%2Funity-render-optimize%2F</url>
    <content type="text"><![CDATA[移动平台的特点和PC平台相比，移动平台上的GPU架构有很大的不同。由于处理资源等条件的限制，移动设备上的GPU架构专注于尽可能使用更小的带宽和公共能，也由此带来许多和PC平台完全不同的现象。例如，为了尽可能移除那些隐藏的表面，减少overdraw（即一个像素被绘制多次），PowerVR芯片（通常用于iOS设备和某些Android设备）使用了基于瓦片的延迟渲染（Tiled-based Deffered Rendering，TBDR）架构，把所有的渲染图像装入一个个瓦片（tile）中，再由硬件找到可见的片元，而只有这些可见片元才会执行片元着色器。另一些基于瓦片的GPU架构，如Adreno（高通的芯片）和Mali（ARM的芯片）则会使用Early-Z或相似的技术进行一个低精度的深度检测，来剔除那些不需要渲染的片元。还有一些GPU，如Tegra（英伟达的芯片），则使用了传统的架构设计，因为在这些设备上，overdraw更可能造成性能的瓶颈。由于这些芯片架构造成的不同，一些游戏往往需要针对不通的芯片发布不同的版本，以便对每个芯片进行更有针对性的优化。尤其是在Android平台上，不通设备使用的硬件，如图形芯片、屏幕分辨率等，大相径庭，这对图形优化提出了更高的挑战。相比于Android平台，iOS平台的硬件条件则相对统一。 影响性能的因素首先，在学习如何优化之前，我们得先了解影响游戏性能的因素有哪些。对于一个游戏来说，它主要需要使用两种计算资源：CPU和GPU。它们会互相合作，来让我们的游戏可以在预期的帧率和分辨率下工作。其中，CPU主要负责保证帧率，GPU主要负责分辨率相关的一些处理。据此，可以把造成游戏性能瓶颈的主要原因分成以下几个方面。 CPU 过多的draw call 复杂的脚本或者物理模拟 GPU 顶点处理 过多的顶点 过多的逐顶点计算 片元处理 过多的片元（既可能是由于分辨率造成的，也可能是由于overdraw造成的）。 过多的逐片元计算。 带宽 使用了尺寸很大且未压缩的纹理 分辨率过高的帧缓存 对于CPU来说，限制它的主要是每一帧draw call的数目。简单来说，就是CPU在每次通知GPU进行渲染之前，都需要提前准备好顶点数据（如位置、法线、颜色、纹理坐标等），然后调用一系列API把它们放到GPU可以访问到的指定位置，最后，调用一个绘制命令，来告诉GPU。而调用一次绘制命令的时候，就会产生一个draw call。过多的draw call会造成CPU的性能瓶颈，这是因为每次调用draw call时，CPU往往都需要改变很多渲染状态的设置，而这些操作是非常耗时的。如果一帧中需要的draw call数目过多的话，就会导致CPU把大部分时间都花费在提交draw call的工作上面了。当然，其他原因也可能造成CPU瓶颈，例如物理、布料模拟、蒙皮、粒子模拟等，这些都是计算量很大的操作。而对于GPU来说，它负责整个渲染流水线。它从处理CPU传递过来的模拟数据开始，进行顶点着色器、片元着色器等一系列工作，最后输出屏幕上的每个像素。因此，GPU的性能瓶颈和需要处理的顶点数目、屏幕分辨率、显存等因素有关。而相关的优化策略可以减少处理的数据（包括顶点数目和片元数目）、减少运算复杂度等方面入手。 CPU优化 使用批处理技术减少draw call数目 GPU优化 减少需要处理的顶点数目。 优化几何体 使用模型的LOD（Level of Detail）技术 使用遮挡剔除（Ovvlusion Culling）技术 减少需要处理的片元数目 控制绘制顺序 警惕透明物体 减少实时光照 减少计算复杂度 使用Shader的LOD（Level Of Deail）技术 代码方面的优化 节省内存带宽 减少纹理大小 利用分辨率缩放 在开始优化之前，我们首先需要知道是哪个步骤造成了性能瓶颈。而这可以利用Unity提供的一些渲染分析工具来实现。 Unity中的渲染分析工具Unity内置了一些工具，来帮助我们方便地查看和渲染相关的各个统计数据。这些数据可以帮助我们分析游戏渲染性能，从而更有针对性的进行优化。这些工具包括了渲染统计窗口（Rendering Statistics Window）、性能分析器（Profiler），以及帧调试器（Frame Debugger）。需要注意的是，在不同的目标平台上，这些工具中显示的数据也会发生变化。 渲染统计窗口渲染统计窗口主要包含了音频（Audio）、图像（Graphics）。这里我们只关心图像相关的渲染统计结果。渲染统计窗口中显示了很多重要的渲染数据，例如FPS、批处理数目、顶点和三角网格的数目等。 信息名称 描述 每帧的时间和FPS 在Graphic的右侧显示，给出了处理和渲染一帧所需的时间，以及FPS数目 Batches 一帧中需要进行的批处理数目 Saved by batching 合并的批处理数目，这个数字表明了批处理为我们节省了多少的draw call Tris和Verts 需要绘制的三角面片和顶点数目 Screen 屏幕的大小，以及它占用的内存大小 SetPass calls 渲染使用的Pass的数目，每个Pass都需要Unity的runtime来绑定一个新的Shader，这可能造成CPU瓶颈 Shadow casters 场景中有多少可以投射阴影的物体，一般这些物体都作为场景中光源 visible skinned meshed 渲染皮肤网格的数量 animations 正在播放动画的数量 性能分析器的渲染区域 性能分析器显示了绝大部分在渲染统计窗口中提供的信息，例如，绿线显示了批处理数目、蓝线显示了Pass数目等，同时还给出了许多其他非常有用的信息，例如，draw call数目、动态批处理/静态批处理的数目、渲染纹理的数目和内存占用等。结合渲染统计窗口和性能分析器，我们可以查看与渲染相关的绝大多数重要的数据。一个值得注意的想象是，性能分析器给出的draw call数目和批处理数目、Pass数目并不相等，并且看起来好像要大于我们估算的数目，这是因为Unity在背后需要进行很多工作，例如，初始化各个缓存、为阴影更新深度纹理和阴影映射纹理等，因此需要花费比“预期”更多的draw call。 帧调试器帧调试器的调试面板上显示了渲染这一帧锁需要的所有的渲染时间，在本例中，事件数目为41，而其中包含了36个draw call事件（其他渲染时间多为清空缓存等）。通过单击面板上的每个事件，我们可以在Game视图查看该时间的绘制结果，同时渲染统计面上的数据也会显示成截至当前事件为止的各个渲染统计数据。 其他性能分析工具对于Android平台来说，高通的Adreno分析工具可以对不同的测试机进行详细的性能分析。英伟达提供的NVPerfHUD工具来帮助我们得到几乎所有需要的性能分析数据，例如，每个draw call的GPU时间，每个shader话费的cycle数目等。对于iOS平台来说，Unity内置的分析器可以得到整个场景的花费的GPU时间。PowerVRaw的PVRUniSCo shader分析器也可以给出一个大致的性能评估。Xcode中的OpenGL ES Driver Instruments可以给出一些宏观上的性能信息，例如，设备利用率、渲染器利用率等。但相对于Android平台，对iOS的性能分析更加困难（工具较少）。而且PowerVR芯片采用了基于瓦片的延迟渲染器，因此，想要得到每个draw call话费的GPU时间是几乎不可能的。这是，一些宏观上统计数据可能更有参考价值。 减少draw call数目批处理的实现原理就是为了减少每一帧需要的draw call数目。为了把一个对象渲染到屏幕上， 动态批处理基本原理：每一帧把可以进行批处理的模型网格进行合并，再把合并后的模型数据传递给GPU，然后使用同一个材质对其渲染。动态批处理的一个好处是实现方便，另一个好处是，经过批处理的物体仍然可以移动，这是由于在处理每帧时Unity都会重新合并一次网格。 条件限制： 能够进行动态批处理的网格的顶点属性规模要小于900。例如，如果shader中需要使用顶点位置、发现和纹理坐标这3个顶点属性，那么要想让模型能够被动态批处理，它的顶点数目不能超过300。 多Pass的shader会中断批处理。在前向渲染中，我们有时需要使用额外的Pass来为模型添加更多的光照效果，但这样一来模型就不会被动态批处理了。 静态批处理Unity提供了另一种批处理方式，即静态批处理。相比于动态批处理来说，静态批处理适用于任何大小的几何模式。它的实现原理是，只在运行开始阶段，把需要进行静态批处理的模型合并到一个新的网络结构中，这意味着这些模型不可以在运行时刻被移动。但由于它只需要进行一次合并操作，因此，比动态批处理更加高效。静态批处理的另一个缺点在与，它往往需要占用更多的内存来存储合并后的几何结构。这是因为，如果在静态批处理钱一些物体共享了相同的网格，那么在内存中每一个物体都会对应一个该网格的复制品，即一个网格会变成多个网格在发送给GPU。如果这类使用同一网格的对象很多，那么这就会成为一个性能瓶颈了。例如，如果在一个使用了1000个相同模型的森林中使用静态批处理，那么，就会多使用1000倍的内存，这会造成严重的内存影响。 共享材质无论是静态批处理还是动态批处理，都要求模型之间需要共享同一个材质。但不同的模型之间总会需要有不同的渲染属性，例如，使用不同的纹理、颜色等。这是，我们需要一些策略来尽可能地合并材质。如果两个材质之间只有使用的纹理不同，我们可以把这些纹理合并到一张更大的纹理中，这张更大的纹理被称为是一张图集（atlas）。一旦使用了同一张纹理，我们就可以使用同一个材质，再使用不同的采样坐标对纹理采样即可。但有时，除了纹理不同外，不同的物体在材质上还有一些微小的参数变化，例如，颜色不同、某些浮点属性不同。但是，不管是动态批处理还是静态批处理，它们的前提都是要使用同一个材质。是同一个，而不是使用了同一种Shader的材质，也就是说它们指向的材质必须是同一个实体。这意味着，只要我们调整了参数，就会影响所有使用这个材质的对象，那么想要微小的调整怎么办？一种常用的方法就是使用网格的顶点（最常见的就是顶点颜色数据）来存储这些参数。经过批处理后的物体会被处理成更大的VBO发送给GPU，VBO中的数据可以作为输入传递给顶点着色器，因此，我们可以巧妙地对VBO中的数据进行控制，从而达到不通效果的目的。一个例子是，森林场景中所有的树使用了同一种材质，我们希望它们可以通过批处理来减少draw call，但不同树的颜色可能不同。这么，我们可以利用网格的顶点的颜色数据来调整。 批处理的注意事项减少需要处理的顶点数目优化几何体移除不必要的硬边以及纹理衔接，避免边界平滑和纹理分离。 模型的LOD技术遮挡剔除技术减少需要处理的片元数目控制绘制顺序时刻警惕透明物体减少实时光照和阴影节省带宽减少纹理大小 纹理的长宽比最好是正方形，长宽值最好是2的整数幂 多级渐远纹理技术（mipmapping）和纹理压缩。 利用分辨率缩放减少计算复杂度Shader的LOD技术代码方面的优化根据硬件进行缩放]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于物理的渲染]]></title>
    <url>%2F2019%2F04%2F11%2Fphysics-base-render%2F</url>
    <content type="text"><![CDATA[双向反射分布函数（BRDF）辐射率（radiance）是单位面积、单位方向上光源的辐射通量，通常用L表示，被认为是对单一光线的亮度和颜色评估。在渲染中，我们通常会基于表面的入射光线的入射辐射率 $ Li $ 来计算出射辐射率 $L{0}$ ，这个过程往往也称为着色（shading）过程。而要得到出射辐射率$L_{o}$，我们需要知道物体表面一点是如何和光进行交互的。而这个过程就可以使用BRDF（Bidirectional Reflectance Distribution Function，双向反射分布函数）来定量分析。在大多数情况下，BRDF可以用$f(I,v)$来表示，其中I为入射方向和v为观察方向（双向的含义）。这种情况下，绕着表面法线旋转入射方向或观察方向并不会影响BRDF的结果，这种BRDF被称为是各项同性（isotropic）的BRDF。与之对应的则是各项异性（anisotropic）的BRDF。 公式如下： $L{o}(p,w{o}) = \int\Omega(k{d}{c \over \pi} + k{s}{DGF \over 4(w{o} \cdot n)(w{i} \cdot n)})L{i}(p,w{i})(w{i} \cdot n)dw_{i}$ 这是PBR的核心，也是主要的劝退点。翻译成自然语言，大概是这样的： $输出颜色 = \int\Omega(漫反射比例{纹理颜色 \over \pi} + 镜面反射比例{镜面高光 x 几何遮蔽 x 菲涅尔效应 \over 4(view{Dir} \cdot normal)(lightDir \cdot normal)})光源颜色(lightDir,normal)dw_{i}$ 先解释下这个公式遗留的部分。半球积分($\int\Omega………dw{i}$) 放置反射探针在实时渲染中，我们经常会使用Cubemap来模拟物体的反射效果。例如，在赛车游戏中，我们需要对车身或车窗使用反射映射的技术来模拟它们的反光材质。然而，如果我们永远使用同一个Cubemap，那么，当赛车周围的场景发生较大变化时，就很容易出现“穿帮镜头”，因为车身或车窗的环境反射并没有随环境变化而变换。一种解决办法是可以在脚本中控制何时生成从当前位置观察到的Cubemap，Unity中提供了反射探针（Reflection Probes）。反射探针的工作原理和光照探针（Light Probes）类似，它允许我们在场景中的特定位置上对整个场景的环境反射进行采样，并把采样结果存储在每个探针上。当游戏中包含反射效果的物体从这些探针附近经过时，Unity会把这些邻近探针存储的反射结果传递给物体使用的反射纹理。如果物体周围存在多个反射探针，Unity还会在这些反射之间进行插值，来得到平滑渐变的反射效果。实际上，Unity会在场景中放置一个默认的反射探针，这个反射探针粗怒触了对场景使用的Skybox的反射结果，来作为场景的环境光照。如果我们需要让场景中的物体包含额外的反射效果，就需要放置更多的反射探针。反射探针同样有3种类型：Baked，这种类型的反射探针是通过提前烘培来得到该位置使用的Cubemap的，在游戏运行时反射探针中存储的Cubemap并不会发生变化。需要注意的是，这种类型的反射探针在烘培时同样只会处理那些静态物体（即那些被标志为Reflection Probe Static的物体）；Realtime，这种类型则会实时更新当前的Cubemap，并且不受静态物体还是动态物体的影响。当然，这种类型的反射探针需要花费更多的处理时间，因此，在使用时应当非常小心它们的性能。幸运的是，Unity允许我们从脚本中通过触发来精确控制反射探针的更新；最后一种类型是Custom，这种类型的探针即可以让我们从编辑器中烘培它，也可以让我们使用一个自定义的Cubemap来作为反射映射，但自定义的Cubemap不会被实时更新。]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十九章 效果架构(The Effects Framework)]]></title>
    <url>%2F2019%2F04%2F11%2FThe-Effects-Framework%2F</url>
    <content type="text"><![CDATA[概述一个渲染效果一般由以下部分组成：一个顶点和/或像素着色器，一个需要设置的设备状态列表，一个或更多的渲染通道（rendering passes）。此外，有一个能在不同级别的图形硬件上渲染效果的可靠机制通常是值得的（也就是说，有不同的可用的效果版本执行同样的效果或尽可能尝试执行同样的效果）。显然，所有这些必要的任务组合在一起成为一个效果。因此，一个合理的做法是，设法将这些任务封装到一个单元中。Direct3D效果构架提供了这样一个机制：将渲染效果的任务封装到一个效果文件。在效果文件中实现效果有两方面优势。其一，它允许我们不必重编译应用程序就能改变一个效果的执行。这是一种更新效果的过程，不管是修正一个bug，一些简单的加强，或者利用最新的3D硬件特性。第二，它将所有的效果组成部分封装到一个文件。这一章指导你用必要信息和步骤，编写和创建一个效果文件的。我们注意到效果文件象我们的HLSL程序一样可以写在任何ASCII文件中。 目标 理解一个效果文件的结构和组织 找到HLSL中的一些额外的对象 学习如何在效果文件中指定设备状态 学习如何创建并使用一个效果 通过学习一些例子程序，取得使用效果框架上的一些经验技术与传递（Techniques and Passes）一个效果文件由一个或多个技术组成。一个技术是用一个特殊的方法渲染一些特效。所以换句话说，一个效果文件提供了渲染相同特效的一个或多个不同的传递。为什么同样的效果需要几个不同实现呢？是的，一些硬件可能不支持一个效果的一种特定实现。因此，必需在不同硬件上实现相同效果的不同版本。注意：例如，我们可能实现一种效果的两个版本，一种用着色器实现而一种用固定管线实现。这样，那些有着色器（shader）支持的显卡用户能够利用着色器实现，而那些不支持着色器的用户仍然可以使用固定管线实现。可以在一个效果文件中实现所有版本的效果，这让我们更完整的封装了所有的效果，也是效果框架的目标之一 ―― 封装（encapsulation）。每种技术包括一次或多次渲染传递（passes）。一次渲染传递（rendering pass）在特定传递（pass）中封装了设备状态、采样器、和/或用于渲染几何体的着色器。注意：一个效果不仅限于可编程管线使用。例如，它可以使用固定功能管线控制设备状态，比如灯光、材质以及纹理。使用多次传递（multiple passes）的理由是，因为对每种特效，是通过使用不同的设备状态、着色器等等，对同样的几何体进行多次渲染来完成的。举例来说，回忆第8章 ，我们不得不在每帧里用不同的设备状态、多次渲染相同的几何体，以达到反射效果。 这个例子，是一个用两种技术实现的效果文件的框架，第一种技术包括一次传递而每二种技术包括两次传递:12345678910111213141516171819202122232425// effect.txttechnique T0&#123; // first and only pass for this technique pass P0 &#123; [specify pass device states, shaders, samplers, etc.] &#125;&#125;technique T1&#123; // first pass pass P0 &#123; [specify pass device states, shaders, samplers, etc.] &#125; // second pass pass P1 &#123; [specify pass device states, shaders, samplers, etc.] &#125;&#125; 更多HLSL内置对象（ More HLSL Intrinsic Objects）这是一些在HLSL中额外的内建对象类型。我们以前没有过早的提及，是因为它们主要用于效果框架。 纹理对象 HLSL内建纹理类型描述了一个IDirect3DTexture9对象。通过使用纹理对象我们可以直接地在效果文件中对特定的采样器阶段结合纹理。纹理对象有下面的可以访问的数据成员： type—纹理类型 (例如：2D, 3D) format—纹理的像素格式 width—纹理的宽度（单位像素） height—纹理的高度（单位像素） depth—纹理的深度（如果是3D纹理，单位像素） 注意：迄今为止我们仅仅使用纹理来存贮图形数据，但是当你学到更高级的技术，你会发现纹理可用来保存任意表格信息。换句话说，纹理仅是数据表，不是必须包含图形数据。例如，在碰撞映射（bump mapping）时我们用到一种叫做法线图的东东（normal map），就是一种在每个点上包括了法向量的纹理。 采样器对象与采样器状态我们在18章讨论了采样器对象，然而，效果框架定义了新的关键字：sampler_state。使用sampler_state关键字，我们能初始化一个采样器对象（即，直接在效果方件中设置采样器对象的纹理和状态）。下面的例子说明了这点：12345678910Texture Tex;sampler SO = sampler_state&#123; Texture = (Tex); // 纹理 // 采样器状态 MinFilter = LINEAR; MagFilter = LINEAR; MipFilter = LINEAR;&#125;; 这里我们给采样器S0的texture成员关联了纹理 Tex，并给状态成员设置了采样状态。我们直接明了的在效果文件中设置所有信息。 顶点与像素着色器对象（Vertex and Pixel Shader Objects）vertexshader 和 pixelshader是HLSL的内建类型，分别表示顶点着色器和像素着色器。它们在效果文件中表示特定顶点和/或像素着色器，用于一个特定的渲染传递(pass)。vertexshader和/或pixelshader类型在应用程序中用ID3DXEffect::SetVertexShader和ID3DXEffect::SetPixelShader函数分别设置。例如，在效果文件中，让Effect是一个有效的ID3DXEffect对象，让VS是一个有效的IDirect3DVertexShader9对象，以及让VSHandle是一个D3DXHANDLE（是vertexshader 对象的引用）。然后，我们可以通过如下写法初始化VSHandle所引用的顶点着色器：Effect-&gt;SetVertexShader(VSHandle, VS);当在应用程序中设置效果文件中的变量时，多数时候我们使用SetVertexShader 和 SetPixelShader。做为选择，我们可以直接在效果文件中写顶点和/或像素着色器。当使用一种特定的编译语法时，我们可以设置一个着色器变量。下面的例子展示了如何初始化一个pixelshader类型的变量ps。12345// 定义入口函数OUTPUT Main(INPUT input)&#123;...&#125;// 编译入口函数pixelshader ps = compile ps_2_0 Main(); 观察在pixelshader关键字之后的特定的版本名，接下来是着色器入口函数。注意，当用这种方式（style）初始化一个顶点或像素着色器对象时，入口函数必须定义在效果文件中。 最后，我们给一个特定传递关联一个着色器，如下：123456789101112// 定义入口函数OUTPUT Main(INPUT input)&#123;...&#125;// 编译入口函数vertexshader vs = compile vs_2_0 Main();pass P0&#123; // 给这个传递（pass）关联一个着色器（vs） vertexshader = (vs); ...&#125; 或者更简洁的：123456pass P0&#123; // 设置这个传递的顶点着色器，为入口函数" Main()"的顶点着色器 vertexshader = compile vs_2_0 Main(); ...&#125; 注意：这是一个相当有价值的论述，因此你至少要明白，你能用这样的语法来初始化一个vertexshader 和 pixelshader 类型：12vertexshader vs = asm &#123; /*assembly instructions go here */ &#125;;pixelshader ps = asm &#123; /*assembly instructions go here */ &#125;; 如果你用汇编语言来写着色器，你就用这种语法。 字符串最后，这是一个字符串对象，它的用法是这样地：1string filename = "texName.bmp"; 尽管没有任何HLSL的内建函数支持字符串类型，但它可以在应用程序中读取。这样，我们能进一步封装效果使用的数据文件，比如纹理文件名和X文件字。 注解 (Annotations)除我们已经描述过的语义符之外，注解可以用在变量上。注解在HLSL中是不使用的，但是它们可以被应用程序通过效果框架访问。它们仅仅服务于一个绑定 “note”的变量，这样应用程序就能够访问这个变量了。为注解加入了语法。下面一行举例说明：1texture tex0 &lt; string name = "tiger.bmp"; &gt;; 在这个例子中的注解是。它关联了一个字符串到变量tex0，即保存纹理数据的文件名。很明显，用相应的文件名注解一个纹理是有益的。注解可以使用下面函数被重新得到：1234D3DXHANDLE ID3DXEffect::GetAnnotationByName( D3DXHANDLE hObject, LPCSTR pName); pName是我们要操作的注解的名字，而hObject是注解所在的父块句柄，如一个technique、pass或者结构块。一旦我们有了一个注解的句柄，我们就能通过应用ID3DXEffect::GetParameterDesc得到有关它的信息。查看DirectX SDK文档以得到更多详细的内容。 效果文件的设备状态（ Device States in an Effect File）通常，为了正确执行一个效果，我们必须设置设备的状态，比如渲染状态、纹理状态、材质、灯光和纹理。将全部效果封装进一个文件使它有支持全部效果的能力，效果框架允许我们在效果文件中设置设备状态。设备状态被在渲染的传递部分（pass block）里设置，语法看起来象这样：State= Value;对于完整的状态的列表，在DirectX SDK文档的索引（index）中查找”states”，或者从SDK的目录（Contents）标签下，查找DirectX Graphics\Reference\Effect Reference\Effect Format\States考虑FillMode状态。如果你看了一下刚刚提到的SDK中的内容，值与D3DFILLMODE一样，但没有D3DFILL_前缀。如果我们在SDK文档中查找D3DFILLMODE，我们找到值：D3DFILL_POINT, D3DFILL_WIREFRAME, and D3DFILL_SOLID。因而，对于效果文件我们省略了前缀，并获得下列状态FillMode的有效值：POINT, WIREFRAME, 和 SOLID。例如，你可以在效果文件中这么写-：123FillMode = WIREFRAME;FillMode = POINT;FillMode = SOLID; 注意：在后面的小节中我们将在例子程序中设置几个设备状态。多数时候能够通过状态的名字猜到它的用途，但如果你想得到更详细的描述，请查看SDK文档。 创建效果效果用ID3DXEffect接口表示，我们用下面的D3DX函数创建它： 12345678910HRESULT D3DXCreateEffectFromFile( LPDIRECT3DDEVICE9 pDevice, LPCSTR pSrcFile, CONST D3DXMACRO* pDefines, LPD3DXINCLUDE pInclude, DWORD Flags, LPD3DXEFFECTPOOL pPool, LPD3DXEFFECT* ppEffect, LPD3DXBUFFER *ppCompilationErrors); pDevice—被创建的ID3DXEffect对象所关联的设备 pSrcFile—我们要编译的包括效果源代码的文本文件的名字（效果文件名） pDefines—这个参数是可选的，在本书中指定为null pInclude—ID3DXInclude接口指针。这个接口被设计成由应用程序执行，因而我们可以替换默认行为。通常，默认行为就挺好，我们可以指定null忽略这个参数。 Flags—编译效果文件中的shader的选项标志，指定0为没有标志。有效选项为：o D3DXSHADER_DEBUG—指示编译器写入调试信息o D3DXSHADER_SKIPVALIDATION—指示编译器不做任何代码检测。这只在你正在用到一个已知正常工作的shader时使用。o D3DXSHADER_SKIPOPTIMIZATION—指示编译器不执行任何优化。实际上这只用于调试时，当你不想让编译器对代码做任何更改时。 pPool—可选的ID3DXEffectPool接口指针，用于指定效果参数如何共享其它的效果实例。本例中指定null，表示我们不在参数与效果文件之间共享。 ppEffect—返回一个ID3DXEffect接口指针，表示被创建的效果。 ppCompilationErrors—返回一个包含错误代码字符串和消息的ID3DXBuffer指针。 这是一个调用D3DXCreateEffectFromFile的例子：12345678910111213141516171819202122232425// 修建效果ID3DXEffect* Effect = 0;ID3DXBuffer* errorBuffer = 0;hr = D3DXCreateEffectFromFile( Device, // 关联的设备 "effect.txt", // 效果源文件 0, // no preprocessor definitions 0, // no ID3DXInclude interface D3DXSHADER DEBUG, // 编译标记 0, // 不共享参数 &amp;Effect, // 返回创建效果的指针 &amp;errorBuffer); // 返回的错误信息// 输出错误信息if( errorBuffer )&#123; ::MessageBox(0, (char*)errorBuffer-&gt;GetBufferPointer(), 0, 0); d3d::Release&lt;ID3DXBuffer*&gt;(errorBuffer);&#125;if (FAILED(hr))&#123; ::MessageBox(0, "D3DXCreateEffectFromFile() - FAILED", 0, 0); return false;&#125; 设置系数（Setting Constants）因为对于顶点和像素着色器，我们需要从程序代码中初始化效果文件中的变量。代替使用常量表，就象我们在顶点和像素着色器中做的那样，ID3DXEffect接口中有内建的设置变量的方法。我们这里不会列出所有的设置不同类型变量的方法，因为要完全列出实在是大多了—请查看DirectX SDK文档以获得完整列表。这里是一个删节的列表：123456789101112131415161718192021222324252627282930313233343536HRESULT ID3DXEffect::SetFloat( D3DXHANDLE hParameter, FLOAT f);Sets a floating-point variable in the effect file identified by hParameter to the value f HRESULT ID3DXEffect::SetMatrix( D3DXHANDLE hParameter, CONST D3DXMATRIX* pMatrix);Sets a matrix variable in the effect file identified by hParameter to the value pointed to by pMatrix HRESULT ID3DXEffect::SetString( D3DXHANDLE hParameter, CONST LPCSTR pString);Sets a matrix variable in the effect file identified by hParameter to the value pointed to by pString HRESULT ID3DXEffect::SetTexture( D3DXHANDLE hParameter, LPDIRECT3DBASETEXTURE9 pTexture);Sets a texture variable in the effect file identified by hParameter to the value pointed to by pTexture HRESULT ID3DXEffect::SetVector( D3DXHANDLE hParameter, CONST D3DXVECTOR4* pVector);Sets a vector variable in the effect file identified by hParameter to the value pointed to by pVector HRESULT ID3DXEffect::SetVertexShader( D3DXHANDLE hParameter, LPDIRECT3DVERTEXSHADER9 pVertexShader);Sets a vertex shader variable in the effect file identified by hParameter to the value pointed to by pVertexShader HRESULT ID3DXEffect::SetPixelShader( D3DXHANDLE hParameter, LPDIRECT3DPIXELSHADER9 pPShader);Sets a pixel shader variable in the effect file identified by hParameter to the value pointed to by pPShader 我们通过下面的方法得到变量（又叫效果参数effect parameters）句柄：1234D3DXHANDLE ID3DXEffect::GetParameterByName( D3DXHANDLE hParent, // scope of variable - parent structure LPCSTR pName // name of variable); 它的用法与D3DXConstantTable::GetConstantByName方法一样。即每一个参数是一个D3DXHANDLE，它标识我们想得到的在哪个父结构中的变量句柄。对于没有父结构的全局变量，我们指定null。第二个参数是在效果文件中所显示的变量名。做为例子，以下显示如何设置效果文件中的一些变量：123456789101112131415161718// some data to setD3DXMATRIX M;D3DXMatrixIdentity(&amp;M);D3DXVECTOR4 color(1.0f, 0.0f, 1.0f, 1.0f);IDirect3DTexture9* tex = 0;D3DXCreateTextureFromFile(Device, "shade.bmp", &amp;tex);// get handles to parametersD3DXHANDLE MatrixHandle = Effect-&gt;GetParameterByName(0, "Matrix");D3DXHANDLE MtrlHandle = Effect-&gt;GetParameterByName(0, "Mtrl");D3DXHANDLE TexHandle = Effect-&gt;GetParameterByName(0, "Tex");// set parametersEffect-&gt;SetMatrix(MatrixHandle, &amp;M);Effect-&gt;SetVector(MtrlHandle, &amp;color);Effect-&gt;SetTexture(TexHandle, tex); 注意：对每一个ID3DXEffect::Set方法都有相应的ID3DXEffect::Get方法用来取得效果文件中的变量值。例如，为得到一个距阵类型的变量，我们可以用这个函数：1234HRESULT ID3DXEffect::GetMatrix( D3DXHANDLE hParameter, D3DXMATRIX* pMatrix); 要取得所有的方法列表，查看DirectX SDK文档。 使用效果在这一节和它的小节，我们展示一旦一个效果被创建出来后如何使用它。下面步骤概述了全部过程： 得到一个在你想使用的效果文件中的技术句柄。 激活想得到的技术。 启动当前活动的技术。 对每个激活技术中的渲染传递，渲染想要的几何体。回想一下，技术可能由几个渲染传递组成，我们必须在每个传递中渲染一次几何体。 结束当前激活的技术。 获得效果句柄（ Obtaining a Handle to an Effect）使用技术的第一步是获得一个技术D3DXHANDLE。可以用这个方法得到一个技术句柄：123D3DXHANDLE ID3DXEffect::GetTechniqueByName( LPCSTR pName // Name of the technique.); 注意：实际上，一个效果文件包括几个技术，每一个都被针对一个特定的硬件能力设计。因此，应用程序通常在系统上运行一些能力测试，然后通过这些测试选择最好的技术。看下面小节中的ID3DXEffect::ValidateTechnique。 激活一个效果（ Activating an Effect）一旦得到了想要的技术的句柄，我们必须激活这个技术。这可以通过下面方法实现：123HRESULT ID3DXEffect::SetTechnique( D3DXHANDLE hTechnique // Handle to the technique to set.); 注意：在激活一项技术前你可能想用现有设备验证它。也就是说，你也许想确保硬件支持的特色、配置技术的使用。你可以用下面的方法：123HRESULT ID3DXEffect::ValidateTechnique( D3DXHANDLE hTechnique // Handle to the technique to validate.); 回想一个效果文件可能有几个技术，每个偿试用不同的硬件特色执行一个特定效果，希望最少一个技术将在用户系统上执行。对于一个效果，你将遍例每一个技术并用ID3DXEffect::ValidateTechnique运行它，因而你能检测哪个技术是被支持的而哪个不被支持，然后进行适当的动作。 启动效果为了使用一个效果渲染几何体，我们必须围绕绘图函数在ID3DXEffect::Begin 和 ID3DXEffect::End技术间调用。这些函数就是分别开启和关闭效果。1234HRESULT ID3DXEffect::Begin( UINT* pPasses, DWORD Flags); pPasses—返回在当前活动的技术中的传递的数量。 Flags—下面标志的任何一个：o Zero (0)—指定效果保存当前设备状态和着色状态，并在效果结束（这时ID3DXEffect::End被调用）后恢复它们。因为效果文件能够改变状态，对于可以保存启动效果前的状态来说，是很有用的。o D3DXFX_DONOTSAVESTATE—指示效果不保存和恢复设备状态（除shader状态外）。o D3DXFX_DONOTSAVESHADERSTATE—指示效果不保存和恢复shader状态。 设置当前的渲染传递（Setting the Current Rendering Pass）在我们用效果渲染任何几何体前，我们必须指定使用的渲染传递。回想一个技术包括一个或多个渲染传递，每一个传递封装了不同的设备状态、采样器、和/或用于这一传递的着色器。渲染传递通过下面方法指定：123HRESULT ID3DXEffect::Pass( UINT iPass // Index identifying the pass.); 一个技术的渲染传递被用标识为0…n-1的索引，共n个传递。因而，我们能用一个简单的循环遍例每一个传递，并用这一传递渲染几何体。19.6.6节有一个例子。 结束效果（Ending an Effect）最后，对于每个传递，我们渲染完几何体后，停止并结束效果时使用ID3DXEffect::End方法：HRESULT ID3DXEffect::End(VOID); 例子下面的代码片断示例了以上的使用一个效果的必要的五个步骤：12345678// 有效果文件中technique T0&#123; pass P0 &#123; &#125;&#125; 1234567891011121314151617181920212223// 在应用程序中，取得技术句柄D3DXHANDLE hTech = 0;hTech = Effect-&gt;GetTechniqueByName("TO");// 激活技术Effect-&gt;SetTechnique(hTech );// 启动激活的技术UINT numPasses = 0;Effect-&gt;Begin(&amp;numPasses, 0);// 遍例每个传递for(int i = 0; i &lt; numPasses; i++)&#123; // 设置当前传递 Effect-&gt;Pass(i); // 在传递中渲染几何体 Sphere-&gt;Draw();&#125;// 结束效果Effect-&gt;End(); 例子程序: Lighting and Texturing in an Effect File做为热身，让我们创建一个在3D模型中操作灯光和纹理的效果文件。这个例子完全运行于固定功能管线，意味着效果框架不仅限于使用着色器。图19.1展示了使用灯光和纹理例子的屏幕截图。 图19.1: 灯光和纹理例子的屏幕截图. 纹理、材质和灯光状态在效果文件中指定。 以下是效果文件的实现：// File: light tex.txt// Desc: 效果文件控制光的设备状态，和纹理一个3D模型?// 全局变量matrix WorldMatrix;matrix ViewMatrix;matrix ProjMatrix;?texture Tex;?// 过滤器?// Associated the texture ‘Tex’ with the texture stage ‘S0’// corresponds with and also set the sampler states for the sampler// stage ‘S0’ corresponds with.sampler S0 = sampler state{ Texture = (Tex); MinFilter = LINEAR; MagFilter = LINEAR; MipFilter = LINEAR;}; // Effecttechnique LightAndTexture{ pass P0 { // Set misc. render states.? pixelshader = null; // No pixel shader. vertexshader = null; // No vertex shader. fvf = XYZ | Normal | Tex1; // Flexible vertex format Lighting = true; // Enable lighting. NormalizeNormals = true; // Renormalize normals. SpecularEnable = false; // Disable specular highlights. // Set transformation states? WorldTransform[0] = (WorldMatrix); ViewTransform = (ViewMatrix); ProjectionTransform = (ProjMatrix); // Set a light source at light index 0. We fill out all the // components for light[0] because the Direct3D // documentation recommends filling out all components // for best performance.? LightType[0] = Directional; LightAmbient[0] = {0.2f, 0.2f, 0.2f, 1.0f}; LightDiffuse[0] = {1.0f, 1.0f, 1.0f, 1.0f}; LightSpecular[0] = {0.0f, 0.0f, 0.0f, 1.0f}; LightDirection[0] = {1.0f, -1.0f, 1.0f, 0.0f}; LightPosition[0] = {0.0f, 0.0f, 0.0f, 0.0f}; LightFalloff[0] = 0.0f; LightRange[0] = 0.0f; LightTheta[0] = 0.0f; LightPhi[0] = 0.0f; LightAttenuation0[0] = 1.0f; LightAttenuation1[0] = 0.0f; LightAttenuation2[0] = 0.0f; ? // Finally, enable the light:? LightEnable[0] = true;? // Set material components. This is like calling // IDirect3DDevice9::SetMaterial.? MaterialAmbient = {1.0f, 1.0f, 1.0f, 1.0f}; MaterialDiffuse = {1.0f, 1.0f, 1.0f, 1.0f}; MaterialEmissive = {0.0f, 0.0f, 0.0f, 0.0f}; MaterialPower = 1.0f; MaterialSpecular = {1.0f, 1.0f, 1.0f, 1.0f};? // Hook up the sampler object ‘S0’ to sampler stage 0, // which is given by Sampler[0].? Sampler[0] = (S0); }} 在这个效果文件中我们主要设置设备状态，就象在19.3节所述。例如，我们直接在效果文件中设置一个光源和一个材质。此外，我们指定转换距阵和纹理及采样器状态。这些状态被指定，然后用LightAndTexture方法和渲染传递P0渲染全部几何体，。 注意：考虑到在一个效果文件中涉及到的的变量，你必须把它们装入圆括号中。举例来说，涉及到距阵变量，你必须这样写：(WorldMatrix), (ViewMatrix), and (ProjMatrix)。不使用圆括号是违法的。 因为大部分必需的和繁琐的工作都在效果文件里做了，比如设置灯光、材质和纹理。应用程序代码就是做一些创建效果和开启效果等简单的事情。例子中有下面一些相关的全局变量：ID3DXEffect* LightTexEffect = 0; D3DXHANDLE WorldMatrixHandle = 0;D3DXHANDLE ViewMatrixHandle = 0;D3DXHANDLE ProjMatrixHandle = 0;D3DXHANDLE TexHandle = 0; D3DXHANDLE LightTexTechHandle = 0; ?这些东西很没劲 ——- 只是一个ID3DXEffect指针和一些句柄。LightTexTechHandle是一个技术的句柄，因此在它的名字中有子字符串“Tech”。 RestoreDeviceObjects函数执行三个主要步骤：创建效果，获得作为效果参数的我们要用的技术的句柄，并初始化一些效果参数。下面是删节的实现：bool Setup(){ HRESULT hr = 0; // …省略了采样器的读取? // 创建效果 ID3DXBuffer errorBuffer = 0; hr = D3DXCreateEffectFromFile( m_pd3dDevice , “light_tex.txt”, 0, // 没有定义预处理器 0, // 没有ID3DXInclude接口 D3DXSHADER_DEBUG, // 编译标记 0, // 不共享参数 &amp;m_LightTexEffect, &amp;errorBuffer);? // 输出错误信息 if( errorBuffer ) { ::MessageBox(0, (char)errorBuffer-&gt;GetBufferPointer(), 0, 0); SAFE_RELEASE(errorBuffer); }? if(FAILED(hr)) { ::MessageBox(0, “D3DXCreateEffectFromFile() - FAILED”, 0, 0); return false; }? // 保存经常访问的参数句柄 m_WorldMatrixHandle = m_LightTexEffect-&gt;GetParameterByName(0, “WorldMatrix”); m_ViewMatrixHandle = m_LightTexEffect-&gt;GetParameterByName(0, “ViewMatrix”); m_ProjMatrixHandle = m_LightTexEffect-&gt;GetParameterByName(0, “ProjMatrix”); m_TexHandle = m_LightTexEffect-&gt;GetParameterByName(0, “Tex”);? m_LightTexTechHandle = m_LightTexEffect-&gt;GetTechniqueByName(“LightAndTexture”);? // 设置效果参数 // 设置矩阵 D3DXMATRIX W, P;? D3DXMatrixIdentity(&amp;W); m_LightTexEffect-&gt;SetMatrix( m_WorldMatrixHandle, &amp;W);? D3DXMatrixPerspectiveFovLH( &amp;P, D3DX_PI * 0.25f, // 45 - degree (float)800.0f / (float)600.0f, 1.0f, 1000.0f);? m_LightTexEffect-&gt;SetMatrix( m_ProjMatrixHandle, &amp;P); ? // Set texture IDirect3DTexture9 tex = 0; D3DXCreateTextureFromFile(m_pd3dDevice, “Terrain_3x_diffcol.jpg”, &amp;tex);? LightTexEffect-&gt;SetTexture(TexHandle, tex); d3d::Release&lt;IDirect3DTexture9&gt;(tex);? return true;} Disply函数很简单，运行步聚在19.6 节中简要说明:bool Display(float timeDelta){ if( Device ) { // …[Camera update snipped] // set the new updated view matrix LightTexEffect-&gt;SetMatrix(ViewMatrixHandle, &amp;V); // Activate the technique and render Device-&gt;Clear(0, 0, D3DCLEAR TARGET | D3DCLEAR ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); // set the technique to use LightTexEffect-&gt;SetTechnique( LightTexTechHandle ); UINT numPasses = 0; LightTexEffect-&gt;Begin(&amp;numPasses, 0); for(int i = 0; i &lt; numPasses; i++) { LightTexEffect-&gt;Pass(i); for(int j = 0; j &lt; Mtrls.size(); j++) { Mesh-&gt;DrawSubset(j); } } LightTexEffect-&gt;End(); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); } return true;} 19.8例子程序: Fog Effect 非常遗憾，我们没有用一整章篇幅来介绍Direct3D雾化效果。雾化效果（以下简称雾）提高了场景的真实性，可以用它来模拟逼真的天气状况。另外，雾可以大大减少长剪裁（far-clip）平面视觉效果。 虽然我们不能给它应有的重视，这里我们还是挤出了一个简要的雾化例程。虽然我们不涉及详细的细节，我们还是展示并解释了Direct3D代码，这是很直接的。 Direct3D雾化是固定功能管线的一部份，受渲染状态限制。下面的效果文件设置顶点雾，以达到必要的雾化状态。 注意：Direct3D也支持像素雾（也叫表格雾table fog），比顶点雾要更精确。// File: fog.txt// Desc: Effect file that handles device states for linear vertex fog.technique Fog{ pass P0 { // Set misc render states.? pixelshader = null; vertexshader = null; fvf = XYZ | Normal; Lighting = true; NormalizeNormals = true; SpecularEnable = false;? // Fog states? FogVertexMode = LINEAR; // Linear fog function. FogStart = 50.0f; // Fog starts 50 units away from viewpoint. FogEnd = 300.0f; // Fog ends 300 units away from viewpoint.? FogColor = 0x00CCCCCC; // Gray colored fog. FogEnable = true; // Enable vertex fog. }} 就象你看到的，线性顶点雾能够通过五个简单的渲染状态控制：*???????? FogVertexMode—使用指定的雾函数用于顶点雾。雾函数指定雾如何根据距离增长，自然界的雾在近视口的地方比较薄并且根据距离增长变得厚起来了。有效的任务类型为LINEAR、EXP、EXP2。这些函数被定义为： d 是到视口的距离(viewpoint.) 注意：如果你用EXP或EXP2雾化函数，你不用设置FogStart 和 FogEnd，因为它们在这些雾函数类型中没被用到。代替的你必须设置雾密度（fog density）渲染状态（如，FogDensity = someFloatType）???????? FogStart—标记了物体将开始雾化的起始深度。 ???????? FogEnd—标记了物体将结束雾化的结束深度。 注意：FogStart 与 FogEnd本质上定义了物体在其中被雾化的深度间隔（从视口）。???????? FogColor—一个DWORD 或 D3DCOLOR值，以描述雾的颜色 ???????? FogEnable—指定true以开启顶点雾或false以关闭顶点雾 任何我们用fog.txt效果渲染的几何体将被雾化。通过这种方式，我们可以控制哪一物体得到雾化，而哪些不用雾化。这对只雾化特定区域是很有用的。例如，通常屋外是有雾的，屋里不被雾化。同样的，一定地理部分可能有雾，而另外部分可能没有。图19.2展示了这一小节的调用雾效果的例程的屏幕截图。图19.2: 雾化效果例子程序的屏幕截图，在这个例子中我们使用线性雾函数，而且雾化渲染状态在效果文件中指定。19.9例子程序: Cartoon Effect 到目前为止的2个效果文件的例子，我们没有使用着色器（shader）。因为着色器在特效中的重要部分，我们想展示一个最精简的例子。例程CartoonEffect执行了在17章中讨论的卡通着色器，但是这次应用效果框架。下面是一个删节版的效果文件：// File: tooneffect.txt// 在效果文件中的卡通着色器extern matrix WorldMatrix;extern matrix ViewMatrix;extern matrix ProjMatrix;extern vector Color;extern vector LightDirection;static vector Black = {0.0f, 0.0f, 0.0f, 0.0f};extern texture ShadeTex;?struct VS_INPUT{ vector position : POSITION; vector normal : NORMAL;}; struct VS_OUTPUT{ vector position : POSITION; float2 uvCoords : TEXCOORD; vector diffuse : COLOR;};?// Cartoon Shader Function:VS_OUTPUT Main(VS_INPUT input){ …[Implementation omitted for brevity.]}?sampler ShadeSampler = sampler state{ Texture = (ShadeTex); MinFilter = POINT; // no filtering for cartoon shading MagFilter = POINT; MipFilter = NONE;};?technique Toon{ pass P0 { // Set P0’s vertex shader. vertexShader = compile vs_1_1 Main(); // Hook up the sampler object to sampler stage 0. Sampler[0] = (ShadeSampler); }} 我们注意到卡通着色器函数被定义在效果文件中，并且我们指定着色器使用一个特定的传递，在传递部分使用语法：vertexShader = compile vs_1_1_Main();。在效果文件中的设备状态象通常一样设置。 19.10 效果编辑（EffectEdit） 在结束这章前，我们想提一下在DirectX SDK中的EffectEdit程序。可以在\DXSDK\Samples\C++\Direct3D\Bin文件夹中找到它。图19.3显示了一个屏幕截图。 图19.3: 一个在DirectX SDK 中的EffectEdit 程序的屏幕截图 这个EffectEdit程序在测试和书写效果文件时是很有用的。我们推荐您在这个工具上花点时间。 19.11摘要略 相关文章：AGP内存AGP（Accelerate Graphical Port），加速图形接口。随着显示芯片的发展，PCI总线日益无法满足其需求。英特尔于1996年7月正式推出了AGP接口，它是一种显示卡专用的局部总线。严格的说，AGP不能称为总线，它与PCI总线不同，因为它是点对点连接，即连接控制芯片和AGP显示卡，但在习惯上我们依然称其为AGP总线。AGP接口是基于PCI 2.1 版规范并进行扩充修改而成，工作频率为66MHz。 AGP总线直接与主板的北桥芯片相连，且通过该接口让显示芯片与系统主内存直接相连，避免了窄带宽的PCI总线形成的系统瓶颈，增加3D图形数据传输速度，同时在显存不足的情况下还可以调用系统主内存。所以它拥有很高的传输速率，这是PCI等总线无法与其相比拟的。 由于采用了数据读写的流水线操作减少了内存等待时间，数据传输速度有了很大提高；具有133MHz及更高的数据传输频率；地址信号与数据信号分离可提高随机内存访问的速度；采用并行操作允许在CPU访问系统RAM的同时AGP显示卡访问AGP内存；显示带宽也不与其它设备共享，从而进一步提高了系统性能。 AGP标准在使用32位总线时，有66MHz和133MHz两种工作频率，最高数据传输率为266Mbps和533Mbps，而PCI总线理论上的最大传输率仅为133Mbps。目前最高规格的AGP 8X模式下，数据传输速度达到了2.1GB/s。 AGP接口的发展经历了AGP1.0(AGP1X、AGP2X)、AGP2.0(AGP Pro、AGP4X)、AGP3.0(AGP8X)等阶段，其传输速度也从最早的AGP1X的266MB/S的带宽发展到了AGP8X的2.1GB/S。AGP 1.0（AGP1X、AGP2X） 1996年7月AGP 1.0 图形标准问世，分为1X和2X两种模式，数据传输带宽分别达到了266MB/s和533MB/s。这种图形接口规范是在66MHz PCI2.1规范基础上经过扩充和加强而形成的，其工作频率为66MHz，工作电压为3.3v，在一段时间内基本满足了显示设备与系统交换数据的需要。这种规范中的AGP带宽很小，现在已经被淘汰了，只有在前几年的老主板上还见得到。AGP2.0(AGP4X) 显示芯片的飞速发展，图形卡单位时间内所能处理的数据呈几何级数成倍增长，AGP 1.0 图形标准越来越难以满足技术的进步了，由此AGP 2.0便应运而生了。1998年5月份，AGP 2.0 规范正式发布，工作频率依然是66MHz，但工作电压降低到了1.5v，并且增加了4x模式，这样它的数据传输带宽达到了1066MB/sec，数据传输能力大大地增强了。AGP Pro AGP Pro接口与AGP 2.0同时推出，这是一种为了满足显示设备功耗日益加大的现实而研发的图形接口标准，应用该技术的图形接口主要的特点是比AGP 4x略长一些，其加长部分可容纳更多的电源引脚，使得这种接口可以驱动功耗更大（25-110w）或者处理能力更强大的AGP显卡。这种标准其实是专为高端图形工作站而设计的，完全兼容AGP 4x规范，使得AGP 4x的显卡也可以插在这种插槽中正常使用。AGP Pro在原有AGP插槽的两侧进行延伸，提供额外的电能。它是用来增强，而不是取代现有AGP插槽的功能。根据所能提供能量的不同，可以把AGP Pro细分为AGP Pro110和AGP Pro50。在某些高档台式机主板上也能见到AGP Pro插槽，例如华硕的许多主板。AGP 3.0(AGP8X) 2000年8月，Intel推出AGP3.0规范，工作电压降到0.8V,并增加了8x模式，这样它的数据传输带宽达到了2133MB/sec，数据传输能力相对于AGP 4X成倍增长，能较好的满足当前显示设备的带宽需求。AGP接口的模式传输方式 不同AGP接口的模式传输方式不同。1X模式的AGP，工作频率达到了PCI总线的两倍—66MHz，传输带宽理论上可达到266MB/s。AGP 2X工作频率同样为66MHz，但是它使用了正负沿（一个时钟周期的上升沿和下降沿）触发的工作方式，在这种触发方式中在一个时钟周期的上升沿和下降沿各传送一次数据，从而使得一个工作周期先后被触发两次，使传输带宽达到了加倍的目的，而这种触发信号的工作频率为133MHz，这样AGP 2X的传输带宽就达到了266MB/s×2（触发次数）＝533MB/s的高度。AGP 4X仍使用了这种信号触发方式，只是利用两个触发信号在每个时钟周期的下降沿分别引起两次触发，从而达到了在一个时钟周期中触发4次的目的，这样在理论上它就可以达到266MB/s×2（单信号触发次数）×2（信号个数）＝1066MB/s的带宽了。在AGP 8X规范中，这种触发模式仍然使用，只是触发信号的工作频率变成266MHz，两个信号触发点也变成了每个时钟周期的上升沿，单信号触发次数为4次，这样它在一个时钟周期所能传输的数据就从AGP4X的4倍变成了8倍，理论传输带宽将可达到266MB/s×4（单信号触发次数）×2（信号个数）＝2133MB/s的高度了。 目前常用的AGP接口为AGP4X、AGP PRO、AGP通用及AGP8X接口。需要说明的是由于AGP3.0显卡的额定电压为0.8—1.5V，因此不能把AGP8X的显卡插接到AGP1.0规格的插槽中。这就是说AGP8X规格与旧有的AGP1X/2X模式不兼容。而对于AGP4X系统，AGP8X显卡仍旧在其上工作，但仅会以AGP4X模式工作，无法发挥AGP8X的优势。 Direct3D中实现图元的鼠标拾取索引： 1、什么是拾取，拾取能做什么？ 2、拾取操作的步骤和实现 2.1． 变换并获得通过视点和屏幕上点击点的射线矢量（Dir） 2.1.1 确定鼠标选取点的屏幕坐标 2.1.2 得到Dir在观察坐标空间内的表示 2.1.3 转换Dir到世界坐标空间，并得到观察点在世界坐标系中的坐标 2.2 使用射线矢量对场景中的所有三角形图元求交，获得三角形索引值和重心坐标。 2.2.1 D3D扩展函数实现求交 2.2.2射线三角面相交的数学算法 2.2.3 拾取完成根据获得的中心坐标计算我们关心的常见量 3、结束及声明 4、参考文献 补充：重心坐标的概念 3D交互图形应用程序中，常常要用鼠标去选择图形，其实现的机制基于鼠标拾取算法。本文主要讲述如何在D3D中实现图元的鼠标拾取。为了讨论简单，本文假定读者理解D3D 坐标变换流程和基本的图形学知识，如果阅读有困难请参考相关资料。1、什么是拾取，拾取能做什么？ 首先，拾取操作指当我们在屏幕上用鼠标点击某个图元，应用程序能返回该图元的一个标志和某些相关信息。有图形程序设计经验的人都知道，有这些信息就表示我们有了对该图元的控制权，我们可以删除，可以编辑，可以任意对待该图元，至于你到底想干什么，就是阁下自己的事了^_^。 2、拾取操作的步骤和实现 拾取算法的思想很简单：得到鼠标点击处的屏幕坐标，通过投影矩阵和观察矩阵把该坐标转换为通过视点和鼠标点击点的一条射入场景的光线，该光线如果与场景模型的三角形相交（本文只处理三角形图元），则获取该相交三角形的信息。本文讲述的方法除可以得到三角形的一个索引号以外还可以得到相交点的重心坐标。从数学角度来看，我们只要得到射线的方向矢量和射线的发射点，我们就具备了判断射线与空间三角面是否相交的条件，本文主要讨论如何获得这些条件，并描述了射线与三角面相交判断算法和D3D的通常实现方法。 根据拾取操作的处理顺序，大概可以依次分为以下几个步骤2.1． 变换并获得通过视点和屏幕上点击点的射线矢量（Dir）详细介绍之前，为了大家方便理解，我们要先简单说一下d3d坐标转换的大概流程，如下图: 所以我们要通过一系列的反变换，得到我们关心的值在世界坐标中的表示。 2.1.1 确定鼠标选取点的屏幕坐标 这一步是非常简单的Windows给我们提供了API来完成屏幕坐标的获取，使用GetCursorPos获得鼠标指针位置，然后再利用ScreenToClient转换坐标到客户区坐标系(以窗口视区左上角为坐标原点，单位为像素)，设该坐标为（POINT screenPt）。 2.1.2 得到Dir在观察坐标空间内的表示 在观察坐标系中，Dir是一条从观察坐标原点出发的射线，所以我们只需要再确定一个该射线经过的点，就可以得到它在观察坐标系中的表示。假设我们要求的射线上的另外一点为该射线与透视投影平截头体近剪切面的交点，针对最普遍的透视投影而言，透视投影平截头体经投影变换后，变成一个1/2立方体（请允许我这么叫^_^，因为它的大小为一个正方体的一半，x,y方向边长为2，z方向为1）如图： 投影坐标系以近剪切面中心为坐标原点，该立方体从z轴负向看过去与图形程序视区相对应，最终近剪切面（前剪切面）上一点与屏幕坐标之间的对应关系如下图所示： 根据比例关系，screenPt与投影空间上的点projPt之间的关系为 假设图形程序窗口的宽为screenWidth,高为screenHeight, projPt.x = (screenPt.x-screenWidth/2)/screenWidth2; （公式1） projPt.y = (screenPt.y-screenHeight/2)/screenHeight2; （公式2） projPt.z =0;（实际该值可任意取，不影响最终结果。为了处理简单，我们取改值为0，表示该点取在近剪切面上） 得到projPt后，我们需要做的是把该点坐标从投影空间转换到观察空间(view space), 根据透视投影的定义，可假设点(projPt.x，projPt.y，projPt.z) 对应的其次坐标为 (projPt.xprojPt.w，projPt.yprojPt.w，projPt.zprojPt.w，projPt.w) 我们可以通过 GetTransform( D3DTS_PROJECTION, &amp;ProjMatrix)函数获得投影矩阵ProjMatrix,则根据观察空间到投影空间的变换关系则：投影坐标 = 观察坐标×投影矩阵 (projPt.xprojPt.w，projPt.yprojPt.w，projPt.zprojPt.w，projPt.w) = (viewPt.x，viewPt.y，viewPt.z, 1)pProjMatrx; 根据定义和图形学原理 ProjMatrix = = 所以, (projPt.xprojPt.w，projPt.yprojPt.w，projPt.zprojPt.w，projPt.w) = ( viewPt.xProjMatrix._m11, viewPt.yProjMatrix._m22, viewPt.z*Q-QZn, viewPt.z) 所以 projPt.xprojPt.w = viewPt.xProjMatrix._m11 projPt.yprojPt.w = viewPt.yProjMatrix._m22 projPt.zprojPt.w = viewPt.zQ-QZn （注意projPt.z = 0） projPt.w = viewPt.z; 解得 viewPt.x = projPt.xZn/ ProjMatrix._m11; viewPt.y = projPt.yZn/ ProjMatrix._m22; viewPt.z = Zn; 好了，到这里为止我们终于求出了射线与近剪切面交点在观察坐标系中的坐标，现在我们拥有了射线的出发点(0,0,0)和射线方向上另外一点(viewPt.x,viewPt.y,viewPt.z),则该射线的方向矢量在观察空间中的表示可确定为（viewPt.x-0,viewPt.y-0,viewPt.z-0）,化简一下三个分量同除近剪切面z坐标Zn，该方向矢量可写作 DIRview = (projPt.x/projMatrix._m11,projPt.y/projMatrix._m22,1) 代入公式1，公式2 DIRview.x = (2screenPt.x/screenWidth-1)/projMatrix._m11; DIRview.y = (2screenPt.y/screenHeight-1)/projMatrix._m22; DIRview.z = 1; 其中screenWidth和screenHeight可以通过图像显示的backBuffer的目标表面（D3DSURFACE_DESC）来获得，该表面在程序初始化时由用户创建。 2.1.3 转换Dir到世界坐标空间，并得到观察点在世界坐标系中的坐标 由于最终的运算要在世界坐标空间中进行，所以我们还需要把矢量DIRview从观察空间转换为世界坐标空间中的矢量DIRworld。 因为 DIRview = DIRworldViewMatrix; 其中ViewMatrix为观察矩阵，在D3D中可以用函数GetTransform( D3DTS_VIEW, &amp;ViewMatrix )得到。 所以DIRworld = DIRview inverse_ViewMatrix,其中inverse_ViewMatrix为ViewMatrix的逆矩阵。 观察点在观察坐标系中坐标为OriginView（0，0，0，1），所以其在世界坐标系中的坐标同样可以利用ViewMatrix矩阵，反变换至世界坐标系中，事实上我们可以很简单的判断出,其在世界坐标系中的表示为: OriginWorld = (inverse_ViewMatrix._41, inverse_ViewMatrix._42, inverse_ViewMatrix._43, 1); 到这里为止，判断射线与三角面是否相交的条件就完全具备了。2.2 使用射线矢量对场景中的所有三角形图元求交，获得三角形索引值和重心坐标。 这一步骤地实现由两种途径: 第一种方法非常简单，利用D3D提供的扩展函数D3DXIntersect可以轻松搞定一切。见2.1 第二种方法就是我们根据空间解析几何的知识，自己来完成射线三角形的求交算法。一般来讲，应用上用第一种方法就足够了，但是我们如果要深入的话，必须理解相交检测的数学算法，这样才能自由的扩展，面对不同的需求，内容见2.2 下面分别讲解两种实现途径： 2.2.1 D3D扩展函数实现求交 这种方法很简单也很好用，对于应用来说应尽力是用这种方式来实现，毕竟效率比自己写得要高得多。 实际上其实没什么好讲的，大概讲一下函数D3DXIntersect吧 D3D SDK该函数声明如下 HRESULT D3DXIntersect( LPD3DXBASEMESH pMesh, CONST D3DXVECTOR3 pRayPos, CONST D3DXVECTOR3 pRayDir, BOOL pHit, DWORD pFaceIndex, FLOAT pU, FLOAT pV, FLOAT pDist, LPD3DXBUFFER ppAllHits, DWORD pCountOfHits ); l pMesh指向一个ID3DXBaseMesh的对象，最简单的方式是从.x文件获得，描述了要进行相交检测的三角面元集合的信息，具体规范参阅direct9 SDK l pRayPos 指向射线发出点 l pRayDir 指向前面我们辛辛苦苦求出的射线方向的向量 l pHit 当检测到相交图元时，指向一个true,不与任何图元相交则为假 l pU 用于返回重心坐标U分量 l pV返回重心坐标V分量 l pDist 返回射线发出点到相交点的长度 注意：以上红色字体部分均指最近的一个返回结果（即pDist最小） l ppAllHits用于如果存在多个相交三角面返回相交的所有结果 l pCountOfHits 返回共有多少个三角形与该射线相交 补充：重心坐标的概念三角形的重心坐标： P1，P2，P3为空间三角形的三个顶点矢量， (U,?V)就称为三角形的重心坐标在空间三角形平面上的点可以表示为： P?=?P1?+?U??(P2?-?P1)?+?V??(P3?-?P1)当0?&lt;?U?&lt;?1，0?&lt;?V?&lt;?1，0?&lt;?U?+?V?&lt;?1时，这个点P就在这个三角形的内部 收集 其中pU和pV用到了重心坐标的概念，下面稍作描述 一个三角形有三个顶点，在迪卡尔坐标系中假设表示： V1(x1,y1,z1), V2(x2,y2,z2), V3(x3,y3,z3), 则三角形内任意一点的坐标可以表示为（pV为任意点）： pV = V1 + U(V2-V1) + V(V3-V1) 所以已知三个顶点坐标的情况下，任意一点可用坐标(U,V)来表示，其中 参数U控制V2在结果中占多大的权值，参数V控制V3占多大权值，最终V1占多大权值 = 1 - U - V，这种坐标定义方式就叫重心坐标。 2..2.2射线三角面相交的数学算法 使用d3d扩展函数，毕竟有时不能满足具体需求，掌握了该方法，我们才能够获得最大的控制自由度，任意修改算法。 已知条件: 射线源点orginPoint,三角形三个顶点 v1,v2,v3,射线方向 Dir（均以三维坐标向量形式表示）。 算法目的: 判断射线与三角形是否相交，如果相交求出交点的重心坐标(U,V)和射线原点到交点的距离T。 我们可先假设射线与三角形相交则交点 (注以下均为向量运算：dot(X,Y) 点乘； cross(X，Y) 叉乘； U，V，T 标量(这三个值为X、Y、Z轴坐标)) 则：（IntersectPoint为三角形上的交点） IntersectPoint = V1 + U×(V2-V1) + V×(V3-V1) ; IntersectPoint = originPoint + T×Dir； 所以： orginPoint + T×Dir = V1 + U×(V2-V1) + V×(V3-V1); 整理得： orginPoint - V1 = U×(V2-V1) + V×(V3-V1) - T×Dir;?这是一个简单的线性方程组，若有解则行列式［-Dir, V2-V1, V3-V1］不为0。 根据T,U,V的含义当T&gt;0, 0&lt;U&lt;1,0&lt;V&lt;1,0&lt;U+V&lt;1时该交点在三角形内部，解此方程组即可获得我们关心的值,具体解法不再赘述，克莱姆法则就够了（详细见线性代数）:射线原点到相交点的距离T,和交点的中心坐标(U,V)。下面给出Direct 9 SDK示例程序中的实现代码：IntersectTriangle( const D3DXVECTOR3&amp; orig,?????????????????? const D3DXVECTOR3&amp; dir, D3DXVECTOR3&amp; v0,?????? ???????????? D3DXVECTOR3&amp; v1, D3DXVECTOR3&amp; v2,?????? ???????????? FLOAT t, FLOAT u, FLOAT* v ){??? // 算出两个边的向量??? D3DXVECTOR3 edge1 = v1 - v0;??? D3DXVECTOR3 edge2 = v2 - v0;? D3DXVECTOR3 pvec; D3DXVec3Cross( &amp;pvec, &amp;dir, &amp;edge2 ); // 如果det为0，或接近于零则射线与三角面共面或平行，不相交 //此处det就相当于上面的[-Dir, V2-V1, V3-V1]，??? FLOAT det = D3DXVec3Dot( &amp;edge1, &amp;pvec );???? D3DXVECTOR3 tvec;??? if( det &gt; 0 )??? {??????? tvec = orig - v0;??? }??? else??? {??????? tvec = v0 - orig;??????? det = -det;??? }???? if( det &lt; 0.0001f )??????? return FALSE;???? // 计算u并测试是否合法（在三角形内）??? u = D3DXVec3Dot( &amp;tvec, &amp;pvec );??? if( u &lt; 0.0f || u &gt; det )??????? return FALSE;???? // Prepare to test V parameter??? D3DXVECTOR3 qvec;??? D3DXVec3Cross( &amp;qvec, &amp;tvec, &amp;edge1 );???? //计算u并测试是否合法（在三角形内）??? v = D3DXVec3Dot( &amp;dir, &amp;qvec );??? if( v &lt; 0.0f || u + v &gt; det )??????? return FALSE;???? /计算t,并把t,u,v放缩为合法值（注意前面的t,v,u不同于算法描述中的相应量，乘了一个系数det）,注意：由于该步运算需要使用除法，所以放到最后来进行，避免不必要的运算，提高算法效率/??? t = D3DXVec3Dot( &amp;edge2, &amp;qvec );??? FLOAT fInvDet = 1.0f / det;??? t = fInvDet;??? u = fInvDet;??? v = fInvDet;???? return TRUE;} ?2.2.3? 拾取完成根据获得的中心坐标计算我们关心的常见量根据重心坐标（U,V）,我们可以很容易的算出各种相关量比如纹理坐标和交点的差值颜色，假设以纹理坐标为例设V1,V2,V3的纹理坐标分别为T1(tu1,tv1),T2(tu2,tv2),T3(tu3,tv3)则交点的坐标为?IntersectPointTexture = T1 + U(T2-T1) + V(T3-T1) 3、结束及声明 Ok, 到这里为止关于拾取的相关知识就介绍完了，小弟第一次写这种文章，不知道有没有把问题说清楚，希望对大家有所帮助，有任何问题可以给我发email: jzhang1@mail.xidian.edu.cn 或者到我的网站留言： www.heavysword.com 声明： 本文写作的目的是为了广大D3D学习者方便学习服务，文中算法为作者参考相关文献总结，作者无意把这些据为自己的成果，所有权原算法提出者所有（参阅参考文献），文中代码为D3d SDK的示例内容，由笔者进行了必要的解释，代码版权归microsoft所有。4、参考文献 【1】Microsoft DirectX 9.0 SDK,microsoft 【2】fast,Minimun Storage Ray/Triangle Intersection,Tomas Moler,Ben Trumbore ?BY 克莱姆（Cramer）法则一、线性方程组 元线性方程组是指形式为： （1）的方程组，其中代表个未知量，是方程的个数，， ; 称为方程组的系数，称为常数项。 线性方程组的一个解是指由个数组成的有序数组， 当个未知量分别用代入后，式（1）中每个等式都成为恒等式。方程组（1）的解的全体称为它的解集合，如果两个线性方程组有相同的解集合，就称它们是同解方程组。 为了求解一个线性方程组，必须讨论以下一些问题： (1).这个方程组有没有解？ (2).如果这个方程组有解，有多少个解？ (3).在方程组有解时,解之间的关系,并求出全部解。 本节讨论方程的个数与未知量的个数相等(即)的情形。 二、克莱姆法则 定理1（克莱姆法则）如果线性方程组 ???????????（2）的系数行列式： 那么这个方程组有解，并且解是唯一的，这个解可表示成： （3）其中是把中第列换成常数项所得的行列式，即 。 分析：定理一共有3个结论：方程组有解；解是唯一的；解由公式（3）给出。因此证明的步骤是： 第一，把 代入方程组，验证它确实是解。这样就证明了方程组有解，并且（3）是一个解，即证明了结论与。 第二，证明如果是方程组（２）的一个解，那么一定有。这就证明了解的唯一性，即证明了结论。 证明：先回忆行列式的一个性质，设阶行列式，则有： 接下来证明定理。首先，证明（3）确实是（2）的解。将行列式按第列展开得： ，其中是行列式中元素的代数余子式。现把代入第个方程的左端，得： 这说明将（3）代入第个方程后，得到了一个恒等式，所以（3）是（2）的一个解。 其次，设是方程组（2）的一个解，那么，将代入（2）后，得到个恒等式： （4）用系数行列式的第列的代数余子式依次去乘（4）中个恒等式，得到： 将此个等式相加，得： 从而有：。这就是说，如果是方程组（2）的一个解，那么一定有，所以方程组只有一个解。 三、齐次线性方程组 在线性方程组中，有一种特殊的线性方程组，即常数项全为零的方程组，称为齐次线性方程组。显然，齐次线性方程组总是有解的，因为就是它的解，这个解称为零解；其他的，即不全为零的解（如果还有的话），称为非零解。所以，对于齐次线性方程组，需要讨论的问题，不是有没有解，而是有没有非零解。这个问题与齐次线性方程组解的个数是有密切关系的。如果一个齐次线性方程组只有零解，那么这个方程组就只有唯一解；反之， 如果某个齐次线性方程组有唯一解， 那么由于零解是一个解，所以这个方程组不可能有非零解。 对于方程个数与未知量个数相同的齐次线性方程组，应用克莱姆法则，有 推论1? 如果齐次线性方程组 （5）的系数行列式不等于零，那么（5）只有零解。 推论2 齐次线性方程组 有非零解的必要条件是它的系数行列式等于零。 四、例子 例1 解线性方程组 解：方程组的系数行列式： 所以根据克莱姆法则，这个线性方程组有唯一解。又因 所以这个线性方程组的唯一解为： 例2 解线性方程组 解：方程组的系数行列式： 所以根据克莱姆法则，这个线性方程组有唯一解。又因 所以这个线性方和组的唯一解为： 例3???????? 已知三次曲线在四个点处的值分别为：，试求其系数。 解：将三次曲线在4点处的值代入其方程，得到关于的线性方程组： 它的系数行列式是范德蒙行列式： 所以根据克莱姆法则，这个线性方程组有唯一解。又因 所以，即所求的三次曲线方程为。 例4 如果齐次线性方程组 有非零解，那么必须满足什么条件？ 解：由克莱姆法则知，齐次线性方程组有非零解的必要条件是其系数行列式等于零，因此有 又由：，从而必须满足的条件为。 注 用克莱姆法则求解系数行列式不等于零的元非齐次线性方程组，需要计算个阶行列式，它的计算工作量很大。实际上关于数字系数的线性方程组（包括系数行列式等于零及方程个数和未知量个数不相同的线性方程组）的解法，一般都采用后续章节介绍的方法来求解。克莱姆法则主要是在理论上具有重要的意义，特别是它明确地揭示了方程组的解和系数之间的关系。]]></content>
  </entry>
  <entry>
    <title><![CDATA[第十八章 像素着色器入门(Introduction to Pixel Shaders)]]></title>
    <url>%2F2019%2F04%2F11%2FIntroduction-to-Pixel-Shaders%2F</url>
    <content type="text"><![CDATA[像素着色器是一个执行在图形卡的GPU上的程序，它运行在对每个像素进行光栅化处理时。（不像顶点着色器，Direct3D不会以软件模拟像素着色器的功能。）它实际上替换了固定功能管线的多纹理化阶段（the multitexturing stage），并赋予我们直接操纵单独的像素和访问每个像素的纹理坐标的能力。这种对像素和纹理坐标的直接访问使我们可以达成各种特效，例如：多纹理化（multitexturing）、每像素光照（per pixel lighting）、景深（depth of field）、云状物模拟（cloud simulation）、焰火模拟（fire simulation）、高级阴影技术（sophisticated shadowing technique）。 图形卡支持的像素着色器的版本可以通过D3DCAPS9结构的PixelShaderVersion成员和D3DPS_VERSION宏进行检查。下列代码片断展示了这点：// If the device’s supported version is less than version 2.0if( caps.PixelShaderVersion &lt; D3DPS_VERSION(2, 0) ) // Then pixel shader version 2.0 is not supported on this device. 目标 获得对多纹理化概念的基本理解 学习如何编写、创建并使用像素着色器 学习如何使用像素着色器实现多纹理化效果 18.1多纹理化概览 多纹理化（Multitexturing）可能是用像素着色器实现的最简单的技巧了。此外，因为像素着色器替换多纹理化阶段，那么接下来我们应该对多纹理化“是什么”和“做什么”有一个最基本的理解。本节介绍多纹理化的简明概览。 当我们一开始讨论纹理化（texturing）的时候（第6章），我们忽略了固定功能管线中对多纹理化的讨论，这有两个原因：第一，多纹理化是有一点棘手的过程，我们考虑到这在当时是一个高级话题；此外，固定功能多纹理化阶段被新的和更强有力的像素着色器替换掉了。因此花时间在已经过时的固定功能纹理化阶段上是无意义的。 多纹理化后面的概念有一点和混合（blending）相关。在第七章中我们了解到：可以将正要被光栅化的像素与之前写入后台缓冲的像素进行混合来达成一种特效。我们延伸这种相同的思想到多纹理化中（multiple texture）。也就是说，我们一次使用几个纹理，然后定义这些纹理如何被混合在一起，以达到一种特殊效果。多纹理化的一个通常的用法是执行光照。作为在顶点处理阶段使用Direct3D的光照模型的替代，我们使用一种叫做“光照图”（light map）的特殊纹理贴图（texture map），它编码（encode）表面是如何被光照的。例如，假设我们希望一盏聚光灯（spotlight）照在一个大木箱上，我们要么可以定义一个D3DLIGHT9结构的聚光灯，要么可以将代表木箱的纹理贴图与代表聚光灯的光照映射混合在一起，如图18.1所示。 图18.1：使用多纹理化渲染一个通过聚光灯照亮的木箱。这里我们通过将相应的纹理像素（texels）相乘来将这两个纹理组合起来。 注意：用第七章里的混合，结果图像依赖于纹理被混合的方式。在固定功能管线的多纹理化阶段，混合方程式被纹理渲染状态（texture render state）控制。用像素着色器，我们 能够以可编程的方式在代码中写出混合函数的简单表达式。这使我们可以用任何我们想要的方式混合纹理。我们将在讨论本章的例子程序时详细讨论纹理混合。 混合多个纹理（本例中是两个）来照亮木箱比起Direct3D的光照来有两个好处： 光照是是预先在聚光灯的光照贴图里计算好的。因此，光照不需要在运行时被计算，这节省了处理时间。当然，只有静态对象和静态灯光的光照可以被预先计算。 因为光照图是预先计算好的，我们能够使用比Direct3D的（光照）模型多的多的更加精确的和成熟的光照模型。（更好的光照可以产生更真实的场景。） 备注：多纹理化阶段的典型应用是实现静态对象的完全光照引擎（full lighting engine）。例如，我们可以用一个纹理贴图保存对象的颜色，比如木箱的纹理贴图。然后我们可以用一个散射光照贴图（diffuse light map）保存散射表面着色（diffuse surface shade），一个单独的镜面光照贴图保存镜面表面着色，一个雾状物贴图（fog map）保存覆盖在表面的雾状物的总量，还有可以用一个详细贴图（detail map）保存小的、高访问率的表面的细节。当所有这些纹理被组合起来，只需到这些预先计算的纹理中检索，就可以有效的照亮、着色并且增加细节到场景中去。 注意：聚光灯光照贴图在很基础的光照贴图中是一个价值不高（trivial）的例子。一般的的程序通过给定的场景和光源来生成光照贴图。生成光照贴图超越了本书的范围。有兴趣的读者可以参考Alan Watt和Fabio Policarpo在《3D Games: Real-time Rendering and Software Technology》中描述的光照贴图。 18.1.1 允许多个纹理 回忆一下，纹理是用IDirect3DDevice9::SetTexture方法设置，而采样器状态（sampler state）是用IDirect3DDevice9::SetSamplerState方法设置，原型如下：HRESULT IDirect3DDevice9::SetTexture( DWORD Stage, // specifies the texture stage index IDirect3DBaseTexture9 *pTexture); HRESULT IDirect3DDevice9::SetSamplerState( DWORD Sampler, // specifies the sampler stage index D3DSAMPLERSTATETYPE Type, DWORD Value); 注意：一个特定的采样器阶段索引I联合第i个纹理阶段（texture stage）。即第i个采样器阶段指定采样器状态是第i集（set）纹理。 纹理/采样器阶段索引标识了我们希望设置的纹理/采样器的纹理/采样器阶段。因此，我们可以允许多个纹理并通过使用不同的阶段索引设置其相应的采样器状态。在本书前面的部分中，我们总是指定0，来指示第一个阶段，因为我们一次仅使用一个纹理。所以例如，假设我们要允许三个纹理，我们像这样使用阶段0,1和2：// Set first texture and corresponding sampler states.Device-&gt;SetTexture(0, Tex1);Device-&gt;SetSamplerState(0, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(0, D3DSAMP_MINFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(0, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR); // Set second texture and corresponding sampler states.Device-&gt;SetTexture(1, Tex2);Device-&gt;SetSamplerState(1, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(1, D3DSAMP_MINFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(1, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR); // Set third texture and corresponding sampler states.Device-&gt;SetTexture(2, Tex3);Device-&gt;SetSamplerState(2, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(2, D3DSAMP_MINFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(2, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR);这段代码使用Tex1, Tex2和Tex3，并设置每个纹理的过滤模式。 18.1.2 多纹理坐标 回忆一下第六章，对于每个3D三角形，我们应该在纹理上定义一个三角形以映射该3D三角形。我们通过对每个顶点增加纹理坐标完成映射。因此，每三个顶点定义一个三角形，它对应于纹理上的三角形。 因为我们现在使用多纹理，每三个顶点定义一个三角形，我们需要在每个被使用的纹理上定义一个相应的三角形。我们通过给每个顶点增加额外的一套纹理坐标——每个顶点一套，对应于每个使用的纹理。举个例子，如果我们混合三个纹理到一起，那么每个顶点必须有三套纹理坐标以索引到三个使用的纹理。因此，一个包含三个纹理的多纹理化顶点结构看起来可能像这样：struct MultiTexVertex{ MultiTexVertex(float x, float y, float z, float u0, float v0, float u1, float v1, float u2, float v2) { _x = x; _y = y; _z = z; _u0 = u0; _v0 = v0; _u1 = u1; _v1 = v1; _u2 = u2; _v2 = v2; } float _x, _y, _z; float _u0, _v0; // Texture coordinates for texture at stage 0. float _u1, _v1; // Texture coordinates for texture at stage 1. float _u2, _v2; // Texture coordinates for texture at stage 2. static const DWORD FVF; };const DWORD MultiTexVertex::FVF = D3DFVF_XYZ | D3DFVF_TEX3; 注意，指定自由顶点格式标记D3DFVF_TEX3表明顶点结构包含3套纹理坐标。固定功能管线支持最多8套纹理坐标。如果多于8套，你必须使用顶点声明和可编程顶点管线。 注意：在新版本像素着色器中，我们可以使用一套纹理坐标集来索引多个纹理，并因此消除了对多个纹理坐标的需要。当然这得假设每个纹理阶段使用相同的纹理坐标。如果每个阶段的纹理坐标不同，则我们仍然需要多纹理坐标。 像素着色器输入和输出有两样东西要输入到像素着色器：颜色和纹理坐标。两样都是以每像素为单位的。注意：回想一下，顶点颜色是在图元的面（face of primitive）间进行插值的。每个像素的纹理坐标就是简单的 (u , v) ，它指定了纹理的哪个图素被映射到像素上。在输入到像素着色器前，Direct3D根据顶点颜色和顶点纹理坐标，为每个像素计算颜色和纹理坐标。输入到像素着色器的颜色和纹理坐标的数值依赖于顶点着色器输出的颜色和纹理坐标的数值。例如，如果一个顶点着色器输出了两个颜色和三个纹理坐标，那么Direct3D将会为每个像素计算两个颜色和三个纹理坐标并且把它们把它们输入到像素着色器。我们使用带语意的语法（semantic syntax）映射输入颜色和纹理坐标进我们的着色器程序的变量里。用前面的例子，我们可以这样写：12345678struct PS_INPUT&#123; vector c0 : COLOR0; vector c1 : COLOR1; float2 t0 : TEXCOORD0; float2 t1 : TEXCOORD1; float2 t2 : TEXCOORD2;&#125;; 对于输出，像素着色器只输出一个计算过的该像素的颜色值：1234struct PS_OUTPUT&#123; vector finalPixelColor : COLOR0;&#125;; 使用像素着色器的步骤下面的列表概述了创建和使用像素着色器的必要步骤： 编写并编译像素着色器 创建一个IDirect3DPixelShader9接口来代表基于已编译代码的像素着色器 用IDirect3DDevice9::SetPixelShader方法允许该像素着色器 当然，用完顶点着色器之后我们必须销毁它。下面几个小节将深入这些步骤。 18.3.1 编写并编译像素着色器 我们用与编译顶点着色器一样的方式编译像素着色器。首先，我们必须编写一个像素着色器程序。本书中，我们用HLSL编写我们的着色器。一旦写好着色器代码，我们就可以用D3DXCompileShaderFromFile函数编译该着色器了，如16.2节所述。回忆一下，这个函数返回一个ID3DXBuffer指针，它包含已编译的着色器代码。 注意：因为我们使用的是像素着色器，所以要记得把编译目标改成像素着色器目标（比如：ps_2_0），而不是顶点着色器目标（比如：vs_2_0）。编译目标通过D3DXCompileShaderFromFile函数的一个参数指定。详见16.2节。18.3.2 创建像素着色器 一旦我们编译了着色器代码，我们就可以获得一个IDirect3DPixelShader的接口指针，它代表一个像素着色器，使用下面的方法：HRESULT IDirect3DDevice9::CreatePixelShader( CONST DWORD pFunction, IDirect3DPixelShader9* ppShader);pFunction——已编译着色器代码的指针ppShader——返回一个IDirect3DPixelShader9接口的指针 例如，假设变量shader是一个包含已编译着色器代码的ID3DXBuffer接口指针。那么要获得IDirect3DPixelShader9接口，我们应该写：IDirect3DPixelShader9 MultiTexPS = 0;hr = Device-&gt;CreatePixelShader( (DWORD)shader-&gt;GetBufferPointer(), &amp;MultiTexPS);注意：重申一遍，D3DXCompileShaderFromFile是一个可以返回已编译着色器代码（shader）的函数。 18.3.3 建立像素着色器 在我们获得一个代表我们的像素着色器的IDirect3DPixelShader9接口的指针之后，我们可以使用下面的方法使用它：HRESULT IDirect3DDevice9::SetPixelShader( IDirect3DPixelShader9* pShader); 这个方法只接受一个参数，我们通过它传递一个我们希望使用的指向像素着色器的指针。要使用我们在18.3.2节创建的像素着色器，我们应该写：Device-&gt;SetPixelShader(MultiTexPS); 18.3.4 销毁像素着色器 和其它所有Direct3D接口一样，要清除这些接口，我们必须在使用完毕后调用它们的Release方法。继续使用我们在18.3.2节创建的像素着色器，我们写：d3d::Release(MultiTexPS); 18.4 HLSL采样器对象 在像素着色器中使用HLSL的内建函数tex*XXXX给纹理采样。注意：采样时引用纹理上图素的坐标索引和采样器状态来生成像素。 看16.7节详细地解释了这些函数，通常这些函数需要我们做2件事： 使用纹理中的索引建立(u, v)纹理坐标。 给特定的纹理中编入索引。 将纹理坐标（u, v）输入到像素着色器，在一个指定的HLSL对象中的像素着色器中，我们想编入索引的纹理是在像素着色器中被定义过的，在HLSL中叫作采样器。（The particular texture that we want to index into is identified in the pixel shader by a special HLSL object called a sampler.），我们可以把采样器对象想象成定义纹理和采样器阶段的对象。例如：假如我们使用3张纹理，这意味着我们需要在像素着色器里能够引用3个阶段中的每个一个。在像素着色器中我们这样写：sampler FirstTex;sampler SecondTex;sampler ThirdTex; Direct3D将给每个采样器对象连接一个唯一的纹理级别(stage)，在应用程序中我们找出与采样器对象相关联的阶段，并设置相应的纹理和采样器状态给该阶段。下列代码将举例说明如何在应用程序中设置纹理并把采样器状态设置为FirstTex：// 创建IDirect3DTexture9* Tex;D3DXCreateTextureFromFile(Device, “tex.bmp”, &amp;Tex);… …// 取得常量FirstTex的句柄FirstTexHandle = MultiTexCT-&gt;GetConstantByName(0, “FirstTex”); // 取得常量的描述D3DXCONSTANT_DESC FirstTexDesc;UINT count;MultiTexCT-&gt;GetConstantDesc(FirstTexHandle, &amp;FirstTexDesc, &amp;count);… …// 为FirstTex设置纹理和采样器状态. We identify// the stage FirstTex is associated with from the// D3DXCONSTANT_DESC::RegisterIndex member:Device-&gt;SetTexture(FirstTexDesc.RegisterIndex, Tex); Device-&gt;SetSamplerState(FirstTexDesc.RegisterIndex, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(FirstTexDesc.RegisterIndex, D3DSAMP_MINFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(FirstTexDesc.RegisterIndex, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR); 注意：作为选择，替换使用采样器类型，你可以使用更多特殊的、强大的类型，如：sampler1D，sampler2D，sampler3D，和samplerCube类型，这些类型更安全并且它们只使用tex 函数。例如：一个sampler2D对象只使用tex2D函数，同样一个sampler3D对象只使用tex3D*函数。18.5 例子程序：Multitexturing in a Pixel Shader 这章中的例子演示了在像素着色器中使用多纹理，这个例子将纹理一个基于图18.2方格，渲染的目标是一个木箱纹理，一个聚光灯纹理，和一个包含字符串的纹理。这就是例子程序：Pixel Shader。 图18.2: 混合纹理. 让我们分别取得木箱纹理上、聚光灯纹理和字符串纹理上相关联的像素颜色：b，s和t，然后定义如何将这些颜色混合： c = b × s + t 。 这个例子可以不使用像素着色器来实现，但实现这个程序是简单直接，它允许我们示范如何写，创建，而且使用像素着色器实现一些特效不必使用那些复杂的算法。 虽然在这个例子中一次只使用3张纹理，检查采样器对象的成员以确定每个像素着色器能够使用的版本，这是值得的。换句话说，我们一次能使用多少纹理这依赖 于使用的像素着色器的版本。 像素着色器的版本ps_1_1 到 ps_1_3支持4个纹理采样器。 像素着色器的版本ps_1_4支持6个纹理采样器。 像素着色器的版本ps_2_0到 ps_3_0支持16个纹理采样器。1234567891011121314151617181920212223242526272829303132333435363738394041// File: ps_multitex.txt// Desc: Pixel shader that does multitexturing.// Globalssampler BaseTex;sampler SpotLightTex;sampler StringTex;// Structuresstruct PS_INPUT&#123; float2 base : TEXCOORD0; float2 spotlight : TEXCOORD1; float2 text : TEXCOORD2;&#125;;struct PS_OUTPUT&#123; vector diffuse : COLOR0;&#125;;// MainPS_OUTPUT Main(PS_INPUT input)&#123; // zero out members of output PS_OUTPUT output = (PS_OUTPUT)0; // sample appropriate textures vector b = tex2D(BaseTex, input.base); vector s = tex2D(SpotLightTex, input.spotlight); vector t = tex2D(StringTex, input.text); // combine texel colors vector c =b *s +t; // increase the intensity of the pixel slightly c += 0.1f; // save the resulting pixel color output.diffuse = c; return output;&#125; 首先像素着色器定义了3个sampler对象，要渲染的每个纹理，接下来定义是input和output结构。注意：我们没有将任何的颜色值输入到像素着色器中，这是因为我们使用纹理自己的颜色和光照；即BaseTex保存表面的颜色，SpotLightTex是光照图。像素着色器输出只一个简颜色值，指定了我们计算过的这个特定像素的颜色。Main函数使用tex2D函数采样3 个纹理，即它取得每个纹理的图素，计算映射到的像素，这通常依赖于指定的纹理坐标和采样器对象。然后我们混合图素的颜色用公式：c = b * s + t。接下来我们让全部的像素变亮一个bit，给每个部分增加0.1f。最后我们保存结果像素颜色并返回它。现在我们看到了的像素着色器的代码，现在我们改变并考虑应用程序的代码。应用程序有下列相应的全局变量：123456789101112131415IDirect3DPixelShader9* MultiTexPS = 0;ID3DXConstantTable* MultiTexCT = 0;IDirect3DVertexBuffer9* QuadVB = 0;IDirect3DTexture9* BaseTex = 0;IDirect3DTexture9* SpotLightTex = 0;IDirect3DTexture9* StringTex = 0;D3DXHANDLE BaseTexHandle = 0;D3DXHANDLE SpotLightTexHandle = 0;D3DXHANDLE StringTexHandle = 0;D3DXCONSTANT_DESC BaseTexDesc;D3DXCONSTANT_DESC SpotLightTexDesc;D3DXCONSTANT_DESC StringTexDesc; 多纹理顶点结构的例子如下：123456789101112131415161718192021struct MultiTexVertex&#123; MultiTexVertex(float x, float y, float z, float u0, float v0, float u1, float v1, float u2, float v2) &#123; _x = x; _y = y; _z = z; _u0 = u0; _v0 = v0; _u1 = u1; _v1 = v1; _u2 = u2, _v2 = v2; &#125; float _x, _y, _z; float _u0, _v0; float _u1, _v1; float _u2, _v2; static const DWORD FVF;&#125;;const DWORD MultiTexVertex::FVF = D3DFVF_XYZ | D3DFVF_TEX3; 它包含3个纹理坐标系统。 Setup函数执行下列功能： 填充方形的顶点缓存 编译着像素色器 创建像素色器 读取纹理 设置投影矩阵，不使用光照 取得采样器(sampler)对象的句柄 取得采样器对象的描述123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100bool Setup()&#123; HRESULT hr = 0; // Create quad geometry. Device-&gt;CreateVertexBuffer( 6 * sizeof(MultiTexVertex), D3DUSAGE_WRITEONLY, MultiTexVertex::FVF, D3DPOOL_MANAGED, &amp;QuadVB, 0); MultiTexVertex*v =0; QuadVB-&gt;Lock(0, 0, (void**)&amp;v, 0); v[0] = MultiTexVertex(-10.0f, -10.0f, 5.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, 1.0f); v[1] = MultiTexVertex(-10.0f, 10.0f, 5.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f); v[2] = MultiTexVertex( 10.0f, 10.0f, 5.0f, 1.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f); v[3] = MultiTexVertex(-10.0f, -10.0f, 5.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, 1.0f); v[4] = MultiTexVertex( 10.0f, 10.0f, 5.0f, 1.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f); v[5] = MultiTexVertex( 10.0f, -10.0f, 5.0f, 1.0f, 1.0f, 1.0f, 1.0f, 1.0f, 1.0f); QuadVB-&gt;Unlock(); // Compile shader ID3DXBuffer* shader = 0; ID3DXBuffer* errorBuffer = 0; hr = D3DXCompileShaderFromFile( "ps_multitex.txt", 0, 0, "Main", // entry point function name "ps_1_1", D3DXSHADER_DEBUG, &amp;shader, &amp;errorBuffer, &amp;MultiTexCT); // output any error messages if( errorBuffer ) &#123; ::MessageBox(0, (char*)errorBuffer-&gt;GetBufferPointer(), 0, 0); d3d::Release&lt;ID3DXBuffer*&gt;(errorBuffer); &#125; if(FAILED(hr)) &#123; ::MessageBox(0, "D3DXCompileShaderFromFile() - FAILED", 0, 0); return false; &#125; // Create Pixel Shader hr = Device-&gt;CreatePixelShader((DWORD*)shader-&gt;GetBufferPointer(),&amp;MultiTexPS); if(FAILED(hr)) &#123; ::MessageBox(0, "CreateVertexShader - FAILED", 0, 0); return false; &#125; d3d::Release&lt;ID3DXBuffer*&gt;(shader); // Load textures. D3DXCreateTextureFromFile(Device, "crate.bmp", &amp;BaseTex); D3DXCreateTextureFromFile(Device, "spotlight.bmp", &amp;SpotLightTex); D3DXCreateTextureFromFile(Device, "text.bmp", &amp;StringTex); // Set projection matrix D3DXMATRIX P; D3DXMatrixPerspectiveFovLH(&amp;P, D3DX_PI * 0.25f, (float)Width / (float)Height, 1.0f, 1000.0f); Device-&gt;SetTransform(D3DTS_PROJECTION, &amp;P); // Disable lighting. Device-&gt;SetRenderState(D3DRS_LIGHTING, false); // Get handles BaseTexHandle = MultiTexCT-&gt;GetConstantByName(0, "BaseTex"); SpotLightTexHandle = MultiTexCT-&gt;GetConstantByName(0, "SpotLightTex"); StringTexHandle = MultiTexCT-&gt;GetConstantByName(0, "StringTex"); // Set constant descriptions: UINT count; MultiTexCT-&gt;GetConstantDesc(BaseTexHandle, &amp;BaseTexDesc, &amp;count); MultiTexCT-&gt;GetConstantDesc(SpotLightTexHandle, &amp;SpotLightTexDesc, &amp;count); MultiTexCT-&gt;GetConstantDesc(StringTexHandle,&amp;StringTexDesc, &amp;count); MultiTexCT-&gt;SetDefaults(Device); return true;&#125; Display函数设置像素着色器，使用2个纹理，并且在渲染方格前设置他们对应的采样器状态。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950bool Display(float timeDelta)&#123; if( Device ) &#123; // ...camera update code snipped // Render Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); // set the pixel shader Device-&gt;SetPixelShader(MultiTexPS); Device-&gt;SetFVF(MultiTexVertex::FVF); Device-&gt;SetStreamSource(0, QuadVB, 0, sizeof(MultiTexVertex)); // base tex Device-&gt;SetTexture(BaseTexDesc.RegisterIndex, BaseTex); Device-&gt;SetSamplerState(BaseTexDesc.RegisterIndex, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(BaseTexDesc.RegisterIndex, D3DSAMP_MINFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(BaseTexDesc.RegisterIndex, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR); // spotlight tex Device-&gt;SetTexture(SpotLightTexDesc.RegisterIndex, SpotLightTex); Device-&gt;SetSamplerState(SpotLightTexDesc.RegisterIndex, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(SpotLightTexDesc.RegisterIndex, D3DSAMP_MINFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(SpotLightTexDesc.RegisterIndex, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR); // string tex Device-&gt;SetTexture( StringTexDesc.RegisterIndex, StringTex); Device-&gt;SetSamplerState(StringTexDesc.RegisterIndex, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(StringTexDesc.RegisterIndex, D3DSAMP_MINFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(StringTexDesc.RegisterIndex, D3DSAMP_MIPFILTER, D3DTEXF_LINEAR); // draw the quad Device-&gt;DrawPrimitive(D3DPT_TRIANGLELIST, 0, 2); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0);&#125;return true;&#125; 当然我们必须想着在Cleanup函数中释放我们自己分配的接口。12345678910void Cleanup()&#123; d3d::Release&lt;IDirect3DVertexBuffer9*&gt;(QuadVB); d3d::Release&lt;IDirect3DTexture9*&gt;(BaseTex); d3d::Release&lt;IDirect3DTexture9*&gt;(SpotLightTex); d3d::Release&lt;IDirect3DTexture9*&gt;(StringTex); d3d::Release&lt;IDirect3DPixelShader9*&gt;(MultiTexPS); d3d::Release&lt;ID3DXConstantTable*&gt;(MultiTexCT);&#125; 摘要 像素着色器取代了固定功能管线的多纹理级别（stage），而且，像素着色器给我们更改单独像素的能力，以任何方式选择和访问纹理数据。因而，使我们能实现很多使用固定功能管线所不能完成的特殊效果。 多纹理是一次使用几个纹理，并渲染它们一起创造出一个想要的结果的一个过程。多纹理代表性的用法是用它为静态几何图形实现光引擎。 HLSL内建的采样器（sampler）对象，标识特定的纹理/采样器级别（stage）。A采样器常用于从像素着色器中引用一个纹理/采样器级别。 注意：一旦你懂得了如何去实现顶点和像素着色器，你需要的一些特效的创意，可以用它们去实现。得到特效创意最好的方法是，学习现有的用顶点和像素着色器实现的特效。《Direct3D ShaderX: Vertex and Pixel Shader Tips》和《Tricks edited by Wolfgang Engel》这2本书是众多出版物中最好的，像Nvidia和ATI的开发站点：http://developer.nvidia.com/ 和 http://ati.com/developer/index.html。另外我们推荐CG方面：由Randima Fernando 和 Mark J. Kilgard写的《The Cg Tutorial by Randima Fernando》，这本书对于使用Cg的3D图形编程是一本相当好的指南，它基本上和Direct3D’s HLSL相同。]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction-to-Vertex-Shaders]]></title>
    <url>%2F2019%2F04%2F11%2FIntroduction-to-Vertex-Shaders%2F</url>
    <content type="text"><![CDATA[第十七章 顶点着色器入门(Introduction to Vertex Shaders)概览 顶点着色器（vertex shader）是一个在图形卡的GPU上执行的程序，它替换了固定功能管线（fixed function pipeline）中的变换（transformation）和光照（lighting）阶段。（这不是百分之百的正确，因为顶点着色器可以被Direct3D运行时（Direct3D runtime）以软件模拟，如果硬件不支持顶点着色器的话）。图16.1说明了管线中顶点着色器替换的部件。 图16.1：顶点着色器替换固定功能管线的光照和变形阶段 从图16.1，我们知道，顶点以局部坐标输入到顶点着色器，并且必须输出齐次剪裁空间的有颜色的顶点。（为了保持简单，本书中我们没有深入研究投影变换的细节。但是经投影矩阵变换顶点后的空间称作齐次剪裁空间（homogeneous clip space）。因此，要把一个顶点从局部空间变换到齐次坐标空间，我们必须应用下列变换序列：世界变换（world transformation），视图变换（view transformation）和投影变换（projection transformation），它们分别由世界矩阵，视图矩阵和投影矩阵来完成。）对于点元（point primitive），顶点着色器也被用于操作每个顶点的顶点大小。 由于顶点着色器是我们（在HLSL中）写的一个自定义程序，因此我们在图形效果方面获得了我们能够达到的极大的自由性。我们不再受限于Direct3D的固定光照算法。此外，应用程序操纵顶点位置的能力也有了多样性，例如：cloth simulation，粒子系统的点大小操纵，还有顶点混合/morphing。此外，我们的顶点数据结构更自由了，并且可以在可编程管线中包含比在固定功能管线中多得多的数据。 顶点着色器仍然是相对新的特性，并且许多图形卡不支持它们，特别是随DirectX 9发布的较新版本的顶点着色器。通过检查D3DCAPS9结构的VertexShaderVersion成员，可以测试顶点着色器的版本。下列代码段展示了这一点：// If the device’s supported version is less than version 2.0if( caps.VertexShaderVersion &lt; D3DVS VERSION(2, 0) ) // Then vertex shader version 2.0 is not supported on this device. 我们看到D3D_VERSION的两个参数分别接收主和次版本号。现在，D3DXCompileShaderFromFile函数支持顶点着色器版本1.1和2.0。 目标 学习如何在可编程管线中定义顶点结构的分量 了解顶点分量的不同用法 学习如何创建、设置和销毁一个顶点着色器 学习如何使用顶点着色器实现卡通动画渲染效果 17.1顶点声明 到现在为止，我们已经使用自由顶点格式（flexible vertex format，FVF）来描述顶点结构中的各分量。但是，在可编程管线中，顶点数据包含的数据比用FVF所能表达的多很多。因此，我们通常使用更具表达性并且更强大的顶点声明（vertex declaration）。 注意：如果FVF能够描述我们的顶点格式 我们仍然可以在可编程管线中使用它。不管用何种方法，只是为了方便，同样FVF会在内部被转换为一个顶点声明。 17.1.1 描述顶点声明 我们将一个顶点声明描述为一个D3DVERTEXELEMENT9结构的数组。D3DVERTEXELEMENT9数组中的每个成员描述了一个顶点的分量。所以，如果你的顶点结构有三个分量（例如：位置、法线、颜色），那么其相应的顶点声明将描述3个D3DVERTEXELEMENT9结构的数组。这个D3DVERTEXELEMENT9结构定义如下：typedef struct _D3DVERTEXELEMENT9 { BYTE Stream; BYTE Offset; BYTE Type; BYTE Method; BYTE Usage; BYTE UsageIndex;} D3DVERTEXELEMENT9; Stream——指定关联到顶点分量的流 Offset——偏移，按字节，相对于顶点结构成员的顶点分量的开始。例如，如果顶点结构是：struct Vertex{ D3DXVECTOR3 pos; D3DXVECTOR3 normal;};……pos分量的偏移是0，因为它是第一个分量；normal分量的偏移是12，因为sizeof(pos) == 12。换句话说，normal分量以Vertex的第12个字节为开始。 Type——指定数据类型。它可以是D3DDECLTYPE枚举类型的任意成员；完整列表请参见文档。常用类型如下： D3DDECLTYPE_FLOAT1——浮点数值 D3DDECLTYPE_FLOAT2——2D浮点向量 D3DDECLTYPE_FLOAT3——3D浮点向量 D3DDECLTYPE_FLOAT4——4D浮点向量 D3DDECLTYPE_D3DCOLOR—D3DCOLOR类型，它扩展为RGBA浮点颜色向量(r g b a)，其每一分量都是归一化到区间[0, 1]了的。 Method——指定网格化方法。我们认为这个参数是高级的，因此我们使用默认值，标识为D3DDECLMETHOD_DEFAULT.。 Usage——指定已计划的对顶点分量的使用。例如，它是否准备用于一个位置向量、法线向量、纹理坐标等？有效的用途标识符（usage identifier）是D3DDECLUSAGE枚举类型的：typedef enum _D3DDECLUSAGE { D3DDECLUSAGE_POSITION = 0, // Position. D3DDECLUSAGE_BLENDWEIGHTS = 1, // Blending weights. D3DDECLUSAGE_BLENDINDICES = 2, // Blending indices. D3DDECLUSAGE_NORMAL = 3, // Normal vector. D3DDECLUSAGE_PSIZE = 4, // Vertex point size. D3DDECLUSAGE_TEXCOORD = 5, // Texture coordinates. D3DDECLUSAGE_TANGENT = 6, // Tangent vector. D3DDECLUSAGE_BINORMAL = 7, // Binormal vector. D3DDECLUSAGE_TESSFACTOR = 8, // Tessellation factor. D3DDECLUSAGE_POSITIONT = 9, // Transformed position. D3DDECLUSAGE_COLOR = 10, // Color. D3DDECLUSAGE_FOG = 11, // Fog blend value. D3DDECLUSAGE_DEPTH = 12, // Depth value. D3DDECLUSAGE_SAMPLE = 13 // Sampler data.} D3DDECLUSAGE; D3DDECLUSAGE_PSIZE类型用于指定一个顶点的点的大小。它用于点精灵，因此我们可以基于每个顶点控制其大小。一个D3DDECLUSAGE_POSITION成员的顶点声明意味着这个顶点已经被变换，它通知图形卡不要把这个顶点送到顶点处理阶段（变形和光照）。 注意：这些中的少数用途类型（usage type）未在本书中提及，例如BLENDWEIGHTS, BLENDINDICES, TANGENT, BINORMAL, 和TESSFACTOR UsageIndex——用于标识多个相同用途的顶点分量。这个用途索引是位于区间[0, 15]间的一个整数。例如，假设我们有三个用途为D3DDECLUSAGE_NORMAL的顶点分量。我们可以为第一个指定用途索引为0，为第二个指定用途索引为1，并且为第三个指定用途索引为2。按这种方式，我们可以通过其用途索引标识每个特定的法线。 顶点描述声明的例子：假设我们想要描述的顶点格式由位置向量和三个法线向量组成。顶点声明可以指定如下：D3DVERTEXELEMENT9 decl[] ={{0, 0, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_POSITION, 0}, {0, 12, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_NORMAL, 0}, {0, 24, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_NORMAL, 1}, {0, 36, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_NORMAL, 2}, D3DDECL_END()};D3DDECL_END宏用于初始化D3DVERTEXELEMENT9数组的最后一个顶点元素。同样的，注意法线向量的用途索引标签。 17.1.2 创建顶点声明一旦你描述了一个顶点声明为D3DVERTEXELEMENT9数组，我们就可以使用下面的方法获得一个IDirect3DVertexDeclaration9接口指针：HRESULT IDirect3DDevice9::CreateVertexDeclaration( CONST D3DVERTEXELEMENT9 pVertexElements, IDirect3DVertexDeclaration9* ppDecl); pVertexElements——D3DVERTEXELEMENT9结构数组，它描述我们想要创建的顶点声明。 ppDecl——用于返回创建的IDirect3DVertexDeclaration9接口指针例子调用，其中decl是一个D3DVERTEXELEMENT9数组：IDirect3DVertexDeclaration9* _decl = 0;hr = _device-&gt;CreateVertexDeclaration(decl, &amp;_decl); 17.1.3 使用一个顶点声明 回忆一下：自由顶点格式是一个方便的特性并且在内部转换成了顶点声明。因此，当直接使用顶点声明，我们不再需要调用：Device-&gt;SetFVF( fvf );相反，我们调用：Device-&gt;SetVertexDeclaration( _decl );其中，_decl是一个IDirect3DVertexDeclaration9接口指针。17.2顶点数据用途考虑这个顶点声明：D3DVERTEXELEMENT9 decl[] ={{0, 0, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_POSITION, 0}, {0, 12, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_NORMAL, 0}, {0, 24, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_NORMAL, 1}, {0, 36, D3DDECLTYPE_FLOAT3, D3DDECLMETHOD_DEFAULT, D3DDECLUSAGE_NORMAL, 2}, D3DDECL_END()}; 我们需要一种方式，来定义一个顶点声明的元素到顶点着色器的Input结构的数据成员的映射。我们在Input结构中通过指定每个数据成员的语义（: usage-type [usage-index]）定义这个映射。语义通过元素的用途类型和用途索引标识顶点声明中的一个元素。由数据成员的语义标识的顶点元素是得以映射到数据成员的元素。例如，对应于前面的顶点声明的输入结构是：struct VS_INPUT{ vector position : POSITION; vector normal : NORMAL0; vector faceNormal1 : NORMAL1; vector faceNormal2 : NORMAL2;}; 注意：如果我们遗漏了用途索引，就意味着用途索引为零。例如，POSITION和POSITION0是同一样东西。 这里decl中的元素0，由用途POSITION和用途索引0标识，它映射到position。decl中的元素1，由用途NORMAL和用途索引0标识，它映射到normal。decl中的元素2，由NORMAL和用途索引1标识，它映射到faceNormal1。decl中的元素3，由用途NORMAL和用途索引2标识，它映射到faceNormal2。 受支持的顶点着色器输入用途（input usage）是： POSITION [n]——位置 BLENDWEIGHTS [n]——混合权重 BLENDINDICES [n]——混合索引 NORMAL [n]——法线向量 PSIZE[n]——顶点大小 DIFFUSE [n]——散射颜色 SPECULAR [n]——镜面颜色 TEXCOORD [n]——纹理坐标其中，n是一个位于区间[0, 15]的可选整数。 注意：再重复一遍，这些用途类型中的少数未在本书中提及，如：BLENDWEIGHTS, TANGENT, BINORMAL, BLENDINDICES, 和TESSFACTOR。 此外，对于输出结构，我们必须指定每个成员是用来做什么的。例如，数据成员应该被作为位置向量、颜色、纹理坐标等对待吗？图形卡没主意，除非你强制的告诉它。这也需要通过语法的语义来完成：struct VS_OUTPUT{ vector position : POSITION; vector diffuse : COLOR0; vector specular : COLOR1;}; 受支持的顶点着色器输出用途是： POSITION—位置 PSIZE—顶点大小 FOG—雾混合值 COLOR [n]—顶点颜色。注意：可以有多个顶点颜色被输出，并且这些颜色可以被混合在一起以产生最终的颜色。 TEXCOORD [n]—顶点纹理坐标。注意：多个顶点纹理坐标可以被输出。其中，n是一个位于区间[0, 15]的可选整数。 17.3使用顶点着色器的步骤下面的列表概括了创建和使用顶点着色器的必须步骤： 编写并编译顶点着色器 创建一个IDirect3DVertexShader9接口以引用已编译的着色器代码上的顶点着色器。 用IDirect3DDevice9:: SetVertexShader方法使用这个顶点着色器。 当然，在我们做完这些之后，我们还得销毁这个顶点着色器。下面的各小节将更详细的迈入这些步骤。 17.3.1 编写并编译顶点着色器 首先，我们必须编写一个顶点着色器程序。在本书中的HLSL一章中，我们已经编写了我们的着色器（译者注：参见我翻译的译文第一章中各节）。一旦着色器代码写好之后，我们就使用D3DXCompileShaderFromFile函数编译这个着色器，如16.2.2节所述。回忆一下，这个函数返回一个ID3DXBuffer指针，它包含已编译的着色器代码。 17.3.2 创建顶点着色器 一旦我们拥有了编译好的着色器代码，我们就能够获得一个IDirect3DVertexShader9接口的指针，它代表一个顶点着色器——通过使用下面的方法：HRESULT IDirect3DDevice9::CreateVertexShader( const DWORD pFunction, IDirect3DVertexShader9* ppShader);pFunction——已编译着色器代码的指针ppShader——返回一个IDirect3DVertexShader9接口的指针 例如，假设变量shader是一个包含已编译的，着色器代码的ID3DXBuffer指针。然后要获得一个IDirect3DVertexShader9接口，我们可以写：IDirect3DVertexShader9 ToonShader = 0;hr = Device-&gt;CreateVertexShader( (DWORD)shader-&gt;GetBufferPointer(), &amp;ToonShader);注意：重申一遍，D3DXCompileShaderFromFile是一个函数，它将返回已编译着色器的代码（shader）。 17.3.3 建立顶点着色器 在我们获得了一个代表我们的顶点着色器的IDirect3DVertexShader9接口的指针之后，我们就能够使用下面的方法使用它：HRESULT IDirect3DDevice9::SetVertexShader( IDirect3DVertexShader9* pShader);这个方法仅接受一个参数，我们在其中传递一个想要使用的顶点着色器的指针。要使用这个我们在17.3.2节创建的着色器，我们可以写：Device-&gt;SetVertexShader(ToonShader); 17.3.4 销毁顶点着色器 和所有的Direc3D接口一样，要清除他们，我们就必须在用完它们之后调用其的Release方法。仍然以我们在17.3.2节创建的顶点着色器为例，我们写：d3d::Release(ToonShader); 17.4样例应用程序：散射光照 作为创建并使用顶点着色器的热身，我们写一个顶点着色器，它用一个方向（平行）光对每个顶点进行标准的散射光照。简而言之，散射光照根据顶点法线和光线向量（它的点朝向光源方向）的角度计算顶点接收到的光线的数量。角度越小，则顶点接收到的光线就越多；而角度越大，则顶点接收到的光线就越少。如果角度大于等于90度，顶点就接收不到光线了。 我们以检阅着色器代码作为开始：// File: diffuse.txt// Desc: Vertex shader that does diffuse lighting.// Global variables we use to hold the view matrix, projection matrix,// ambient material, diffuse material, and the light vector that// describes the direction to the light source. These variables are// initialized from the application. matrix ViewMatrix;matrix ViewProjMatrix;vector AmbientMtrl;vector DiffuseMtrl;vector LightDirection; // 环境光强度，漫射光强度// 这些变量定义在着色器代码中vector DiffuseLightIntensity = {0.0f, 0.0f, 1.0f, 1.0f};vector AmbientLightIntensity = {0.0f, 0.0f, 0.2f, 1.0f}; // Input and Output structures.struct VS_INPUT{ vector position : POSITION; vector normal : NORMAL;}; struct VS_OUTPUT{ vector position : POSITION; vector diffuse : COLOR;}; //MainVS_OUTPUT Main(VS_INPUT input){ // zero out all members of the output instance. VS_OUTPUT output = (VS_OUTPUT)0; // 变换位置到齐次坐标空间，保存到output.position成员中 output.position = mul(input.position, ViewProjMatrix); // 变换光和法线到视图空间，设置w分量为0，是因为变换的向量不是点 LightDirection.w = 0.0f; input.normal.w = 0.0f; LightDirection = mul(LightDirection, ViewMatrix); input.normal = mul(input.normal, ViewMatrix); // 计算光与法线夹角的余弦 float s = dot(LightDirection, input.normal); // 回忆一下，如果法线和光的夹角大于90度，则表面接收不到光。 if( s &lt; 0.0f ) s = 0.0f; // 环境光反射是执行一个叉积（环境材质向量与环境光强度向量）， // 漫射光反射是执行一个叉积（漫射材质向量与漫射光强度向量， // 更进一步讲，我们测量着色器的颜色，基于顶点从光源处接收到多少光 //环境光和漫射光综合起来，决定一个顶点的最终颜色 output.diffuse = (AmbientMtrl * AmbientLightIntensity) + ((DiffuseMtrl * DiffuseLightIntensity) * s); return output; } 既然我们已经看到了实际的顶点着色器的代码，那么就让我们改变方式来看看应用程序的代码。这个应用程序有下列相关的全局变量：IDirect3DVertexShader9 DiffuseShader = 0;ID3DXConstantTable DiffuseConstTable = 0;ID3DXMesh* Teapot = 0;D3DXHANDLE ViewMatrixHandle = 0;D3DXHANDLE ViewProjMatrixHandle = 0;D3DXHANDLE AmbientMtrlHandle = 0;D3DXHANDLE DiffuseMtrlHandle = 0;D3DXHANDLE LightDirHandle = 0;D3DXMATRIX Proj; 有代表顶点着色器及其常量表的变量，有茶壶网格的变量，接着是一组D3DXHANDLE，其名字描述了他们引用的变量： Setup函数执行下列任务： 创建茶壶网格 编译顶点着色器 根据已编译代码创建顶点着色器 通过常量表获取着色器程序中的几个变量的句柄 通过常量表初始化着色器的这几个变量 注意：对于本应用程序，我们的顶点结构不需要任何自由顶点格式没有的额外的分量。因此，在本例中，我们使用一个自由顶点格式来代替顶点声明。回想一下，自由顶点格式描述最终在内部被转换为一个顶点声明。bool Setup(){ HRESULT hr = 0; // Create geometry: D3DXCreateTeapot(Device, &amp;Teapot, 0); // Compile shader ID3DXBuffer* shader = 0; ID3DXBuffer* errorBuffer = 0; hr = D3DXCompileShaderFromFile( &quot;diffuse.txt&quot;, 0, 0, &quot;Main&quot;, // entry point function name &quot;vs_1_1&quot;, D3DXSHADER_DEBUG, &amp;shader, &amp;errorBuffer, &amp;DiffuseConstTable); // output any error messages if( errorBuffer ) { ::MessageBox(0, (char*)errorBuffer-&gt;GetBufferPointer(), 0, 0); d3d::Release&lt;ID3DXBuffer*&gt;(errorBuffer); } if(FAILED(hr)) { ::MessageBox(0, &quot;D3DXCompileShaderFromFile() - FAILED&quot;, 0, 0); return false; } // Create shader hr = Device-&gt;CreateVertexShader( (DWORD*)shader-&gt;GetBufferPointer(), &amp;DiffuseShader); if(FAILED(hr)) { ::MessageBox(0, &quot;CreateVertexShader - FAILED&quot;, 0, 0); return false; } d3d::Release&lt;ID3DXBuffer*&gt;(shader); // Get Handles LightDirHandle = DiffuseConstTable-&gt;GetConstantByName(0, &quot;LightDirection&quot;); ViewMatrixHandle = DiffuseConstTable-&gt;GetConstantByName(0, &quot;ViewMatrix&quot;); ViewProjMatrixHandle = DiffuseConstTable-&gt;GetConstantByName(0, &quot;ViewProjMatrix&quot;); AmbientMtrlHandle = DiffuseConstTable-&gt;GetConstantByName(0, &quot;AmbientMtrl&quot;); DiffuseMtrlHandle = DiffuseConstTable-&gt;GetConstantByName(0, &quot;DiffuseMtrl&quot;); // Set shader constants: // Light direction: D3DXVECTOR4 directionToLight(-0.57f, 0.57f, -0.57f, 0.0f); DiffuseConstTable-&gt;SetVector(Device, LightDirHandle, &amp;directionToLight); // Materials: D3DXVECTOR4 ambientMtrl(0.0f, 0.0f, 1.0f, 1.0f); D3DXVECTOR4 diffuseMtrl(0.0f, 0.0f, 1.0f, 1.0f); DiffuseConstTable-&gt;SetVector(Device,AmbientMtrlHandle,&amp;ambientMtrl); DiffuseConstTable-&gt;SetVector(Device,DiffuseMtrlHandle,&amp;diffuseMtrl); DiffuseConstTable-&gt;SetDefaults(Device); // Compute projection matrix. D3DXMatrixPerspectiveFovLH( &amp;Proj, D3DX PI * 0.25f, (float)Width / (float)Height, 1.0f, 1000.0f); return true; } Display函数非常简单。它检测用户输入（译者注：这里指的是用户输入的传入着色器程序的变量），并相应的更新视图矩阵。但是，因为我们在着色器中执行这个视图矩阵变换，所以我们还必须更新着色器中的视图矩阵变量。我们用常量表完成这件事情。bool Display(float timeDelta){ if( Device ) { // Update view matrix code snipped… D3DXMATRIX V; D3DXMatrixLookAtLH(&amp;V, &amp;position, &amp;target, &amp;up); DiffuseConstTable-&gt;SetMatrix(Device, ViewMatrixHandle, &amp;V); D3DXMATRIX ViewProj =V *Proj; DiffuseConstTable-&gt;SetMatrix(Device, ViewProjMatrixHandle, &amp;ViewProj); // Render Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); Device-&gt;SetVertexShader(DiffuseShader); Teapot-&gt;DrawSubset(0); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); } return true; } 同样注意，就在DrawSubset调用之前，我们允许了这个我们希望使用的顶点着色器。清理也需要被完成；我们简单的释放了这个已分配的接口：void Cleanup(){ d3d::Release(Teapot); d3d::Release(DiffuseShader); d3d::Release(DiffuseConstTable);} 17.5 卡通渲染 作为第二个顶点着色器的例子，让我们编写两个顶点着色器，它们以卡通风格的绘画方式对网格着色（shade）并画轮廓（outline）。图17.2展示了这一点： 图17.2：（a）使用卡通着色法着色的对象（注意着色间的尖锐过渡）。（b）增强卡通效果，轮廓边（silhouette edge）被勾出。（c）使用标准散射光照着色的对象 注意：卡通渲染是一种特定类型的非写实渲染（non-photorealistic rendering），有时被称作风格化渲染（stylistic rendering）。 虽然卡通渲染不适用于所有游戏，例如激烈的第一人称射击游戏，但是它仍然可以增强一些希望表现卡通感觉类型游戏的气氛。此外，卡通渲染是漂亮的，并易于实现。让我们好好的演示一个顶点着色器。 我们将卡通渲染分为两步： 卡通绘画的特点是：在一个顶点到下一个顶点的强烈转换时，有少量的阴影强度级别；我们看一下这个卡通阴影（cartoon shading）。在图17.2（a）中，我们看到网络着色使用了三种阴影强度（亮、中、暗），而且其间的过渡是不平滑的——不像图17.2（c），其明暗过渡是平滑的。 卡通绘图的主要特点是：在其外框上勾画轮廓，如图17.2（b）所示。这两个步骤都需要其各自的顶点着色器。 17.5.1 卡通着色 要实现卡通着色，我们采用Lander在2000年3月发表在Game Developer Magazine的文章“Shades of Disney: Opaquing a 3D World”中所描述的方法。它像这样工作：我们创建一个带强度级别的灰度纹理，它包含我们需要的不同的着色强度。图17.3显示了我们在样例程序中使用的这个纹理。 图 17.3：用来保存着色强度的着色纹理。注意观察不连续的着色间过渡和纹理着色强度必须从左到右增加。 然后在顶点着色器中，我们执行标准散射点积运算（standard diffuse calculation dot product）来确定顶点法线N和光线向量L之间角度的余弦，用以确定顶点接收到多少光线：s=L·N 如果s＜0，就表示光线向量和顶点法线之间的角度大于90度，也就表示该表面接收不到光线。因此，如果s＜0，我们就让s＝0。所以s ∈ [0, 1]。 现在，在通常的散射光照模型中，我们使用s来标记颜色向量。这样，顶点颜色的明暗取决于接收到的光照的数量：diffuseColor = s(r, g, b, a) 但是，这将会导致从亮到暗之间平滑的着色。这是与我们期望的卡通着色相反的。我们想要一种在几个不同着色器间突然转换颜色的效果（对卡通渲染来说，在2至4种着色器工作起来还是挺不错的）。 不使用s来标记颜色向量，我们将使用s作为早先提到的强度纹理的u纹理坐标——如图17.3。注意：标量（scalar）s必定是一个有效的纹理坐标，因为s ∈ [0, 1]，这是通常的纹理坐标区间。 按这种方式，顶点不会被平滑着色，而是间断的。例如，强度纹理可能被分成3种着色，如图17.4所示： 图17.4：那么，s ∈ [0, 0.33]的值使用shader0着色，s ∈ [ 0.33，0.66]的值使用shader1着色，s ∈ [0.66,1]的值使用shader2着色。当然，从这些着色的一种到另一种的过渡是不平滑的，这就赋予了我们期望的效果。 注意：我们还为卡通着色关闭了纹理过滤，因为这种过滤会试图使着色过渡变平滑。这对于我们要求的不连续过渡是多余的。 17.5.2 卡通着色的顶点着色器代码 我们现在介绍卡通着色的顶点着色器。这个着色器的主要任务只是根据s=L·N计算并设置纹理坐标。注意观察输出结构，我们已经增加了一个数据成员来存储已被计算过的纹理坐标。同时还需注意，我们仍然输出顶点颜色，虽然我们不修改它，不过当颜色被与强度纹理组合起来的时候，它呈现为被着色的。// File: toon.txt// Desc: Vertex shader that lights geometry so it appears to be// drawn in a cartoon style. // Globalsextern matrix WorldViewMatrix;extern matrix WorldViewProjMatrix;extern vector Color;extern vector LightDirection;static vector Black = {0.0f, 0.0f, 0.0f, 0.0f}; // Structuresstruct VS_INPUT{ vector position : POSITION; vector normal : NORMAL;}; struct VS_OUTPUT{ vector position : POSITION; float2 uvCoords : TEXCOORD; vector diffuse : COLOR;}; // MainVS_OUTPUT Main(VS_INPUT input){ // zero out each member in output VS_OUTPUT output = (VS_OUTPUT)0; // transform vertex position to homogenous clip space output.position = mul(input.position, WorldViewProjMatrix); // Transform lights and normals to view space. Set w // components to zero since we’re transforming vectors. // Assume there are no scalings in the world // matrix as well. LightDirection.w = 0.0f; input.normal.w = 0.0f; LightDirection = mul(LightDirection, WorldViewMatrix); input.normal = mul(input.normal, WorldViewMatrix); // Compute the 1D texture coordinate for toon rendering. float u = dot(LightDirection, input.normal); // Clamp to zero if u is negative because u // negative implies the angle between the light // and normal is greater than 90 degrees. And // if that is true then the surface receives no light. if(u &lt; 0.0f) u = 0.0f; // Set other tex coord to middle. float v = 0.5f; output.uvCoords.x = u; output.uvCoords.y = v; // save color output.diffuse = Color; return output;} 两点注解： 我们假设世界矩阵没有执行任何缩放。因为如果它执行，它就会弄乱乘以它的顶点的长度和方向。 我们总是设置v纹理坐标为纹理的中点。这意味着我们仅使用纹理中一条单一的线，那就是说我们可以使用1D强度纹理来代替2D的那个纹理。不管怎样，1D和2D纹理都能工作。本例中，我们使用了2D纹理而不是1D纹理，这是没有什么特别的原因的。 17.5.3轮廓勾勒要完成卡通效果，我们还需要勾勒（outline）轮廓边（silhouette edge）。这比卡通着色稍微复杂一点。 17.5.3.1 边的表示法我们将一个网格的一条边表示为一个四元组（构建自2个三角形）——参见图17.5。 图 17.5：表示边的四元组 我们选择四元组有两个原因：我们可以通过调整四元组的维容易的改变边的厚度，并且我们可以渲染退化的四元组来隐藏某些边，也即非轮廓边。在Direct3D中，我们从两个三角形来构建一个四元组。退化四元组（degenerate quad）是从两个退化三角形构建而来的四元组。退化三角形（degenerate triangle）是一个面积为零的三角形，或者换句话说，是一个三点位于一线上的三角形。如果我们传入一个退化三角形到渲染管线，则该三角形显示为空。这是很有用的，因为如果我们希望隐藏特定三角形，我们可以简单的退化它而不需要实际的从三角形列表（顶点缓冲）移除它。回想一下，我们只需要显示轮廓边——而不是网格的每一条边。 当我们首先创建一条边的时候，我们指定其四个顶点，并使其退化，这意味着边将会被隐藏（渲染时不显示）。 图17.6：由两个三角形共用边描述的退化四元组 注意图17.6中的两个顶点v0和v1，我们设置其顶点法线向量为零向量。然后当我们将边的顶点送入顶点着色器的时候，顶点着色器将会检测顶点是否位于轮廓边上；如果是，则顶点着色器将按顶点法线的方向偏移顶点位置的标量。观察法线向量为零的顶点，它不会被偏移。 因此，我们最终以一个非退化四元组（non-degenerate quad）来表示轮廓边，如图17.7所示。 图17.7：位于轮廓边上的顶点v2和v3被按照其各自的顶点法线n2和n3进行偏移。观察顶点v0和v1仍然保持在其固定位置，因为其顶点法线等于零向量，因此对于它们来说没有偏移发生。按这种方式，四元组成功的重新生成来表示轮廓边。 备注：如果我们没有设置顶点v0和v1的顶点法线为零向量，那么那些顶点就同样会被偏移。但是如果偏移描述轮廓边的所有四个顶点，那么我们仅是平移了该退化四元组。通过保持顶点v0和v1固定并仅仅偏移顶点v2和v3，我们重新生成了四元组。 17.5.3.2 轮廓边测试 若两个三角面face0和face1在视图方向上与两个不同方向的面共享同一条边，则该边为轮廓边。也就是说，如果一个面是前面（front facing）而另一个面是后面（back facing），那么这条边就是一条轮廓边。图17.8给出了一个轮廓边和一个非轮廓边的例子。 图17.8：在（a）中，由v0 和v1定义的共享边的一个面是前面，而共享边另一个面是背面，因此该边是轮廓边。在（b）中，由v0 和v1定义的这两个共享边面都是前面，因此该边不是轮廓边。 接下来，为了检测一个顶点是否在轮廓边上，我们必须以每个顶点为基础了解face0 和 face1的法线向量。我们的边的顶点数据结构反映如下：struct VS_INPUT{ vector position : POSITION; vector normal : NORMAL0; vector faceNormal1 : NORMAL1; vector faceNormal2 : NORMAL2;}; 前两个分量很直接，但让我们看看两个额外的法线向量，它们是faceNormal1和faceNormal2。这些向量描述了两个三角面的面法线，共享边的顶点位于这两个面的共享边上，这两个面是face0和face1。 实际检测顶点是否在共享边上的数学如下。假设我们在视图空间中，令v为一原点指向检测顶点的向量——图17.8，令n0为face0的面法线且n1为face0的面法线，若下面的不等式为真，则顶点位于轮廓边上：（1）（v·n0）（v·n1）＜0 若两点积符号相异，则不等式为真，使得不等式左边为负。回想一下点积的性质：两个点积的符号相异，这意味着一个三角面是前面而另一个是后面。 现在，考虑一条边只有一个三角形共享它的情况，如图17.9，其法线将会被存储在faceNormal1中。 图 17.9：顶点v0和v1定义的边只有一个三角面共享它 我们定义这种边总为轮廓边。要确保顶点着色器将这种边作为轮廓边处理，我们要让faceNormal2 = -faceNormal1。因此，反向的面法线和不等式（1）为真，表示该边为一轮廓边。 17.5.3.3 边的生成 生成网格的边是微不足道的；我们简单的遍历网格的每个三角面并为三角面上每条边计算一个四元组（退化的，如图17.6所示）。注意：每个三角面有三条边，因为每个三角形有三条边。 对于每条边上的顶点，我们同样需要知道共享边的两个三角面。一个面是边所在的三角形。例如，如果要计算第1个面的一条边，那么第1个面共享该边。共享该边的另一个面可以使用网格的邻接信息找到。17.5.4 轮廓边顶点着色器代码 我们现在呈现渲染轮廓边的顶点着色器代码。这个着色器的主要任务就是确定传入的顶点是否在轮廓边上。如果是，顶点着色器就以一定的值，按顶点法线的方向偏移顶点。// File: outline.txt// Desc: Vertex shader renders silhouette edges. // Globals extern matrix WorldViewMatrix;extern matrix ProjMatrix;static vector Black = {0.0f, 0.0f, 0.0f, 0.0f}; // Structuresstruct VS_INPUT{ vector position : POSITION; vector normal : NORMAL0; vector faceNormal1 : NORMAL1; vector faceNormal2 : NORMAL2;};struct VS_OUTPUT{ vector position : POSITION; vector diffuse : COLOR;}; // MainVS_OUTPUT Main(VS_INPUT input){ // zero out each member in output VS_OUTPUT output = (VS_OUTPUT)0; // transform position to view space input.position = mul(input.position, WorldViewMatrix); // Compute a vector in the direction of the vertex // from the eye. Recall the eye is at the origin // in view space - eye is just camera position. vector eyeToVertex = input.position; // transform normals to view space. Set w // components to zero since we&#39;re transforming vectors. // Assume there are no scalings in the world // matrix as well. input.normal.w = 0.0f; input.faceNormal1.w = 0.0f; input.faceNormal2.w = 0.0f; input.normal = mul(input.normal, WorldViewMatrix); input.faceNormal1 = mul(input.faceNormal1, WorldViewMatrix); input.faceNormal2 = mul(input.faceNormal2, WorldViewMatrix); // compute the cosine of the angles between // the eyeToVertex vector and the face normals. float dot0 = dot(eyeToVertex, input.faceNormal1); float dot1 = dot(eyeToVertex, input.faceNormal2); // if cosines are different signs (positive/negative) // then we are on a silhouette edge. Do the signs // differ? if( (dot0 * dot1) &lt; 0.0f ) { // yes, then this vertex is on a silhouette edge, // offset the vertex position by some scalar in the // direction of the vertex normal. input.position += 0.1f * input.normal; } // transform to homogeneous clip space output.position = mul(input.position, ProjMatrix); // set outline color output.diffuse = Black; return output; } 17.6 摘要 使用顶点着色器，我们可以替换固定功能管线的变换和光照阶段。通过用我们自己的程序（顶点着色器）替换此固定处理，我们可以在图形效果方面获得我们能够达到的极大的自由性。 顶点声明用于描述顶点格式。它们和自由顶点格式相似，但是更加自由并允许我们描述FVF不能描述的顶点格式。注意，如果顶点可以用FVF描述，我们仍然可以使用它们；不管怎样，在内部它们被转换为顶点声明。 对于输入，用途语义指定了顶点分量如何被从顶点声明映射到HLSL程序中的变量。对于输出，用途语义指定了顶点分量是用来做什么的（例如：位置、颜色、纹理坐标，等等）。]]></content>
  </entry>
  <entry>
    <title><![CDATA[高级着色器语言入门(Introduction to the High-Level Shading Language)]]></title>
    <url>%2F2019%2F04%2F11%2FIntorduction-to-the-High-Level-Shading-Language%2F</url>
    <content type="text"><![CDATA[在这一章里我们描述高级着色器语言（High-Level Shading Language ，简称HLSL），在下三章里我们用它去编写顶点和像素着色器。简单的说，在我们写的程序里顶点和像素是很小的对象，它们由GPU来执行，是固定功能管线的一部分。用我们自己写的着色器程序替换一部分固定功能管线，在绘制效果上我们获得很大的灵活性。我们不再局限于预定义的”固定”操作。 为了编写着色器程序，我们需要一种语言。 在DirectX 8.x,中，着色器是用低级着色器汇编语言编写的。幸运的是，我们不必再用汇编语言来写着色器了，DirectX 9支持一种高级着色器语言来xyna写。用HLSL在汇编语言来写着色器程序与使用高级语言有同样的优势，像C++，它超越了汇编语言，即： 增加生产力—用高级语言比用低级语言写程序更快、更容易。 我们可以花费更多的时间关注于算法而不是代码。 增加可读性—用高级语言写的程序更易读，这意味着用高级语言编程更易于调试和维护。 大多数情况下，编译器产生的汇编代码比手写有效率。 使用HLSL 编译器，我们可以编译我们的代码到任何可用shader版本，使用汇编语言我们将不得不为每个需要的版本移植代码。 HLSL 同C和C++语法很类似, 所以缩短了学习曲线。 最后，如果你的显卡不支持顶点和像素着色器的话，为了执行着色器的例子程序你将需要转换REF设备。使用REF设备意味着着色器例子运行的会很慢，但它至少能显示结果，让我们去检查是否代码可以被执行。 提示：顶点shaders可以用软件来模拟 ―― D3DCREATE_SOFTWARE_VERTEX-PROCESSING。16.1 目标 学习如何定、编译一个HLSL 着色器程序。 学习如何将程序中的数据传送到着色器程序。 熟悉语法、类型，和HLSL的内建函数。 编写HLSL着色器我们可以在程序源文件中用字符串直接编写HLSL着色器代码，然而更方便、更模块化的方法是把它与程序代码分离出来。因此，我们在记事本中编写着色器并保存成一般的ASCII文本文件，然后可以用D3DXCompileShaderFromFile函数(section 16.2.2)来编译它们。作为介绍，下面是用HLSL编写的一个简单的顶点着色器，用记事本生成并保存成文本文件“Transform.txt”。全部工程都在标题为Transform的目录下，顶点着色器用组合视图和投影矩阵转换顶点，并设置顶点漫射光为蓝色。 注意：这是一个顶点着色器的例子，不必关心顶点着色器做了什么，这是下一章包含的内容，现在的目标是熟悉HLSL编程的语法和格式。// File: transform.txt// Author: Frank D. Luna (C) All Rights Reserved// System: AMD Athlon 1800+ XP, 512 DDR, Geforce 3, Windows XP,// MSVC++ 7.0 // Desc: 顶点着色器用组合视图和投影矩阵转换顶点，并设置顶点漫射光为蓝色. //全局变量//用来保存视图和投影的组合矩阵，在程序中初始化变量matrix ViewProjMatrix; // 初始化颜色变量（蓝色）vector Blue = {0.0f, 0.0f, 1.0f, 1.0f}; // 结构// Input结构用来描述输入到着色器的顶点，这个Input顶点只包含一个位置成员struct VS_INPUT{ vector position : POSITION;}; //Output结构用来描述从着色器输出的顶点，这个Output顶点包含位置和颜色成员struct VS_OUTPUT{ vector position : POSITION; vector diffuse : COLOR;}; //主入口点，这个main函数接收一个Input顶点的拷贝作为参数，返回一个Output顶点的拷贝VS_OUTPUT Main(VS_INPUT input){ // 将output结构所有成员初始化 VS_OUTPUT output = (VS_OUTPUT)0; // 将位置变换到投影空间 output.position = mul(input.position, ViewProjMatrix); // 设置顶点颜色 output.diffuse = Blue; //Output the projected and colored vertex. return output;} 16.1.1 全局变量首先是2个全局变量：matrix ViewProjMatrix;vector Blue = {0.0f, 0.0f, 1.0f, 1.0f}; 第1个变量ViewProjMatrix是矩阵类型，它是一个在HLSL 内创建的4×4的矩阵类型。这个变量保存视图与投影的组合矩阵，它描述两者的变换。使用这种方法我们只要做一个向量和矩阵的乘法（而不是二个）。注意，在着色器源代码的任何地方都没有初始化这个变量，因为它是我们在应用程序的源代码里设置的，而不是在着色器中。从应用程序向着色器程序通讯是常用的操作，例子在16.2.1节。 第二个变量Blue是built-in（内建）类型的4D向量，我们简单的将它初始化成蓝色，它是个RGBA的颜色向量。 16.1.2 输入和输出结构 在全局变量定义之后，定义2个特殊的结构，我们调用输入和输出结构。对于顶点着色器而言，这些结构定义了顶点的数据，分别是：struct VS_INPUT{ vector position : POSITION;}; struct VS_OUTPUT{ vector position : POSITION; vector diffuse : COLOR;};注意：给像素着色器的结构定义输入和输出像素数据。 在例子中，INPUT 顶点着色器只包含位置成员（POSITION），OUTPUT顶点着色器包含位置和颜色成员（POSITION and COLOR）。 特殊的冒号是一种语义，用于是声明变量。这与vertex结构中的自由顶点格式（FVF）相似。例如，在VS_INPUT中有成员：vector position : POSITION; “: COLOR”是说顶点的漫射光是用VS_OUTPUT结构的COLOR成员来说明的。在下一章中对于顶点和像素着色器中向量的标识符用法，我们将会有更多的讨论。 注意：从底层来说，着色器变量的语义和语法同硬件寄存器是相关联的。即，input变量与input寄存器关联，output变量与output寄存器关联。例如，VS_INPUT中的position成员与顶点input的position寄存器相关联。同样，diffuse与顶点的output 的color寄存器关联。 16.1.3 函数的入口点 在C++程序中，每个HLSL程序有一个入口点。在我们的着色器例子中，我们调用入口点函数main。然而名字不是强制的。入口点函数名可以是任何有效的函数名，入口点函数必须有一个input结构参数，它通过input顶点进入着色器。入口点函数必须返回一个output结构实例，在着色器中使用output操作顶点。VS_OUTPUT Main(VS_INPUT input){ 注意：实际上，使用input、output结构不是强制的。例如，有时你将会看到使用类似下面的语法，特别是在像素着色器中：float4 Main(in float2 base : TEXCOORD0, in float2 spot : TEXCOORD1, in float2 text : TEXCOORD2) : COLOR{…} 例子中，输入到着色器中的参数是3个纹理坐标。着色器输出（返回）一个颜色，COLOR语句在函数的声明以后。这种定义是类似于：struct INPUT{ float2 base : TEXCOORD0; float2 spot : TEXCOORD1; float2 text : TEXCOORD2;}; struct OUTPUT{ float4 c : COLOR;}; OUTPUT Main(INPUT input){…} 输入点函数负责根据给定的input顶点计算output顶点。例子中的着色器简单的变换input顶点到视图空间和投影空间，设置顶点颜色为蓝色，并返回结果顶点。首先我们定义VS_OUTPUT的实例并初始化所有成员为0。VS_OUTPUT output = (VS_OUTPUT)0; // zero out all members 然后着色器变换input顶点位置用ViewProjMatrix变量，使用mul 函数。它是一个built-in（内建）函数，实现向量与矩阵相乘，或矩阵与矩阵相乘。我们保存结果变换的向量（在output实例的position成员中）。// 变换后为投影空间的位置output.position = mul(input.position, ViewProjMatrix); 然后设置output的成员diffuse的颜色为蓝色：// 设置顶点颜色output.diffuse = Blue; 最后返回结果向量：return output;}16.2 编译HLSL 着色器16.2.1 常量表 每个着色器有一个常量表，用来保存它的变量。D3DX库通过ID3DXConstantTable接口，提供给应用程序访问着色器的常量表。通过这个接口我们能够在应用程序中设置着色器源代码中的变量。 我们现在描述一个被节选了的ID3DXConstantTable接口的方法列表的实现，全部的列表请查阅Direct3D文档。16.2.1.1 取得常量句柄 为了在应用程序中设置着色器中的一个特定变量，需要有一种方法去引用它，我们能够在应用程序中用D3DXHANDLE引用一个在着色器中的变量，下面的方法返回一个着色器中的变量的D3DXHANDLE，使用时，需要传递一个变量的名字作为参数：D3DXHANDLE ID3DXConstantTable::GetConstantByName( D3DXHANDLE hConstant, // scope of constant LPCSTR pName // name of constant); Hconstant——我们要取得的父结构中变量句柄的D3DXHANDLE标识。例如，如果我们想获得一个特定数据结构中单一数据成员的句柄，我们可以传递结构实例的句柄。如果我们获得一个顶级变量的句柄，给这个参数设为0。 PName——我们想获得的句柄的着色器代码中的变量的名字。 例如，如果在着色器中变量的名字为ViewProjMatrix，并且这是顶级变量，我们这么写：// 取得着色器中ViewProjMatrix变量的句柄D3DXHANDLE h0;h0 = ConstTable-&gt;GetConstantByName(0, “ViewProjMatrix”); 16.2.1.2 设置常量 一旦应用程序有了一个D3DXHANDLE，要引用着色器代码中的具体变量，我们可以在应用程序中使用ID3DXConstantTable::SetXXX方法设置变量。如果我们想设置一个向量数组类型的变量，方法名是SetVectorArray。 ID3DXConstantTable::SetXXX的一般语法是：HRESULT ID3DXConstantTable::SetXXX( LPDIRECT3DDEVICE9 pDevice, D3DXHANDLE hConstant, XXX value); PDevice：常量表所关联的设备的指针。 HConstant：我们正在设置的变量句柄的引用。 Value：我们要把变量设置成的值，XXX是我们设置的要替换的变量类型名，对于有些类型（bool, int, float），传递变量值的COPY，另外一些类型（vectors, matrices, structures），传递值的指针。 下面列表描述了我们能用ID3DXConstantTable接口设置的类型列表。这里假定我们有一个有效的设备，和一个有效句柄。SetBool—Used to set a Boolean value. Sample call:bool b = true;ConstTable-&gt;SetBool(Device, handle, b); SetBoolArray—Used to set a Boolean array. Sample call:bool b[3] = {true, false, true};ConstTable-&gt;SetBoolArray(Device, handle, b, 3); SetFloat—Used to set a float. Sample call:float f = 3.14f;ConstTable-&gt;SetFloat(Device, handle, f); SetFloatArray—Used to set a float array. Sample call:float f[2] = {1.0f, 2.0f};ConstTable-&gt;SetFloatArray(Device, handle, f, 2); SetInt—Used to set an integer. Sample call:int x = 4;ConstTable-&gt;SetInt(Device, handle, x); SetIntArray—Used to set an integer array. Sample call:int x[4] = {1, 2, 3, 4};ConstTable-&gt;SetIntArray(Device, handle, x, 4); SetMatrix—Used to set a 4 × 4 matrix. Sample call:D3DXMATRIX M(…);ConstTable-&gt;SetMatrix(Device, handle, &amp;M); SetMatrixArray—Used to set a 4 × 4 matrix array. Sample call:D3DXMATRIX M[4];// …Initialize matricesConstTable-&gt;SetMatrixArray(Device, handle, M, 4); SetMatrixPointerArray—Used to set an array of 4 × 4 matrix pointers. Sample call:D3DXMATRIX* M[4];// …Allocate and initialize matrix pointersConstTable-&gt;SetMatrixPointerArray(Device, handle, M, 4); SetMatrixTranspose—Used to set a transposed 4 × 4 matrix. Sample call:D3DXMATRIX M(…);D3DXMatrixTranspose(&amp;M, &amp;M);ConstTable-&gt;SetMatrixTranspose(Device, handle, &amp;M); SetMatrixTransposeArray—Used to set an array of 4 × 4 transposed matrices. Sample call:D3DXMATRIX M[4];// …Initialize matrices and transpose them.ConstTable-&gt;SetMatrixTransposeArray(Device, handle, M, 4); SetMatrixTransposePointerArray—Used to set an array of pointers to 4 × 4 transposed matrices. Sample call:D3DXMATRIX* M[4];// …Allocate,initialize matrix pointers and transpose them.ConstTable-&gt;SetMatrixTransposePointerArray(Device, handle, M, 4); SetVector—Used to set a variable of type D3DXVECTOR4. Sample call:D3DXVECTOR4 v(1.0f, 2.0f, 3.0f, 4.0f);ConstTable-&gt;SetVector(Device, handle, &amp;v); SetVectorArray—Used to set a variable that is a vector array. Sample call:D3DXVECTOR4 v[3];// …Initialize vectorsConstTable-&gt;SetVectorArray(Device, handle, v, 3); SetValue—Used to set an arbitrarily sized type, such as a structure. In the sample call, we use SetValue to set a D3DXMATRIX:D3DXMATRIX M(…);ConstTable-&gt;SetValue(Device, handle, (void*)&amp;M, sizeof(M)); 16.2.1.3 设置常量默认值 下一个方法就是设置常量的默认值，这些默认值在声明时初始化。这个方法应该在应用程序建立（setup）期间被一次性调用（called once）。 HRESULT ID3DXConstantTable::SetDefaults( LPDIRECT3DDEVICE9 pDevice ); pDevice——关联到常量表的设备的指针。 16.2.2 编译HLSL着色器 我们可以编译一个着色器——用我们已保存的着色器的文本文件——使用下列函数： HRESULT D3DXCompileShaderFromFile( LPCSTR pSrcFile, CONST D3DXMACRO pDefines, LPD3DXINCLUDE pInclude, LPCSTR pFunctionName, LPCSTR pTarget, DWORD Flags, LPD3DXBUFFER ppShader, LPD3DXBUFFER ppErrorMsgs, LPD3DXCONSTANTTABLE ppConstantTable ); pSrcFile——要编译的包含着色器源代码的文本文件的文件名 pDefines——参数可选，本书中指定为空。 pInclude——ID3DXInclude接口指针。这个接口被设计成由应用程序实现，所以我们可以重载默认include的行为。通常，默认行为就可以了，而且我们可以通过将其指定为空忽略此参数。 pFunctionName——指定入口点函数名的字符串。例如，如果着色器的入口点函数叫做Main，我们可以给此参数传递“Main”。 pTarget——指定要编译成的HLSL着色器源文件的版本的字符串。有效的顶点着色器版本是：vs_1_1, vs_2_0, vs_2_sw。有效的像素着色器版本是2.0，我们可以给此参数传递vs_2_0。 备注：有编译不同版本着色器的能力，是HLSL与汇编语言比的主要优势。用HLSL我们只需为需要的目标简单的重新编译，便可快速移植着色器到不同的版本。使用汇编，我们可能需要手动移植代码。 Flags——可选的编译标记，指定为0标识没有标记。有效的选项是： D3DXSHADER_DEBUG——通知编译器写入调试信息 D3DXSHADER_SKIPVALIDATION——通知编译器不要做任何代码检查。此项仅用于你已知着色器能够工作时 D3DXSHADER_SKIPOPTIMIZATION——通知编译器不要执行任何代码优化。实践中，这个选项应该仅用于调试，因为这种情况下你不希望编译器以任何方式修改代码。 ppShader——返回已编译的着色器代码的ID3DXBuffer指针。这个已编译过的着色器代码将作为另一个实际创建顶点/像素着色器函数的参数 ppErrorMsgs——返回包含错误码和错误消息字符串的ID3DXBuffer指针 ppConstantTable——返回包含此着色器常量表数据的ID3DXConstantTable指针 这里是一个调用D3DXCompileShaderFromFile的例子： // Compile shader ID3DXConstantTable TransformConstantTable = 0; ID3DXBuffer shader = 0; ID3DXBuffer* errorBuffer = 0; hr = D3DXCompileShaderFromFile( &quot;transform.txt&quot;, // shader filename 0, 0, &quot;Main&quot;, // entry point function name &quot;vs 2 0&quot;, // shader version to compile to D3DXSHADER_DEBUG, // debug compile &amp;shader, &amp;errorBuffer, &amp;TransformConstantTable); // output any error messages if( errorBuffer ) { ::MessageBox(0, (char*)errorBuffer-&gt;GetBufferPointer(), 0, 0); d3d::Release&lt;ID3DXBuffer*&gt;(errorBuffer); } if (FAILED (hr)) { ::MessageBox(0, &quot;D3DXCreateEffectFromFile() - FAILED&quot;, 0, 0); return false; } 16.3 变量类型 注意：除了下列各小节中描述的类型外，HLSL还有一些内建的对象类型（如：纹理对象）。但是，由于这些对象类型主要用于效果框架，我们将对其延迟到第19章讨论。 16.3.1 数值类型HLSL支持下列数值类型（scalar type）： bool—True or false value. Note that HLSL provides the true and false keywords. int—32-bit signed integer half—16-bit floating-point number float—32-bit floating-point number double—64-bit floating-point number 注意：一些平台不支持int, half, and double类型，这时我们使用 float类型模拟。 16.3.2 向量类型HLSL有下列内建的向量类型（vector type）： vector——各分量为float类型的4D向量 vector——一个n维向量，其每个分量都为T类型。n维必须在1到4之间。这里是一个2D double向量的例子：vector vec2; 我们可以使用数组下标的语法访问向量的一个分量。例如，要设置向量vec的第i个分量，我们可以写成：vec[i] = 2.0f; 此外，我们可以像访问结构的成员一样访问向量vec的一个分量，使用已定义的分量名x，y，z，w，r，g，b和a。vec.x = vec.r = 1.0f;vec.y = vec.g = 2.0f;vec.z = vec.b = 3.0f; vec.w = vec.a = 4.0f; 名称为r，g，b和a的分量分别对应x，y，z和w的分量。当使用向量来表示颜色时，RGBA符号是更适合的，因为它加强了向量所表示的颜色。 作为选择，我们可以使用其它一些预定义类型，分别用来代表2D，3D和4D向量的类型：float2 vec2;float3 vec3;float4 vec4; 考虑向量u = (ux, uy, uz, uw)，假设我们要拷贝u的所有分量到一个像v = (ux, uy, uy, uw)这样的向量v。最直接的方法可能是逐个从u往v拷贝每个分量。但不管怎样，HLSL提供了一种特殊的语法做这些无序的拷贝，它叫做“鸡尾酒”（swizzles）：vector u = {l.0f, 2.0f, 3.0f, 4.0f};vector v = {0.0f, 0.0f, 5.0f, 6.0f};v = u.xyyw; // v = {1.0f, 2.0f, 2.0f, 4.0f} 拷贝数组时，我们不必拷贝每个分量。例如，我们可以仅拷贝x和y分量，代码段举例如下：vector u = {1.0f, 2.0f, 3.0f, 4.0f};vector v = {0.0f, 0.0f, 5.0f, 6.0f};v.xy = u; // v = {l.0f, 2.0f, 5.0f, 6.0f} 16.3.3 矩阵类型HLSL有下列内建矩阵类型： matrix——一个4×4矩阵，其各项类型为float matrix——一个m×n矩阵，其每个成员为类型T。矩阵维数m和n必须在1至4之间。 这里是一个2×2整型矩阵的例子：matrix m2x2; 作为选择，我们可以定义一个m×n矩阵，其m和n在1至4之间，使用下列语法：floatmxn matmxn;实例：float2x2 mat2x2;float3x3 mat3x3;float4x4 mat4x4;float2x4 mat2x4;注意：类型不必是float类型——我们可以使用其它类型。举例来说，我们可以用整型，写成这样：int2x2 i2x2;int2x2 i3x3;int2x2 i2x4; 我们可以用二维数组的下标语法访问矩阵中的项。例如，要设置矩阵M的第i，j个项，我们可以写成：M[i] [j] = value; 此外，我们可以像访问结构的成员那样访问矩阵M的项。下列条目已定义：以1为基数的：M._11 = M._12 = M._13 = M._14 = 0.0f;M._21 = M._22 = M._23 = M._24 = 0.0f;M._31 = M._32 = M._33 = M._34 = 0.0f;M._41 = M._42 = M._43 = M._44 = 0.0f; 以0为基数的：M._m00 = M._m01 = M._m02 = M._m03 = 0.0f;M._m10 = M._m11 = M._m12 = M._m13 = 0.0f;M._m20 = M._m21 = M._m22 = M._m23 = 0.0f;M._m30 = M._m31 = M._m32 = M._m33 = 0.0f; 有时，我们想要访问矩阵中一个特定的行。我们可以用一维数组的下标语法来做。例如，要引用矩阵M中第i行的向量，我们可以写：vector ithRow = M[i]; // get the ith row vector in M 注意：可以使用两种语法在HLSL中初始化变量：vector u = {0.6f, 0.3f, 1.0f, 1.0f};vector v = {1.0f, 5.0f, 0.2f, 1.0f}; 也可以，等价的，使用构造风格的语法：vector u = vector(0.6f, 0.3f, 1.0f, 1.0f);vector v = vector(1.0f, 5.0f, 0.2f, 1.0f); 其它一些例子:float2x2 f2x2 = float2x2(1.0f, 2.0f, 3.0f, 4.0f);int2x2 m = {1, 2, 3, 4};int n = int(5);int a = {5};float3 x = float3(0, 0, 0); 16.3.4 数组我们可以用类似C++的语法声明特定类型的一个数组。例如：float M[4][4];half p[4];vector v[12]; 16.3.5 结构结构的定义和在C++里一样。但是，HLSL里的结构不能有成员函数。这是一个HLSL里的结构的例子：struct MyStruct{ matrix T; vector n; float f; int x; bool b;};MyStruct s; // instantiates.f = 5.0f; // member access 16.3.6 typedef关键字 HLSL的typedef关键字功能和C++里的完全一样。例如，我们可以给类型vector用下面的语法命名：typedef vector point;然后，不用写成：vector myPoint;……我们只需这样写：point myPoint; 这里是另外两个例子，它展示了如何对常量和数组类型使用typedef关键字：typedef const float CFLOAT;typedef float point2[2]; 1.3.7 变量前缀下列关键字可以做变量声明的前缀： static——如果带static关键字前缀，那它是全局变量。就表示它不是暴露于着色器之外的。换句话说，它是着色器局部的。如果一个局部变量以static关键字为前缀，它就和C++中static局部变量有相同的行为。也就是说，该变量在函数首次执行时被一次性初始化，然后在所有函数调用中维持其值。如果变量没有被初始化，它就自动初始化为0。static int x = 5; uniform——如果变量以uniform关键字为前缀，就意味着此变量在着色器外面被初始化，比如被C++应用程序初始化，然后再输入进着色器。 extern——如果变量以extern关键字为前缀，就意味着该变量可在着色器外被访问，比如被C++应用程序。仅全局变量可以以extern关键字为前缀。不是static的全局变量默认就是extern。 shared——如果变量以shared关键字为前缀，就提示效果框架（参见19章）：变量将在多个效果间被共享。仅全局变量可以以shared为前缀。 volatile——如果变量以volatile关键字为前缀，就提示效果框架（参见19章）：变量将被时常修改。仅全局变量可以以volatile为前缀。 const——HLSL中的const关键字和C++里的意思一样。也就是说，如果变量以const为前缀，那此变量就是常量，并且不能被改变。const float pi = 3.14f;16.4关键字、语句和强制转换16.4.1 关键字为便于参考，这里给出一个HLSL定义的关键字列表：asm bool compile const decl dodouble else extern false float forhalf if in inline inout intmatrix out pass pixelshader return samplershared static string struct technique texturetrue typedef uniform vector vertexshader voidvolatile while 下面的集合显示了被保留并且未使用但是将来可能成为关键字的标识符：auto break case catch char classconst_cast continue default delete dynamic cast enumexplicit friend goto long mutable namespacenew operator private protected public registerreinterpret_cast short signed sizeof static_cast switchtemplate this throw try typename unionunsigned using virtual 16.4.2 基本程序流程HLSL支持很多与C++相似的选择、重复、和一般程序流程语句。这些语句的语法和C++极为相似。return语句：return (expression);if和if…else语句：if( condition ){ statement(s);} if( condition ){ statement(s);}else{ statement(s);} for语句：for(initial; condition; increment){ statement(s);} while语句：while( condition ){ statement(s);} do…while语句：do{ statement(s);}while( condition ); 16.4.3 强制转换（casting） HLSL支持一种非常自由的强制转换设计。HLSL中强制转换的语法和C程序语言中的一样。例如要把float转换到matrix，我们写：float f = 5.0f;matrix m = (matrix)f; 从本书的例子中，你就能推断出这个转换语法的意思。但是，如果想要得到更详细的受支持的转换的信息，那么在DirectX SDK里，Content（内容）标签页下，看DirectX Graphics\Reference\Shader Reference\High Level Shading Language\Type就可以了。 16.5 操作符 HLSL支持很多类似C++的操作符。除了很少一些底下注释的例外以外，他们的用法和C++里的完全一样。下表列出了HLSL的操作符：[]?&gt;&lt;&lt; = =! == =!&amp;&amp;??:+ =- = =//=%%= + +=()‘ 虽然操作符的行为和C++很相似，但是也有一些差异。第一，求模%运算符对整型和浮点型都起作用。为了使用求模操作符，左边的值和右边的值都必须有相同的正负号（如：左边和右边必须都是正或者负）。 第二，要注意HLSL操作是以每个分量为基础的。这是由于实际上向量和矩阵是语言内建的，并且这些类型是由若干个分量组成。通过将这些操作施加在分量级别之上，我们可以像使用数值类型一样完成诸如向量/矩阵的加法，减法和相等测试这些操作（），见下例： 注意：操作符的行为正如对数值操作一样（也就是说，按一般C++的方式）。vector u = {1.0f, 0.0f, -3.0f, 1.0f};vector v = {-4.0f, 2.0f, 1.0f, 0.0f};// adds corresponding componentsvector sum = u + v; // sum = (-3.0f, 2.0f, -2.0f, 1.0f) 增量一个向量就是增量其每个分量：// before increment: sum = (-3.0f, 2.0f, -2.0f, 1.0f)sum++; // after increment: sum = (-2.0f, 3.0f, -1.0f, 2.0f) 向量相乘也是按分量的：vector u = {1.0f, 0.0f, -3.0f, 1.0f};vector v = {-4.0f, 2.0f, 1.0f, 0.0f}; // multiply corresponding componentsvector sum = u * v; // product = (-4.0f, 0.0f, -3.0f, 0.0f) 比较操作也是按分量进行的，并且返回一个每个分量都为bool类型的向量或者数组。作为结果的“bool”向量包含了每个分量比较的结果。例如：vector u = { 1.0f, 0.0f, -3.0f, 1.0f};vector v = {-4.0f, 0.0f, 1.0f, 1.0f};vector b = (u == v); // b = (false, true, false, true) 最后，我们以讨论二元操作的变量提升（promotion）作为结束： 对于二元操作，如果（操作符的）左边和右边维数不同，则维数较少的一边提升（强制转换）到具有和维数较大的一边相同的维数。例如，如果x的类型为float，而y的类型为float3，在表达式(x + y)中变量x被提升到float3，并且计算出来的表达式的值的类型也为float3。提升使用已定义的转换完成。注意，若转换未定义则提升也是未定义的。例如，我们不能转换float2到float3，因为没有定义这个转换。 对于二元操作，如果左边和右边类型不同，那么较低精度的类型（the lower type resolution）被提升（强制转换）到具有同类型的较高精度的类型（the higher type resolution）。例如，如果x类型为int，y类型为half，则表达式(x + y)中的变量x被提升到half，并且计算出来的表达式的值的类型也为half。 16.6 用户定义函数HLSL中的函数有下例属性： 函数使用类似C++的语法 参数总是按值传递 递归不被支持 函数总是inline的 此外，函数还加上了一些用于其上的额外的关键字。例如，考虑一个写在HLSL中的下面这个函数：bool foo(in const bool b, // input bool out int r1, // output int inout float r2) // input/output float{ if( b ) // test input value { r1 = 5; // output a value through r1 } else { r1 = 1; // output a value through r1 } // since r2 is inout we can use it as an input // value and also output a value through it r2 = r2 * r2 * r2; return true; } 函数几乎和C++函数是一样的，除了in，out和inout关键字： in——指定型参（argument，特指传递给实参的变量）应该在函数开始前被拷贝给实参。传入参数不必强制指定，因为实参默认是in的。例如，下面两段是等价的：float square(in float x){ return x * x;} 也可以不强制指定in：float square(float x){ return x * x;} out——指定实参应该在函数返回时被拷贝给型参。这样可以通过参数返回值。out关键字是必须的，因为HLSL不允许传递一个引用或一个指针。我们要注意：如果实参标记为out，在函数开始前，型参就不拷贝给实参。换句话说，out实参仅可以被用于输出数据——它不能用于输入。void square(in float x, out float y){ y = x * x;}这里，我们输入了要被乘方的数x，并且通过参数y返回了x的乘方。 inout——这是一个指示实参既用于输入又用于输出的快捷方法。如果要使用实参同时用作输入和输出，就指定inout。void square(inout float x){ x = x * x;}这里，我们输入了要被乘方的数x，同时又通过x返回了的x的乘方。 16.7内建函数 HLSL有一个丰富的内建函数的集合，它们对3D图形来说非常有用。下表是一个删减了的列表。在下两章中，我们会使用这些函数中的一些进行实践。而现在，熟悉它们就够了。 注意：要得到更多的参考，可以参看DirectX文档中内建HLSL函数的完整列表，在Content页下，然后到DirectX Graphics\Reference\Shader Reference\High Level Shader Language\Intrinsic Functions。 译者注：以下表格中，////表示变量variable的模（例如向量的绝对值）。函数描述abs(x)返回 |x|ceil(x)返回 ≥ x 的最小整数clamp(x, a, b)clamp(x, a, b)clamp(x, a, b)clamp(x, a, b)cross(u, v)返回 u × v（叉积）degrees(x)转换 x 从弧度到角度determinant(M)返回矩阵M的行列式det(M)distance(u, v)返回u点和v点之间的距离||v - u||dot(u, v)返回 u · v（点积）floor(x)返回 ≤ x 的最大整数length(v)返回 ||v||lerp(u, v, t)在u和v之间线性插值，根据参数 t ? [0, 1 ]log(x)返回 ln(x)log10(x)返回 log10(x)log2(x)返回 log2(x)max(x, y)如果x ≥ y，则返回 x；否则返回 ymin(x, y)如果 x ≤ y，返回x；否则返回 ymul(M, N)返回矩阵乘积 MN. 注意：矩阵乘积必须是已定义的. 如果M是一个向量，它被作为一个行向量，则向量－矩阵（vector-matrix）乘法是已定义的。类似的,如果N 是一个向量，他被作为一个列向量，则矩阵－向量（matrix-vector）乘法是已定义的normalize(v)返回 v/∥v∥pow(b, n)返回 bnradians(x)转换 x 从 角度 到 弧度reflect(v, n)给定向量v和表面法线n，计算其反射向量refract(v,n, eta)给定向量v、表面法线n和两种材质的两个索引的比率eta，计算其折射向量. 翻看一下物理书中Snell的规则或者在互联网上搜索一下关于refraction（反射）的信息rsqrt(x)返回x的平方根的倒数saturate(x)返回clamp(x, 0.0, 1.0)sin(x)返回x的正弦,其中x单位为弧度返回x的正弦,其中x单位为弧度返回x的正弦和余弦，其中x单位为弧度sqrt(x)返回x的平方根tan(x)返回x的正切,其中 x 单位为弧度transpose(M)返回MT的转置 大多数函数已经重载以使其可以对所有内建类型有意义。例如，abs对所有数值类型有意义，所以它为所有这些数值类型进行了重载。又例如，叉积的叉乘仅对3D向量有意义，所以它对所有类型的3D向量（比如：int，float，double的3D向量）进行了重载。另一方面，线性插值——lerp，对于数值、2D、3D和4D向量有意义，因此重载了这些类型。 注意：如果你传递进去一个非数值类型到一个（要求）数值类型的函数，也就是一个仅能对数值类型进行操作的函数（比如：cos(x)），那么这个函数会对传进去的每个分量进行操作。例如，你写：floats v = float3 (0.0f, 0.0f, 0.0f);v = cos(v); 那么函数将会对每个分量进行操作：v=(cos(x),cos(y),cos(z))。下例展示了这些固有的函数可能被调用的方式：float x = sin(1.0f); // sine of 1.0f radian.float y = sqrt(4.0f); // square root of 4. vector u = {1.0f, 2.0f, -3.0f, 0.0f};vector v = {3.0f, -1.0f, 0.0f, 2.0f};float s = dot(u, v); // compute dot product of u and v. float3 i = {1.0f, 0.0f, 0.0f};float3 j = {0.0f, 1.0f, 0.0f};float3 k = cross(i, j); // compute cross product of i and j. matrix M = {1.0f, 2.0f, 3.0f, 4.0f};matrix T = transpose(M); // compute transpose 16.8 摘要 我们在ASCII文本文件中编写了HLSL程序，并且在我们的应用程序中使用D3DXCompileShaderFromFile函数编译了它们。 ID3DXConstantTable接口允许我们在应用程序中对着色器程序中的变量进行设置。这种通信是必须的，因为被着色器使用的变量可以按一帧一帧的变化而改变。例如，如果应用程序中的视图矩阵发生了改变，我们需要使用新的视图矩阵更新着色器的视图矩阵变量。我们可以用ID3DXConstantTable完成这种更新。 对于每个着色器，我们必须定义一个输入和一个输出结构，这些结构分别描述了着色器中输入和输出数据的格式。 每个着色器有一个入口点函数，它有一个输入结构参数用于传递数据进着色器。此外，每个着色器返回一个输出结构的实例，它用于从着色器输出数据。]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
      <tags>
        <tag>Direct3D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十五章 选取(Picking)]]></title>
    <url>%2F2019%2F04%2F11%2FPicking%2F</url>
    <content type="text"><![CDATA[概览(OVERVIEW) 如果用户点击了屏幕上的点 s = (x, y)。 从图15.1 我们能看到用户选取了茶壶。 无论如何，应用程序无法根据给定的s点就立即确定茶壶是被选取。所以，我们必须拿出计算这个动作技巧来，叫做选取技巧。 图15.1 用户正在选择茶壶 我们知道一些知识：关于茶壶和它的关联点s，茶壶投影在围绕s点的区域，更准确的说是：它投影到投影窗口上围绕p点的区域，与它对应的屏幕点是s。因为这个问题依赖于3D物体与它的投影之间的关系，我们看图15.2就可以了解。 图15.2放射线穿过点p点将会相交于围绕p点投影的对象。 注意：在投影窗口上的点 p与荧屏上被按下了点s相关联。 图15.2我们看到如果我们发射一条选取射线，从原点发出，经过点p，会与围绕p点投影的对象相交，即茶壶。所以一旦我们计算选取射线，我们可以遍例场景中的每个对象并测试，看射线是否与它相交。与射线相交的对象即是用户选择的对象，在这个例子中用户选取的对象是茶壶。 上面的例子讲解了点s与茶壶的关系。通常我们任意点击屏幕上的点，我们遍例场景中的每个对象，如果对象与射线相交，那么这个对象就是用户选取的对象。例如，图15.1中，如果用户没有点击5个对象中的一个，而是点击了白色的背景区域，射线将不能相交任何对象。因此，结论是：如果射线没有与场景中的任何对象相交，则用户没有点击任何一个对象，其它的我们不关心。 “选取”适用于所有种类的游戏和3D程序。例如，玩家通过用鼠标点击来影响3D世界中的不同对象，玩家可能点击向敌人射击，或点击拾取物品。好的程序会适当做出反应，程序需要知道哪个对象被选取（是敌人还是物品），和在3D空间中的位置（开枪会击中哪？或玩家将要移动到哪去拾取物品？）。选取回答了我们这些问题。 目标学习如何计算选取算法并了解它是如何工作的，我们将选取分解成四步：1) 给一个屏幕点s，找出它在投影窗口上相交的点，即p。2) 计算射线，它是从原点出发并经过点p。3) 转换射线与模型到同一空间。4) 测试与射线相交的对象，相交的对象即是屏幕上点击的对象。15.1 屏幕到投影窗口的转换首先，转换屏幕点到投影窗口，视口变换矩阵是： 根据屏幕上的点s = (sx, sy)，通过视口转换，得到在投影窗口上的点p = (px, py, pz)： 回忆一下2D图形部分：视口转换后z轴是不用保存的，而被保存在z缓存中。给出屏幕点s，我们要找到点p，使用下列公式： 假定视口成员x和y都是0，通常我们能进一步得到： 因为前面的定义，投影窗口就是z=1的平面，所以pz = 1。 可是我们还什么都没做，投影矩阵缩放投影窗口上的点，来模拟不同的视角。为了返回缩放前的点值，我们必须用与缩放相反的操作来转换点。P是投影矩阵，因为P00 和 P11转换距阵缩放点的x和y坐标，我们得到： 15.2 计算射线 回忆一下，射线能够描述参数方程：p(t) = p0 + tu。其中p0是射线的起点，用来描述它的位置，u是向量，用来描述它的方向。 如图15.2，我们知道射线的起点总是视图空间的原点，所以p0 = (0, 0, 0)，如果p是射线穿过投影窗口上的点，方向向量u给出：u = p - p0 = (px, py, 1) - (0, 0, 0) = p。 下面的方法用来计算选取射线（从屏幕空间点击的点所对应的视图空间的点x、y坐标）：d3d::Ray CalcPickingRay(int x, int y){ float px = 0.0f; float py = 0.0f; D3DVIEWPORT9 vp; Device-&gt;GetViewport(&amp;vp); D3DXMATRIX proj; Device-&gt;GetTransform(D3DTS_PROJECTION, &amp;proj); px = ((( 2.0f*x) / vp.Width) - 1.0f) / proj(0, 0); py = (((-2.0f*y) / vp.Height) + 1.0f) / proj(1, 1); d3d::Ray ray; ray._origin = D3DXVECTOR3(0.0f, 0.0f, 0.0f); ray._direction = D3DXVECTOR3(px, py, 1.0f); return ray; }where Ray is defined as:struct Ray{ D3DXVECTOR3 _origin; D3DXVECTOR3 _direction;}; 我们更新d3dUtility.h文件，在d3d命名空间中加入选取射线Ray。 15.3 变换射线 上一节讲到，选取射线的计算被描述在视图空间，为了完成射线的相交的测试，射线和对象必须在同一个坐标系统。通常转换射线到世界空间（甚至对象在本地空间）要好于将所有对象转换到视图空间。 我们能够将一个变换矩阵转换为一条原点为p0，方向为u的射线r(t) = p0 + tu，注意：原点转换为一个点，方向转换为一个向量，在本章的选取例子中，下列函数转换一条射线：void TransformRay(d3d::Ray ray, D3DXMATRIX T){ // transform the ray’s origin, w = 1. D3DXVec3TransformCoord( &amp;ray-&gt;_origin, &amp;ray-&gt;_origin, T); // transform the ray&#39;s direction, w = 0. D3DXVec3TransformNormal( &amp;ray-&gt;_direction, &amp;ray-&gt;_direction, T); // normalize the direction D3DXVec3Normalize(&amp;ray-&gt;_direction, &amp;ray-&gt;_direction); } D3DXVec3TransformCoord和D3DXVec3TransformNormal接受一个Ray类型参数（包含二个3D向量成员）。 D3DXVec3TransformCoord函数中，射线的原点（_origin）向量的第四部分w = 1。相反，函数D3DXVec3TransformNormal中，射线的方向（_direction）向量的第四部分w = 0。 这样，当我们向世界空间转换时，能够用D3DXVec3TransformCoord转换一个点，用D3DXVec3TransformNormal转换一个向量。 15.4 射线－对象 交点 我们将射线和对象转换到同一坐标系统后，准备测试哪个对象与射线相交。因为我们将对象描述为三角形组成的网络，下面详细说明这种方法。遍例场景中每个对象的三角形列表并测试，如果射线相交于一个三角形，它就与三角形所在的对象相交。 然而，通过遍例场景中的每个三角形来实现射线相交在计算上会增加时间，一种比较快的方法，虽然准确性会差一点。它将每个对象围成一个近似的球形（边界球），这样我们就能通过遍例每个边界球来测试射线相交。用边界球来描述相交的对象。 注意：射线可能相交多个对象，然而离照相机近的对象会被选取。因为近距离对象遮挡了后面的对象。 给出一个边界球的圆心c和半径r，使用下列恒等式能够测试点p是否在边界球上： ||p-c||-r = 0 如果恒等式满足，则点p在边界球上。如图15.3 图15.3 向量p到c的长度表示为：||p - c||，如果等于半径则表示点p在边界球上。注意：我们使用边界球是为了方便，但这将扩展出三个种情况。 假定射线p(t) = p0 + tu相交于边界球，我们将射线代入球的恒等式中，使参数t满足了球的恒等式，给出了满足相交点的参数。 将射线p(t) = p0 + tu代入球的恒等式：||p(t) - c|| - r = 0 —&gt; ||p0 + tu - c|| - r = 0 通过以上推导，我们得到二次方程：At2 + Bt + C = 0 其中A = u · u, B = 2(u · (p0 - c))，而C = (p0 - c) . (p0 - c) – r 2。如果u是标准化的，那么A = 1。因为u是标准化的，我们解t0 和 t1： 图15.4显示可能返回的t0 和 t1，并显示了一些返回值的几何意义： 图15.4 (a)射线从球边上擦过；(b)射线在球前；(c)射线在球的内部；(d)射线相交于球；(e)射线是球的切线。 下列方法射线通过并与边界球相交，返回true；射线错过边界球，返回false。 bool PickApp::raySphereIntersectionTest(Ray ray, BoundingSphere sphere){ D3DXVECTOR3 v = ray-&gt;_origin - sphere-&gt;_center; float b = 2.0f D3DXVec3Dot(&amp;ray-&gt;_direction, &amp;v); float c = D3DXVec3Dot(&amp;v, &amp;v) - (sphere-&gt;_radius sphere-&gt; _radius); // find the discriminant float discriminant = (b * b) - (4.0f * c); // test for imaginary number if( discriminant &lt; 0.0f ) return false; discriminant = sqrtf(discriminant); float s0 = (-b + discriminant) / 2.0f; float s1 = (-b - discriminant) / 2.0f; // if a solution is &gt;= 0, then we intersected the sphere if( s0 &gt;= 0.0f || s1 &gt;= 0.0f ) return true; return false; } 当然，我们已经准备了一个边界球，为了便于理解我们再次显示它的定义：bool PickApp::raySphereIntersectionTest(Ray ray, BoundingSphere sphere){struct BoundingSphere{ BoundingSphere(); D3DXVECTOR3 _center; float _radius; }; 15.5 例子程序：选取图15.5显示了本章例子程序的屏幕截图，茶壶绕着屏幕移动，你可以用鼠标试着点击它。如果你点击到茶壶的边界球上，一个消息框将弹出，表示你点中了。我们通过测试WM_LBUTTONDOWN消息来处理鼠标点击事件：case WM_LBUTTONDOWN: // compute the ray in view space given the clicked screen pointd3d::Ray ray = CalcPickingRay(LOWORD(lParam), HIWORD(lParam)); // transform the ray to world spaceD3DXMATRIX view;Device-&gt;GetTransform(D3DTS_VIEW, &amp;view); D3DXMATRIX viewInverse;D3DXMatrixInverse(&amp;viewInverse, 0, &amp;view); TransformRay(&amp;ray, &amp;viewInverse); // test for a hitif( RaySphereIntTest(&amp;ray, &amp;BSphere) ) ::MessageBox(0, “Hit!”, “HIT”, 0); break; 图15.5 这章例子程序的屏幕截图 15.6 摘要 选取技巧通过鼠标点击，来确定与3D对象对应的屏幕上显示的2D投影对象。 选取线是一个射线，源自视图空间的原点，穿过投影窗口上的点关联到屏幕上点击的点。 我们能够变换一个射线r(t) = p0 + tu，通过变换原点p0和通过矩阵变换得到方向u。注意：原点变换自一个（w=1）的点，方向是（w=0）的向量。 测试射线与对象相交，我们能测试射线是否相交于组成对象的三角形，或测试射线是否相交于围绕对象的一个体积，比如边界球。]]></content>
  </entry>
  <entry>
    <title><![CDATA[第十四章 粒子系统(Particle Systems)]]></title>
    <url>%2F2019%2F04%2F11%2FParticle-System%2F</url>
    <content type="text"><![CDATA[许多自然现象是由很多小的小颗粒组成的，它们有相似的行为。（例如，雪花落下，闪烁的火焰，冲出枪管的“子弹”），粒子系统用来模拟这种现象。目标： 学习我们给定的粒子属性，如何描述D3D中的粒子。 设计一个灵活的粒子基系统的基类，包括一般的粒子系统都有的属性和方法。 模拟3个具体的粒子系统，雪、爆炸、粒子枪。14.1 粒子和点精灵（Point Sprite） 粒子是一个很小的对象，它通常用来模拟数学中的一个点。点元是用来显示粒子的很好的方案。可是点元被光栅化成一个简单的像素。这没给我们多少灵活性，因为我们想有各种大小不同的粒子，并且把整个纹理平滑映射到这些粒子上。在Direct3D 8.0,以前，因为点元方法的局限性而完全不使用他们。代替的方法是，程序员将使用公告板去显示粒子，一个板是一个方格，世界矩阵用它来确定方向，使它总是朝向照相机。 Direct3D 8.0引入一个特殊的点元叫点精灵，多数时候被应用在粒子系统中。与一般的点元不同的是，点精灵有纹理映射并能改变大小。与公告板不同的是，能用一个简单的点描述一个点精灵，节省内存和处理时间，因为我们只是必须保存和处理一个点，而公告板则是四个。 14.1.1 结构的格式 我们使用下面的顶点结构来描述粒子的位置和颜色：struct Particle{ D3DXVECTOR3 _position; D3DCOLOR _color; static const DWORD FVF;};const DWORD Particle::FVF = D3DFVF_XYZ | D3DFVF_DIFFUSE; 这个结构只保存粒子的位置和颜色，这取决于你程序的需要，你能够用同样的结构去保存一套纹理坐标，我们在下一节讨论给点精灵赋予纹理。 增加一个浮点变量给Particle结构去指定粒子的大小是可能的。我们必须增加一个D3DFVF_PSIZE标记给我们的灵活的顶点格式，以反映这个变化。每个粒子维护自己的大小很有用，因为它允许我们以具体情况指定并改变粒子的大小。可是，大多数的图形卡不支持控制粒子的大小，因此我们不使用它。（检查D3DFVFCAPS_PSIZE在D3 DCAPS9结构的FVFCaps成员）代替的方法是：用渲染状态（render states）去控制粒子的大小，就像你很快看到的，有尺寸成员的顶点结构的例子：strict Particle{ D3DXVECTOR3 _position; D3DCOLOR _color; float _size; static const DWORD FVF;};const DWORD Particle::FVF = D3DFVF XYZ | D3DFVF DIFFUSE | D3DFVF_PSIZE; 注意：通过vertex shader，能够获取每个粒子的大小，即使你的硬件不支持D3DFVFCAPS_PSIZE。Vertex shaders的内容在本书的第IV部分。 14.1.2点精灵（Point Sprite）渲染状态 点精灵的行为大部分由渲染状态（render states）来控制，现在让我们来看一下这些渲染状态：D3DRS_POINTSPRITEENABLE—A Boolean value. The default value is false.True表示将当前的纹理全部映射到点精灵上。False 表示用指定的纹理坐标映射到点精灵的点（图素）上。_device-&gt;SetRenderState(D3DRS_POINTSPRITEENABLE, true); D3DRS_POINTSCALEENABLE—A Boolean value. The default value is false.True表示用视图空间单位来解释点的大小。视图空间单位的3D空间点在照相机中，点精灵将会自动缩放，这取决到它有多远, 像其他对象一样，离照相机近的粒子比离照相机远的粒子要小。False 表示点的大小将用屏幕空间单位来解释。屏幕空间单位是屏幕上的像素单位。. 因此如果你指定false, 例如, 设置点精灵的尺寸为3, 则点精灵在屏幕区域中的尺寸为3×3像素。._device-&gt;SetRenderState(D3DRS_POINTSCALEENABLE, true); D3DRS_POINTSIZE—表示点精灵的尺寸. 这个值可以任意指定视图空间或屏幕空间的点精灵的尺寸, 取决于D3DRS_POINTSCALEENABLE 状态如何设置. 下面的代码段设置点的尺寸为2.5个单位。:_device-&gt;SetRenderState( D3DRS_POINTSIZE, d3d::FtoDw(2.5f) ); d3d::FtoDw 是我们新加进 d3dUtility.h/cpp 文件中的一个函数，它将float型转换为 DWORD型。 我们必须这么做是因为所有的IDirect3DDevice9::SetRenderState 都要一个 DWORD 型的值而不是float型。DWORD d3d::FtoDw(float f){ return ((DWORD)&amp;f);} D3DRS_POINTSIZE_MIN—表示点精灵的最小尺寸。例子，将设置最小值为0.2：_device-&gt;SetRenderState(D3DRS_POINTSIZE_MIN, d3d::FtoDw(0.2f)); D3DRS_POINTSIZE_MAX—表示点精灵的最大尺寸。例子，将设置最大值为5.0:_device-&gt;SetRenderState(D3DRS_POINTSIZE_MAX, d3d::FtoDw(5.0f)); D3DRS_POINTSCALE_A, D3DRS_POINTSCALE_B, D3DRS_POINTSCALE_C—这3个常量表示如何根据距离控制点精灵的尺寸—这个距离是点精灵到照相机的距离。 D3D用以下的公式去计算点精灵的最终尺寸，这取决于距离和这3个常量。 其中：FinalSize：距离计算后，点精灵的最后尺寸。ViewportHeight：视口的高度。Size：分别为D3DRS_POINTSCALE_A, D3DRS_POINTSCALE_B, and D3DRS_POINTSCALE_C值。D：在视图空间中点精灵与照相机的距离。因为照相机被放置在视图空间中的原点，这个值是：，也是点精灵所在的位置。 下面代码设置点精灵的距离常量，因此远处的点精灵将变小。_device-&gt;SetRenderState(D3DRS_POINTSCALE_A, d3d::FtoDw(0.0f));_device-&gt;SetRenderState(D3DRS_POINTSCALE_B, d3d::FtoDw(0.0f));_device-&gt;SetRenderState(D3DRS_POINTSCALE_C, d3d::FtoDw(1.0f)); 14.1.3 粒子和他们的属性 一个粒子系统是由除了位置、颜色以外的更多的属性组成，例如，一个粒子有某些速度。然而，这些额外的属性对于渲染粒子来说不是必须的。因此，我们在单独的结构中保存渲染粒子所必须的数据和属性。当我们创建、显示或更新粒子时，我们使用属性来工作。当我们准备渲染时，我们从Particle（粒子）结构中COPY位置和颜色。 对于我们模拟的具体粒子系统，粒子的属性也是不同的。因此我们能够归纳一些通用的属性，一面的结构例子中包含一些通用的属性，大多数系统用不上这么多，一些系统需要的属性这里可能还没有。struct Attribute{ D3DXVECTOR3 _position; D3DXVECTOR3 _velocity; D3DXVECTOR3 _acceleration; float _lifeTime; float _age; D3DXCOLOR _color; D3DXCOLOR _colorFade; bool _isAlive;};_position—粒子在世界空间中的位置_velocity—粒子的速度，每秒多少个单位。_acceleration—粒子的加速度, 每秒多少个单位。_lifeTime—粒子的生命周期. 例如,当一个时间段后，我们可以杀死一个激光柱的粒子._age—粒子的当前年龄。_color—粒子的颜色。_colorFade—粒子随时间的变化而褪去的颜色。_isAlive—True 表示粒子活着;false 表示粒子死了。 14.2 粒子系统的组成 粒子系统是粒子的集合，用来保存和显示这些粒子。粒子系统维护所有粒子的全部属性，影响系统中的所有粒子：粒子的尺寸，起始的位置及应用在粒子上的纹理等。粒子系统的方法负责更新、显示、杀死和创建粒子。 虽然不同的具体（与抽象是相对的）粒子系统有不同的行为，我们归纳并找到一些所有的粒子系统共有的基本属性，我们把这些公共的属性放到一个抽象的Psystem基类，它是我们所有的具体粒子系统的父类，现在让我们看一下Psystem类：class PSystem{public: PSystem(); virtual ~PSystem(); virtual bool init(IDirect3DDevice9* device, char* texFileName); virtual void reset(); virtual void resetParticle(Attribute* attribute) = 0; virtual void addParticle(); virtual void update(float timeDelta) = 0; virtual void preRender(); virtual void render(); virtual void postRender(); bool isEmpty(); bool isDead(); protected: virtual void removeDeadParticles(); protected: IDirect3DDevice9 _device; D3DXVECTOR3 _origin; d3d::BoundingBox _boundingBox; float _emitRate; float _size; IDirect3DTexture9 _tex; IDirect3DVertexBuffer9* _vb; std::list _particles; int _maxParticles; DWORD _vbSize; DWORD _vbOffset; DWORD _vbBatchSize; }; 一些数据成员： _origin—粒子系统的原点， 这是粒子系统产生时的位置。 _boundingBox—创建粒子系统使用的边界盒，用于限制粒子的活动范围。例如，假如我们让雪系统只落在一个围绕高山的峰顶的体积内； 我们会定义一个包括这个体积的边界盒, 出界的粒子将会被杀死。 _emitRate—新增加到系统中的粒子的速度。 通常的标准是每秒。 _size—系统中所有粒子的尺寸。 _particles—系统中粒子属性的一个列表。 我们用这个列表创建，释放及更新粒子。 当我们准备画粒子时, 我们COPY列表节点的一部分到顶点缓存并画粒子。 当我们COPY另外一批时绘制这批粒子，然后重复这一过程直到绘制完所有粒子。 这有点太简单了，我们将在section 14.2.1节详细的解释绘制的过程。 _maxParticles—在给定的时间内，系统中允许的粒子最大数。例如, 如果创建粒子的速度比释放快的话, 随着时间的增长粒子的数量将会是巨大的，这个成员将避免出现这样的问题。 _vbSize—在给定的时间内顶点缓存中能够保存的粒子的数量，这个值与实际的粒子系统中的粒子数量无关。注意：member _vbOffset和_vbBatchSize数据成员在渲染粒子系统时使用，我们在稍后的section 14.2.1节讨论。 方法： PSystem/ ~PSystem—用来初始化默认值的构造器/用来释放设备接口的析构器 (vertex buffer, texture)。 init—这个方法做与设备无关的初始化工作, 比如创建用来保存点精灵的顶点缓存或创建纹理。 顶点缓存的创建包括一些标记，现在我们都已经讨论过了，但还没有用:hr = device-&gt;CreateVertexBuffer( _vbSize * sizeof(Particle), D3DUSAGE DYNAMIC | D3DUSAGE POINTS | D3DUSAGE WRITEONLY, Particle::FVF, D3DPOOL_DEFAULT, &amp;_vb, 0) ; o 注意： 我们使用动态的顶点缓存（D3DUSAGE DYNAMIC）。 因为我们需要在每帧中更新我们的粒子,意思是我们将会去存取顶点缓存的内存，回想一下，访问一个静态的顶点缓存慢得不可接受， 所以我们使用动态的顶点缓存。o 查看我们用过的 D3DUSAGE_POINTS 标记,它说明顶点缓存将保存点精灵。o 顶点缓存的尺寸是由_vbSize预先确定的，而且与系统中粒子的数量无关。 也就是说, _vbSize 将小于等于系统中粒子的数量。 这是因为渲染粒子系统是一批一批的，不是一次渲染全部。 我们将在section 14.2.1节中解释渲染过程。o 我们使用默认的内存池(pool)代替通常使用的托管内存池，因为动态顶点缓存不能用在托管内存池中。 reset—这个方法重新设置系统中每个粒子的属性:void PSystem::reset(){ std::list::iterator i; for(i = _particles.begin(); i != _particles.end(); i++) { resetParticle( &amp;(*i) ); }} resetParticle—这个方法重新设置粒子的属性。如何重设粒子的属性，这依赖于具体粒子系统的特性。因此我们定义这个方法为虚拟的，等待子类去实现。 addParticle—这个方法用来在系统中增加一个粒子。在增加它到粒子列表之前，使用resetParticle 方法先初始化粒子:void PSystem::addParticle(){ Attribute attribute; resetParticle(&amp;attribute); _particles.push_back(attribute);}void PSystem::addParticle() update—这个方法更新系统中所有的粒子。因为这个的方法的执行取决于具体粒子系统的特性, 因此我们定义这个方法为抽象的，等待子类去实现。 render—这个方法用来显示系统中所有的粒子。 执行起来很复杂，我们将在14.2.1 节讨论。 preRender—用它来初始化渲染状态， 在渲染前设置。 因为系统与系统之间是不同的,所以我们定义它为虚拟的。 默认将执行下列代码:void PSystem::preRender(){_device-&gt;SetRenderState(D3DRS_LIGHTING, false);_device-&gt;SetRenderState(D3DRS_POINTSPRITEENABLE, true);_device-&gt;SetRenderState(D3DRS_POINTSCALEENABLE, true);_device-&gt;SetRenderState(D3DRS_POINTSIZE, d3d::FtoDw( size));_device-&gt;SetRenderState(D3DRS_POINTSIZE MIN, d3d::FtoDw(0.0f)); // control the size of the particle relative to distance_device-&gt;SetRenderState(D3DRS_POINTSCALE A, d3d::FtoDw(0.0f));_device-&gt;SetRenderState(D3DRS_POINTSCALE B, d3d::FtoDw(0.0f));_device-&gt;SetRenderState(D3DRS_POINTSCALE C, d3d::FtoDw(1.0f)); // use alpha from texturedevice-&gt;SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA TEXTURE);device-&gt;SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP SELECTARG1); _device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, true);_device-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_SRCALPHA);_device-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_INVSRCALPHA);} 注意：我们使用alpha混合渲染，以便设置纹理的alpha通道，来设置纹理像素的透明度。 用它产生多种效果；一种特殊的情况是：获得象纹理那样的非矩形的粒子。例如， 获得一个圆形“雪球形”的粒子, 我们使用一个简单的带有alpha通道的纹理， 它看上去是背景为黑色的带有白色圆形的样子。因此，显示出来时只是一个白圆，这比白色的矩形纹理要好。 postRender—用它去保存所有渲染状态，它是一个特殊的粒子系统可能有的设置。因为系统与系统间是不同的,所以我们定义它为虚拟的。默认将执行下列代码: 1234567void PSystem::postRender()&#123; _device-&gt;SetRenderState(D3DRS_LIGHTING, true); _device-&gt;SetRenderState(D3DRS_POINTSPRITEENABLE, false); _device-&gt;SetRenderState(D3DRS_POINTSCALEENABLE, false); _device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, false);&#125; isEmpty—如果为True 则在当前的系统中没有粒子， 否则为false. isDead—如果为True 则系统中的所有粒子都是死的，否则为false。 注意： 系统中所有粒子状态为idDead时并不意味着isEmpty. 空意思着系统中没有粒子。 Dead的意思是系统中有粒子，但都是死的。. removeDeadParticles—搜索属_particle性表，从表中杀死并删除粒子。14.2.1 绘制粒子系统 因为粒子系统是动态的，在每一个帧中我们需要更新系统中的粒子，对于渲染粒子系统的一种直观但效率低下的方法如下: 创建一个足够大的顶点缓存保存最大数量的粒子。 每一帧里执行： A. 更新所有粒子。B. COPY所有活着的粒子到顶点缓存。C. 绘制顶点缓存。 这个方法正确，不过不是最有效率的。第一，顶点缓冲必须足够大以保存系统中所有粒子。但是非常重要的是，当我们从列表拷贝所有粒子到顶点缓冲（步骤B）时，显卡却什么也不做。举个例子，假设我们系统有10,000个粒子，首先我们需要一个能容纳10,000个粒子的顶点缓冲，这是一个很大的内存。另外显卡将停着什么也不做直到列表中的10,000个粒子拷到顶点缓冲，并且我们调用DrawPrimitive。这个特定情况是CPU与显卡不同时工作的一个很好的例子。 更好的办法（SDK中点精灵例程中用到的方法）就象这样： 提示：这是一个简单的描述，但它说明了这一思想。它假定我们总是有500个粒子以填充一个缓存片段，但是这是不可能发生的，因为我们经常杀死并创建粒子，所以从一帧到另一帧粒子数量是变化的。举个例子，假设我们只剩下200个粒子要在当前帧拷贝并渲染。因为200个粒子不能填充整个缓存片段，我们用代码处理这个特定情形。这个特定情形只有在最后的缓存片段中才会出现，因为如果不是最后的片断，就意味着必然有500个粒子将被移到下一缓存片段。 创建一个合适尺寸的顶点缓存（能够保存2000个粒子），然后我们划分顶点缓存为几个小的块，就像这个例子，我们设置每个缓存片断的尺寸为500个粒子。 然后创建一个全局变量 i = 0 ，用来记录片段。 每一帧里执行: A. 更新所有粒子。B. 直到所有粒子渲染完毕。: 如果顶点缓存没有满：a 用D3DLOCK_NOOVERWRITE标记锁定缓存片段ib COPY 500个粒子到片段i 如果顶点缓存满了：a 从起始的地方开始顶点缓冲: i=0b 用D3DLOCK_NOOVERWRITE标记锁定缓存段ic COPY 500个粒子到片段i 渲染片段i. 下一片段： i+ +备注：顶点缓存是动态的， 因此我们能利用动态锁定标记D3DLOCK_NOOVERWRITE 和 D3DLOCK_DISCARD。这两个标记允许我们锁定顶点缓存的某一部分。当顶点缓存中的其他部分被渲染时，它是不能渲染的。例如，假如我们正在使用D3DLOCK_NOOVERWRITE标记渲染片段0时， 当渲染片段0的时候我们能锁定并填充片段1。这样可以防止渲染的延迟。 这个方法更有效率。首先，我们减少顶点缓存的尺寸；然后， CPU与显卡在协调的工作。也就是说，当我们绘制一小批粒子时(graphics card work)，同时拷贝另一小批粒子到顶点缓存 (CPU work)。这个动作是连续执行的，直到所有的粒子都被渲染完毕，就像你了解的一样， 显卡在全部顶点缓存被填充的时候是不用处于空闲状态的。我们现在将注意力转向这一个渲染方案的实现，为了方便使用这个粒子系统的渲染方案, 我们使用 PSystem 类中的下列数据成员: _vbSize—在给定时间内我们的顶点缓存能够保存的粒子数量。这个值与实际的粒子系统中的粒子数无关。 _vbOffset—这个变量是在顶点缓存中的偏移，在顶点缓存里我们将用它开始COPY下一批粒子，例如，如果第一批在缓存中是0到499，偏移到第二批COPY的开始处将是500。 _vbBatchSize—定义一批缓存中的粒子数量。 我们现在介绍渲染方法的代码：void PSystem::render(){if( !_particles.empty() ){ // set render states preRender(); _device-&gt;SetTexture(0, _tex); _device-&gt;SetFVF(Particle::FVF); _device-&gt;SetStreamSource(0, _vb, 0, sizeof(Particle)); // start at beginning if we’re at the end of the vb if(_vbOffset &gt;= _vbSize) _vbOffset = 0; Particle*v =0; _vb-&gt;Lock( _vbOffset * sizeof( Particle ), _vbBatchSize * sizeof( Particle ), (void**)&amp;v, _vbOffset ? D3DLOCK_NOOVERWRITE : D3DLOCK_DISCARD); DWORD numParticlesInBatch = 0; // // Until all particles have been rendered. // std::list&lt;Attribute&gt;::iterator i; for(i = _particles.begin(); i != _particles.end(); i++) { if( i-&gt;_isAlive ) { // // Copy a batch of the living particles to the // next vertex buffer segment // v-&gt;_position = i-&gt;_position; v-&gt;_color = (D3DCOLOR)i-&gt;_color; v++; // next element; numParticlesInBatch++; //increase batch counter // is this batch full? if(numParticlesInBatch == _vbBatchSize) { // // Draw the last batch of particles that was // copied to the vertex buffer. // _vb-&gt;Unlock(); _device-&gt;DrawPrimitive( D3DPT_POINTLIST, _vbOffset, _vbBatchSize); // // While that batch is drawing, start filling the // next batch with particles. // // move the offset to the start of the next batch _vbOffset += _vbBatchSize; // don&#39;t offset into memory thats outside the vb&#39;s // range. If we&#39;re at the end, start at the beginning. if(_vbOffset &gt;= _vbSize) _vbOffset = 0; _vb-&gt;Lock( _vbOffset * sizeof( Particle ), _vbBatchSize * sizeof( Particle ), (void**)&amp;v, _vbOffset ? D3DLOCK_NOOVERWRITE : D3DLOCK_DISCARD); numParticlesInBatch = 0; // reset for new batch }//end if }//end if }//end for _vb-&gt;Unlock(); // it&#39;s possible that the LAST batch being filled never // got rendered because the condition // (numParticlesInBatch == _vbBatchSize) would not have // been satisfied. We draw the last partially filled batch now. if( numParticlesInBatch ) { _device-&gt;DrawPrimitive( D3DPT_POINTLIST, _vbOffset, numParticlesInBatch); } // next block _vbOffset += _vbBatchSize; postRender(); }//end if }// end render() 14.2.2 随机 这有一个随机的粒子系统。例如，如果我们模拟雪花，不能让所有雪花以完全相同的方式落下。我们要让它们按相似的方式落下而不是完全相同的方式。为了使粒子系统的随机功能更简单，我们增加了下列两个函数到d3dUtility.h/cpp文件。 第一个函数在[lowBound, highBound]区间内随机的返回一个Float类型值：float d3d::GetRandomFloat(float lowBound, float highBound){ if( lowBound &gt;= highBound ) // bad input return lowBound; // get random float in [0, 1] interval float f = (rand() % 10000) * 0.0001f; // return float in [lowBound, highBound] interval. return (f * (highBound - lowBound)) + lowBound; } 第二个函数在边界盒的范围内，输出一个随机的向量。void d3d::GetRandomVector( D3DXVECTOR3 out, D3DXVECTOR3 min, D3DXVECTOR3* max){ out-&gt;x = GetRandomFloat(min-&gt;x, max-&gt;x); out-&gt;y = GetRandomFloat(min-&gt;y, max-&gt;y); out-&gt;z = GetRandomFloat(min-&gt;z, max-&gt;z);} 注意：记得用srand()去seed随机数生成器。14.3 具体的粒子系统：雪、火、粒子枪现在让我们用Psystem类开始一个具体的粒子系统，为了说明用意，这些系统的设计很简单，没有用到Psystem类所提供的所有灵活性。我们实现雪、火、粒子枪系统。这些系统的名字基本上概括了他们的模型。雪系统模拟下落的雪花，火系统模拟看上去像火焰的爆炸，粒子枪系统从照相机位置向对面发射出粒子（用键盘）。注意：照例，用全部的工程代码来说明这些系统，你能够在本章找到这些文件。 14.3.1 例子程序：雪 图14.2 雪系统例子的屏幕截图 雪系统类定义如下：class Snow : public PSystem{public: Snow(d3d::BoundingBox boundingBox, int numParticles); void resetParticle(Attribute attribute); void update(float timeDelta);};备注：因为父类做了大部分的工作，所以雪系统的接口非常简单。事实上，我们在这一节中实现的这三个粒子系统，接口简单并相对容易实现。 构造器提供一个点给边界盒结构，边界盒是粒子系统的成员。边界盒描述雪花在哪个范围内（体积范围）下落，如果雪花出了边界盒，它将被杀死并再生。这样，雪系统始终能保存有同样数量的激粒子，构造器的实现：Snow::Snow(d3d::BoundingBox boundingBox, int numParticles){ _boundingBox = boundingBox; _size = 0.8f; _vbSize = 2048; _vbOffset = 0; _vbBatchSize = 512; for(int i = 0; i &lt; numParticles; i++) addParticle();} 同样注意：我们指定顶点缓存的尺寸，每一批的尺寸和开始的偏移。 ResetParticle方法创建一个雪花，在x、z轴随机的位置并在边界盒的范围内。设置y轴高度为边界盒的顶部。如果给雪花一个速度，以便让雪花下落时稍稍向左倾斜。雪花是白色的。void Snow::resetParticle(Attribute* attribute){ attribute-&gt;_isAlive = true; // get random x, z coordinate for the position of the snowflake. d3d::GetRandomVector( &amp;attribute-&gt;_position, &amp;_boundingBox._min, &amp;_boundingBox._max); // no randomness for height (y-coordinate). Snowflake // always starts at the top of bounding box. attribute-&gt;_position.y = _boundingBox._max.y; // snowflakes fall downward and slightly to the left attribute-&gt;_velocity.x = d3d::GetRandomFloat(0.0f, 1.0f)*-3.0f; attribute-&gt;_velocity.y = d3d::GetRandomFloat(0.0f, 1.0f)*-10.0f; attribute-&gt;_velocity.z = 0.0f; // white snowflake attribute-&gt;_color = d3d::WHITE; } Update方法更新粒子和粒子间的位置，并且测试粒子是否在系统的边界盒之外，如果它已经跳出边界盒，就再重新创建。void Snow::update(float timeDelta){ std::list::iterator i; for(i = _particles.begin(); i != _particles.end(); i++) { i-&gt;_position += i-&gt;_velocity * timeDelta; // is the point outside bounds? if( _boundingBox.isPointInside( i-&gt;_position ) == false ) { // nope so kill it, but we want to recycle dead // particles, so respawn it instead. resetParticle( &amp;(*i) ); } } } 14.3.2 例子程序：火 图14.3 火粒子系统例子的屏幕截图火系统类定义如下：class Firework : public PSystem{public: Firework(D3DXVECTOR3 origin, int numParticles); void resetParticle(Attribute attribute); void update(float timeDelta); void preRender(); void postRender();}; 构造器需要提供一个点作为粒子系统中的原点，和系统中的粒子数，原点是火焰爆发的那个点。ResetParticle方法在原点位置初始化粒子系统，并在边界球内创建一个随机的速度，粒子系统中的每个例子有一个随机的颜色，我们定义粒子只能存活2秒。void Firework::resetParticle(Attribute* attribute){ attribute-&gt;_isAlive = true; attribute-&gt;_position = _origin; D3DXVECTOR3 min = D3DXVECTOR3(-1.0f, -1.0f, -1.0f); D3DXVECTOR3 max = D3DXVECTOR3( 1.0f, 1.0f, 1.0f); d3d::GetRandomVector( &amp;attribute-&gt;_velocity, &amp;min, &amp;max); // normalize to make spherical D3DXVec3Normalize( &amp;attribute-&gt;_velocity, &amp;attribute-&gt;_velocity); attribute-&gt;_velocity *= 100.0f; attribute-&gt;_color = D3DXCOLOR( d3d::GetRandomFloat(0.0f, 1.0f), d3d::GetRandomFloat(0.0f, 1.0f), d3d::GetRandomFloat(0.0f, 1.0f), 1.0f); attribute-&gt;_age = 0.0f; attribute-&gt;_lifeTime = 2.0f; // lives for 2 seconds } Update方法更新每个粒子的位置，并在粒子超出自己的生活周期时杀死它。注意：这个系统不能移除死掉的粒子，这么做是因为我们想产生一个新的火焰的时候，我们只要简单的重新设置已经存在的死了的火焰系统就可以了。这样为我们不必频繁的去产生和释放粒子。void Firework::update(float timeDelta){ std::list::iterator i; for(i = _particles.begin(); i != _particles.end(); i++) { // only update living particles if( i-&gt;_isAlive ) { i-&gt;_position += i-&gt;_velocity * timeDelta; i-&gt;_age += timeDelta; if(i-&gt;_age &gt; i-&gt;_lifeTime) // kill i-&gt;_isAlive = false; } } }当渲染时，火系统使用不同的方法渲染像素。进一步讲，它不写深度缓存，我们可以简单的改变混合像素，通过重写PSystem::preRender方法和PSystem::postRender方法，下面是重写的实现：void Firework::update(float timeDelta){ std::list::iterator i;void Firework::preRender(){ PSystem::preRender(); _device-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_ONE); _device-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_ONE); // read, but don&#39;t write particles to z-buffer _device-&gt;SetRenderState(D3DRS_ZWRITEENABLE, false); } void Firework::postRender(){ PSystem::postRender(); _device-&gt;SetRenderState(D3DRS_ZWRITEENABLE, true); }注意：这两个方法调用父类版本，这样，我们仍能重新使用父类的一些功能，做一些小的改变就变成了火焰系统。14.3.3 例子程序：粒子枪 图14.4 激光枪系统的截图下面是粒子枪系统的定义：class ParticleGun : public PSystem{public: ParticleGun(Camera camera); void resetParticle(Attribute attribute); void update(float timeDelta); private: Camera _camera;}; 构造器需要提供一个照相机的位置点，这是因为系统需要知道照相机的位置及朝向，以决定在哪创建一个粒子。 ResetParticle方法设置粒子的位置为当前照相机的位置，并且设置方向上的速度，在照像机视角的100个单位。这样，子弹将射向我们正在看的方向，粒子颜色为绿色。void ParticleGun::resetParticle(Attribute attribute){ attribute-&gt;_isAlive = true; D3DXVECTOR3 cameraPos; _camera-&gt;getPosition(&amp;cameraPos); D3DXVECTOR3 cameraDir; _camera-&gt;getLook(&amp;cameraDir); // change to camera position attribute-&gt;_position = cameraPos; attribute-&gt;_position.y -= 1.0f; // slightly below camera so it&#39;s // like we&#39;re carrying gun // travels in the direction the camera is looking attribute-&gt;_velocity = cameraDir * 100.0f; // green attribute-&gt;_color = D3DXCOLOR(0.0f, 1.0f, 0.0f, 1.0f); attribute-&gt;_age = 0.0f; attribute-&gt;_lifeTime = 1.0f; // lives for 1 seconds } Update方法更新粒子的位置，并且杀死超过其生命周期的粒子，然后，我们搜索粒子列表删除已经死了的粒子。{ std::list::iterator i; for(i = _particles.begin(); i != _particles.end(); i++) { i-&gt;_position += i-&gt;_velocity * timeDelta; i-&gt;_age += timeDelta; if(i-&gt;_age &gt; i-&gt;_lifeTime) // kill i-&gt;_isAlive = false; } removeDeadParticles(); } 14.4 摘要 用点精灵来显示一个粒子是方便且灵活的，它可能改变粒子尺寸、给粒子赋予纹理。此外，能够使用简单的顶点（vertex）来描述它们。 粒子系统维护一个粒子的集合，并负责创建、释放、更新和显示粒子。 还有一些其他粒子系统的概念，是你能够实现的：烟，火箭的轨迹，喷泉/河水车效果，火，光，爆炸，和雨。]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
      <tags>
        <tag>Direct3D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十三章 地形渲染基础(Basic Terrain Rendering)]]></title>
    <url>%2F2019%2F04%2F11%2FBasic-Terrain-Rendering%2F</url>
    <content type="text"><![CDATA[实际上，地形网格不比三角形网格复杂，图13.1.(a)所示，网络的每个顶点指定了高度，格子模型用这种方式显示从山脉到河流的平滑过渡。图13.1 (b)，模拟自然地形。当然，我们可以用漂亮的纹理表现沙石地，绿色的山丘。图13.1.(c)雪山效果。 图 13.1: (a) 三角网格. (b) 平滑高度过渡的三角网格. (c) 光和纹理，我们在这一章节中写的例子的一个屏幕截图。 这一章的内容是实现一个Terrain（地形）类。这个类的功能很强。我们的意思是，它只是储存整个地形的顶点/索引数据，然后渲染它。因为如果游戏需要一个小的地形，那么它能够在现代图形卡支持的硬件顶点处理下工作。然而实际上，游戏需要大量的地形，你必须对细节做某种（级别）程度的捡选，因为模型需要大量的几何数据，这样大的地形对于再强大的处理方法也是无法处理的。 目标 学习怎样生成地形的高度信息，它能使山丘、河流等地带的平滑的过度，模拟自然界的地形。 了解怎样生成地形的顶点和三角形数据。 学习使用地形的纹理和光照. 找到控制地形上照相机位置的方法，以便模拟在地形上走动。 13.1 Heightmaps（高度图） 我们使用高度图去描述地形上的山丘、河流。高度图是一个数组，数组中的每个成员指定地形顶点描述中的高度信息。我们经常把高度图想像成一个矩阵，因为每个元素都一一对应于每个地形网格中的顶点。 当我们保存高度图到磁盘上时，我们通常为高度图的每个元素分配1个byte的内存，所以高度的范围是0..255，0..255的范围对于地形的高度之间保持平滑过渡是足够用的。但为了在我们的程序中匹配3D世界中的物体，可能需要的范围在0..255以外。例如，我们在3D世界中的测量单位是英尺，那么0..255的范围对于表现任何有趣的东西是不够的。因此，当我们读取数据进应用程序时，给每个高度元素分配一个整型数（或浮点型），它允许我们很好的缩放0..255范围之外的任何大小的物品。 高度图图形表示法这一是灰度图(grayscale map)。较黑的值表示地形中较低的地方，较白的值表现地形中较高的地方。 图13.2: 高度图的灰度图表示 13.1.1 创建高度图（Heightmap） 高度图不是用程序生成就是用图像编辑器生成，比如：Adobe Photoshop。使用图像编辑器大概是最容易的方法了。当你想生成地形时，可以交互式的可视化的创建。你可以利用图像编辑器的功能，比如：过滤器，创建一个有趣的高度图，图13.3显示了一个用Adobe Photoshop图像编辑器的工具创建的金字塔形的高度图。注意：当创建图像时我们指定一个灰度图类型。 图13.3 一幅用Adobe Photoshop创建的灰度图 一但你画完了你的高度图，你必须将它保存为一个8bit的RAW文件。RAW文件只图像的逐个字节。我们的应用程序可以非常容易的读这样的图像。你的软件可能告诉你保存的RAW文件是有文件头的还是没有文件头的。 注意：用RAW格式保存高度信息不是必须的；你可以用符合你需要的任何格式。RAW格式是我们能使用的的格式之一。我决定使用RAW格式是因为很多流行的图像编辑器支持导出这种格式，而且应用程序读取RAW文件的数据非常简单。这章中有使用8-bit RAW文件的例子。 13.1.2 读取RAW文件 RAW文件与一段连续的bit内存块没什么分别。我们能用很简单的方法读取这段内存块，注意：变量_heightmap是Terrain类的一个成员，定义如下 ：std::vector _heightmap;bool Terrain::readRawFile(std::string fileName){ // A height for each vertex std::vector in( numVertices ); std::ifstream inFile(fileName.c_str(), std::ios_base::binary); if( inFile == 0 ) return false; inFile.read( (char*)&amp;in[0], // buffer in.size());// number of bytes to read into buffer inFile.close(); // copy BYTE vector to int vector _heightmap.resize( _numVertices ); for(int i = 0; i &lt; in.size(); i++) _heightmap[i] = in[i]; return true; }我们COPY一个bytes向量到一个整形向量，这样做我们能够缩放 [0,255]以外的高度。这个方法唯一限制是：RAW文件必须读入至少与地形的顶点数一样多的高度信息。因此，如果你读取一个256x256 的RAW文件，你的地形也必须包含256x256个顶点。 13.1.3 访问与修改Heightmap Terrain类提供以下2个方法访问和修改Heightmap的入口。int Terrain::getHeightmapEntry(int row, int col){ return _heightmap[row * _numVertsPerRow + col];} void Terrain::setHeightmapEntry(int row, int col, int value){ _heightmap[row * _numVertsPerRow + col] = value;} 这些方法允许我们以行和列来访问入口，并且隐藏方法。当使用它去描述矩阵时，我们必须将一个线性数组编入索引。（These methods allow us to refer to an entry by row and column and hide the way we must index a linear array when using it to describe a matrix） 13.2 生成地形几何数据 图13.4显示Terrain类的一些属性、词汇和我们提到的一些关键点。我们定义地形的大小，指定每行、每列顶点的数量，和单元的间隔。传递这些值到Terrain类的构造器中。另外，也传递地形所关联的设备，一个包含高度图数据的字符串文件名，一个用来缩放高度图成员的高度缩放值。 图13.4：三角形网络的属性，延着方格线上的点是地形的顶点。 class Terrain{public: Terrain( IDirect3DDevice9* device, std::string heightmapFileName, int numVertsPerRow, int numVertsPerCol, int cellSpacing, // space between cells float heightScale); // value to scale heights by ... methods snipped private: …device/vertex buffer etc snipped int _numVertsPerRow; int _numVertsPerCol; int _cellSpacing; int _numCellsPerRow; int _numCellsPerCol; int _width; int _depth; int _numVertices; int _numTriangles; float _heightScale; };Terrain类定义的全部的源代码，实在是太多了，无法在这里全部包含进来。根据传递给构造器的值，我们能够计算Terrain类的其他变量：123456_numCellsPerRow = _numVertsPerRow - 1;_numCellsPerCol = _numVertsPerCol - 1;_width = _numCellsPerRow * _cellSpacing;_depth = _numCellsPerCol * _cellSpacing;_numVertices = _numVertsPerRow * _numVertsPerCol;_numTriangles = _numCellsPerRow * _numCellsPerCol * 2; Terrain类定义的顶点结构：123456789101112struct TerrainVertex&#123; TerrainVertex()&#123;&#125; TerrainVertex(float x, float y, float z, float u, float v) &#123; _x = x; _y = y; _z = z; _u = u; _v = v; &#125; float _x, _y, _z; float _u, _v; static const DWORD FVF;&#125;; 注意：TerrainVertex是Terrain类内部的一个嵌套类（译者：看样子是结构啊？），之所以这么做，是因为它在Terrain类外部基本没有什么用处。13.2.1 计算顶点 在图13.4中，计算三角形网格上的顶点，我们只是在开始产生顶点的地方，一行一行的生成顶点数据，直到结束为止。单元格的顶点与顶点之间有一块空白区域，这会让我们取得x、z坐标，但y坐标是什么呢？得到y坐标很容易，当读取高度图数据结构时会找到对应的入口。 注意：这个操作使用一个巨大的顶点缓存去保存所有地形上的所有顶点。这可能会引起硬件局限性的问题。例如：一个原始计数界限的最大值和3D设备设定的最大的顶点索引界限。检查MaxPrimitiveCount和D3DCAPS9结构的MaxVertexlndex成员，查看你的设备的限定值，在13.7节讨论，使用顶点缓存时存在问题和解决方法。 计算纹理坐标，看图13.5，给我们一个简单的设定，允许我们用(u, v)纹理坐标去对应地形顶点坐标。 图13.5：地形顶点与纹理顶点之间一一对应。 u = j uCoordIncrementSize v = i vCoordIncrementSize And where: 最后，用代码生成顶点：bool Terrain::computeVertices(){ HRESULT hr = 0; hr = _device-&gt;CreateVertexBuffer( _numVertices * sizeof(TerrainVertex), D3DUSAGE_WRITEONLY, TerrainVertex::FVF, D3DPOOL_MANAGED, &amp;_vb, 0); if(FAILED(hr)) return false; // 对应第一个生成的顶点坐标 int startX = -_width / 2; int startZ = _depth / 2; // 对应最后一个生成的顶点坐标 int endX = _width / 2; int endZ = -_depth / 2; // compute the increment size of the texture coordinates // from one vertex to the next. float uCoordIncrementSize = 1.0f / (float)_numCellsPerRow; float vCoordIncrementSize = 1.0f / (float)_numCellsPerCol; TerrainVertex* v = 0; _vb-&gt;Lock(0, 0, (void**)&amp;v, 0); int i = 0; for(int z = startZ; z &gt;= endZ; z -= _cellSpacing) { int j = 0; for(int x = startX; x &lt;= endX; x += _cellSpacing) { // compute the correct index into the vertex buffer // and heightmap based on where we are in the nested // loop. int index = i * _numVertsPerRow + j; v[index] = TerrainVertex( (float)x, (float)_heightmap[index], (float)z, (float)j * uCoordIncrementSize, (float)i * vCoordIncrementSize); j++; // next column } i++; // next row } _vb-&gt;Unlock(); return true; } 13.2.2 计算索引-定义三角形 计算三角形网格的索引，只需要循环访问每一个格子，从左上到右下，如图13.4，并且计算组成格子的2个三角形。 这里的技巧是：提取出计算第ij格子的2个三角形的公式。用图13.6去推导公式，找到第ij的格子： ?ABC = {i · numVertsPerRow + j i·numVertsPerRow + j + 1 (i + 1). numVertsPerRow + j}?CBD = {(i + 1) numVertsPerRow + j i·numVertsPerRow + j + 1 (i·l) numVertsPerRow + j + 1} 图13.6 方格的顶点 代码生成索引：bool Terrain::computeIndices(){ HRESULT hr = 0; hr = _device-&gt;CreateIndexBuffer( _numTriangles * 3 * sizeof(WORD), // 每个三角形有3个索引 D3DUSAGE_WRITEONLY, D3DFMT_INDEX16, D3DPOOL_MANAGED, &amp;_ib, 0); if(FAILED(hr)) return false; WORD* indices = 0; _ib-&gt;Lock(0, 0, (void**)&amp;indices, 0); // 将组成一个方格的2个三角形的一组6个索引的开始位置编入索引 int baseIndex = 0; // 从头到尾计算每一个格子中的三角形 for(int i = 0; i &lt; _numCellsPerCol; i++) //行循环 { for(int j = 0; j &lt; _numCellsPerRow; j++) //列循环 { indices[baseIndex] = i * _numVertsPerRow + j; indices[baseIndex + 1] = i * _numVertsPerRow + j + 1; indices[baseIndex + 2] = (i+1) * _numVertsPerRow + j; indices[baseIndex + 3] = (i+1) * _numVertsPerRow + j; indices[baseIndex + 4] = i * _numVertsPerRow + j + 1; indices[baseIndex + 5] = (i+1) * _numVertsPerRow + j + 1; // next quad baseIndex += 6; } } _ib-&gt;Unlock(); return true; }; 纹理Terrain类提供2个方法去处理地形的纹理。最简单的方法是简单地读取一个已经制作好的纹理文件并使用它，下面的方法使用Terrain类实现将一个文件读取纹理到_tex成员中，然后指向一个IDirect3DTexture9接口的指针。关键是，在地形渲染之前先用Terrain: :draw方法设置_tex。12345678910111213bool Terrain::loadTexture(std::string fileName)&#123; HRESULT hr = 0; hr = D3DXCreateTextureFromFile( _device, fileName.c_str(), &amp;_tex); if(FAILED(hr)) return false; return true;&#125; 13.3.1 程序上的处理方法 一个可选择的方法是用程序计算地形的纹理，就是说，我们创建一个空纹理，根据定义的参数用代码计算每一个部分的颜色，在例子中，参数是地形的高度。 我们用Terrain::genTexture方法用程序去生成纹理，首先用D3DXCreateTexture方法创建一个空的纹理，锁定高度级别（top level，纹理图的一个成员，有多个级别），不断的循环每一个texel（图素）并给它上色，texel的颜色取决于与方格对应的高度（近似高度）。我们的想法是：地形中较低的地方是沙滩色，中间的地方像是绿色的小山丘，较高的地方颜色好像雪山。我们定义的高度是方格中左上角的近似高度。 一旦每个texel都有了颜色，我们想让每一个texel变暗或是变亮，这基于光打在格子中对应的texel上的角度，由Terrain::lightTerrain方法实现。（Once we have a color for each texel, we want to darken or brighten each texel based on the angle at which sunlight (modeled by a directional light) strikes the cell to which the texel corresponds. This is done in the Terrain::lightTerrain method） Terrain::genTexture方法通过计算lower mipmap级别的texels来得出结论，它是通过D3DXFilterTexture函数实现。用代码生成纹理：bool Terrain::genTexture(D3DXVECTOR3* directionToLight){ // Method fills the top surface of a texture procedurally. Then // lights the top surface. Finally, it fills the other mipmap // surfaces based on the top surface data using // D3DXFilterTexture. HRESULT hr = 0; // texel for each quad cell int texWidth = _numCellsPerRow; int texHeight = _numCellsPerCol; // create an empty texture hr = D3DXCreateTexture( _device, texWidth, texHeight, // dimensions 0, // create a complete mipmap chain 0, // usage - none D3DFMT_X8R8G8B8, // 32-bit XRGB format D3DPOOL_MANAGED, // memory pool &amp;_tex); if(FAILED(hr)) return false; D3DSURFACE DESC textureDesc; _tex-&gt;GetLevelDesc(0 /*level*/, &amp;textureDesc); // make sure we got the requested format because our code // that fills the texture is hard coded to a 32-bit pixel depth. if( textureDesc.Format != D3DFMT_X8R8G8B8 ) return false; D3DLOCKED_RECT lockedRect; _tex-&gt;LockRect(0/*lock top surface*/, &amp;lockedRect, 0 /* lock entire tex*/, 0/*flags*/); // fill the texture DWORD* imageData = (DWORD*)lockedRect.pBits; for(int i = 0; i &lt; texHeight; i++) { for(int j = 0; j &lt; texWidth; j++) { D3DXCOLOR c; // get height of upper-left vertex of quad. float height = (float)getHeightmapEntry(i, j)/_heightScale; // set the color of the texel based on the height // of the quad it corresponds to. if( (height) &lt; 42.5f ) c = d3d::BEACH SAND; else if( (height) &lt; 85.0f ) c = d3d::LIGHT YELLOW GREEN; else if( (height) &lt; 127.5f ) c = d3d::PUREGREEN; else if( (height) &lt; 170.0f ) c = d3d::DARK YELLOW GREEN; else if( (height) &lt; 212.5f ) c = d3d::DARKBROWN; else c = d3d::WHITE; // fill locked data, note we divide the pitch by four // because the pitch is given in bytes and there are // 4 bytes per DWORD. imageData[i * lockedRect.Pitch / 4 + j] = (D3DCOLOR)c; } } _tex-&gt;UnlockRect(0); // light the terrain if(!lightTerrain(directionToLight)) { ::MessageBox(0, &quot;lightTerrain() - FAILED&quot;, 0, 0); return false; } // fill mipmaps hr = D3DXFilterTexture( _tex,// texture to fill mipmap levels 0, // default palette 0, // use top level as source for lower levels D3DX_DEFAULT); // default filter if (FAILED (hr)) { ::MessageBox(0, &quot;D3DXFilterTexture() - FAILED&quot;, 0, 0); return false; } return true; } 注意：颜色常量BEACH_SAND等定义在d3dUtility.h.文件中。 13.4 光照 Terrain::genTexture方法会调用Terrain::lightTerrain，顾名思义，光照使地形更接近于现实。当我们已经计算完地形纹理以后，我们只需要计算阴影系数（shade factor），使一个定义了光源的地形区域变亮或变暗。在这一节中，我们检验这样一个技巧，你会惊讶于为什么我们照亮地图却没有让Direct3D来做。我们自己来计算有三个好处： 内存中不必保存顶点法线。 因为纹理是静态的，所以不能随意的移动光源。虽然我们可以重新计算光源，但因此采用Direct3D实时的照亮地形是很耗时的。 我们获得了一些数学上的经验，熟悉了一些基本的光照概念，并且是用Direct3D函数实践的。 13.4.1概览(OVERVIEW) 光照是计算地形阴影（shade）的一个最基本的技巧之一，一般认为的光是漫射光（diffuse lighting），我们定义一个平行光源，指定光的方向，延着光线的相反方向是散发平行光的光源。因此，如果我们想让光线从空中笔直落下，那么lightRaysDirection = (0, -1, 0)，按相反的方向：directionToLight = (0, 1, 0)。注意：创建光照向量要使用单位向量。 注意：虽然指定方向的光是从光源发射出来的，这么说更直接一点，指定方向的光在计算上要比漫谢光更合得来。 对于地形中的每个方格，我们计算光的向量与方格的面法线之间的角度。 在图13.7中我们看到，当角度变得比较大时，方格的面离光源越来越远，接收的光越少。反过来说，角度变小，方格的面则离光源越来越近，相应的会接收更多的光。注意：一旦光向量与法线角度大于90度，表面就接收不到光。 图13.7 光向量与平面法线的关系，我们能够创建一个阴影（shading） 标量，用0..1之间的范围来表示表面能接收到光的多少。使用阴影标量，角度大则标量接近于0。当颜色与一个阴影标量接近0的值相乘时，得到的结果是：颜色变暗。相反，乘以一个阴影标量的值接近1的值时，颜色则接近于原始亮度。 13.4.2 计算方格的阴影（Shade） 光源的方向是一个单位向量，为了计算光源方向与面法线间的夹角，首先需要找到面法线，这是叉积的一小部分应用，但首先必须在方格里找到二个共面的非0并且不平行的向量。看图 13.8有两个这样的向量： 图13.8: 计算在同一方格中的共面的二个向量 u = (cellSpacing, by - ay, 0)v = (0, cy, -ay, -cellSpacing) 关于u和v，方格的法线N = u × v，当然要把N标准化： 找到光线与法线的夹角，回忆一下点积，是二个3维空间中的单位向量组成的夹角的余弦。 它的标量是在-1..1的范围，因为-1..0的sin值符合夹角角度且大于90度，在图13.7中接受不到光照，如果它在-1..0之间那么夹角是0度。float cosine = D3DXVec3Dot(&amp;n, directionToLight); if(cosine &lt; 0.0f) cosine = 0.0f; 现在s的夹角大于90度，s的阴影标量将在0..1之间。因为光线与法线的角度从0增加到90度时，s的值将从1到降到0。这是我们想要的结果，具体讲解请看13.4.1节。 给指定的格子计算阴影系数用Terrain::computeShade方法，它需要参数：行和列来确定方格，还有平行方向光的光源。float Terrain::computeShade(int cellRow, int cellCol, D3DXVECTOR3* directionToLight){ // 取得方格中三个顶点的高度（从高度图中） float heightA = getHeightmapEntry(cellRow, cellCol); float heightB = getHeightmapEntry(cellRow, cellCol+1); float heightC = getHeightmapEntry(cellRow+1, cellCol); // 创建方格中的二个顶点 D3DXVECTOR3 u( cellSpacing, heightB - heightA, 0.0f); D3DXVECTOR3 v(0.0f, heightC - heightA, - cellSpacing); //用方格中的二个向量的叉积找到面法线 D3DXVECTOR3 n; D3DXVec3Cross(&amp;n, &amp;u, &amp;v); D3DXVec3Normalize(&amp;n, &amp;n); float cosine = D3DXVec3Dot(&amp;n, directionToLight); if(cosine &lt; 0.0f) cosine = 0.0f; return cosine; } 13.4.3 地形阴影（Shading） 一旦知道了如何给指定的方格加阴影，我们就能给地形上所有的方格加阴影。只要遍例每一个方格，计算方格的阴影值，并测量方格对应的texel颜色。光照少则方格会变暗。下面一段代码展示了Terrain::lightTerrain方法的重要部分： DWORD imageData = (DWORD)lockedRect.pBits;for(int i = 0; i &lt; textureDesc.Height; i++){ for(int j = 0; j &lt; textureDesc.Width; j++) { int index = i * lockedRect.Pitch / 4 + j; // get current color of cell D3DXCOLOR c( imageData[index] ); // shade current cell c *= computeShade(i, j, lightDirection);; // save shaded color imageData[index] = (D3DCOLOR)c; } } 13.5 在地形上“行走” 构造了一个地形以后，我们想要有移动照相机的能力，以便模拟在地形上行走的效果。我们需要调整照相机的高度，这依赖于地形部分的知识，好的，我们继续往下看。我们首先需要找到照相机所在的方格的位置，并给出x轴和z轴坐标，Terrain::getHeight函数能做到这些，它能提供x轴、y轴坐标参数，返回照相机需要被设置在地形上的高度值，现在看实现部分。float Terrain::getHeight(float x, float z){ // Translate on xz-plane by the transformation that takes // the terrain START point to the origin. x = ((float) width / 2.0f) + x; z = ((float) depth / 2.0f) - z; // Scale down by the transformation that makes the // cellspacing equal to one. This is given by // 1 / cellspacing since cellspacing * 1 / cellspacing = 1. x /= (float) cellSpacing; z /= (float)_cellSpacing; 我们首先转换地形的起始点为原点，然后，我们按反方向去测量空间变量（we scale by the inverse of the cell spacing variable），设置单元空间间隔为1。我们切换到一个新的参考框架，z轴正方向是向下的。当然，没有代码转换参考框架，但现在我们知道+z是向下的。图13.9显示了这些步骤： 图13.9：地形网格在转换前的第一个点，转换后为原点。单元格的空间为1，转换z轴。我们看到我们转换的坐标系统与矩阵的行和列相对应，也就是说左上为原点，列数的增加向右，行数的增加向下。因此，在图13.9中我们知道了单元格的空间是1，通过以下的方法我们马上就能得到单元格行和列：float col = ::floorf(x);float row = ::floorf(z); 换句话说，在x轴部分列是整数，z轴部分行也是整数。回忆floor(t)函数，。现在我们将取得方格的四个顶点的高度。 // A B // — // | / | // — // C Dfloat A = getHeightmapEntry(row, col);float B = getHeightmapEntry(row, col+1);float C = getHeightmapEntry(row+1, col);float D = getHeightmapEntry(row+1, col+1); 现在我们知道了方格的四个顶点的高度，我们需要找到照相机所在的位置的方格的高度，因为一个方格可能同时向几个方向倾斜，这可能会稍微难一点，见图 13.10: 图13.10: 照相机所在的位置的方格的高度 为了找到高度，我们需要知道我们在方格中的哪个三角形里。方格是由二个三角形渲染成的，找到我们所在的三角形，我们要取得我们所在的方格并且转换它，它的左上点是原点。 自从用行和列来描述我们所在的方格左上顶点的位置以来，我们必须转换列x轴与行z轴，转换x、z坐标： float dx = x - col; float dz = z - row; 图13.11: 我们所在的方格在转换前与转换后，左上顶点变成了原点。 .现在解释当我们在方格中的上三角形时如何找到高度，这和在下三角形是相似的。马上你会看到这两种情况的代码。在上三角形时，构造2个向量：u = (cellSpacing, B -A, 0) and v = (0, C - A, - cellSpacing)，三角形的边上并且在矢量q = (qx, A, qz)终点点开始的地方，如图13.12(a)。 图13.12 (a) 计算三角形的邻边和对边这两个向量。 (b)使用线性差值创建高度 注意：我们只关心改变的高度值，我们只修改y值，忽视其他部分，因此，Height=sum A + dxuy + dzvy 以下是Terrian::getHeight函数的实现代码： （Note that since we are only concerned about the interpolated height value, we can just interpolate the y-components and ignore the other components. Thus, the height is obtained by the sum A + dxuy + dzvy.）if(dz &lt; 1.0f - dx) // upper triangle ABC { float uy = B - A; // A-&gt;B float vy = C - A; // A-&gt;C height = A + d3d::Lerp(0.0f, uy, dx) + d3d::Lerp(0.0f, vy, dz) ; } else // lower triangle DCB { float uy = C - D; // D-&gt;C float vy = B - D; // D-&gt;B height = D + d3d::Lerp(0.0f, uy, 1.0f - dx) + d3d::Lerp(0.0f, vy, 1.0f - dz); } return height; } Lerp函数是一个沿着一维直线的基本线性插值算法，实现如下：float d3d::Lerp(float a, float b, float t){ return a - (at) + (bt);} 13.6 例子程序: Terrain 这章的例子是用一个包含高度信息的RAW文件创建一个地形，纹理和光源。用方向键在地形上行走。注意，下列函数中不相关的代码被省略了，被省略的代码用(…)表示，依赖你的硬件，这个例子可能运行得很慢，请偿试运行一个小地形。 首先，增加全局变量：地形、照相机、每秒帧数。Terrain TheTerrain = 0;Camera TheCamera(Camera::LANDOBJECT);FPSCounter FPS = 0; 下面是框架函数：bool Setup(){ D3DXVECTOR3 lightDirection(0.0f, -1.0f, 0.0f); TheTerrain = new Terrain(Device, “coastMountain256.raw”, 256, 256, 10, 1.0f); TheTerrain-&gt;genTexture(); TheTerrain-&gt;lightTerrain(&amp;directionToLight); … return true; } void Cleanup(){ d3d::Delete(TheTerrain); d3d::Delete(FPS);} bool Display(float timeDelta){ if( Device ) { // Update the scene: …[snipped input checking] // Walking on the terrain: Adjust camera&#39;s height so we // are standing 5 units above the cell point we are // standing on. D3DXVECTOR3 pos; TheCamera.getPosition(&amp;pos); float height = TheTerrain-&gt;getHeight( pos.x, pos.z ); pos.y = height + 5.0f; TheCamera.setPosition(&amp;pos); D3DXMATRIX V; TheCamera.getViewMatrix(&amp;V); Device-&gt;SetTransform(D3DTS VIEW, &amp;V); // Draw the scene: Device-&gt;Clear(0, 0, D3DCLEAR TARGET | D3DCLEAR ZBUFFER, 0xff000000, 1.0f, 0); Device-&gt;BeginScene(); D3DXMATRIX I; D3DXMatrixIdentity(&amp;I); if( TheTerrain ) TheTerrain-&gt;draw(&amp;I, false); if( FPS ) FPS-&gt;render(0xffffffff, timeDelta); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); } return true; } 13.7 一些改进 Terrain读取顶点数据到一个很大的缓存，在多重的顶点缓存中划分地形结构，在速度和可测量性方面都十分有利。为我们提出一个问题：顶点缓存最大支持多大？回答是，这依赖于你的硬件。所以你必须先检测。 将地图划分为许多小的顶点缓存是重要的练习，然后将类似矩阵的数据结构编入索引，并且管理数据，这不需要引入新的概念。我们不必详细讨论它。简单的说，你基本上站在地形中一个我们叫做“blocks”的矩阵上,每个block是地形的一个矩形区域。另外，每个block区域（在它自己的顶点索引缓存中）的下方包含地形中的几何信息，为了画它在地形中的位置。 另外，你可以读取地形到一个很大的ID3DXMesh接口。使用D3D函数D3DXSplitMesh划分地形为许多小的Mesh, 以下是D3DXSplitMesh函数原型：void D3DXSplitMesh( const LPD3DXMESH pMeshIn, const DWORD pAdjacencyIn, const DWORD MaxSize, const DWORD Options, DWORD pMeshesOut, LPD3DXBUFFER ppMeshArrayOut, LPD3DXBUFFER ppAdjacencyArrayOut, LPD3DXBUFFER ppFaceRemapArrayOut, LPD3DXBUFFER ppVertRemapArrayOut); 这个函数将一个源Mesh划分多个小的Mesh,，pMeshIn参数是一个指针，指向想划分的Mesh，pAdjacencyIn指向一个邻接数组，MaxSize参数指定作为结果返回的最大顶点数，为返回的Meshe使用指定的创建标记，pMeshesOut参数返回ppMeshArrayOut数组中的Mesh数量，最后3个参数是可选的（可以指定为null），返回邻接信息的数组。13.8 摘要 我们能用三角形网格和不同的高度值来模拟地形，创建山丘、河流。 Heightmap数据包含地形顶点的高度值。 我们能通过程序使用磁盘上的图像文件生成地形上的纹理。 我们能照亮地形，通过计算阴影系数来使每个格子变亮或变暗，阴影系数是由光照在格子上的角度决定的。 使照相机在地形上走动，我们需要找到我们站立的三角形。我们计算三角形上的邻边和对边这两个向量，高度是通过…（线性插值在这些向量中每个使用x、z对应的单位向量，以左高顶点为原点为参数。）找到的。（The height is then found by linearly interpolating on each of these vectors using the x- and z-coordinates in a normalized cell with an upper-left vertex at the origin as parameters.）]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第十一章 网格模型II(Building a Flexible Camera Class)]]></title>
    <url>%2F2019%2F04%2F11%2FBuilding-a-Flexible-Camera-Class%2F</url>
    <content type="text"><![CDATA[ID3DXBuffer 对ID3DXBuffer接口的一些参考是在上一章，这里我们不会详细讲解。在D3DX库中到处都能看见这个接口，因此大概介绍一下该接口还是很有必要的。 ID3DXBuffer接口是一个很普通的数据结构， D3DX用它将数据存储到邻接内存块中。它只有两个方法： LPVOID GetBufferPointer()——返回一个指向开始数据的指针。 DWORD GetBufferSize()——返回在缓存中的字节大小。 为了保持结构特性，它使用一个空指针。也就是说它让我们知道被存储的数据的类型。例如，D3DXLoadMeshFromX使用一个ID3DXBuffer来返回mesh的邻接信息。因为邻接信息是被存储在DWORD数组中的，所以当我们希望使用缓存中的邻接信息时，我们不得不将缓存转换为DWORD数组。 例如：DWORD info =(DWORD)adjacencyInfo-&gt;GetBufferPointer();D3DXMATERIAL mtrls = (D3DXMATERIAL)mtrlBuffer-&gt;GetBufferPointer(); 因为ID3DXBuffer是一个COM对象，当你使用完以后就必须释放它以防止内存泄漏：adjacencyInfo-&gt;Release();mtrlBuffer-&gt;Release(); 我们能够使用下面的方法来创建一个空的ID3DXBuffer：HRESULT D3DXCreateBuffer( DWORD NumBytes, // Size of the buffer, in bytes. LPD3DXBUFFER ppBuffer // Returns the created buffer.); 下面的例子是创建一个能包含4个整数的缓存：ID3DXBuffer buffer = 0;D3DXCreateBuffer( 4 sizeof(int), &amp;buffer );11.2 X文件 迄今为止，我们已经使用过了简单的几何物体，如球体，圆柱体，立方体等，它们都是用D3DXCreate函数来创建的。假如你想通过手工指定顶点来创建你自己的3D物体，你能，不用怀疑，不过这是非常枯燥乏味的事情。为了减轻建造3D物体数据的工作，专门的应用程序已经被开发出来了，我们把它们叫做3D建模工具。它们允许我们在一个虚拟的拥有丰富工具的交互环境下建造复杂的真实的mesh，在这建造这些模型都是非常容易的。例如在游戏开发中常用到的有3DSMax（www.discreet.com）,LightWave 3D（www.newtek.com）,以及Maya（www.aliaswavefront.com）。 这些工具，当然能够输出创建好的mesh数据到文件中。因此，我们也能够写一个文件来提取在我们的3D应用程序中要用到的mesh数据。这的确是一种可行的解决办法。不过，还存在一个更方便的解决方案。它是一种叫做X文件的特殊mesh文件格式（扩展名为.X）。很多3D建模软件都能输出这种格式，当然这里存在一个将其他流行的mesh文件转换为X文件的过程。是什么使X文件这么便利呢？因为它是DirectX定义的格式，并且D3DX库很容易地支持X文件。D3DX库提供了读和写X文件的函数。因此，如果我们使用这种格式就避免了还要自己写程序文件来读/写模型文件了。 注意：你能够下载DirectX9 SDK Extra——你能从MSDN（www.msdn.microsoft.com）上得到一些已经开发好的针对3DMax,LightWave,Maya软件导出.X文件的Direct3D工具包。11.2.1读取X文件 我们使用下面的函数来读取存储在X文件中的mesh数据。注意这个方法创建一个ID3DXMesh对象，且从X文件中读取几何信息数据填入其中。HRESULT D3DXLoadMeshFromX( LPCSTR pFilename, DWORD Options, LPDIRECT3DDEVICE9 pDevice, LPD3DXBUFFER ppAdjacency, LPD3DXBUFFER ppMaterials, LPD3DXBUFFER ppEffectInstances, PDWORD pNumMaterials, LPD3DXMESH ppMesh); pFilename — 读取的X文件的文件名。 Options — 用来创建mesh的一个或多个创建标志。要了解所有标志信息请查看sdk文档。现在列出一部分： D3DXMESH_32BIT — mesh使用32位索引。 D3DXMESH_MANAGED — mesh数据将被放在受控的内存中。 D3DXMESH_WRITEONLY — mesh数据只能执行写操作，不能执行读操作。 D3DXMESH_DYNAMIC — mesh缓存将是动态的。 pDevice — 与复制mesh有关的设备。 ppAdjacency — 返回一个ID3DXBuffer包含一个DWORD数组，描述mesh的邻接信息。 ppMaterials — 返回一个ID3DXBuffer包含一个D3DXMATERIAL结构的数组，存储了mesh的材质数据。我们在下一节介绍mesh材质。 ppEffectInstances — 返回一个ID3DXBuffer包含一个D3DXEFFECTINSTANCE结构的数组。我们现在通过指定0值来忽略这个参数。 pNumMaterials — 返回mesh的材质数。 ppMesh — 返回填充了X文件几何信息的ID3DXMesh对象。11.2.2 X文件的材质 D3DXLoadMeshFromX的第七个参数返回的是mesh包含的材质数，第五个参数返回的是包含着材质数据的一个D3DXMATERIAL结构数组。D3DXMATERIAL结构的定义如下：typedef struct D3DXMATERIAL { D3DMATERIAL9 MatD3D; LPSTR pTextureFilename;} D3DXMATERIAL; 这是一个简单的结构；它包含一个基本的D3DMATERAIL9结构和一个用来指定与之相关联的纹理文件名的一个以null结束的字符串指针。一个X文件是不能插入纹理数据的；它只能插入文件名。因此，在使用D3DXLoadMeshFromX读取一个X文件以后，我们还必须从纹理文件中读取纹理数据。我们将在下一节中说明怎样具体实现。 D3DXLoadMeshFromX函数读取X文件数据以便在返回的D3DXMATERIAL数组中的第i项与第i个子集相对应。因此，子集是使用0，1，2，…，n-1标记的，n是子集和材质的数目。这也就允许使用简单的循环来渲染mesh了。11.2.3 实例程序：X文件 我们现在演示本章中的第一个实例（X文件）的相关代码。该例子调用一个叫做bigship1.x的x文件，你可以在DirectX SDK下的media文件夹下找到它。完整原代码可以在相应的文件中找到。图11.1是该实例的一个截图。 图11.1 该实例使用下面的全局变量：ID3DXMesh Mesh = 0;std::vector Mtrls(0);std::vector&lt;IDirect3DTexture9&gt; Textures(0); 这里有一个ID3DXMesh对象，它被用来存储从X文件中读取的mesh数据。也有一个材质vector和纹理vector,我们用它们来分别存储mesh的材质和纹理。 我们首先在Setup函数中操作。首先，我们读取X文件：bool Setup(){ HRESULT hr = 0; // // Load the XFile data. // ID3DXBuffer adjBuffer = 0; ID3DXBuffer mtrlBuffer = 0; DWORD numMtrls = 0; hr = D3DXLoadMeshFromX( “bigship1.x”, D3DXMESH_MANAGED, Device, &amp;adjBuffer, &amp;mtrlBuffer, 0, &amp;numMtrls, &amp;Mesh); if(FAILED(hr)) { ::MessageBox(0, “D3DXLoadMeshFromX() - FAILED”, 0, 0); return false; } 读取完X文件数据以后，我们必须遍历D3DXMATERIAL数组来读取mesh中所使用的所有纹理： // // Extract the materials, and load textures. // if( mtrlBuffer != 0 &amp;&amp; numMtrls != 0 ) { D3DXMATERIAL mtrls = (D3DXMATERIAL)mtrlBuffer-&gt;GetBufferPointer(); for(int i = 0; i &lt; numMtrls; i++) { // the MatD3D property doesn’t have an ambient value set // when its loaded, so set it now: mtrls[i].MatD3D.Ambient = mtrls[i].MatD3D.Diffuse; // save the ith material Mtrls.push_back( mtrls[i].MatD3D ); // check if the ith material has an associative texture if( mtrls[i].pTextureFilename != 0 ) { // yes, load the texture for the ith subset IDirect3DTexture9 tex = 0; D3DXCreateTextureFromFile( Device, mtrls[i].pTextureFilename, &amp;tex); // save the loaded texture Textures.push_back( tex ); } else { // no texture for the ith subset Textures.push_back( 0 ); } } } d3d::Release&lt;ID3DXBuffer&gt;(mtrlBuffer); // done w/ buffer . . // Snipped irrelevant code to this chapter (e.g., setting up lights, . // view and projection matrices, etc.) . return true;} // end Setup() 在Display函数中我们让mesh在每一帧中都旋转一个小角度。我们使用简单的循环，Mesh便能够被渲染了：bool Display(float timeDelta){ if( Device ) { // // Update: Rotate the mesh. // static float y = 0.0f; D3DXMATRIX yRot; D3DXMatrixRotationY(&amp;yRot, y); y += timeDelta; if( y &gt;= 6.28f ) y = 0.0f; D3DXMATRIX World = yRot; Device-&gt;SetTransform(D3DTS_WORLD, &amp;World); // // Render // Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); for(int i = 0; i &lt; Mtrls.size(); i++) { Device-&gt;SetMaterial( &amp;Mtrls[i] ); Device-&gt;SetTexture(0, Textures[i]); Mesh-&gt;DrawSubset(i); } Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); } return true; }11.2.4 产生顶点法线 一个X文件不包含顶点法线数据，这是很有可能的。假如是这种情况，那么手动计算顶点法线以便我们能够使用灯光这是很有必要的。在第5章中我们简要的介绍了一下怎么做。然而，现在我们知道了ID3DXMesh接口和它的父接口ID3DXBaseMesh，我们能够使用下面的函数来产生任何mesh的顶点法线：HRESULT D3DXComputeNormals( LPD3DXBASEMESH pMesh, // Mesh to compute normals of. const DWORD pAdjacency // Input adjacency info.); 这个函数通过使用平均法线的方法来产生顶点法线。假如有邻接信息，那么重复的顶点是被忽略的。假如没有邻接信息，那么重复的顶点也会被重复计算。了解这些是很重要的，我们检查pMash必须有一个包含D3DFVF_NORMAL标记的顶点格式。 注意假如X文件不包含顶点法线数据，那么通过D3DXLoadMeshFromX创建的ID3DXMesh对象在它的顶点格式中没有指定的D3DFVF_NORMAL标记。因此，在我们能够使用D3DXComputeNormals之前，我们必须复制mesh并且为其指定包含D3DFVF_NORMAL的顶点格式。下面就是相应的代码：// does the mesh have a D3DFVF_NORMAL in its vertex format?if ( !(pMesh-&gt;GetFVF() &amp; D3DFVF_NORMAL) ){ // no, so clone a new mesh and add D3DFVF_NORMAL to its format: ID3DXMesh pTempMesh = 0; pMesh-&gt;CloneMeshFVF( D3DXMESH_MANAGED, pMesh-&gt;GetFVF() | D3DFVF_NORMAL, // add it here Device, &amp;pTempMesh ); // compute the normals: D3DXComputeNormals( pTempMesh, 0 ); pMesh-&gt;Release(); // get rid of the old mesh pMesh = pTempMesh; // save the new mesh with normals }11.3渐进网格（Progressive Meshes） 渐进网格，它通过ID3DXPMesh接口来表现，允许我们通过简化边缩减转换（edge collapse transformations，ECT）来简化mesh。每执行一次ECT就移除一个顶点和一或2个面。因为每个ECT是可逆的（它的逆过程叫顶点分裂），我们能够逆转简化过程并且恢复mesh为它的原始状态。当然，我们不可能得到比原始情况还要精细的网格。我们仅仅只能简化然后恢复简化操作。图11.2显示了同一个mesh的三种不同精细级别（levels of detail，LOD）：高，中，低。 图11.2 渐进网格和mipmaps纹理非常相似。当使用纹理时，我们已经注意到在一个小或远的图元上使用高分辨率的纹理简直就是浪费。对于mesh也是同样的道理；一个小或远的mesh不需要太多三角形，多了也是浪费。因此，我们不会花费渲染高三角形模型的时间来渲染一个只需要表现小的低三角形模型。 我们可以使用渐进网格来根据模型距离摄象机的距离来调整模型的LOD。也就是说，当距离减少时，我们增加mesh的细节，当距离增加时我们减少mesh的细节。 注意我们还没有讨论渐进网格是怎样被实现的；这里我们只讲解怎样使用ID3DXPMesh接口。对此感兴趣的读者可以到渐进网格的原始页面Hoppe上查看。Hoppe的网址：http://research.microsoft.com/~hoppe/。11.3.1 产生一个渐进网格 我们能够使用下面的函数来创建一个ID3DXPMesh对象：HRESULT D3DXGeneratePMesh( LPD3DXMESH pMesh, CONST DWORD pAdjacency, CONST LPD3DXATTRIBUTEWEIGHTS pVertexAttributeWeights, CONST FLOAT pVertexWeights, DWORD MinValue, DWORD Options, LPD3DXPMESH *ppPMesh); pMesh— 输入原始mesh，它包含了我们想要生成的渐进网格的mesh数据。 pAdjacency — 指向一个包含pMesh邻接信息的DWORD数组。 pVertexAttributeWeights — 指向一个D3DXATTRIBUTEWEIGHTS数组，它的大小是pMesh-&gt;GetNumVertices（）。它的第i项与pMesh中的第i个顶点相对应并且指定的是它的品质权重。品质权重被用来确定一个顶点被删除的可能性大小。你能够将此参数设置为null，对于每个顶点一个默认的顶点品质权重将被设置。在11.3.2节中有关于顶点品质权重和D3DXATTRIBUTEWEIGHTS结构的更多信息。 pVertexWeights — 指向一个float数组，它的大小是pMesh-&gt;GetNumVertices（），它的第i项与pMesh中的第i个顶点相对应并且指定的是它的顶点权重。顶点权重越高被删除的可能性越小。你能够将此参数设置为null，对于每个顶点一个默认的顶点品质权重1.0将被设置。 MinValue — 我们想要简化到的最小顶点或面数。注意该值是必须的，而且与顶点/品质权重有关，最终可能达不到该值。 Options — 只能取D3DXMESHSIMP枚举类型中的一个值： D3DXMESHSIMP_VERTEX — 指定在上一个参数MinValue中提到的数为顶点数。 D3DXMESHSIMP_FACE —指定在上一个参数MinValue中提到的数为面数。 ppPMesh — 返回生成好的渐进网格。11.3.2 顶点品质权重typedef struct _D3DXATTRIBUTEWEIGHTS { FLOAT Position; FLOAT Boundary; FLOAT Normal; FLOAT Diffuse; FLOAT Specular; FLOAT Texcoord[8]; FLOAT Tangent; FLOAT Binormal;} D3DXATTRIBUTEWEIGHTS; 顶点权重结构允许我们为每个顶点属性指定一个权值。0.0表示该属性没有权重。顶点属性的权重越高在简化过程中被移除的可能性越小。默认的权值如下：D3DXATTRIBUTEWEIGHTS AttributeWeights;AttributeWeights.Position = 1.0;AttributeWeights.Boundary = 1.0;AttributeWeights.Normal = 1.0;AttributeWeights.Diffuse = 0.0;AttributeWeights.Specular = 0.0;AttributeWeights.Tex[8] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}; 默认的权值是被推荐的，除非你的应用程序有一个重要的理由而不使用它。11.3.3 ID3DXPMesh方法 ID3DXPMesh接口是继承自ID3DXBaseMesh接口。因此它拥有以前所学习过的ID3DXMesh的所有函数，下面是一些额外的方法：DWORD GetMaxFaces(VOID)——返回渐进网格能够被设置的最大面数。DWORD GetMaxVertices(VOID)——返回渐进网格能够被设置的最大顶点数。DWORD GetMinFaces(VOID)——返回渐进网格能够被设置的最小面数。DWORD GetMinVertices(VOID)——返回渐进网格能够被设置的最小顶点数。HRESULT SetNumFaces(DWORD Faces)——这个方法允许我们设置面的个数，以便让mesh简化/复杂化。例如，假设mesh目前有50个面，我们现在想将它简化到30个面；我们将写成：pmesh-&gt;SetNumFaces(30); 注意调整后的面数可能并不是我们设定的面数。假如面数小于了GetMinFaces（），那么面数将为GetMinFaces（）。同样的，假如面数大于了GetMaxFaces（），那么面数将为GetMaxFaces（）。HRESULT SetNumVertices(DWORD Vertices)——这个方法允许我们设置顶点的个数，以便让mesh简化/复杂化。例如，假设mesh目前有20个顶点，我们现在想将它增加到40个；我们将写成：pmesh-&gt;SetNumVertices(40); 注意调整后的顶点数可能并不是我们设定的数。假如顶点数小于了GetMinVertices（），那么顶点数将为GetMinVertices（）。同样的，假如顶点数大于了GetMaxVertices（），那么顶点数将为GetMaxVertices（）。HRESULT TrimByFaces(DWORD NewFacesMin,DWORD NewFacesMax,DWORD rgiFaceRemap, // Face remap info.DWORD rgiVertRemap // Vertex remap info.); 这个方法允许我们设置新的最小和最大面数，分别通过NewFacesMin和NewFacesMax指定。注意新的最小和最大值必须在现有最小和最大面数之间；也就是说，必须在[GetMinFaces（），GetMaxFaces（）]之中。该函数也返回面和顶点的重影射信息。重影射信息参见10.4节。HRESULT TrimByVertices(DWORD NewVerticesMin,DWORD NewVerticesMax,DWORD rgiFaceRemap, // Face remap info.DWORD rgiVertRemap // Vertex remap info.); 这个方法允许我们设置新的最小和最大顶点数，分别通过NewVerticesMin和NewVerticesMax指定。注意新的最小和最大值必须在现有最小和最大顶点数之间；也就是说，必须在[GetMinVertices（），GetMaxVertices（）]之中。该函数也返回面和顶点的重影射信息。重影射信息参见10.4节。11.3.4实例程序：渐进网格 渐进网格例子与X文件例子很相似，除了实际上我们创建和渲染的是一个渐进网格，通过ID3DXPMesh接口来表现。我们允许用户通过键盘输入进行交互式地改变渐进网格。你能通过按A键来增加mesh的面数，按S键来减少mesh的面数。 在这个例子中使用的全局变量和X文件例子中的是一样的，不过我们增加了一个用来存储渐进网格的变量：ID3DXMesh SourceMesh = 0;ID3DXPMesh PMesh = 0; // progressive meshstd::vector Mtrls(0);std::vector Textures(0); 回想一下，为了得到一个渐进网格我们必须输入一个包含了数据信息的源mesh。因此，我们首先读取一个X文件数据到ID3DXMesh对象SourceMesh之中，然后再产生渐进网格：bool Setup(){ HRESULT hr = 0; // …Load XFile data into SourceMesh snipped. // // …Extracting materials and textures snipped. 因为这一部分代码和X文件例子中的是完全一样的，在这里我们就把它省略了。一但有了源mesh，我们就能够象下面一样来生成渐进网格了： // // Generate the progressive mesh. // hr = D3DXGeneratePMesh( SourceMesh, (DWORD*)adjBuffer-&gt;GetBufferPointer(), // adjacency 0, // default vertex attribute weights 0, // default vertex weights 1, // simplify as low as possible D3DXMESHSIMP_FACE, // simplify by face count &amp;PMesh); d3d::Release(SourceMesh); // done w/ source mesh d3d::Release(adjBuffer); // done w/ buffer if(FAILED(hr)) { ::MessageBox(0, &quot;D3DXGeneratePMesh() - FAILED&quot;, 0, 0); return false; } 注意，因为顶点/品质权值的缘故，很难将Mesh简化到只有一个面，但是，如果将其指定为1，则可以将Mesh简化到最低。 在这一点上，渐进网格已经被产生了，但是假如你现在就渲染它，它将以最简化的方式来渲染。以为我们想开始渲染最高精度的mesh，所以我们设置它为： // set to original detail DWORD maxFaces = PMesh-&gt;GetMaxFaces(); PMesh-&gt;SetNumFaces(maxFaces); 在Display函数中，我们测试A键和S键并将结果输入。bool Display(float timeDelta){ if( Device ) { // // Update: Mesh resolution. // // Get the current number of faces the pmesh has. int numFaces = PMesh-&gt;GetNumFaces(); // Add a face, note the SetNumFaces() will automatically // clamp the specified value if it goes out of bounds. if( ::GetAsyncKeyState(&#39;A&#39;) &amp; 0x8000f ) { // Sometimes we must add more than one face to invert // an edge collapse transformation PMesh-&gt;SetNumFaces( numFaces + 1 ); if( PMesh-&gt;GetNumFaces() == numFaces ) PMesh-&gt;SetNumFaces( numFaces + 2 ); } // Remove a face, note the SetNumFaces() will automatically // clamp the specified value if it goes out of bounds. if( ::GetAsyncKeyState(&#39;S&#39;) &amp; 0x8000f ) PMesh-&gt;SetNumFaces( numFaces - 1 ); 这是很简单的，但是要注意当增加面时我们有时必须增加两个面来完成ECT。 最后，我们就能象渲染ID3DXMesh对象一样来渲染ID3DXPMesh对象。另外，为了更加直观的观察网格的三角形数的变化情况，使用黄色材质在线框模式（Wireframe Mode）下渲染Mesh的三角形。 Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); for(int i = 0; i &lt; Mtrls.size(); i++) { // draw pmesh Device-&gt;SetMaterial( &amp;Mtrls[i] ); Device-&gt;SetTexture(0, Textures[i]); PMesh-&gt;DrawSubset(i); // draw wireframe outline Device-&gt;SetMaterial(&amp;d3d::YELLOW_MTRL); Device-&gt;SetRenderState(D3DRS_FILLMODE, D3DFILL_WIREFRAME); PMesh-&gt;DrawSubset(i); Device-&gt;SetRenderState(D3DRS_FILLMODE, D3DFILL_SOLID); } Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); } return true;} 图11.311.4 界线容积（Bounding Volumes） 有时我们需要计算mesh的界线容积（边界范围）。常用的有两种类型：立方体和球。也有使用其它方法的，如圆柱体，椭球体，菱形体，胶囊形。图11.4演示了对同一个mesh分别使用立方体和球体类型。这一节我们只讨论立方体和球体两种边界形式。 图11.4 边界盒/球常常被用来加速可见性测试，碰撞检测等。例如，假如一个mesh的边界盒/球不可见，那么我们就说mesh不可见。一个盒/球可见性测试是比分别测试mesh中的每个三角形要廉价的多。对于一个碰撞检测例子，如果一枚导弹点火起飞，我们需要检测它是否击中了同一场景中的目标。由于这些物体都是由大量三角形构成，我们可以依次检测每个对象的每个三角形，来测试导弹（可以用射线数学模型）是否碰撞到了这些三角形。这个方法需要进行多次的射线/三角形交点的运算。一个更好的方法是使用边界盒或边界球，计算射线与场景中的每个对象的边界盒/边界球的交点。如果射线与对象的边界范围相交，可以认为该对象被击中了。这是一个公平的近似方法，如果需要更高的精度，可以用边界范围法先去除那些明显不会相撞的对象，然后用更精确地方法检测很可能相撞的对象。如果边界范围检测发现相撞，则该对象就很有可能相撞。 D3DX库提供了计算mesh的边界盒和边界球的函数。这些函数使用顶点数组作为输入计算边界盒/球。这些函数本来就是设计的很灵活的，它们可以使用各种顶点格式：HRESULT D3DXComputeBoundingSphere( LPD3DXVECTOR3 pFirstPosition, DWORD NumVertices, DWORD dwStride, D3DXVECTOR3 pCenter, FLOAT pRadius); pFirstPosition——指向在顶点数组中第一个顶点的向量，描述顶点位置。 NumVertices——在顶点数组中的的顶点数。 dwStride——每个顶点的字节大小。这是很需要的，因为顶点结构可能有一些额外信息如法向量和纹理坐标，这些信息对计算边界又没有用，函数需要知道应该跳过多少字节来得到下一个顶点的位置。 pCenter——返回边界球的中心。 pRadius——返回边界球的半径。HRESULT D3DXComputeBoundingBox( LPD3DXVECTOR3 pFirstPosition, DWORD NumVertices, DWORD dwStride, D3DXVECTOR3 pMin, D3DXVECTOR3 pMax);前三个参数和D3DXComputeBoundingSphere的前三个参数是完全一样的。最后两个参数分别用来返回边界盒的最小和最大点。11.4.1一些新的特殊常量让我来介绍两个常量，它们在本书中是经常要用到的。我们把它们添加到d3d名称空间中：namespace d3d{ … const float INFINITY = FLT_MAX; const float EPSILON = 0.001f;常量INFINITY是用来表示一个浮点数所能存储的最大数。因为我们找不到一个比FLT_MAX还要大的浮点数，我们可以将它视为无穷大。常量EPSILON是一个很小的值，我们这样定义它，凡是比它小的数就视为0。这也是很有必要的，因为得到的浮点是不精确的，一个被读作0的数可能有一点点小偏差。因此，让它和0比较相等肯定会失败。我们因此可以通过把该值与0的差值与EPSILON比较来确定是否相等：bool Equals(float lhs, float rhs){ // if lhs == rhs their difference should be zero return fabs(lhs - rhs) &lt; EPSILON ? true : false;}11.4.2界线容积类型 为了更容易的使用边界盒和边界球，我们将它们分别封装到两个类中。现在在d3d名称空间中定义类：struct BoundingBox{ BoundingBox(); bool isPointInside(D3DXVECTOR3&amp; p); D3DXVECTOR3 _min; D3DXVECTOR3 _max;};struct BoundingSphere{ BoundingSphere(); D3DXVECTOR3 _center; float _radius;};d3d::BoundingBox::BoundingBox(){ // infinite small bounding box _min.x = d3d::INFINITY; _min.y = d3d::INFINITY; _min.z = d3d::INFINITY; _max.x = -d3d::INFINITY; _max.y = -d3d::INFINITY; _max.z = -d3d::INFINITY;}bool d3d::BoundingBox::isPointInside(D3DXVECTOR3&amp; p){ // is the point inside the bounding box? if(p.x &gt;= _min.x &amp;&amp; p.y &gt;= _min.y &amp;&amp; p.z &gt;= _min.z &amp;&amp; p.x &lt;= _max.x &amp;&amp; p.y &lt;= _max.y &amp;&amp; p.z &lt;= _max.z) { return true; } else { return false; }}d3d::BoundingSphere::BoundingSphere(){ _radius = 0.0f;}11.4.3实例程序：界线容积 在这一章中被叫做界线容积的实例程序主要是演示使用D3DXComputeBoundingSphere和D3DXComputeBoundingBox。程序读取一个X文件并且计算该mesh的边界球。它创建两个ID3DXMesh对象，一个用来作为边界球模型一个用来作为边界盒模型。X文件生成的mesh被渲染，其中的边界球或边界盒不可见（如图11.5）。你能够通过敲空格键来再边界球和边界盒之间切换。 图11.5 这个例子是非常简单的，我们列出你要学习的代码。我们实现的两个函数是用来计算网格的边界球和边界盒的：bool ComputeBoundingSphere( ID3DXMesh mesh, // mesh to compute bounding sphere for d3d::BoundingSphere sphere) // return bounding sphere{ HRESULT hr = 0; BYTE* v = 0; mesh-&gt;LockVertexBuffer(0, (void**)&amp;v); hr = D3DXComputeBoundingSphere( (D3DXVECTOR3*)v, mesh-&gt;GetNumVertices(), D3DXGetFVFVertexSize(mesh-&gt;GetFVF()), &amp;sphere-&gt;_center, &amp;sphere-&gt;_radius); mesh-&gt;UnlockVertexBuffer(); if( FAILED(hr) ) return false; return true; } bool ComputeBoundingBox( ID3DXMesh mesh, // mesh to compute bounding box for d3d::BoundingBox box) // return bounding box{ HRESULT hr = 0; BYTE* v = 0; mesh-&gt;LockVertexBuffer(0, (void**)&amp;v); hr = D3DXComputeBoundingBox( (D3DXVECTOR3*)v, mesh-&gt;GetNumVertices(), D3DXGetFVFVertexSize(mesh-&gt;GetFVF()), &amp;box-&gt;_min, &amp;box-&gt;_max); mesh-&gt;UnlockVertexBuffer(); if( FAILED(hr) ) return false; return true; } 注意，类型转换(D3DXVECTOR3*)v假定顶点位置成员是被存储在我们所使用的顶点结构的开始位置。同样要注意我们能够使用D3DXGetFVFVertexSize函数来得到顶点结构的大小。11.5 摘要(略) 第十二章 创建灵活的摄像机类(Building a Flexible Camera Class) 迄今，我们已经使用过D3DXMatrixLookAtLH函数来计算视图空间变换矩阵。这个函数对于在固定位置布置和对准摄像机是非常好用的，不过它的用户接口对于要响应用户输入来实现摄像机移动就不那么好用了。这就激发我们用我们自己的方法来解决。在这一章我们展示了怎样实现一个Camera类，它使我们能够比D3DXMatrixLookAtLH函数更好地操作摄像机，并且可以用来作为飞行模拟摄像机和第一人称视角摄像机。目标 学习怎样实现一个灵活的摄像机类，它可以用作飞行模拟摄像机和第一人称视角摄像机。12.1 摄像机设计 我们定义一个相对于世界坐标系的位置和摄像机的方向，这里使用四个摄像机向量：right vector , up vector, look vector 以及 position vector, 如图12.1所示。这些向量用来为摄像机定义一个坐标系来描述在世界坐标中的对应关系。因为 right ，up 和 look 向量定义了摄像机在世界中的方向，我们有时把它们三个向量一起称为方向向量（orientation vectors）。方向向量必须被标准化。假如彼此互相垂直且都是单位长度，那么我们就称它们是正交标准化向量。我们做这些限制是因为等一会儿我们要将方向向量插入到一个行矩阵中。因为行向量是正交标准化的，所以该矩阵也就是直交矩阵。回忆一下，直交矩阵有一个特性就是它的逆矩阵等于它的转置矩阵。这在等一下的12.2.1.2节中是很有用的。 图12.1 有了这四个向量来描述摄像机，我们的摄像机就能够按照下面六种方式变化了： 围绕right向量旋转（pitch倾斜） 围绕up向量旋转（yaw 偏航） 围绕look向量旋转（roll 滚转） 沿着right向量平移（strafe） 沿着up向量飞行（fly） 沿着look向量移动（move）通过这六种操作，我们能够沿着三个轴移动以及饶着三个轴旋转，这给了我们一个六度的自由。下面的Camera类定义了我们要的描述数据以及想要的方法：1234567891011121314151617181920212223242526272829class Camera&#123;public: enum CameraType &#123; LANDOBJECT, AIRCRAFT &#125;; Camera(); Camera(CameraType cameraType); ~Camera(); void strafe(float units); // left/right void fly(float units); // up/down void walk(float units); // forward/backward void pitch(float angle); // rotate on right vector void yaw(float angle); // rotate on up vector void roll(float angle); // rotate on look vector void getViewMatrix(D3DXMATRIX* V); void setCameraType(CameraType cameraType); void getPosition(D3DXVECTOR3* pos); void setPosition(D3DXVECTOR3* pos); void getRight(D3DXVECTOR3* right); void getUp(D3DXVECTOR3* up); void getLook(D3DXVECTOR3* look);private: CameraType _cameraType; D3DXVECTOR3 _right; D3DXVECTOR3 _up; D3DXVECTOR3 _look; D3DXVECTOR3 _pos;&#125;; 在类中我们定义了一个还没有讨论的CameraType枚举类型。目前，我们的摄像机支持两种摄像机模式，LANDOBJECT模式和AIRCRAFT模式。AIRCRAFT模式允许我们在空间中完全自由的移动。不过，在有些游戏中，比如第一人称设计游戏，人是不能飞的；因此我们必须限制它在某些轴上的运动。指定为LANDOBJECT模式的摄像机就限制了这些，你可以在下一部分看见。12.2 执行详细资料12.2.1计算视图矩阵 我们现在演示怎样根据摄像机向量来计算视图矩阵变换的。让 p = (px, py, pz), r = (rx, ry, rz), u = (ux, uy, uz) 以及 d = (dx, dy, dz) 分别表示 position, right, up 以及 look 向量。 回忆第二章我们所说的，视图空间变换是指在世界坐标系中进行几何变换以便将照相机平移变换到坐标系的源点并把它的方向旋转至朝向Z轴的正方向（如图12.2）。 图12.2因此，我们希望有一个象这样的变换矩阵V ： pV = (0, 0, 0)—矩阵V能将摄像机移动到原点。 rV = (1, 0, 0)—矩阵V能将摄像机的right向量与世界坐标系中的x轴对齐。 uV = (0, 1, 0)—矩阵V能将摄像机的up向量与世界坐标系中的y轴对齐。 dV = (0, 0, 1)—矩阵V能将摄像机的look向量与世界坐标系中的z轴对齐。我们能将变换任务分为两个部分：1）平移部分，将摄像机的位置移动到原点；2）旋转部分，将摄像机的方向向量与世界坐标系的轴对齐。12.2.1.1 第一部分：平移 平移只需要利用 –p 就可简单地将 p 移动到原点，因为 p–p=0。因此我们能够用下面的矩阵来描述视图变换中的平移部分： 12.2.1.2 第二部分：旋转 矫正摄像机的三个方向向量使其与世界坐标系的轴对齐需要更多的工作。我们需要一个33的旋转矩阵A ，它能将right，up和look分别与x-，y-以及z轴对齐。这个矩阵将满足如下三个等式： 注意：我们在这里使用33矩阵来工作是因为现在不需要额外的信息来表现旋转。等一下我们将它增加到常用的44矩阵。 因为这三个等式都有一个相同系数矩阵A ，所以我们能够把它们合在一起。我们把它们从新写到一起来： 求A有很多方法，但是我们知道A是B逆矩阵因为BA = BB-1 = I。因为B 是一个直交矩阵（它的行向量是正交标准化的），我们知道它的逆矩阵就是它的转置矩阵。因此，将方向向量和世界坐标系中的坐标轴对齐的变换如下： 12.2.1.3 将两部分合并 最后，将A增加为44矩阵，同时将平移部分合并到旋转部分形成的视图变换矩阵V： 我们在Camera::getViewMatrix方法中建立这个矩阵：void Camera::getViewMatrix(D3DXMATRIX* V){ // Keep camera’s axes orthogonal to eachother D3DXVec3Normalize(&amp;_look, &amp;_look); D3DXVec3Cross(&amp;_up, &amp;_look, &amp;_right); D3DXVec3Normalize(&amp;_up, &amp;_up); D3DXVec3Cross(&amp;_right, &amp;_up, &amp;_look); D3DXVec3Normalize(&amp;_right, &amp;_right); // Build the view matrix: float x = -D3DXVec3Dot(&amp;_right, &amp;_pos); float y = -D3DXVec3Dot(&amp;_up, &amp;_pos); float z = -D3DXVec3Dot(&amp;_look, &amp;_pos); (*V)(0,0) = _right.x; (*V)(0, 1) = _up.x; (*V)(0, 2) = _look.x; (*V)(0, 3) = 0.0f; (*V)(1,0) = _right.y; (*V)(1, 1) = _up.y; (*V)(1, 2) = _look.y; (*V)(1, 3) = 0.0f; (*V)(2,0) = _right.z; (*V)(2, 1) = _up.z; (*V)(2, 2) = _look.z; (*V)(2, 3) = 0.0f; (*V)(3,0) = x; (*V)(3, 1) = y; (*V)(3, 2) = z; (*V)(3, 3) = 1.0f; }你可能想知道方法中前面几行代码是干什么的。在几次旋转后，摄像机的方向向量可能变的不相互垂直了。因此，每当该函数被调用时，我们根据look向量从新计算up和right向量，使它们保持相互垂直。新的up向量是这样计算的up = look × right。 接着新的right向量是这样计算的right = up × look。12.2.2围绕任意轴旋转为了实现我们的摄像机旋转方法，我们需要能够绕着任意轴旋转。D3DX库提供下面的函数来解决这个问题：D3DXMATRIX D3DXMatrixRotationAxis( D3DXMATRIX pOut, // returns rotation matrix CONST D3DXVECTOR3 *pV, // axis to rotate around FLOAT Angle // angle, in radians, to rotate); 图12.3例如，假如我们想绕向量（0.707, 0.707, 0）轴旋转π/2角度。我们可以这样写：D3DXMATRIX R;D3DXVECTOR3 axis(0.707f, 0.707f, 0.0f);D3DXMatrixRotationAxis(&amp;R, &amp;axis, D3DX_PI / 2.0f);D3DXMatrixRotationAxis的变换矩阵的来源你可以在Eric Lengyel的 Mathematics for 3D Game Programming &amp;Computer Graphics中找到。12.2.3 Pitch、Yaw和Roll因为方向向量描述了摄像机相对于世界坐标系的方向，我们必须考虑在使用倾斜（pitch）、偏航（yaw）和滚转（roll）时及时更新方向向量。这其实也是非常简单的。图12.4，12.5，12.6分别显示了摄像机的倾斜、偏航和滚转操作。 图12.4 图12.5 图12.6当倾斜（pitch）时，我们需要将up和look向量绕着right向量旋转一定角度。同样的，当偏航（yaw）时，我们需要将look和right向量绕着up向量旋转一定角度。最后，当滚转（roll）时，我们需要将up和right向量绕着look向量旋转一定角度。 我们现在明白了为什么D3DXMatrixRotationAxis函数是非常必要的，因为这三个向量中的任何一个都可能围绕世界坐标系中的任意轴旋转。 对于倾斜（pitch）、偏航（yaw）和滚转（roll）的执行我们已经讨论了。然而，对于LANDOBJECT模式就有一些限制。我们在偏航（yaw）方法中只围绕y轴旋转，我们完全屏蔽滚转（roll）。当然你可以根据你的程序需要来改变Camera类。我们这里只是一个示例而已。倾斜（pitch）、偏航（yaw）和滚转（roll）方法代码的具体实现如下：12345678910111213141516171819202122232425262728293031323334353637383940void Camera::pitch(float angle)&#123; D3DXMATRIX T; D3DXMatrixRotationAxis(&amp;T, &amp;_right, angle); // rotate _up and _look around _right vector D3DXVec3TransformCoord(&amp;_up,&amp;_up, &amp;T); D3DXVec3TransformCoord(&amp;_look,&amp;_look, &amp;T);&#125;void Camera::yaw(float angle)&#123; D3DXMATRIX T; // rotate around world y (0, 1, 0) always for land object if( _cameraType == LANDOBJECT ) D3DXMatrixRotationY(&amp;T, angle); // rotate around own up vector for aircraft if( _cameraType == AIRCRAFT ) D3DXMatrixRotationAxis(&amp;T, &amp;_up, angle); // rotate _right and _look around _up or y-axis D3DXVec3TransformCoord(&amp;_right,&amp;_right, &amp;T); D3DXVec3TransformCoord(&amp;_look,&amp;_look, &amp;T);&#125;void Camera::roll(float angle)&#123; // only roll for aircraft type if( _cameraType == AIRCRAFT ) &#123; D3DXMATRIX T; D3DXMatrixRotationAxis(&amp;T, &amp;_look, angle); // rotate _up and _right around _look vector D3DXVec3TransformCoord(&amp;_right,&amp;_right, &amp;T); D3DXVec3TransformCoord(&amp;_up,&amp;_up, &amp;T); &#125;&#125; 12.2.4 Walking、Strafing和Flying当提到walking时，我们的意思是在我们观察的方向上移动位置（也就是说，沿着look向量）。Strafing是说在我们观察方向的左右移动，也就是沿着right向量移动。最后，我们说flying就是沿着up向量移动。为了沿着这些轴移动，我们只需要简单地加一个向量就可以了（如图12.7）。 图12.7就象旋转一样，我们需要对移动作一些限制。例如，LANDOBJECT不允许飞起来。因此我们把移动限制在xz平面。然而，因为LANDOBJECT能够允许爬楼梯和登山，所以，我们设置Camera::setPosition方法，它允许你手动设置你的摄像机位置来达到你的高度和位置。 移动（walk）、平移（strafe）和飞行（fly）方法代码的具体实现如下：void Camera::walk(float units){ // move only on xz plane for land object if( _cameraType == LANDOBJECT ) _pos += D3DXVECTOR3(_look.x, 0.0f, _look.z) units; if( _cameraType == AIRCRAFT ) _pos += _look units;}void Camera::strafe(float units){ // move only on xz plane for land object if( _cameraType == LANDOBJECT ) _pos += D3DXVECTOR3(_right.x, 0.0f, _right.z) units; if( _cameraType == AIRCRAFT ) _pos += _right units;}void Camera::fly(float units){ // move only on y-axis for land object if( _cameraType == LANDOBJECT ) _pos.y += units; if( _cameraType == AIRCRAFT ) _pos += _up * units;}12.3实例程序：摄像机 这一章的实例程序是创建和渲染一个如图12.8所示的场景。你能够通过键盘输入在场景中自由地飞行。下面是相应键盘设置： W/S—向前/向后移动 A/D—向左/向右平移 R/F—向上/向下飞行 Up/Down方向键—倾斜 Left/Right方向键—偏航 N/M—滚转 图12.8 例子的执行是非常简单的，因为所有工作都包含在摄像机类中了，这些我们都已经讨论过了。我们在Display函数中获得键盘的输入。记住，我们在全局域中实例化了一个摄像机类对象TheCamera。同样注意我们使用时间变化量来控制移动摄像机；这可以排除帧速度的影响而稳定地移动。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849bool Display(float timeDelta)&#123; if( Device ) &#123; // // Update: Update the camera. // if( ::GetAsyncKeyState('W') &amp; 0x8000f ) TheCamera.walk(4.0f * timeDelta); if( ::GetAsyncKeyState('S') &amp; 0x8000f ) TheCamera.walk(-4.0f * timeDelta); if( ::GetAsyncKeyState('A') &amp; 0x8000f ) TheCamera.strafe(-4.0f * timeDelta); if( ::GetAsyncKeyState('D') &amp; 0x8000f ) TheCamera.strafe(4.0f * timeDelta); if( ::GetAsyncKeyState('R') &amp; 0x8000f ) TheCamera.fly(4.0f * timeDelta); if( ::GetAsyncKeyState('F') &amp; 0x8000f ) TheCamera.fly(-4.0f * timeDelta); if( ::GetAsyncKeyState(VK_UP) &amp; 0x8000f ) TheCamera.pitch(1.0f * timeDelta); if( ::GetAsyncKeyState(VK_DOWN) &amp; 0x8000f ) TheCamera.pitch(-1.0f * timeDelta); if( ::GetAsyncKeyState(VK_LEFT) &amp; 0x8000f ) TheCamera.yaw(-1.0f * timeDelta); if( ::GetAsyncKeyState(VK_RIGHT) &amp; 0x8000f ) TheCamera.yaw(1.0f * timeDelta); if( ::GetAsyncKeyState('N') &amp; 0x8000f ) TheCamera.roll(1.0f * timeDelta); if( ::GetAsyncKeyState('M') &amp; 0x8000f ) TheCamera.roll(-1.0f * timeDelta); // Update the view matrix representing the cameras // new position/orientation. D3DXMATRIX V; TheCamera.getViewMatrix(&amp;V); Device-&gt;SetTransform(D3DTS_VIEW, &amp;V); // // Render // Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0x00000000, 1.0f, 0); Device-&gt;BeginScene(); d3d::DrawBasicScene(Device, 1.0f); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); &#125; return true;&#125; 注意：我们已经用一个新的函数DrawBasicScene更新了d3d名称空间。这个函数绘制了如图12.8的场景。我们已经将其添加进了d3d名称空间，这是因为对于建立一个基本的场景它是一个非常方便的函数。以后的例子我们就可以集中精力在例子代码中而不需要关注这些不相关的绘制场景的代码了。它是在d3dUtility.h中被声明的：12345// Function references "desert.bmp" internally. This file must// be in the working directory.bool DrawBasicScene( IDirect3DDevice9* device,// Pass in 0 for cleanup. float scale); // uniform scale 如果该函数不能任何东西也就是什么都显示不出来，你就需要看看相应的代码了。你可以在本章的代码中找到它。注意这个函数需要调用一张desert.bmp图片用作纹理。当然该文件也可以在同一个文件夹下找到。12.4 摘要 我们以四个向量来描述在世界坐标系中照相机的位置和方向：right、up、look、position向量，藉由这个描述, 我们能轻易的实现一个自由的六角度照相机，为游戏中的模拟飞行器、第一人称视角的游戏玩家提供了一个灵活的照相机接口。]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第十章 网格模型I(Meshes Part I)]]></title>
    <url>%2F2019%2F04%2F11%2FMeshes-Part-I%2F</url>
    <content type="text"><![CDATA[几何信息ID3DXBaseMesh接口包含一个用来存储网格顶点的顶点缓存和一个用来定义这些顶点怎样连接在一起组成网格三角形的索引缓存。我们能够通过使用下面的方法来得到这些缓存的指针：12HRESULT ID3DXMesh::GetVertexBuffer(LPDIRECT3DVERTEXBUFFER9* ppVB);HRESULT ID3DXMesh::GetIndexBuffer(LPDIRECT3DINDEXBUFFER9* ppIB); 这里有一些使用这些方法的例子：1234IDirect3DVertexBuffer9* vb = 0;Mesh-&gt;GetVertexBuffer( &amp;vb );IDirect3DIndexBuffer9* ib = 0;Mesh-&gt;GetIndexBuffer( &amp;ib ); 假如想锁定这些缓存来读写数据，那么我们能够使用下面的方法。注意这些方法锁定整个顶点/索引缓存。HRESULT ID3DXMesh::LockVertexBuffer(DWORD Flags, BYTE ppData);HRESULT ID3DXMesh::LockIndexBuffer(DWORD Flags, BYTE ppData);Flags参数描述怎样锁定它。这些Flags参数在第三章中我们介绍过。ppData是函数返回的指向锁定内存的指针的地址。 当然在你锁定以后一定要记得解锁：HRESULT ID3DXMesh::UnlockVertexBuffer();HRESULT ID3DXMesh::UnlockIndexBuffer(); 下面是另外一些与mesh几何结构有关的ID3DXMesh接口方法： DWORD GetFVF() — 返回顶点的格式 DWORD GetNumVertices() — 返回顶点缓存中的顶点数 DWORD GetNumBytesPerVertex() — 返回一个顶点所占的字节数 DWORD GetNumFaces() — 返回在mesh中的面（三角形）数10.2 子集和属性缓存 一个mesh由一个或数个子集组成。一个子集（subset）是在mesh中的使用相同属性渲染的一组三角形。这里的属性是指材质，纹理和渲染状态。图10.1显示了一座房子mesh可能被分成的几个子集。 图10.1我们通过给每个子集指定一个唯一非负整数来标识子集。这个值可以是存储在一个DWORD中的任意数值。例如，在图10.1中我们用0，1，2和3来标识子集。 在mesh中的每个三角形都与一个属性ID相关联，表示该三角形属于该子集。例如，图10.1中组成地板的三角形具有属性ID0，它表示这些三角形属于子集0。同样，组成墙的三角形具有属性ID1，它表示这些三角形属于子集1。 三角形的属性ID存储在mesh的属性缓存中，它是一个DWORD数组。因为每个面对应属性缓存中的一项，所以属性缓存中的项目数等于mesh中的面的个数。属性缓存中的项目和索引缓存中定义的三角形一一对应。即，属性缓存中的第i项和索引缓存中的第i个三角形相对应。三角形i由下面三个索引缓存中的索引项定义： A = i 3 B = i 3 + 1 C = i * 3 + 2图10.2显示了这个对应关系： 图10.2 我们可以锁定属性缓存，就象下面的代码片段：DWORD* buffer = 0;Mesh-&gt;LockAttributeBuffer(lockingFlags, &amp;buffer);// Read or write to attribute buffer…Mesh-&gt;UnlockAttributeBuffer();10.3 绘制 ID3DXMesh接口提供了DrawSubset（DWORD AttribId）方法来绘制AttribId指示的子集中的各个三角形。例如，要绘制子集0中的所有三角形，我们将这样写：Mesh-&gt;DrawSubset(0); 为了绘制整个mesh，我们必须绘制mesh的所有子集。这是非常方便的用0，1，2，…，n-1来标识子集，这里的n是子集的总数。且有一个相对应的材质和纹理数组，即子集i与材质和纹理数组的第i项对应。这就使我们能够简单的用循环来渲染mesh：123456for(int i = 0; i &lt; numSubsets; i++)&#123; Device-&gt;SetMaterial( mtrls[i] ); Device-&gt;SetTexture( 0, textures[i] ); Mesh-&gt;DrawSubset(i);&#125; 10.4 优化 Mesh的顶点和索引能够被重组以便能更有效的渲染mesh。当我们这样做时，我们说我们优化了一个mesh。我们可以使用下面的方法来进行优化：HRESULT ID3DXMesh::OptimizeInplace( DWORD Flags, CONST DWORD pAdjacencyIn, DWORD pAdjacencyOut, DWORD pFaceRemap, LPD3DXBUFFER ppVertexRemap); Flags — 表示执行什么类型的优化方法。它可以是下面的一个或几个的组合： D3DXMESHOPT_COMPACT — 从mesh中移除没有用的顶点和索引项。 D3DXMESHOPT_ATTRSORT — 根据属性给三角形排序并调整属性表，这将使DrawSubset执行更有效（参见10.5节）。 D3DXMESHOPT_VERTEXCACHE — 增加顶点缓存的命中率。 D3DXMESHOPT_STRIPREORDER — 重组顶点索引使三角带尽可能的长。 D3DXMESHOPT_IGNOREVERTS — 只优化索引信息；忽略顶点信息。注意：D3DXMESHOPT_VERTEXCACHE和D3DXMESHOPT_STRIPREORDER不能同时使用。 pAdjacencyIn — 指向没有优化的mesh的邻接数组。 pAdjacencyOut — 指向一个DWORD数组，它被用来填充优化好了的mesh邻接信息。该数组必须有ID3DXMesh::GetNumFaces() * 3个元素。如果不需要该信息，可以将其设置为0。 pFaceRemap —指向一个DWORD数组，它被用来填充面重影射信息。该数组必须不小于ID3DXMesh::GetNumFaces()。当一个mesh被优化时，由索引缓存定义的面可能被移动；也就是说，在pFaceRemap中的第i项表示第i个原始面被移动到的面索引值。如果不需要该信息，可以将其设置为0。 ppVertexRemap — 指向ID3DXBuffer指针的地址（参见11.1节），它被用来填充顶点重影射信息。这个缓存应该包含ID3DXMesh::GetNumVertices()个顶点。当一个mesh被优化后，顶点可能被移动。顶点重影射信息用来说明原来的顶点被移动到新位置；也就是说，在ppVertexRemap中的第i项表示原来的第i个顶点的新位置。如果不需要该信息，可以将其设置为0。 例子：123456789101112131415161718192021222324// Get the adjacency info of the non-optimized mesh.DWORD adjacencyInfo[Mesh-&gt;GetNumFaces() * 3];Mesh-&gt;GenerateAdjacency(0.0f, adjacencyInfo);// Array to hold optimized adjacency info.DWORD optimizedAdjacencyInfo[Mesh-&gt;GetNumFaces() * 3];Mesh-&gt;OptimizeInplace( D3DXMESHOPT_ATTRSORT | D3DXMESHOPT_COMPACT | D3DXMESHOPT_VERTEXCACHE, adjacencyInfo, optimizedAdjacencyInfo, 0, 0); 一个更简单的方法是Optimize方法，它输出一个优化的mesh，而不是在原来mesh的基础上进行优化：HRESULT ID3DXMesh::Optimize( DWORD Flags, CONST DWORD* pAdjacencyIn, DWORD* pAdjacencyOut, DWORD* pFaceRemap, LPD3DXBUFFER* ppVertexRemap, LPD3DXMESH* ppOptMesh // the optimized mesh to be output); 10.5 属性表 当一个mesh被使用D3DXMESHOPT_ATTRSORT参数来优化后，mesh的几何信息将按照属性进行排序，这样各个子集的顶点/索引将组成连续的块（如图10.3）。 图10.3 除了进行几何信息的排序外，D3DXMESHOPT_ATTRSORT优化项还将创建一个属性表。该表是D3DXATTRIBUTERANGE结构的一个数组。在属性表中的每一项对应mesh的一个子集并指示顶点/索引缓存中的一个连续连续内存块，这个子集的几何信息就包含在这个块中。D3DXATTRIBUTERANGE结构的定义如下：1234567typedef struct _D3DXATTRIBUTERANGE &#123; DWORD AttribId; DWORD FaceStart; DWORD FaceCount; DWORD VertexStart; DWORD VertexCount;&#125; D3DXATTRIBUTERANGE; AttribId — 子集的ID。 FaceStart — 该子集的面的起始值，FaceStart*3就是起始三角形在索引缓存中的序号。 FaceCount — 在子集中的面（三角形）数。 VertexStart — 该子集的起始顶点在顶点缓存中的序号。 VertexCount — 在子集中的顶点数。 我们能够很容易的明白D3DXATTRIBUTERANGE结构的各个成员，如图10.3。在图10.3中mesh的属性表有三项——它们和各个子集一一对应。 建立了属性表以后，渲染一个子集就很容易了。仅仅查一下属性表就能找出自己的几何信息。注意如果没有属性表，每渲染一个子集就需要对属性缓存进行一次线性搜索来找出子集包含的几何信息。 可以使用下面的方法来访问mesh的属性表：HRESULT ID3DXMesh::GetAttributeTable( D3DXATTRIBUTERANGE pAttribTable, DWORD pAttribTableSize); 这个方法能够做两件事情：它可以返回属性表的属性数，也可以用属性数据来填充一个D3DXATTRIBUTERANGE结构数组。 要得到属性表的元素个数，可以就将第一个参数设置为0：DWORD numSubsets = 0;Mesh-&gt;GetAttributeTable(0, &amp;numSubsets); 一旦我们知道了属性表的元素个数，我们就能够通过写属性表来填充一个D3DXATTRIBUTERANGE结构数组：D3DXATTRIBUTERANGE table = new D3DXATTRIBUTERANGE [numSubsets];Mesh-&gt;GetAttributeTable( table, &amp;numSubsets ); 我们能够使用ID3DXMesh::SetAttributeTable方法来直接设置属性表。下面的代码就是设置一个有12个子集的属性表：D3DXATTRIBUTERANGE attributeTable[12];// …fill attributeTable array with dataMesh-&gt;SetAttributeTable( attributeTable, 12);10.6 邻接信息 对于mesh的某些操作，如优化，有必要了解的是三角形之间的邻接信息。Mesh的邻接数组存储了这些信息。 邻接数组是一个DWORD数组，其中的每一项对应了mesh中的一个三角形。例如，第i项对应的三角形由以下三个索引值定义：A = i ??3B = i ??3 + 1C = i ??3 + 2注意，使用ULONG_MAX = 4294967295表示该边没有邻接三角形。我们也可以用-1来表示，因为-1转换成DWORD就是ULONG_MAX。回想一下，DWORD就是一个unsigned32-bit整数。 因为每个三角形都有三条边，所以他就有三个邻接三角形（如图10.4）。 图10.4 因此，邻接数组必须有三项（ID3DXBaseMesh::GetNumFaces()3）—— 在mesh中每个三角形都可能有三个邻接三角形。 很多D3Dxmesh创造函数都能输出邻接信息，但我们也可以使用下面的方法：HRESULT ID3DXMesh::GenerateAdjacency( FLOAT fEpsilon, DWORD pAdjacency); fEpsilon — 指示当两个点距离有多近时，可以认为是一个点。当两点间的距离小于epsilon时，可认为它们是同一个点。 pAdjacency — 一个指向填充了邻接信息的DWORD数组指针。 例子：DWORD adjacencyInfo[Mesh-&gt;GetNumFaces() * 3];Mesh-&gt;GenerateAdjacency(0.001f, adjacencyInfo);10.7 复制 有时我们需要将一个mesh中的数据拷贝到另一个之中。我们可以使用ID3DXBaseMesh::CloneMeshFVF方法。 123456HRESULT ID3DXMesh::CloneMeshFVF( DWORD Options, DWORD FVF, LPDIRECT3DDEVICE9 pDevice, LPD3DXMESH* ppCloneMesh); Options — 用来创建mesh的一个或多个创建标志。要了解所有标志信息请查看sdk文档。现在列出一部分： D3DXMESH_32BIT — mesh使用32位索引。 D3DXMESH_MANAGED — mesh数据将被放在受控的内存中。 D3DXMESH_WRITEONLY — mesh数据只能执行写操作，不能执行读操作。 D3DXMESH_DYNAMIC — mesh缓存将是动态的。 FVF — 创建复制mesh的灵活顶点格式。 pDevice — 与复制mesh有关的设备。 ppCloneMesh — 输出复制的mesh。 注意这个方法允许指定与原mesh不同的options和FVF。例如我们有顶点格式为D3DFVF_XYZ的mesh，现在想复制一个顶点格式为D3DFVF_XYZ|D3DFVF_NORMAL的mesh。我们可以这样写：// 假设_mesh和device是有效的1234567ID3DXMesh* clone = 0;Mesh-&gt;CloneMeshFVF( Mesh-&gt;GetOptions(), // 使用与源模型同样的选项 D3DFVF_XYZ | D3DFVF_NORMAL,// 指定克隆的FVF Device, &amp;clone); 10.8 创建一个Mesh（D3DXCreateMeshFVF） 我们可以使用D3DXCreate*函数来创建mesh物体。然而，我们也可以使用 D3DXCreateMeshFVF函数来创建一个空mesh。所谓空mesh是指我们已经指定了顶点数和面数，函数D3DXCreateMeshFVF也分配了适当大小的内存给顶点、顶点索引、属性缓冲区。有了这些缓冲区后，就可以手动填写上下文数据了（需要分别向顶点缓存，索引缓存、属性缓存提供顶点、索引、属性数据）。 我们使用D3DXCreateMeshFVF函数来创建空mesh：12345678HRESULT D3DXCreateMeshFVF( DWORD NumFaces, DWORD NumVertices, DWORD Options, DWORD FVF, LPDIRECT3DDEVICE9 pDevice, LPD3DXMESH* ppMesh); NumFaces — mesh将拥有的面数。该值必须大于0。 NumVertices — mesh将拥有的顶点数。该值必须大于0。 Options —用来创建mesh的一个或多个创建标志。要了解所有标志信息请查看sdk文档。现在列出一部分： D3DXMESH_32BIT — mesh使用32位索引。 D3DXMESH_MANAGED — mesh数据将被放在受控的内存中。 D3DXMESH_WRITEONLY — mesh数据只能执行写操作，不能执行读操作。 D3DXMESH_DYNAMIC — mesh缓存将是动态的。 FVF — mesh的顶点格式。 pDevice — 与mesh相关的设备。 ppMesh — 输出创建好的mesh。 下一节将给出实例程序，它演示了用这个函数怎样创建一个mesh以及手动填充mesh的数据内容。 另外，你也可以使用D3DXCreateMesh来创建空mesh。它的原型是：12345678HRESULT D3DXCreateMesh( DWORD NumFaces, DWORD NumVertices, DWORD Options, CONST LPD3DVERTEXELEMENT9* pDeclaration, LPDIRECT3DDEVICE9 pDevice, LPD3DXMESH* ppMesh); 这些参数和D3DXCreateMeshFVF的参数是非常相似的，除了第四个。作为替代指定的FVF，我们指定一个D3DVERTEXELEMENT9结构，它描述了顶点格式。1234HRESULT D3DXDeclaratorFromFVF( DWORD FVF, // input format D3DVERTEXELEMENT9 Declaration[MAX_FVF_DECL_SIZE]//output format); 注意：D3DVERTEXELEMENT9将在第17章中讨论。 这个函数通过输入一个FVF返回一个D3DVERTEXELEMENT9结构的数组。注意MAX_FVF_DECL_SIZE的定义如下：typedef enum { MAX_FVF_DECL_SIZE = 18} MAX_FVF_DECL_SIZE;10.9 实例程序：创建和渲染Mesh这一章的实例程序是渲染一个立方体（如图10.5） 图10.5它演示了这一章中的大部分功能，包括如下一些操作： 创建一个空mesh。 用一个立方体几何信息来填充mesh。 根据mesh的每个面指定子集。 产生mesh的邻接信息。 优化mesh。 绘制mesh。 注意，我们忽略一些无关的代码来讨论本例。你能在叫做D3DXCreateMeshFVF的例子中找到全部的代码。 另外，为了更容易调试和研究mesh的构成，我们执行如下的函数来将内在内容放进文件中：12345void dumpVertices(std::ofstream&amp; outFile, ID3DXMesh* mesh);void dumpIndices(std::ofstream&amp; outFile, ID3DXMesh* mesh);void dumpAttributeBuffer(std::ofstream&amp; outFile, ID3DXMesh* mesh);void dumpAdjacencyBuffer(std::ofstream&amp; outFile, ID3DXMesh* mesh);void dumpAttributeTable(std::ofstream&amp; outFile, ID3DXMesh* mesh); 这些函数的名字就显示了它们的功能。执行这些函数是非常简单的，我们在这里讨论时忽略它们（可以看程序的原代码）。在这一节我们只展示一个dumpAttributeTable函数。 我们首先来浏览一下该例子，看看如下的一些全局变量：1234ID3DXMesh* Mesh = 0;const DWORD NumSubsets = 3;IDirect3DTexture9* Textures[3] = &#123;0, 0, 0&#125;;// texture for each subsetstd::ofstream OutFile; // used to dump mesh data to file 这里我们定义了一个mesh对象的指针，我们以后要创建的。我们也定义了mesh拥有的子集数——三。在这个例子中，每个子集都用一个不同的纹理来渲染；纹理数组包含每个子集的纹理，如第i个纹理对应mesh的第i个子集。最后，Outfile变量被用来把mesh的内容输出为一个文本文件。 这个例子的大部分工作是在setup函数中进行。我们首先创建一个空的mesh：12345678910bool Setup()&#123; HRESULT hr = 0; hr = D3DXCreateMeshFVF( 12, 24, D3DXMESH_MANAGED, Vertex::FVF, Device, &amp;Mesh); 这里我们分配一个有12个面和24个顶点的mesh，这是描述一个盒子所必须的。 这样的话，mesh是空的，因此我们需要将组成盒子的顶点和索引分别写入顶点缓存和索引缓存。锁定顶点/索引缓存并手动写入数据这是很容易的：123456789101112131415161718192021// Fill in vertices of a boxVertex* v = 0;Mesh-&gt;LockVertexBuffer(0, (void**)&amp;v);// fill in the front face vertex datav[0] = Vertex(-1.0f, -1.0f, -1.0f, 0.0f, 0.0f, -1.0f, 0.0f, 0.0f);v[1] = Vertex(-1.0f, 1.0f, -1.0f, 0.0f, 0.0f, -1.0f, 0.0f, 1.0f);v[22] = Vertex( 1.0f, 1.0f, 1.0f, 1.0f, 0.0f, 0.0f, 1.0f, 1.0f);v[23] = Vertex( 1.0f, -1.0f, 1.0f, 1.0f, 0.0f, 0.0f, 1.0f, 0.0f);Mesh-&gt;UnlockVertexBuffer();// Define the triangles of the boxWORD* i = 0;Mesh-&gt;LockIndexBuffer(0, (void**)&amp;i);// fill in the front face index datai[0] = 0; i[1] = 1; i[2] = 2;i[3] = 0; i[4] = 2; i[5] = 3;// fill in the right face index datai[30] = 20; i[31] = 21; i[32] = 22;i[33] = 20; i[34] = 22; i[35] = 23;Mesh-&gt;UnlockIndexBuffer(); 一旦mesh的几何信息被写入，我们必须指定每个三角形在哪个子集中。回想一下属性缓存就是存储的在mesh中每个三角形所属的子集信息。在这个例子中，我们指定索引缓存中的前四个三角形子集为0，接着的四个三角形子集为1，最后四个三角形子集为2。代码如下：DWORD attributeBuffer = 0;Mesh-&gt;LockAttributeBuffer(0, &amp;attributeBuffer);for(int a = 0; a &lt; 4; a++) // triangles 1-4 attributeBuffer[a] = 0; // subset 0for(int b = 4; b &lt; 8; b++) // triangles 5-8 attributeBuffer[b] = 1; // subset 1for(int c = 8; c &lt; 12; c++) // triangles 9-12 attributeBuffer[c] = 2; // subset 2Mesh-&gt;UnlockAttributeBuffer(); 现在我们已经创建了一个包含有效数据的mesh。在这一小部分我们将渲染mesh，不过首先还是先将其优化一下。注意虽然这对于一个盒子mesh来说，优化mesh数据没有真正的效果，但是我们还是用ID3DXMesh接口方法来实践一下。为了优化一个mesh，我们首先需要计算mesh的邻接信息：std::vector adjacencyBuffer(Mesh-&gt;GetNumFaces() 3);Mesh-&gt;GenerateAdjacency(0.0f, &amp;adjacencyBuffer[0]); 然后我们就能够优化mesh了：hr = Mesh-&gt;OptimizeInplace( D3DXMESHOPT_ATTRSORT | D3DXMESHOPT_COMPACT | D3DXMESHOPT_VERTEXCACHE, &amp;adjacencyBuffer[0], 0, 0, 0); 设置好了mesh以后，我们就为渲染它做好了准备。不过在setup函数中还有最后一个问题，也就是在前面我们说的将mesh的内在数据内容写入文件的函数。这能够检查mesh的数据，它能帮助我们调试和学习mesh的结构。OutFile.open(“Mesh Dump.txt”);dumpVertices(OutFile, Mesh);dumpIndices(OutFile, Mesh);dumpAttributeTable(OutFile, Mesh);dumpAttributeBuffer(OutFile, Mesh);dumpAdjacencyBuffer(OutFile, Mesh);OutFile.close();…Texturing loading, setting render states, etc., snippedreturn true;} // end Setup() 例如，dumpAttributeTable函数将属性表的数据写入文件。它的具体实现如下：12345678910111213141516171819202122void dumpAttributeTable(std::ofstream&amp; outFile, ID3DXMesh* mesh)&#123; outFile &lt;&lt; "Attribute Table:" &lt;&lt; std::endl; outFile &lt;&lt; "----------------" &lt;&lt; std::endl &lt;&lt; std::endl; // number of entries in the attribute table DWORD numEntries = 0; mesh-&gt;GetAttributeTable(0, &amp;numEntries); std::vector&lt;D3DXATTRIBUTERANGE&gt; table(numEntries); mesh-&gt;GetAttributeTable(&amp;table[0], &amp;numEntries); for(int i = 0; i &lt; numEntries; i++) &#123; outFile &lt;&lt; "Entry " &lt;&lt; i &lt;&lt; std::endl; outFile &lt;&lt; "------" &lt;&lt; std::endl; outFile &lt;&lt; "Subset ID: " &lt;&lt; table[i].AttribId &lt;&lt; std::endl; outFile &lt;&lt; "Face Start: " &lt;&lt; table[i].FaceStart &lt;&lt; std::endl; outFile &lt;&lt; "Face Count: " &lt;&lt; table[i].FaceCount &lt;&lt; std::endl; outFile &lt;&lt; "Vertex Start: " &lt;&lt; table[i].VertexStart &lt;&lt; std::endl; outFile &lt;&lt; "Vertex Count: " &lt;&lt; table[i].VertexCount &lt;&lt; std::endl; outFile &lt;&lt; std::endl; &#125; outFile &lt;&lt; std::endl &lt;&lt; std::endl;&#125; 下面的文本文件来自于通过dumpAttributeTable函数得到的mesh Dump.txt文件。1234567891011121314151617181920212223Attribute Table:----------------Entry 0------------Subset ID: 0Face Start: 0Face Count: 4Vertex Start: 0Vertex Count: 8Entry 1------------Subset ID: 1Face Start: 4Face Count: 4Vertex Start: 8Vertex Count: 8Entry 2------------Subset ID: 2Face Start: 8Face Count: 4Vertex Start: 16Vertex Count: 8 我们能够了解到我们为mesh所指定的相匹配的数据——有三个子集且每个子集有4个三角形。建议你去看看本例子Dump.txt的完整信息。该文件在本示例文件目录下。最后，我们使用下面的代码就能够非常容易地渲染mesh了；我们只需要循环每个子集，设置相关联的纹理然后在绘制子集即可。这是非常容易的，因为我们已经为每个子集指定的下标如0，1，2，…，n-1，这里的n就是子集的个数。1234567891011121314151617bool Display(float timeDelta)&#123; if( Device ) &#123; //...update frame code snipped Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER,0x00000000, 1.0f, 0); Device-&gt;BeginScene(); for(int i = 0; i &lt; NumSubsets; i++) &#123; Device-&gt;SetTexture( 0, Textures[i] ); Mesh-&gt;DrawSubset( i ); &#125; Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); &#125; return true;&#125;]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第九章 字体(Fonts)]]></title>
    <url>%2F2019%2F04%2F11%2FFonts%2F</url>
    <content type="text"><![CDATA[ID3DXFont在D3DX库中提供了一个ID3DXFont接口，它能被用于在Direct3D应用程序中绘制文字。这个接口是使用GDI来绘制文字的，因此我们能够使用这个接口来执行这个操作。无论如何，因为ID3DXFont使用的是GUI，所以它能够联合字体句柄和格式化字体。 创建一个ID3DXFont 我们能够使用D3DXCreateFontIndirect函数来创建一个ID3DXFont接口。HRESULT D3DXCreateFontIndirect( LPDIRECT3DDEVICE9 pDevice, // device to be associated with the font CONST LOGFONT pLogFont, // LOGFONT structure describing the font LPD3DXFONT ppFont // return the created font); 下面的代码片段显示了怎样使用这个函数：1234567891011121314151617181920212223LOGFONT lf;ZeroMemory(&amp;lf, sizeof(LOGFONT));lf.lfHeight = 25; // in logical unitslf.lfWidth = 12; // in logical unitslf.lfWeight = 500; // boldness, range 0(light) - 1000(bold)lf.lfItalic = false;lf.lfUnderline = false;lf.lfStrikeOut = false;lf.lfCharSet = DEFAULT_CHARSET;strcpy(lf.lfFaceName, "Times New Roman"); // font styleID3DXFont* font = 0;D3DXCreateFontIndirect(Device, &amp;lf, &amp;font); 我们必须填充一个LOGFONT结构来描述想创建的字体类型。 注意：你也能够使用D3DXCreateFont函数来获得一个ID3DXFont接口指针。9.1.2绘制文本 一旦我们获得了ID3DXFont接口指针，绘制文本就是很简单的事情了，我们只要调用ID3DXFont::DrawText方法就可以实现了。INT ID3DXFont::DrawText( LPCSTR pString, INT Count, LPRECT pRect, DWORD Format, D3DCOLOR Color); pString — 指向要绘制的文字。 Count — 字符串中特征字符的数量。假如字符是以null结束的字符串则可将其指定为-1。 pRect — 指向一个RECT结构，它定义一个文字被绘制在屏幕上的范围。 Format — 可选参数，指定文字怎样被格式化；要获得更详细的信息请查看SDK文档。 Color — 文字的颜色。 例子：1234567Font-&gt;DrawText( "Hello World", // String to draw. -1, // Null terminating string. &amp;rect, // Rectangle to draw the string in. DT_TOP | DT_LEFT, // Draw in top-left corner of rect. 0xff000000 ); // Black. 9.1.3计算每秒的渲染帧数 这一章的ID3DXFont和Cfont例子是计算和显示每秒渲染的帧数（FPS）。这一部分说明怎样计算FPS。 首先，我们定义如下三个全局变量：123DWORD FrameCnt; // The number of frames that have occurred.float TimeElapsed; // The time that has elapsed so far.float FPS; // The frames rendered per second. 我们计算每一秒的FPS；它给我们一个很好的平均。另外，在同一秒中内只保存一个FPS，这给了我们足够时间来读取它，在它再一次改变之前。 因此每一帧我们增加FrameCnt并且把从上一帧到现在流逝的时间写进TimeElapsed：FrameCnt++;TimeElapsed += timeDelta;这里timeDelta是两帧之间的时间。 在一秒种结束以后，我们能够用下面的公式来计算FPS：FPS = (float)FrameCnt / TimeElapsed;我们从新设置FrameCnt和TimeElapsed为计算下一秒的FPS做准备。下面就是合在一起的代码：void CalcFPS(float timeDelta){ FrameCnt++; TimeElapsed += timeDelta; if(TimeElapsed &gt;= 1.0f) { FPS = (float)FrameCnt / TimeElapsed; TimeElapsed = 0.0f; FrameCnt = 0; }}9.2 CD3DFont DirectX SDK给我们提供了一些很有用的代码，它们在你的DXSDK目录下的\Samples\C++\Commond下。CD3DFont类代码是使用纹理三角形和Direct3D。因为CD3DFont使用Direct3D代替GDI来渲染， 这比ID3DXFont快的多。然而，CD3DFont不能够联合字体句柄和格式化ID3DXFont。假如你追求速度和只需要一些简单的字体，CD3DFont类就能满足你的要求了。 使用CD3DFont类，你需要添加下列文件到你的程序中：d3dfont.h, d3dfont.cpp, d3dutil.h, d3dutil.cpp, dxutil.h和dxutil.cpp。这些文件可以在刚才所说目录下的Include和Src目录下。9.2.1创建一个CD3DFont 为了创建一个CD3DFont实例，我们只需要简单地象一般的C++对象那样实例化就可以了；下面是它的构造原型：CD3DFont(const TCHAR* strFontName, DWORD dwHeight, DWORD dwFlags=0L); strFontName — 以null结束的字符串，它指定字体类型。 dwHeight — 字体的高度。 dwFlags — 可选参数；你能设置该参数为0或者用下面参数；D3DFONT_BOLD, D3DFONT_ITALIC, D3DFONT_ZENABLE。 实例化一个CD3DFont对象以后，我们必须调用下面的方法来初始化字体：Font = new CD3DFont(“Times New Roman”, 16, 0); // instantiateFont-&gt;InitDeviceObjects( Device );Font-&gt;RestoreDeviceObjects();9.2.2绘制文本 现在我们已经创建和初始化了一个CD3DFont对象，这已经为绘制文字做好了准备。绘制文字是使用下面的方法：HRESULT CD3DFont::DrawText(FLOAT x, FLOAT y, DWORD dwColor, const TCHAR* strText, DWORD dwFlags=0L); x — 文字在屏幕上开始绘制的x坐标。 y —文字在屏幕上开始绘制的y坐标。 dwColor — 文字的颜色。 strText — 要绘制的文字。 dwFlags — 可选参数；你能设置该参数为0或者用下面参数；D3DFONT_CENTERED, D3DFONT_TWOSIDED, D3DFONT_FILTERED。 例子： Font-&gt;DrawText(20, 20, 0xff000000, “Hello, World”);9.2.3 清除 在删除一个CD3DFont对象之前，我们必须首先调用一些清除程序，就象下面列举的代码片段：Font-&gt;InvalidateDeviceObjects();Font-&gt;DeleteDeviceObjects();delete Font;9.3 D3DXCreateText 最后的函数是被用来创建一个3D 文字网格。图9.1显示了本章FontMes3D实例渲染的3D文字网格。 图9.1 该函数的原型是：12345678910HRESULT D3DXCreateText( LPDIRECT3DDEVICE9 pDevice, HDC hDC, LPCTSTR pText, FLOAT Deviation, FLOAT Extrusion, LPD3DXMESH* ppMesh, LPD3DXBUFFER* ppAdjacency, LPGLYPHMETRICSFLOAT pGlyphMetrics); 这个函数如果调用成功则返回D3D_OK。 pDevice — 和mesh关联的device。 hDC — 我们将要用来产生mesh的包含描述字体的设备环境句柄。 pText — 指向以null结束的字符串的指针，此字符串是用来指定创建什么文字mesh。 Deviation — 字型轮廓段数间距。该值必须大于等于0。当它为0时，段数等于字体原始设计单位（该值越接近0，那么字体就越光滑）。 Extrusion — 文字在z轴方向的深度。 ppMesh — 返回创建的mesh。 ppAdjacency — 返回创建mesh的相关信息。假如你不需要它可以将其指定为null。 pGlyphMetrics — 一个指向LPGLYPHMETRICSFLOAT结构数组的指针，它包含了字型米数据。假如你不关心此数据，你可以把它设置为0。 下面的示例代码展示的是使用这个函数来创建一个文字3D 网格模型。123456789101112131415161718192021222324252627282930// Obtain a handle to a device context.HDC hdc = CreateCompatibleDC( 0 );// Fill out a LOGFONT structure that describes the font’s properties.LOGFONT lf;ZeroMemory(&amp;lf, sizeof(LOGFONT));lf.lfHeight = 25; // in logical unitslf.lfWidth = 12; // in logical unitslf.lfWeight = 500; // boldness, range 0(light) - 1000(bold)lf.lfItalic = false;lf.lfUnderline = false;lf.lfStrikeOut = false;lf.lfCharSet = DEFAULT_CHARSET;strcpy(lf.lfFaceName, "Times New Roman"); // font style// Create a font and select that font with the device context.HFONT hFont;HFONT hFontOld;hFont = CreateFontIndirect(&amp;lf);hFontOld = (HFONT)SelectObject(hdc, hFont);// Create the 3D mesh of text.ID3DXMesh* Text = 0;D3DXCreateText(_device, hdc, "Direct3D", 0.001f, 0.4f, &amp;Text, 0, 0);// Reselect the old font, and free resources.SelectObject(hdc, hFontOld);DeleteObject( hFont );DeleteDC( hdc ); 现在你便能简单地调用mesh的DrawSubset方法来渲染一个3D文字：1Text-&gt;DrawSubset(0);]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[模版(Stenciling)]]></title>
    <url>%2F2019%2F04%2F11%2FStenciling%2F</url>
    <content type="text"><![CDATA[模版缓存是一个远离屏幕的缓存，我们能够用它来完成一些特效。模版缓存与后缓存和深度缓存有相同的定义，因此在模版缓存中的ijth像素与后缓存和深度缓存中的ijth像素是相协调的。就象名字所说，模版缓存就象一个模版它允许我们印刷渲染后缓存的某个部分。举例，当要实现一个镜子时，我们只需要简单地反射一个物体细节到镜子平面上；然而，我们仅仅想只绘制镜子里的反射结果。我们能用模版缓存来印制渲染它。图8.1清楚的显示了这一点。 图8.1模版缓存是Direct3D中的一小部分，它是通过一个简单的表面而被约束的。就象混合，这个简单的表面提供了可变的强大的设置能力。有效地学习使用模版缓存最好的方法是通过学习实际的应用程序。一旦你学懂了一点应用程序中的模版缓存，你将会得到一个更好的用于你自己需要特效的主意。正因为这个原因，这一章我们特别安排学习两个使用模版缓存的应用程序。目标 理解模版缓存是怎样工作的，怎样创建一个模版缓存以及怎样控制它。 学习怎样实现一个镜面效果，使用模版缓存来防止绘制反射到不在镜子表面上的物体。 利用模版缓存怎样渲染阴影和防止“双倍混合”。8.1使用模版缓存 为了使用模版缓存，我们在初始化Direct3D时必须首先请求一个，然后必须启用它。我们在8.1.1中讲述怎样请求一个模版缓存。为了启用模版缓存，我们必须设置D3DRS_STENCILENABLE渲染状态并且指定它为true（关闭它即可指定为false）。下面的代码是启用和关闭模版缓存的代码：Device-&gt;SetRenderState(D3DRS_STENCILENABLE, true);… // do stencil workDevice-&gt;SetRenderState(D3DRS_STENCILENABLE, false);我们可以使用IDirect3DDevice9::Clear方法来清除模版缓存并让其拥有默认值。回忆一下，同样的方法被用在清除后缓存和深度缓存中。Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER | D3DCLEAR_STENCIL, 0xff000000, 1.0f, 0 );注意我们已经添加了D3DCLEAR_STENCIL到第三个参数中，它表示我们想把模版缓存和目标（后缓存）以及深度缓存一起清除。有6种值可以用来指定清除后的模版缓存；在这个例子中我们将它清除为0。8.1.1请求一个模版缓存 在我们创建深度缓存的同时一个模版缓存能够被创建。当指定深度缓存格式的时候，我们同时指定模版缓存的格式。这样，模版缓存和深度缓存分享同一个离屏表面缓存，但是每个像素被指定到各自缓存内存片段中。下面列出了3种深度/模版缓存的格式： D3DFMT_D24S8—这种格式是说创建一个32位深度/模版缓存，其中24位为深度缓存，8位为模版缓存。 D3DFMT_D24X4S4—这种格式是说创建一个32位深度/模版缓存，其中24位为深度缓存，4位为模版缓存，还有4位留着不用。 D3DFMT_D15S1—这种格式是说创建一个16位深度/模版缓存，其中15位为深度缓存，1位为模版缓存。注意，还有一些格式没有分配任何位给模版缓存。例如，D3DFMT_D32格式是说只创建一个32位深度缓存。 同样，不同硬件对模版缓存的支持也是不同的。例如有些显卡就不支持8位模版缓存。8.1.2模版测试 如前所述，我们能够使用模版缓存来阻止渲染后缓存中的某些部分。阻止特殊像素被写是通过模版测试（stencil test）来决定的，这是通过下面的表达式来完成的：(ref &amp; mask) ComparisonOperation (value &amp; mask)模版测试是对每个像素进行的，假设模版是被允许。将有两个操作： 左手边操作数（LHS=ref&amp;mask） 右手边操作数（RHS=value&amp;mask）模版测试比较LHS和RHS，通过比较运算来指定。全部的运算都得到一个布尔值（true/false）。假如测试的结果是true，那么我们把像素写入后缓存。假如测试的结果是false,我们就阻止像素被写入后缓存。当然，如果像素不能被写入后缓存，那么它也不能被写入深度缓存。控制模版测试Direct3D允许我们控制变量用于模版测试。换句话说，我们可以指定参考值（stencil reference）和掩码(mask value)，以便进行比较运算。虽然我们不能明确地设定模版值（stencil value）,但是我们能够控制写入模版缓存的值。模版参考值（Reference Value）模版参考值ref的默认值为0，但是我们能够通过设置D3DRS_STENCILREF渲染状态来改变它。例如，下面的代码就是设置模版参考值为1：1Device-&gt;SetRenderState(D3DRS_STENCILREF, 0x1); 注意我们往往使用16进制，因为这让它看起来比整数更容易象一个位队列，并且当我们做位操作时这样看起来更有用，比如相加。 模版掩码模版掩码值mask是被用来掩饰（隐藏）在ref和value变量中的位。它的默认值是0xffffffff，也就是没有掩饰任何位。我们能够通过设置D3DRS_STENCILMASK渲染状态来改变它。下面的例子就是掩饰高16位：1Device-&gt;SetRenderState(D3DRS_STENCILMASK, 0x0000ffff); 模版值（Stencil Value）作为以前的规定，在模版缓存中我们进行模版测试的当前像素。例如，假如我们对ijth像素进行模版测试，那么该值将被写入ijth模版缓存。我们不能明确地设置个别模版值，但是可以清除模版缓存。我们能够使用模版渲染状态来控制将什么写入模版缓存。 比较运算我们能够通过设置D3DRS_STENCILFUNC渲染状态来设置比较运算。这个比较运算能够被D3DCMPFUNC的任何成员类型列举：1234567891011typedef enum _D3DCMPFUNC &#123; D3DCMP_NEVER = 1, // 模版测试永不成功 D3DCMP_LESS = 2, // 假如LHS &lt; RHS，那么模版测试成功 D3DCMP_EQUAL = 3, // 假如LHS = RHS，那么模版测试成功 D3DCMP_LESSEQUAL = 4, // 假如LHS &lt;= RHS，那么模版测试成功 D3DCMP_GREATER = 5, // 假如LHS &gt; RHS，那么模版测试成功 D3DCMP_NOTEQUAL = 6, // 假如LHS &lt;&gt; RHS，那么模版测试成功 D3DCMP_GREATEREQUAL = 7, D3DCMP_ALWAYS = 8, D3DCMP_FORCE_DWORD = 0x7fffffff&#125; D3DCMPFUNC; D3DCMP_GREATEREQUAL——假如LHS &gt;= RHS，那么模版测试成功。 D3DCMP_ALWAYS——模版测试总是成功。更新模版缓存除了决定是否写或阻止一个特殊像素被写入后缓存以外，我们能够定义模版缓存基于三种可能的案例怎样被更新： 对于ijth像素模版测试失败。我们能够定义怎样更新在模版缓存中的ijth，通过设置D3DRS_STENCILFAIL渲染状态来适应这种情形：Device-&gt;SetRenderState(D3DRS_STENCILFAIL, StencilOperation); 对于ijth像素深度测试失败。我们能够定义怎样更新在模版缓存中的ijth，通过设置D3DRS_STENCILZFAIL渲染状态来适应这种情形：Device-&gt;SetRenderState(D3DRS_STENCILZFAIL, StencilOperation); 对于ijth像素模版测试和深度测试都成功。我们能够定义怎样更新在模版缓存中的ijth，通过设置D3DRS_STENCILPASS渲染状态来适应这种情形：Device-&gt;SetRenderState(D3DRS_STENCILPASS, StencilOperation);其中StencilOperation能够是下面预先定义的常数： D3DSTENCILOP_KEEP——指定不改变模版缓存。 D3DSTENCILOP_ZERO——指定设置模版缓存入口为0。 D3DSTENCILOP_REPLACE——指定用模版参考值（reference value）来替换模版缓存入口。 D3DSTENCILOP_INCRSAT——指定增加模版缓存入口。假如增加的值超过了允许的最大值，我们就设置它为最大值。 D3DSTENCILOP_DECRSAT——指定减少模版缓存入口。假如减少后的值小于了0，我们就设置它0。 D3DSTENCILOP_INVERT——指定按位取反模版缓存入口。 D3DSTENCILOP_INCR——指定增加模版缓存入口。假如增加的值超过了允许的最大值，我们就设置它为0。 D3DSTENCILOP_DECR——指定减少模版缓存入口。假如减少后的值小于了0，我们就设置它为允许的最大值。模版写掩码 除了已经提及的模版渲染状态之外，我们能够设置一个写掩码（write mask）它将掩饰我们写进模版缓存的任何值的位。我们能够通过D3DRS_STENCILWRITEMASK渲染状态来设置写掩码。它的默认值是0xffffffff。下面的例子是掩饰高16位：Device-&gt;SetRenderState(D3DRS_STENCILWRITEMASK, 0x0000ffff);8.2实例程序：镜子 在自然界中的很多表面象镜子一样允许我们通过它的反射来看物体。这一部分讲了我们怎样用3D应用程序来模拟镜子。注意为了简单我们只模拟平面镜。举点例子，一辆擦亮的小汽车能够反射；然而，小车的车身是光滑的，圆的，不是一个平面。我们渲染反射是这些，象光滑的大理石地板、挂在墙上的镜子。换句话说就是在一个平面的镜子。 实现镜子的程序需要我们解决两个问题。第一，我们必须学习沿着一个面怎样反射一个物体以便能够正确地绘制反射结果。第二，我们必须只能在一个镜子范围内显示反射结果。即，我们必须掩饰一个表面作为一个镜子，且只渲染那些在镜子里物体。图8.1就是说的这个内容。 第一个问题只需要用一些几何向量就可以简单解决。我们能够利用模版缓存解决第二个问题。下两小节分别介绍怎样解决这两个问题。第三小节把它们柔和在一起并且介绍一下本章的第一个应用程序实例代码——镜子。8.2.1反射数学 我们现在演示怎样计算点V=（Vx, Vy, Vz）被平面np+d=0反射的点V’=（V’x, V’y, V’z）。图8.2贯穿整个讨论。 图8.2 根据Part I中的“平面”部分，我们能够知道q=v-kn,这里k是有符号的从v到平面的距离。下面是v相对与平面（n，d）的反射推导： 我们用下面的矩阵来实现从v到v’的转换： 在D3DX库中用下面的函数来创建反射矩阵R。D3DXMATRIX D3DXMatrixReflect( D3DXMATRIX pOut, // The resulting reflection matrix. CONST D3DXPLANE pPlane // The plane to reflect about.);一旦我们说到反射变换的话题，就让我们看看其他3种特殊的反射变换。它们是关于三个坐标平面的反射—yz平面，xz平面，和xy平面—它们分别通过下面三个矩阵来表现： 通过yz平面反射一个点，我们只需要简单的将x分量取反就可以了。同样的，通过xz平面反射一个点，我们只需要简单的将y分量取反。通过xy平面反射一个点，我们只需要简单的将z分量取反。这种反射是非常容易理解的。8.2.2镜面实现流程当实现一个镜面，一个物体假如在一面镜子前那么它就会被反射。然而，我们不想测试空间假如一个物体在一面镜子前，要做它是非常复杂的。因此，为了简化事情，我们总是反射物体并且无限制地渲染它。但是这样就有一个象本章开头的图8.1一样的问题。即，物体反射被渲染到了没有镜子的表面。我们能够用模版缓存来解决这个问题，因为模版缓存允许我们阻止渲染在后缓存中的特定区域。因此，我们使用模版缓存来阻止渲染被反射的不在镜子里的茶壶。下面的步骤简要的说明了怎样实现：1、 正常渲染所有的场景——地板，墙，镜子和茶壶——不包含反射的茶壶。注意这一步没有修改模版缓存。2、 清除模版缓存为0。图8.3显示了后缓存和模版缓存。 图8.33、 渲染只有镜子部分的图元到模版缓存中。设置模版测试总是成功，并且假如测试成功就指定模版缓存入口为1。我们仅仅渲染镜子，在模版缓存中的所有像素都将为0，除了镜子部分为1以外。图8.4显示了更新以后的模版缓存。也就是说，我们在模版缓存中对镜子像素做了标记。 图8.44、 现在我们渲染被反射的茶壶到后缓存和模版缓存中。但是假如模版测试通过，我们就只渲染后缓存。假如在模版缓存中的值为1，那么我们设置模版测试通过。这样，茶壶就仅仅被渲染到模版缓存为1的地方了。因为只有镜子对应的模版缓存值为1，所以反射的茶壶就只能被渲染到镜子里。8.2.3代码和解释 这个例子的相关代码在RenderMirror函数中，它首先渲染镜子图元到模版缓存，然后渲染那些能被渲染到镜子里的反射茶壶。我们现在一行一行的分析RenderMirror函数的代码，并解释为什么要这么做。 假如你想使用8.2.2部分的步骤实现代码，注意我们从第3步开始，因为对模版缓存来说1和2步已经没有什么事做了。同样我们通过这个解释来讨论通过镜子渲染的信息。 注意我们将分成几个部分来讨论它。8.2.3.1第一部分 我们通过允许模版缓存和设置渲染状态来开始：12345678910void RenderMirror()&#123; Device-&gt;SetRenderState(D3DRS_STENCILENABLE, true); Device-&gt;SetRenderState(D3DRS_STENCILFUNC, D3DCMP_ALWAYS); Device-&gt;SetRenderState(D3DRS_STENCILREF, 0x1); Device-&gt;SetRenderState(D3DRS_STENCILMASK, 0xffffffff); Device-&gt;SetRenderState(D3DRS_STENCILWRITEMASK,0xffffffff); Device-&gt;SetRenderState(D3DRS_STENCILZFAIL, D3DSTENCILOP_KEEP); Device-&gt;SetRenderState(D3DRS_STENCILFAIL, D3DSTENCILOP_KEEP); Device-&gt;SetRenderState(D3DRS_STENCILPASS, D3DSTENCILOP_REPLACE); 这是非常容易理解的。我们设置模版比较运算为D3DCMP_ALWAYS,这就是说让所有模版测试都通过。 假如深度测试失败了，我们指定D3DSTENCILOP_KEEP，它表明不更新模版缓存入口。即，我们保存当前值。这样做的原因是假如深度测试失败了，那么就意味着像素被“模糊”了。我们不想渲染被“模糊”的反射像素。 同样假如模版测试失败了，我们也指定D3DSTENCILOP_KEEP。但是在这里这样做不是必须的，因为我们指定的是D3DCMP_ALWAYS，当然这样的测试也就永远不会失败。然而，我们只改变比较运算的一位，那么设置模版失败渲染状态是必须的。我们现在就这样做。 假如深度测试和模版测试都通过了，我们就指定D3DSTENCILOP_REPLACE，更新模版缓存入口，设置模版参考值为0x1。8.2.3.2第二部分 这下一步阻止渲染镜子代码，除了模版缓存。我们通过设置D3DRS_ZWRITEENABLE并指定为false来阻止写深度缓存。我们能够防止更新后缓存，混合和设置源混合要素为D3DBLEND_ZERO目的混合要素为D3DBLEND_ONE。将这些混合要素代入混合等式，我们得到后缓存是不会改变的：12345678910111213141516// disable writes to the depth and back buffersDevice-&gt;SetRenderState(D3DRS_ZWRITEENABLE, false);Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, true);Device-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_ZERO);Device-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_ONE);// draw the mirror to the stencil bufferDevice-&gt;SetStreamSource(0, VB, 0, sizeof(Vertex));Device-&gt;SetFVF(Vertex::FVF);Device-&gt;SetMaterial(&amp;MirrorMtrl);Device-&gt;SetTexture(0, MirrorTex);D3DXMATRIX I;D3DXMatrixIdentity(&amp;I);Device-&gt;SetTransform(D3DTS_WORLD, &amp;I);Device-&gt;DrawPrimitive(D3DPT_TRIANGLELIST, 18, 2);// re-enable depth writesDevice-&gt;SetRenderState(D3DRS_ZWRITEENABLE, true); 8.2.3.3第三部分 在模版缓存中，符合镜子可视像素的为0x1，因此对已经渲染的镜子区域做记号。我们现在准备渲染被反射的茶壶。回忆一下，我们仅仅想渲染镜子范围内的反射像素。我们现在可以很容易的做到了，因为在模版缓存中这些像素已经被做了记号。 我们设置下面的渲染状态： Device-&gt;SetRenderState(D3DRS_STENCILFUNC, D3DCMP_EQUAL); Device-&gt;SetRenderState(D3DRS_STENCILPASS, D3DSTENCILOP_KEEP); 用一个新的比较运算设置，我们进行下面的模版测试： (ref &amp; mask == (value &amp; mask) (0x1 &amp; 0xffffffff) == (value &amp; 0xffffffff) (0x1)== (value &amp; 0xffffffff) 这说明了只有当value=0x1时模版测试才成功。因为在模版缓存中只有镜子相应位置的值才是0x1，若我们渲染这些地方那么测试将会成功。因此，被反射的茶壶只会在镜子里绘制而不会在镜子以外的表面上绘制。 注意我们已经将渲染状态由D3DRS_STENCILPASS变为了D3DSTENCILOP_KEEP，简单的说就是假如测试通过那么就保存模版缓存的值。因此，在下一步的渲染中，我们不改变模版缓存的值。我们仅仅使用模版缓存来对镜子相应位置的像素做标记。8.2.3.4第四部分 RenderMirror函数的下一部分就是计算在场景中反射位置的矩阵： // position reflection D3DXMATRIX W, T, R; D3DXPLANE plane(0.0f, 0.0f, 1.0f, 0.0f); // xy plane D3DXMatrixReflect(&amp;R, &amp;plane); D3DXMatrixTranslation(&amp;T, TeapotPosition.x, TeapotPosition.y, TeapotPosition.z); W = T * R; 注意我们首先确定没有反射的茶壶位置，然后就通过xy平面来反射。这种变换规则是通过矩阵相乘来指定的。8.2.3.5第五部分 我们已经为渲染反射茶壶做好了准备。然而，假如我们现在就渲染它，它是不会被显示的。为什么呢？因为被反射的茶壶的深度比镜子的深度大，因此镜子的图元将把被反射茶壶的图元弄模糊。为了避免这种情况，我们清除深度缓存： Device-&gt;Clear(0, 0, D3DCLEAR_ZBUFFER, 0, 1.0f, 0); 并不是所有问题都解决了。假如我们简单的清除深度缓存，被反射的茶壶会被绘制到镜子的前面，物体看起来就不对了。我们想做的是清除深度缓存并且要混合被反射的茶壶和镜子。这样，被反射的茶壶看起来就象在镜子里了。我们能够通过下面的混合等式来混合被反射的茶壶和镜子： 因为原像素（sourcePixel）来自被反射的茶壶，目的像素（DestPixel）来自镜子，我们能够通过这个等式明白它们是怎么被混合到一起的。我们有如下的代码： Device-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_DESTCOLOR); Device-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_ZERO); 最后，我们准备绘制被反射的茶壶： Device-&gt;SetTransform(D3DTS_WORLD, &amp;W); Device-&gt;SetMaterial(&amp;TeapotMtrl); Device-&gt;SetTexture(0, 0); Device-&gt;SetRenderState(D3DRS_CULLMODE, D3DCULL_CW); Teapot-&gt;DrawSubset(0); 回顾一下8.2.3.4部分的W，它能够正确的将被反射的茶壶变换到场景中恰当的位置。同样，我们也要改变背面拣选模式。必须这样做的原因是当一个物体被反射以后，它的正面和背面将会被交换。因此为了改变这种情况，我们必须改变背面拣选模式。 Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, false); Device-&gt;SetRenderState( D3DRS_STENCILENABLE, false); Device-&gt;SetRenderState(D3DRS_CULLMODE, D3DCULL_CCW);} // end RenderMirror()8.3实例程序：平面阴影在场景中被灯光照射的地方会产生阴影，这将使场景变的更真实。在这一部分我们将演示怎样实现平面阴影，即在平面上的阴影（如图8.5）。 图8.5注意这种阴影是“快砍”，虽然它们增强了场景效果，但是这并不是现实中的阴影。阴影值是一个高级的概念，要深入研究它已经超出了本书的范围。然而，特别值得提及的是在DirectX SDK中有一个示例程序演示了阴影值。 为了实现平面阴影，我们首先必须找到物体投射到平面上的阴影并进行几何建模以便我们能够渲染它。用一些3D数学就能很容易的实现它。我们然后用50%透明度的黑色材质来渲染描述阴影的多边形。渲染阴影时可能出现“双倍混合”，我们将用一小部分进行解释。我们使用模版缓存来防止双倍混合发生。8.3.1平行光阴影 图8.6图8.6显示了物体在平行光照射下得到的阴影。光线是从平行光源放射出的，它的方向是L,通过顶点p得到r（t） = p + tL。光线r（t）和平面n * p + d = 0 相交得到 s 。交点s 通过射线和平面相交测试是非常容易得到的：把r(t)带进平面等式求解t 那么： 8.3.2点光源阴影 图8.7图8.7显示了物体在点光源照射下得到的阴影。点光源的位置是L。光线通过顶点p，则得到 r(t) = p + t ( p – L )。光线r（t）和平面n p + d = 0 相交得到 s 。用8.3.1同样的方法我们可以得到s。注意：在点光源和平行光中的L是不同的。对于点光源，我们用L来表示点光源的位置。而对于平行光，我们则是用L来表示平行光的照射方向。8.3.3阴影矩阵 注意图8.6中所示的平行光，影子本质上是把物体按照灯光照射方向平行地投射到平面np+d=0之上。同样的，图8.7中所示的点光源，影子本质上是把物体按照透视画法从光源投射到平面np+d=0之上。 我们能够使用一个矩阵来表示从一个顶点p变换到平面np=d=0上的s的变化。而且，我们能够用同一个矩阵来表现正交投影和透视投影。 我们用一个4D向量（nx, ny, nz, d）来表示将要用于投射阴影平面的平面等式中的各个系数。让4D向量L=（Lx, Ly, Lz, Lw）来表示平行光的照射方向或点光源的位置。我们用w来区别：１． 假如w＝０，那么L表示平行光的照射方向。２． 假如w＝1 ，那么L表示点光源的位置。规格化的平面是非常不逊的，我们让k＝（nx, ny, nz, d）*（Lx, Ly, Lz, Lw）= nxLx+nyLy+nzLz+dLw那么我们就可得到表示点p到点s的变换矩阵，即阴影矩阵： 因为在其他地方已经被推导出来了，对于我们来说推导它并没有重大的意义，在这里我们就不再演示推导怎样得到这个矩阵的过程了。但是对与感兴趣的读者可以自己到网上查找相应的信息。 在D3DX库中已经给我们提供了一个建立阴影矩阵的函数。其中当w＝０时表示平行光，当w＝１时表示点光源：12345D3DXMATRIX *D3DXMatrixShadow( D3DXMATRIX *pOut, CONST D3DXVECTOR4 *pLight, // L CONST D3DXPLANE *pPlane // plane to cast shadow onto); 8.3.4用模版缓存防止双倍混合 几何学上，当我们将一个物体投影到一个平面上时，很可能会有两个或者更多的投影三角形被重叠到一起。若我们就这样渲染，那么有重叠三角形的地方就会被多次混合以至这些地方将会变得更黑。图8.8就是这种情况。 图8.8 我们能够使用模版缓存来解决这个问题。我们设置模版测试为允许像素第一次被渲染。即，当把影子像素渲染到后缓存时，我们同时在模版缓存中做好标记。然后，如果试图把像素向一个已经渲染过的地方写，那么模版测试将会失败。这样，我们就防止了重复写像素也就是防止了双倍混合的发生。8.3.5代码和解释 下面的代码就是讲解影子例子。本例的相关代码都在RenderShadow函数中。注意我们假设模版缓存都已经被清除为０了。 首先设置模版渲染状态。将模版比较运算设为D3DCMP_EQUAL且将D3DRS_STENCILREF渲染状态设置为0x0，因此假如在模版缓存中相应的值为0x0，那么就指定渲染阴影到后缓存中。 因为模版缓存是被清除为0x0的，所以我们第一次将影子像素写入的时候总是正确的；不过因为我们设置D3DRS_STENCILPASS为D3DSTENCILOP_INCR,假如你试图将已经写过的像素写入的话，这个测试将会失败。在第一次写入的时候模版像素已经被写成了0x1，因此假如你再一次写入，模版测试将会失败。因此，我们避免了重复写像素，也避免了双倍混合。123456789101112131415161718192021void RenderShadow()&#123; Device-&gt;SetRenderState(D3DRS_STENCILENABLE, true); Device-&gt;SetRenderState(D3DRS_STENCILFUNC, D3DCMP_EQUAL); Device-&gt;SetRenderState(D3DRS_STENCILREF, 0x0); Device-&gt;SetRenderState(D3DRS_STENCILMASK, 0xffffffff); Device-&gt;SetRenderState(D3DRS_STENCILWRITEMASK, 0xffffffff); Device-&gt;SetRenderState(D3DRS_STENCILZFAIL, D3DSTENCILOP_KEEP); Device-&gt;SetRenderState(D3DRS_STENCILFAIL, D3DSTENCILOP_KEEP); Device-&gt;SetRenderState(D3DRS_STENCILPASS, D3DSTENCILOP_INCR); 下一步，我们计算阴影变换并将它放置到场景中适当的位置。 // compute the transformation to flatten the teapot into a shadow. D3DXVECTOR4 lightDirection(0.707f, -0.707f, 0.707f, 0.0f); D3DXPLANE groundPlane(0.0f, -1.0f, 0.0f, 0.0f); D3DXMATRIX S; D3DXMatrixShadow(&amp;S, &amp;lightDirection, &amp;groundPlane); D3DXMATRIX T; D3DXMatrixTranslation(&amp;T, TeapotPosition.x, TeapotPosition.y, TeapotPosition.z); D3DXMATRIX W = T * S; Device-&gt;SetTransform(D3DTS_WORLD, &amp;W); 最后，我们设置一个50%透明度的黑色材质，关闭深度测试，渲染阴影，然后开启深度缓存同时关闭alpha混合和模版测试。我们关闭深度缓存来防止z-fighting，它是当两个不同的表面在深度缓存中有同样的深度值时出现的虚拟物体；深度缓存不知道那一个是在前面，此时就会产生讨厌的闪动。因为阴影和地板是在同一个平面上，z-fighting很可能就会出现。通过先渲染地板然后用深度测试屏蔽阴影，这样我们就能够保证阴影将绘制在地面只之上。 Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, true); Device-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_SRCALPHA); Device-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_INVSRCALPHA); D3DMATERIAL9 mtrl = d3d::InitMtrl(d3d::BLACK, d3d::BLACK, d3d::BLACK, d3d::BLACK, 0.0f); mtrl.Diffuse.a = 0.5f; // 50% transparency. // Disable depth buffer so that z-fighting doesn’t occur when we // render the shadow on top of the floor. Device-&gt;SetRenderState(D3DRS_ZENABLE, false); Device-&gt;SetMaterial(&amp;mtrl); Device-&gt;SetTexture(0, 0); Teapot-&gt;DrawSubset(0); Device-&gt;SetRenderState(D3DRS_ZENABLE, true); Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, false); Device-&gt;SetRenderState(D3DRS_STENCILENABLE, false);}//end RenderShadow()]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第七章 混合(Blending)]]></title>
    <url>%2F2019%2F04%2F11%2FBlending%2F</url>
    <content type="text"><![CDATA[混合因素 观察图7.1，我们将一个红色的茶壶绘制在一个木质背景上。 图7.1 假设想让茶壶有一个透明度，以便我们能够透过茶壶看见背景（如图7.2）。 图7.2 我们怎样才能实现这个效果呢？我们只需要在木箱子上光栅化茶壶三角形，我们需要结合像素颜色，就象通过茶壶显示木箱那样来计算茶壶的像素颜色。结合像素值的意思就是用以前写过的目标像素值去估算源像素值这被叫做混合。注意混合的效果不仅仅象是玻璃透明一样。我们有很多选项来指定颜色是怎样被混合的，就象7.2部分中看到的一样。 这是很重要的，认识三角形普遍利用以前写入后缓存中的像素来与之混合来光栅化。在示例图片中，木箱图片首先被画出来且它的像素在后缓存中。我们然后绘制茶壶，以便用木箱的像素来混合茶壶的像素。因此，当使用混合时，下面的规则将被遵循： 规则：首先不使用混合绘制物体。然后根据物体离摄象机的距离使用混合对物体拣选；这是非常有效的处理，假如物体是在视图坐标中，那么你能够利用z分量简单地拣选。最后使用从后到前的顺序混合绘制物体。 下面的公式是用来混合两个像素值的： 上面的所有变量都是一个4D颜色向量（r,g,b,a），并且符号是表示分量相乘。 OutputPixel——混合后的像素结果。 SourcePixel——通常被计算的像素，它是利用在后缓存中的像素来被混合的。 SourceBlendFactor——在[0，1]范围内的一个值。它指定源像素在混合中的百分比。 DestPixel——在后缓存中的像素。 DestBlendFactor——在[0，1]范围内的一个值。它指定目的像素在混合中的百分比。 源和目的混合要素使我们能够按照多种途径改变原始源和目的像素，允许实现不同的效果。7.2节列举了能够被使用的预先确定的值。 混合默认是被关闭的；你能够通过设置D3DRS_ALPHABLENDENABLE渲染状态为true来开启它：Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, true);7.2混合要素 通过设置不同的源和目的要素，我们能够创造很多不同的混合效果。通过实验，使用不同的组合看看它们到底能实现什么效果。你能够通过设置D3DRS_SRCBLEND和D3DRS_DESTBLEND渲染状态来分别设置源混合要素和目的混合要素。例如我们可以这样写：Device-&gt;SetRenderState(D3DRS_SRCBLEND, Source);Device-&gt;SetRenderState(D3DRS_DESTBLEND, Destination); 这里Source和Destination能够使用下面混合要素中的一个： D3DBLEND_ZERO——blendFactor=(0, 0, 0, 0) D3DBLEND_ONE——blendFactor=(1, 1, 1, 1) D3DBLEND_SRCCOLOR——blendFactor=(rs, gs, bs, as) D3DBLEND_INVSRCCOLOR——blendFactor=(1-rs, 1-gs, 1-bs, 1-as) D3DBLEND_SRCALPHA——blendFactor=(as, as, as, as) D3DBLEND_INVSRCALPHA——blendFactor=(1-as, 1-as, 1-as, 1-as) D3DBLEND_DESTALPHA——blendFactor=(ad, ad, ad, ad) D3DBLEND_INVDESTALPHA——blendFactor=(1-ad, 1-ad, 1-ad, 1-ad) D3DBLEND_DESTCOLOR——blendFactor=(rd, gd, bd, ad) D3DBLEND_INVDESTCOLOR——blendFactor=(1-rd, 1-gd, 1-bd, 1-ad) D3DBLEND_SRCALPHASAT——blendFactor=(f, f, f, 1) , f=min(as, 1 – ad) D3DBLEND_BOTHINVSRCALPHA——这种混合模式设置源混合要素为（1-as, 1-as, 1-as, 1-as,）以及目的混合要素为（as,as,as,as）。这种混合模式仅对D3DRS_SRCBLEND有效。 源和目的混合要素的默认值分别是D3DBLEND_SRCALPHA和D3DBLEND_INVSRCALPHA。7.3透明度 在以前的章节中我们忽略了颜色顶点和材质中的alpha部分，那是因为当时它并不是必须的。现在它首先被用在混合中。 Alpha部分主要是用来指定像素的透明等级。我们为每个像素的alpha部分保留8位，alpha的有效值在[0,255]范围内，[0,255]代表不透明度[0%,100%]。因此，像素的alpha为0时，表示完全透明，像素的alpha为128时，表示50%透明，像素的alpha为255时，表示完全不透明。 为了让alpha部分描述像素的透明等级，我们必须设置源混合要素为D3DBLEND_SRCALPHA以及目的混合要素为D3DBLEND_INVSRCALPHA。这些值碰巧也是被默认设置的。7.3.1Alpha通道 代替使用Alpha部分来计算遮影，我们能够从纹理的alpha通道中得到alpha信息。Alpha通道是额外的设置位，用它来保存每一个点的alpha值。当一个纹理被映射到一个图元上时，在alpha通道中的alpha信息也被映射，并且它们利用alpha信息为每个像素赋予纹理。图7.3显示了一个带8位alpha通道的图片。 图7.3 图7.4显示的是一个利用alpha通道指定透明度来渲染的一个纹理方块。 图7.47.3.2指定Alpha资源 默认情况下，假如设置一个有alpha通道的纹理，alpha值从在alpha通道中获得。假如没有alpha通道，那么alpha值是通过顶点颜色获得。然而，你能够通过下面的渲染状态来指定使用哪一个资源：// compute alpha from diffuse colors during shadingDevice-&gt;SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE);Device-&gt;SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1);// take alpha from alpha channelDevice-&gt;SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE);Device-&gt;SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1);7.4使用DirectX纹理工具创建Alpha通道 绝大多数普通图象文件格式没有存储alpha信息。在这一部分我们给你演示怎样使用DirectX纹理工具来创建一个带alpha通道的DDS文件。DDS文件是一个为DirectX应用程序和纹理设置的图象格式。DDS文件能够利用D3DXCreateTextureFromFile被读进纹理中，就象bmp和jpg文件一样。DirectX纹理工具被放在你的DXSDK目录下的\Bin\DXUtils文件夹下（我是放在C:\Program Files\Microsoft DirectX 9.0 SDK (February 2005)\Utilities\Bin\x86下的，文件名是DxTex.exe）。 打开DirectX纹理工具，并且把本章中示例文件夹下的crate.jpg文件用工具打开。木箱被自动的按照24位RGB纹理被读取。它包含8位红色，8位绿色，以及8位蓝色。我们需要将该纹理增加为32位ARGB纹理，增加的是额外的8位alpha通道。从菜单中选择Format，选择Change Surface Format。一个象图7.5的对话框将被弹出。选择A8R8G8B8格式点击OK。 图7.5 它创建了一个32位颜色深度的图象，它的每个象素都有8位alpha通道，8位红色，8位绿色，8位蓝色。我们下一步是向alpha通道中写入数据。我们将图7.3中的8位灰色图片信息写进alpha通道中。选择菜单中的File，选择Open Onto Alpha Channel Of This Texture。一个对话框将弹出让你选择包含你想要写入alpha通道中数据信息的图片。选择alphachannel.bmp文件。图7.6显示的是程序已经插入了alpha通道数据。 图7.6 现在用你选择的文件名存储纹理；我们使用cratewalpha.dds文件名。7.5实例程序：透明度 这个实例程序是在一个木箱背景上绘制一个透明的茶壶，就象图7.2所显示的一样。在这个例子中alpha值是从材质中得到。应用程序允许我们通过按A或S键来增加/减少alpha的值。 使用混合的必要步骤是： 设置混合要素D3DRS_SRCBLEND 和 D3DRS_DESTBLEND。 假如你使用alpha部分，指定资源（材质或alpha通道）。 允许alpha混合渲染状态。 对于这个例子，我们定义下面的全局变量：123456ID3DXMesh* Teapot = 0; // the teapotD3DMATERIAL9 TeapotMtrl; // the teapot’s materialIDirect3DVertexBuffer9* BkGndQuad = 0; // background quad - crateIDirect3DTexture9* BkGndTex = 0; // crate textureD3DMATERIAL9 BkGndMtrl; // background material Setup方法设置很多东西；我们省略了很多与本章无关的代码。关心混合，Setup方法指定alpha值的获取资源。在这个例子中，我们通过材质指定alpha值。注意我们设置茶壶的材质alpha部分为0.5，也就是说茶壶将按照50%的透明度被渲染。我们在这里也要设置混合要素。要注意的是在这个方法中我们不能将alpha混合设置为启用。理由是alpha混合要进行额外的处理并且应该仅在需要用时才被使用。举例，在这个例子中只有茶壶需要用允许alpha混合来被渲染——而方块不需要。因此，我们在Display函数中启用alpha混合。12345678910111213141516171819202122bool Setup()&#123; TeapotMtrl = d3d::RED_MTRL; TeapotMtrl.Diffuse.a = 0.5f; // set alpha to 50% opacity BkGndMtrl = d3d::WHITE_MTRL; D3DXCreateTeapot(Device, &amp;Teapot, 0); ...// Create background quad snipped ...// Light and texture setup snipped // use alpha in material's diffuse component for alpha Device-&gt;SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE); Device-&gt;SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1); // set blending factors so that alpha // component determines transparency Device-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_SRCALPHA); Device-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_INVSRCALPHA); ...// view/projection matrix setup snipped return true;&#125; 在Display函数中，我们检测假如A或S键被按下那么就通过增加或减少材质的alpha值来反馈。注意这个方法要保证alpha值不会超出[0,1]的范围。我们然后渲染背景。最后，我们启用alpha混合，利用alpha混合来渲染茶壶，关闭alpha混合。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647bool Display(float timeDelta)&#123; if( Device ) &#123; // // Update // // increase/decrease alpha via keyboard input if( ::GetAsyncKeyState('A') &amp; 0x8000f ) TeapotMtrl.Diffuse.a += 0.01f; if( ::GetAsyncKeyState('S') &amp; 0x8000f ) TeapotMtrl.Diffuse.a -= 0.01f; // force alpha to [0, 1] interval if(TeapotMtrl.Diffuse.a &gt; 1.0f) TeapotMtrl.Diffuse.a = 1.0f; if(TeapotMtrl.Diffuse.a &lt; 0.0f) TeapotMtrl.Diffuse.a = 0.0f; // // Render // Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); // Draw the background D3DXMATRIX W; D3DXMatrixIdentity(&amp;W); Device-&gt;SetTransform(D3DTS_WORLD, &amp;W); Device-&gt;SetFVF(Vertex::FVF); Device-&gt;SetStreamSource(0, BkGndQuad, 0, sizeof(Vertex)); Device-&gt;SetMaterial(&amp;BkGndMtrl); Device-&gt;SetTexture(0, BkGndTex); Device-&gt;DrawPrimitive(D3DPT_TRIANGLELIST, 0, 2); // Draw the teapot Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, true); D3DXMatrixScaling(&amp;W, 1.5f, 1.5f, 1.5f); Device-&gt;SetTransform(D3DTS_WORLD, &amp;W); Device-&gt;SetMaterial(&amp;TeapotMtrl); Device-&gt;SetTexture(0, 0); Teapot-&gt;DrawSubset(0); Device-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, false); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); &#125; return true;&#125; 注意：在本章中有另一个使用纹理通道来演示alpha混合的例子texAlpha。与上边的代码不同之处仅仅在于得到alpha值是从纹理而不是从材质。123// use alpha channel in texture for alphaDevice-&gt;SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE);Device-&gt;SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1); 这个应用程序读取的是一个在7.4节中用DX Tex Tool工具创建的带有alpha通道的DDS文件。]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第六章 纹理(Texturing)]]></title>
    <url>%2F2019%2F04%2F11%2FTexturing%2F</url>
    <content type="text"><![CDATA[Direct3D使用一个纹理坐标系统，它是由用水平方向的u轴和竖直方向v轴构成。由u,v坐标决定纹理上的元素，它被叫做texel。注意v轴是向下的（如图6.2）。 图6.2同样，注意规格化的坐标间隔，[0，1]，它被使用是因为它给Direct3D一个固定的范围用于在不同尺寸的纹理上工作。对每一个3D三角形，我们都希望在给它贴图的纹理上定义一个用相应的三角形。（如图6.3）。 图6.3 我们再一次修改原来的顶点结构，添加一个用于在纹理上定位的纹理坐标。struct Vertex{ float _x, _y, _z; float _nx, _ny, _nz; float _u, _v; // texture coordinates static const DWORD FVF;};const DWORD Vertex::FVF = D3DFVF_XYZ | D3DFVF_NORMAL | D3DFVF_TEX1; 我们在顶点格式中添加了一个D3DFVF_TEX1，它是说我们的顶点结构中包含了一个纹理坐标。 现在每个三角形都通过顶点的三个对象来建立，同时也通过纹理坐标定义了一个相应的纹理三角形。6.2创建并赋予材质 纹理数据通常是从存储在磁盘中的图片文件中读取的，且被读进IDirect3DTexture9对象中。我们能够使用下面的D3DX函数完成这项工作：HRESULT D3DXCreateTextureFromFile( LPDIRECT3DDEVICE9 pDevice, // device to create the texture LPCSTR pSrcFile, // filename of image to load LPDIRECT3DTEXTURE9 ppTexture // ptr to receive the created texture);这个函数能够读取下面图片格式中的任意一种：BMP,DDS,DIB,JPG,PNG,TGA。 例如，用一个名为stonewall.bmp的图片创建一个纹理，我们将按照下面的例子来写：IDirect3Dtexture9 _stonewall;D3DXCreateTextureFromFile(_device, “stonewall.bmp”, &amp;_stonewall); 设置当前纹理，我们使用下面的方法：HRESULT IDirect3DDevice9::SetTexture( DWORD Stage, // A value in the range 0-7 identifying the texture // stage – see note on Texture Stages IDirect3DBaseTexture9* pTexture // ptr to the texture to set); 例子：Device-&gt;SetTexture(0, _stonewall);注意：在Direct3D中，你能够设置八个纹理，它们能够组合起来创建更多细节的图象。这又被叫做多重纹理。在本书的第四部分以前我们不会使用多重纹理；因此现在我们总是设置stage为0。 为了销毁一个纹理，我们设置pTexture为0。例如，假如不想用一个纹理来渲染物体，那么我们就这样写：Device-&gt;SetTexture(0, 0);renderObjectWithoutTexture();假如场景中有使用不同纹理的三角形，我们就必须添加与下面类似的一些代码：Device-&gt;SetTexture(0, _tex0);drawTrisUsingTex0(); Device-&gt;SetTexture(0, _tex1);drawTrisUsingTex1();6.3过滤器 就象以前提及的，纹理被映射到屏幕中的三角形上。通常纹理三角形和屏幕三角形是不一样大的。当纹理三角形比屏幕三角形小时，纹理三角形会被适当放大。当纹理三角形比屏幕三角形大时，纹理三角形会被适当缩小。这两种情况，变形都将会出现。过滤（Filtering）是一种Direct3D用它来帮助这些变形变的平滑的技术。 Direct3D提供了三种不同的过滤器；每种都提供了一个不同的品质级别。越好的品质越慢，因此你必须在品质与速度之间取得一个平衡。纹理过滤器是用IDirect3DDevice9::SetSamplerState方法来设置的。 Nearest point sampling——这是默认的过滤方法且返回最差的效果，但是它的计算是最快的。下面的代码就是设置Nearest point sampling作为缩小放大的过滤器：Device-&gt;SetSamplerState(0, D3DSAMP_MAGFILTER, D3DTEXF_POINT);Device-&gt;SetSamplerState(0, D3DSAMP_MINFILTER, D3DTEXF_POINT); Linear filtering——这种过滤产生还算比较好的效果，在今天的硬件上处理它还是非常快的。它是被推荐使用的。下面的代码就是设置Linear filtering作为缩小放大的过滤器。Device-&gt;SetSamplerState(0, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR);Device-&gt;SetSamplerState(0, D3DSAMP_MINFILTER, D3DTEXF_LINEAR); Anisotropic filtering——这种过滤产生最好的效果，但是处理时间也是最长的。下面的代码就是设置Anisotropic filtering作为缩小放大的过滤器。Device-&gt;SetSamplerState(0, D3DSAMP_MAGFILTER, D3DTEXF_ANISOTROPIC);Device-&gt;SetSamplerState(0, D3DSAMP_MINFILTER, D3DTEXF_ANISOTROPIC);当使用Anisotropic filtering时，我们必须设置D3DSAMP_MAXANISOTROPY等级，它决定处理的质量。该值越高处理的效果越好。检查D3DCAPS9结构确认你的显卡是否支持此功能。下面的代码设置该值为4：Device-&gt;SetSamplerState(0, D3DSAMP_MAXANISOTROPY, 4);6.4 Mipmaps 就象6.3节所说的，在屏幕上的三角形和纹理三角形通常是不一样大的。为了使这个大小差异变小，我们为纹理创建mipmaps链。也就是说将一个纹理创建成连续的变小的纹理，但是对它们等级进行定制过滤，因此对我们来说保存细节是很重要的（如图6.4）。 图6.46.4.1 Mipmaps过滤器 mipmap过滤器是被用来控制Direct3D使用mipmaps的。设置mipmap过滤器，你可以这样写：Device-&gt;SetSamplerState(0, D3DSAMP_MIPFILTER, Filter);在Filter处你能用下面三个选项中的一个： D3DTEXF_NONE——不使用mipmap。 D3DTEXF_POINT——通过使用这个过滤器，Direct3D将选择与屏幕三角形大小最接近的mipmap等级。一旦等级选定了，Direct3D就将按照指定的过滤器进行缩小和放大过滤。 D3DTEXF_LINEAR——通过使用这个过滤器，Direct3D将选择两个最接近的mipmap等级，缩小和放大过滤每个等级，然后线性联合计算它们两个等级来得到最终的颜色值。6.4.2 Direct3D中使用Mipmaps 在Direct3D中使用Mipmaps是很简单的。假如你的显卡支持Mipmaps，那么使用D3DXCreateTextureFromFile将为你产生一个Mipmap链。Direct3D自动选择与屏幕三角形最匹配的Mipmap。因此Mipmap有非常广泛的应用，且它能被自动设置。6.5 寻址模式 以前，我们规定纹理坐标必须指定在[0，1]之间。从技术上来说这是不正确的；他们能够超出这个范围。纹理坐标也可以在[0，1]的范围之外，它通过Direct3D的寻址模式来定义。这里有四种寻址模式：环绕纹理寻址模式、边框颜色纹理寻址模式、截取纹理寻址模式、镜像纹理寻址模式，这里分别给出了它们的示意图6.5，6.6，6.7，6.8。 图6.5（环绕） 图6.6（边框） 图6.7（截取） 图6.8（镜像）在这些图片中，纹理坐标通过（0,0）（0,3）（3,0）（3,3）顶点来定义。在u轴和v轴上方块又被分成子块放进3×3的矩阵中。假如，你想让纹理按5×5的方格来平铺，你就应该指定环绕纹理寻址模式并且纹理坐标因该设置为（0,0）（0,5）（5,0）（5,5）。 下面的代码片段列举的是怎样设置这四种寻址模式：// set wrap address modeif( ::GetAsyncKeyState(‘W’) &amp; 0x8000f ){ Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSU, D3DTADDRESS_WRAP); Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSV, D3DTADDRESS_WRAP);}// set border color address modeif( ::GetAsyncKeyState(‘B’) &amp; 0x8000f ){ Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSU, D3DTADDRESS_BORDER); Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSV, D3DTADDRESS_BORDER); Device-&gt;SetSamplerState(0, D3DSAMP_BORDERCOLOR, 0x000000ff);}// set clamp address modeif( ::GetAsyncKeyState(‘C’) &amp; 0x8000f ){ Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSU, D3DTADDRESS_CLAMP); Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSV, D3DTADDRESS_CLAMP);}// set mirror address modeif( ::GetAsyncKeyState(‘M’) &amp; 0x8000f ){ Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSU, D3DTADDRESS_MIRROR); Device-&gt;SetSamplerState(0, D3DSAMP_ADDRESSV, D3DTADDRESS_MIRROR);}6.6实例程序：有纹理的方块 这个例子是怎样为方块加上纹理以及设置一个纹理过滤器（如图6.9）。假如你的显卡支持，通过D3DXCreateTextureFromFile函数一个mipmap链将被自动创建。 图6.9注意：还提供了其他两个例子大家就自己看看了。为一个场景增加纹理的必要步骤是： 用纹理坐标指定的，创建物体的顶点。 用D3DXCreateTextureFromFile函数读取一个纹理到IDirect3DTexture9接口中。 设置缩小倍数，放大倍数以及mipmap过滤器。 在你绘制一个物体前，用IDirect3DDevice9::SetTexture设置与物体关联的纹理。我们先定义几个全局变量；一个是顶点缓存，它存储方块的顶点。另外一个是我们为方块映射的纹理：IDirect3DVertexBuffer9 Quad = 0;IDirect3DTexture9 Tex = 0;Setup程序是很容易读懂的；我们用已经定义了纹理坐标的两个三角形创建一个方块。然后把文件dx5_logo.bmp读进IDirect3DTexture9接口中。接着使用SetTexture方法赋予纹理。最后设置缩小和放大过滤器进行线性过滤，我们也可以设置mipmap过滤器来进行D3DTEXF_POINT: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364bool Setup()&#123; // // Create the quad vertex buffer and fill it with the // quad geoemtry. // Device-&gt;CreateVertexBuffer( 6 * sizeof(Vertex), D3DUSAGE_WRITEONLY, Vertex::FVF, D3DPOOL_MANAGED, &amp;Quad, 0); Vertex* v; Quad-&gt;Lock(0, 0, (void**)&amp;v, 0); // quad built from two triangles, note texture coordinates: v[0] = Vertex(-1.0f, -1.0f, 1.25f, 0.0f, 0.0f, -1.0f, 0.0f, 1.0f); v[1] = Vertex(-1.0f, 1.0f, 1.25f, 0.0f, 0.0f, -1.0f, 0.0f, 0.0f); v[2] = Vertex( 1.0f, 1.0f, 1.25f, 0.0f, 0.0f, -1.0f, 1.0f, 0.0f); v[3] = Vertex(-1.0f, -1.0f, 1.25f, 0.0f, 0.0f, -1.0f, 0.0f, 1.0f); v[4] = Vertex( 1.0f, 1.0f, 1.25f, 0.0f, 0.0f, -1.0f, 1.0f, 0.0f); v[5] = Vertex( 1.0f, -1.0f, 1.25f, 0.0f, 0.0f, -1.0f, 1.0f, 1.0f); Quad-&gt;Unlock(); // // Create the texture and set filters. // D3DXCreateTextureFromFile( Device, "dx5_logo.bmp", &amp;Tex); Device-&gt;SetTexture(0, Tex); Device-&gt;SetSamplerState(0, D3DSAMP_MAGFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(0, D3DSAMP_MINFILTER, D3DTEXF_LINEAR); Device-&gt;SetSamplerState(0, D3DSAMP_MIPFILTER, D3DTEXF_POINT); // // Don't use lighting for this sample. // Device-&gt;SetRenderState(D3DRS_LIGHTING, false); // // Set the projection matrix. // D3DXMATRIX proj; D3DXMatrixPerspectiveFovLH( &amp;proj, D3DX_PI * 0.5f, // 90 - degree (float)Width / (float)Height, 1.0f, 1000.0f); Device-&gt;SetTransform(D3DTS_PROJECTION, &amp;proj); return true;&#125; 我们现在可以渲染方块了，且通常已经为它赋予了纹理：12345678910111213141516bool Display(float timeDelta)&#123; if( Device ) &#123; Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); Device-&gt;SetStreamSource(0, Quad, 0, sizeof(Vertex)); Device-&gt;SetFVF(Vertex::FVF); Device-&gt;DrawPrimitive(D3DPT_TRIANGLELIST, 0, 2); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); &#125; return true;&#125;]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[第五章 灯光(Lighting)]]></title>
    <url>%2F2019%2F04%2F11%2FLighting%2F</url>
    <content type="text"><![CDATA[灯光的组成在Direct3D灯光模型中，灯光是通过灯光资源的三个成员之一来照射的，即有三种灯光。 环境光（Ambient Light）——这种类型的灯光将被其他所有表面反射且被用在照亮整个场景。例如，物体的各部分都被照亮，对于一个角度，甚至穿过不在光源直接照射的地方他们都能被照亮。环境光的使用是粗略的，便宜的，它模仿反射光。 漫反射（Diffuse Reflection）——这种灯光按照特殊方向传播。当它照射到一个表面，它将在所有方向上均匀的反射。因为漫射光在所有方向上都均匀的反射，被反射的光线将到达眼睛而与观察点无关，因此我们不必为观察者考虑。因而，漫射光仅仅需要考虑灯光方向和表面的姿态。这种灯光将成为你的资源中照射的普通灯光。 镜面反射（Specular Reflection）——这种灯光按照特殊方向传播。当它照射到一个表面时，它严格地按照一个方向反射。这将产生一个明亮的光泽，它能在某角度被看见。因为这种灯光在一个方向反射。明显的观察点，必须考虑灯光的方向和表面姿态，且必须按照镜面灯光等式来考虑。镜面灯光被用在物体上产生高光的地方，这种光泽只有在灯光照射在磨光的表面上才会产生。 镜面光比其他灯光类型要求更多的计算；因此，Direct3D提供了一个开关选择。实际上，它默认是被关闭的；要使用镜面光你必须设置D3DRS_SPECULARENABLE渲染状态。1Device-&gt;SetRenderState(D3DRS_SPECULARENABLE, true); 每一种灯光都是通过D3DCOLORVALUE结构或者描述灯光颜色的D3DXCOLOR来描绘的。这里有几个灯光颜色的例子：123D3DXCOLOR redAmbient(1.0f, 0.0f, 0.0f, 1.0f);D3DXCOLOR blueDiffuse(0.0f, 0.0f, 1.0f, 1.0f);D3DXCOLOR whiteSpecular(1.0f, 1.0f, 1.0f, 1.0f); 注意：在D3DXCOLOR类中的alpha值用在描述灯光颜色时是被忽略的。 材质在现实世界中我们看到的物体颜色将由物体反射回来的灯光颜色来决定。比如，一个红色的球是红色的，因为它吸收所有的灯光颜色除了红色光。红色光是被球反射回来进入我们眼睛的，因此我们看到的球是红色的。Direct3D通过我们定义的物体材质来模拟这些所有的现象。材质允许我们定义表面反射灯光的百分比。在代码中通过D3DMATERIAL9结构描述一个材质。1234typedef struct _D3DMATERIAL9 &#123; D3DCOLORVALUE Diffuse, Ambient, Specular, Emissive; float Power;&#125; D3DMATERIAL9; Diffuse——指定此表面反射的漫射光数量。 Ambient——指定此表面反射的环境光数量。 Specular——指定此表面反射的镜面光数量 Emissive——这个是被用来给表面添加颜色，它使得物体看起来就象是它自己发出的光一样。 Power——指定锐利的镜面高光；它的值是高光的锐利值。 举例，想得到一个红色的球。我们将定义球的材质来只反射红光吸收其他颜色的所有光：1234567D3DMATERIAL9 red;::ZeroMemory(&amp;red, sizeof(red));red.Diffuse = D3DXCOLOR(1.0f, 0.0f, 0.0f, 1.0f); // redred.Ambient = D3DXCOLOR(1.0f, 0.0f, 0.0f, 1.0f); // redred.Specular = D3DXCOLOR(1.0f, 0.0f, 0.0f, 1.0f); // redred.Emissive = D3DXCOLOR(0.0f, 0.0f, 0.0f, 1.0f); // no emissionred.Power = 5.0f; 这里我们设置绿色和蓝色的值为0，这表明材质反射0%此颜色的光。我们设置红色为1，表示材质反射100%的红光。注意，我们能够控制每种灯光反射的颜色（环境、漫射和镜面光）。 同样假如我们定义一个只发出蓝色光的光源，对球的光照将失败因为蓝色光将被全部吸收而没有红光被反射。当物体吸收了所有光以后，物体看起来就为黑色。同样的，当物体反射100%的红、绿和蓝光，物体就将呈现为白色。 因为手工填充一个材质结构将是乏味的工作，我们添加下列有用的函数和全局材质常数到d3dUtility.h/cpp文件中：12345678910111213141516171819202122232425D3DMATERIAL9 d3d::InitMtrl(D3DXCOLOR a, D3DXCOLOR d,D3DXCOLOR s, D3DXCOLOR e, float p)&#123; D3DMATERIAL9 mtrl; mtrl.Ambient = a; mtrl.Diffuse = d; mtrl.Specular = s; mtrl.Emissive = e; mtrl.Power = p; return mtrl;&#125;namespace d3d&#123; D3DMATERIAL9 InitMtrl(D3DXCOLOR a, D3DXCOLOR d, D3DXCOLOR s, D3DXCOLOR e, float p); const D3DMATERIAL9 WHITE_MTRL = InitMtrl(WHITE, WHITE, WHITE, BLACK, 8.0f); const D3DMATERIAL9 RED_MTRL = InitMtrl(RED, RED, RED, BLACK, 8.0f); const D3DMATERIAL9 GREEN_MTRL = InitMtrl(GREEN, GREEN, GREEN, BLACK, 8.0f); const D3DMATERIAL9 BLUE_MTRL = InitMtrl(BLUE, BLUE, BLUE, BLACK, 8.0f); const D3DMATERIAL9 YELLOW_MTRL = InitMtrl(YELLOW, YELLOW, YELLOW, BLACK, 8.0f);&#125; 顶点结构没有材质属性；一个通用的材质必须被设置。设置它我们使用IDirect3DDevice9::SetMaterial(CONST D3DMATERIAL9 * pMaterial)方法。假设我们想渲染几个不同材质的物体；我们将按照如下的写法去做：12345678D3DMATERIAL9 blueMaterial, redMaterial;// set up material structuresDevice-&gt;SetMaterial(&amp;blueMaterial);drawSphere(); // blue sphereDevice-&gt;SetMaterial(&amp;redMaterial);drawSphere(); // red sphere 顶点法线面法线（face normal）是描述多边形表面方向的一个向量（如图5.1）。 图5.1 顶点法线（Vertex normals）也是基于同样的概念，但是我们与其指定每个多边形的法线，还不如为每个顶点指定（如图5.2）。 图5.2 Direct3D需要知道顶点法线以便它能够确定灯光照射到物体表面的角度，并且一旦计算了每个顶点的灯光，Direct3D需要知道每个顶点的表面方向。注意顶点法线不一定和面法线相同。球体/环形物就是很好的实物例子，它们的顶点法线和三角形法线是不相同的（如图5.3）。 图5.3为了描述顶点的顶点法线，我们必须更新原来的顶点结构1234567struct Vertex&#123; float _x, _y, _z; float _nx, _ny, _nz; static const DWORD FVF;&#125;const DWORD Vertex::FVF = D3DFVF_XYZ | D3DFVF_NORMAL; 注意，我们已经将上一章中使用的颜色成分去除了。这是因为我们将使用灯光来计算顶点的颜色。 作为一个简单的物体比如立方体和球体，我们能够通过观察看见顶点法线。对于更多复杂的网格，我们需要一个更多的机械方法。假设一个由p0,p1,p2构成的三角形，我们需要计算每个顶点的法线n0,n1,n2。 简单的步骤，我们列举它是为了找到由三个点构成的三角形的面法线，同时使用面法线作为顶点法线。首先计算三角形上的两个向量： 那么面法线是： 每个顶点的法线和面法线是相等的： 下面是一个C函数，它通过三角形的三个顶点计算三角形的面法线。注意这个函数的三个顶点是按照顺时针方向指定的。假如不是这样，那么法线方向将是相反的。12345678910void ComputeNormal(D3DXVECTOR3* p0, D3DXVECTOR3* p1, D3DXVECTOR3* p2, D3DXVECTOR3* out)&#123; D3DXVECTOR3 u = *p1 - *p0; D3DXVECTOR3 v = *p2 - *p0; D3DXVec3Cross(out, &amp;u, &amp;v); D3DXVec3Normalize(out, out);&#125; 当用三角形近似表示曲面时，使用面法线作为顶点法线不能表现一个平滑的结果。一个更好的方法是找到顶点法线的平均法线。为了找到顶点v的顶点法线vn，我们找到网格模型中所有三角形的面法线记为顶点v。vn是通过计算他们的平均面法线得到的。这里有一个例子，假设有3个三角形它们的面法线分别是n0，n1，n2，指定为顶点v。那么vn的平均法线就是： 通过改变“舞台”，把顶点法线变为non-normal,这是有可能的。因此这样最好是安全的且在通过D3DRS_NORMALIZENORMALS设置渲染状态来改变“舞台”后，Direct3D从新规格化所有法线。Device-&gt;SetRenderState(D3DRS_NORMALIZENORMALS, true);5.4光源 Direct3D支持三种类型的光源。 点光源——这种光源在世界坐标中有一个位置且向所有方向上都照射光线。 图5.4 方向光源——这种光源没有位置但是向指定方向发出平行光线。 图5.5 聚光灯——这种类型的光源和手电筒的光类似；它有位置并且发出的光在指定方向上按照圆锥形照射。这个圆锥形有两个角度，θ和φ。角度θ描述内圆锥，φ描述外圆锥。 图5.6 在代码中一个灯光资源是通过D3DLIGHT9结构来表现的。typedef struct _D3DLIGHT9 { D3DLIGHTTYPE Type; D3DCOLORVALUE Diffuse; D3DCOLORVALUE Specular; D3DCOLORVALUE Ambient; D3DVECTOR Position; D3DVECTOR Direction; float Range; float Falloff; float Attenuation0; float Attenuation1; float Attenuation2; float Theta; float Phi;} D3DLIGHT9; Type——定义灯光类型，我们能够使用下面三种类型之一：D3DLIGHT_POINT, D3DLIGHT_SPOT, D3DLIGHT_DIRECTIONAL Diffuse——此光源发出的漫射光颜色。 Specular——此光源发出的镜面光颜色。 Ambient——此光源发出的环境光颜色。 Position——用一个向量来描述的光源世界坐标位置。这个值对于灯光的方向是无意义的。 Direction——用一个向量来描述的光源世界坐标照射方向。这个值不能用在点光源上。 Range——灯光能够传播的最大范围。这个值不能比大。且不能用于方向光源。 Falloff——这个值只能用在聚光灯上。它定义灯光在从内圆锥到外圆锥之间的强度衰减。它的值通常设置为1.0f。 Attenuation0, Attenuation1, Attenuation2——这些衰减变量被用来定义灯光强度的传播距离衰减。它们只被用于点光源和聚光灯上。Attenuation0定义恒定衰减，Attenuation1定义线性衰减，Attenuation2定义二次衰减。适当的使用这个公式，D是代表到光源的距离，A0,A1,A2与Attenuation0，1，2相匹配。 Theta——只用于聚光灯；指定内圆锥的角度，单位是弧度。 Phi——只用于聚光灯；指定外圆锥的角度，单位是弧度。 就象初始化D3DMATERIAL9结构一样，初始化D3DLIGHT9结构是一件单调乏味的工作。我们添加下面的函数到d3dUtility.h/cpp文件中用于初始化简单灯光。namespace d3d{ … … D3DLIGHT9 InitDirectionalLight(D3DXVECTOR3 direction, D3DXCOLOR color); D3DLIGHT9 InitPointLight(D3DXVECTOR3 position, D3DXCOLOR color); D3DLIGHT9 InitSpotLight(D3DXVECTOR3 position, D3DXVECTOR3 direction, D3DXCOLOR color);} 使用这些函数是非常简单的。我们现在只是演示怎样使用InitDirectionalLight。其他的也很类似：D3DLIGHT9 d3d::InitDirectionalLight(D3DXVECTOR3 direction, D3DXCOLOR color){ D3DLIGHT9 light; ::ZeroMemory(&amp;light, sizeof(light)); light.Type = D3DLIGHT_DIRECTIONAL; light.Ambient = color 0.4f; light.Diffuse = color; light.Specular = color 0.6f; light.Direction = *direction; return light;} 然后创建一个方向光源，它沿着x轴正方向照射白色灯光。我们按照下面的方法来做：D3DXVECTOR3 dir(1.0f, 0.0f, 0.0f);D3DXCOLOR c = d3d::WHITE;D3DLIGHT9 dirLight = d3d::InitDirectionalLight(&amp;dir, &amp;c); 在把D3DLIGHT9初始化好以后，我们需要用Direct3D内在支持的灯光来注册。就象这样做：Device-&gt;SetLight( 0, // element in the light list to set, range is 0-maxlights &amp;light);// address of the D3DLIGHT9 structure to set 一旦灯光注册了，我们就能使用下面的列举的例子来开或关灯光了：Device-&gt;LightEnable( 0, // the element in the light list to enable/disable true); // true = enable, false = disable5.5实例程序：灯光 这一章的例子是创建如图5.7所显示的场景。它示范了怎样指定顶点法线，怎样创建材质，以及怎样创建和使用一个方向灯光。注意在这个示例程序中我们不会使用在文件d3dUtility.h/cpp中的材质和灯光函数。因为我们想展示怎样手动来做这些设置。 图5.7 给场景增加灯光的步骤是：1、 允许使用灯光。2、 为每个物体创建材质并且在渲染相应物体前应将材质附予物体。3、 创建一个或多个光源，设置它们，把它们设为可用。4、 将其他附加光源设为可用，比如镜面高光。 首先我们初始化一个全局顶点缓存用他来存储“金字塔”的顶点：IDirect3DVertexBuffer9* Pyramid = 0; Setup函数包含本章的所有代码，因此我们忽略其他函数。它执行刚才讨论的步骤来给场景加入灯光。Setup方法首先允许使用灯光，当然这不是必须的因为默认设置就是允许使用灯光的。bool Setup(){ Device-&gt;SetRenderState(D3DRS_LIGHTING, true); 下一步，我们创建顶点缓存，锁定，并且把“金字塔”的三角形顶点放入其中。顶点法线是利用5.3节中的运算法则预先计算好的。注意三角形共享顶点，但它们的法线不能共享；因此对这个物体使用索引列表并不是最有利的。例如，所有三角形都共享顶点（0,1,0）；然而，对每个三角形，它们的顶点法线是不相同的。1234567891011121314151617181920212223242526272829303132Device-&gt;CreateVertexBuffer( 12 * sizeof(Vertex), D3DUSAGE_WRITEONLY, Vertex::FVF, D3DPOOL_MANAGED, &amp;Pyramid, 0);// fill the vertex buffer with pyramid dataVertex* v;Pyramid-&gt;Lock(0, 0, (void**)&amp;v, 0);// front facev[0] = Vertex(-1.0f, 0.0f, -1.0f, 0.0f, 0.707f, -0.707f);v[1] = Vertex( 0.0f, 1.0f, 0.0f, 0.0f, 0.707f, -0.707f);v[2] = Vertex( 1.0f, 0.0f, -1.0f, 0.0f, 0.707f, -0.707f);// left facev[3] = Vertex(-1.0f, 0.0f, 1.0f, -0.707f, 0.707f, 0.0f);v[4] = Vertex( 0.0f, 1.0f, 0.0f, -0.707f, 0.707f, 0.0f);v[5] = Vertex(-1.0f, 0.0f, -1.0f, -0.707f, 0.707f, 0.0f);// right facev[6] = Vertex( 1.0f, 0.0f, -1.0f, 0.707f, 0.707f, 0.0f);v[7] = Vertex( 0.0f, 1.0f, 0.0f, 0.707f, 0.707f, 0.0f);v[8] = Vertex( 1.0f, 0.0f, 1.0f, 0.707f, 0.707f, 0.0f);// back facev[9] = Vertex( 1.0f, 0.0f, 1.0f, 0.0f, 0.707f, 0.707f);v[10] = Vertex( 0.0f, 1.0f, 0.0f, 0.0f, 0.707f, 0.707f);v[11] = Vertex(-1.0f, 0.0f, 1.0f, 0.0f, 0.707f, 0.707f);Pyramid-&gt;Unlock(); 为物体产生了顶点数据以后，我们描述利用灯光表现各自材质的物体间是怎样相互影响的。在这个例子中，“金字塔”反射出白光，自身不发光，且会产生一些高光。D3DMATERIAL9 mtrl;mtrl.Ambient = d3d::WHITE;mtrl.Diffuse = d3d::WHITE;mtrl.Specular = d3d::WHITE;mtrl.Emissive = d3d::BLACK;mtrl.Power = 5.0f;Device-&gt;SetMaterial(&amp;mtrl); 接着，我们创建一个方向光并将其设为可用。方向光是沿着x轴的正方向照射的。灯光照射最强的白色漫射光（dir.Diffuse = WHITE），较弱的白色镜面光（dir.Specular = WHITE 0.3f）以及一个中等强度的白色环境光（dir.Ambient = WHITE 0.6f）。123456789101112131415D3DLIGHT9 dir;::ZeroMemory(&amp;dir, sizeof(dir));dir.Type = D3DLIGHT_DIRECTIONAL;dir.Diffuse = d3d::WHITE;dir.Specular = d3d::WHITE * 0.3f;dir.Ambient = d3d::WHITE * 0.6f;dir.Direction = D3DXVECTOR3(1.0f, 0.0f, 0.0f);Device-&gt;SetLight(0, &amp;dir);Device-&gt;LightEnable(0, true);//最后，我们设置状态使法线从新规格化且把镜面高光设置为可用。Device-&gt;SetRenderState(D3DRS_NORMALIZENORMALS, true);Device-&gt;SetRenderState(D3DRS_SPECULARENABLE, true);// ... code to set up the view matrix and projection matrix// omittedreturn true; 5.6附加实例 这一章中还有三个附加的例子。它们使用D3DXCreate函数来创建组成场景的3D物体。D3DXCreate函数创建的顶点数据是D3DFVF_XYZ | D3DFVF_NORMAL格式。在增加的函数中为我们的网格模型的每个顶点计算了顶点法线。这些实例演示了怎样使用方向光，点光源，以及聚光灯。图5.8显示的是方向光实例中的一个场景图。 图5.8]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[色彩(Color)]]></title>
    <url>%2F2019%2F04%2F11%2Fcolor%2F</url>
    <content type="text"><![CDATA[颜色表示法 在Direct3D中，颜色是使用RGB三部分来描述的。也就是说，我们要分别指定红、绿和蓝三种颜色的值。混合这三个颜色决定最终的颜色。利用这三种颜色我们能够表现数万种颜色。 我们使用两种不同的结构来存储RGB数据。这第一种是D3DCOLOR，它实际上一个DWORD即32位。在D3DCOLOR类型中的这些位按照8-bit被分为4个部分，每一部分存储的是该色的亮度值。如图4.1所示。 图4.1 每种颜色占用内存的一个字节，各颜色亮度值的取值范围是0-255。这个值越接近0就越暗，越接近255就越亮。注意：现在不要管alpha部分；它被用在alpha混合中——在第7章中会讲解。 指定其中的每一部分并且把它放到D3DCOLOR中适当的位置需要使用到一些位操作。Direct3D为我们提供了一个完成这个任务的宏D3DCOLOR_ARGB.它使用包含每种颜色以及alpha位一共4个参数。每一个参数的取值必须在0-255之间，如：D3DCOLOR brightRed = D3DCOLOR_ARGB(255, 255, 0, 0);D3DCOLOR someColor = D3DCOLOR_ARGB(255, 144, 87, 201); 另外，我们也能使用D3DCOLOR_XRGB宏，它与刚才的宏类似只不过不必指定alpha部分；不过我们最好还是把alpha指定为0xff（255）。 define D3DCOLOR_XRGB(r,g,b) D3DCOLOR_ARGB(0xff,r,g,b) 在Direct3D中另外一种存储颜色的结构是D3DCOLORVALUE。在这个结构中，我们分别使用一个浮点数来表示每一部分的亮度值。其取值范围是0-1，0表示没有亮度，1表示最大亮度。123456typedef struct _D3DCOLORVALUE &#123; float r; // the red component, range 0.0-1.0 float g; // the green component, range 0.0-1.0 float b; // the blue component, range 0.0-1.0 float a; // the alpha component, range 0.0-1.0&#125; D3DCOLORVALUE; 另外，我们能够使用D3DXCOLOR结构，就象D3DCOLORVALUE包含同样的数据成员一样。同时提供有用的构造函数和重载操作符，这将让颜色处理更容易。D3DXCOLOR的定义如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344typedef struct D3DXCOLOR&#123; #ifdef __cplusplus public: D3DXCOLOR() &#123;&#125; D3DXCOLOR( DWORD argb ); D3DXCOLOR( CONST FLOAT * ); D3DXCOLOR( CONST D3DXFLOAT16 * ); D3DXCOLOR( CONST D3DCOLORVALUE&amp; ); D3DXCOLOR( FLOAT r, FLOAT g, FLOAT b, FLOAT a ); // casting operator DWORD () const; operator FLOAT* (); operator CONST FLOAT* () const; operator D3DCOLORVALUE* (); operator CONST D3DCOLORVALUE* () const; operator D3DCOLORVALUE&amp; (); operator CONST D3DCOLORVALUE&amp; () const; // assignment operators D3DXCOLOR&amp; operator += ( CONST D3DXCOLOR&amp; ); D3DXCOLOR&amp; operator -= ( CONST D3DXCOLOR&amp; ); D3DXCOLOR&amp; operator *= ( FLOAT ); D3DXCOLOR&amp; operator /= ( FLOAT ); // unary operators D3DXCOLOR operator + () const; D3DXCOLOR operator - () const; // binary operators D3DXCOLOR operator + ( CONST D3DXCOLOR&amp; ) const; D3DXCOLOR operator - ( CONST D3DXCOLOR&amp; ) const; D3DXCOLOR operator * ( FLOAT ) const; D3DXCOLOR operator / ( FLOAT ) const; friend D3DXCOLOR operator * (FLOAT, CONST D3DXCOLOR&amp; ); BOOL operator == ( CONST D3DXCOLOR&amp; ) const; BOOL operator != ( CONST D3DXCOLOR&amp; ) const; #endif //__cplusplus FLOAT r, g, b, a;&#125; D3DXCOLOR, *LPD3DXCOLOR; 注意：D3DCOLORVALUE和D3DXCOLOR结构都有4个浮点数成员。这使我们的颜色处理符号能象4D向量一样。颜色向量能被加，减以及缩放。另一方面点积和叉积不能用于颜色向量，但是颜色成员相乘是可以的。因此在D3DXCOLOR类中执行的乘法就是成员相乘。它的定义如下： 现在使用下面全局颜色常量更新我们的d3dUtility.h文件： 1234567891011namespace d3d&#123; const D3DXCOLOR WHITE( D3DCOLOR_XRGB(255, 255, 255) ); const D3DXCOLOR BLACK( D3DCOLOR_XRGB( 0, 0, 0) ); const D3DXCOLOR RED( D3DCOLOR_XRGB(255, 0, 0) ); const D3DXCOLOR GREEN( D3DCOLOR_XRGB( 0, 255, 0) ); const D3DXCOLOR BLUE( D3DCOLOR_XRGB( 0, 0, 255) ); const D3DXCOLOR YELLOW( D3DCOLOR_XRGB(255, 255, 0) ); const D3DXCOLOR CYAN( D3DCOLOR_XRGB( 0, 255, 255) ); const D3DXCOLOR MAGENTA( D3DCOLOR_XRGB(255, 0, 255) );&#125; 顶点颜色图元的颜色是由构成它的顶点的颜色决定的。因此，我们必须把一个颜色成员加入到我们的顶点数据结构中。注意D3DCOLORVALUE类型不能用在这里，因为Direct3D希望用一个32位的值来描述顶点的颜色。（通过使用顶点着色器我们能为顶点颜色使用4D颜色向量，它能提供一个128位的颜色，但是对于我们现在的水平来说那太超前了。顶点着色器将在17章中介绍。）123456struct ColorVertex&#123; float _x, _y, _z; D3DCOLOR _color; static const DWORD FVF;&#125; const DWORD ColorVertex::FVF = D3DFVF_XYZ | D3DFVF_DIFFUSE; 着色处理着色处理发生在光栅化和指定图元上的顶点颜色怎样被计算成像素颜色之间。目前这里有2种着色处理模式可用：平面着色（flat shading）和高洛德着色（Gouraud shading）。平面着色，图元像素的颜色是均匀的，且就是指定图元第一个顶点的颜色。因此一旦三角形的第一个顶点被指定成红色，那么它的其他三个顶点也将会是红色。通过使用平面着色来为第二和第三个顶点着色。1234ColorVertex t[3];t[0]._color = D3DCOLOR_XRGB(255, 0, 0);t[1]._color = D3DCOLOR_XRGB(0, 255, 0);t[2]._color = D3DCOLOR_XRGB(0, 0, 255); 平面着色使物体呈现是斑驳的，因为没有从一个颜色到另一个颜色的平滑过渡。一个更好的着色模式叫做高洛德着色（也被叫做平滑着色）。高洛德着色，图元表面的颜色是由每个顶点通过线性插值来赋予。图4.2显示了分别使用平面着色和高洛德着色处理的红色三角形。 图4.2就象Direct3D中很多东西一样，着色处理模式是受Direct3D设置状态决定的。// set flat shadingDevice-&gt;SetRenderState(D3DRS_SHADEMODE, D3DSHADE_FLAT);// set Gouraud shadingDevice-&gt;SetRenderState(D3DRS_SHADEMODE, D3DSHADE_GOURAUD); 实例程序：彩色三角形这个实例程序展示了分别使用本章中的平面着色和高洛德着色处理的三角形。渲染出的图片如图4.2所示。首先我们定义如下的全局变量：D3DXMATRIX World;IDirect3DVertexBuffer9* Triangle = 0; 我们包含一个D3DXMATRIX，它将存储我们将要绘制的三角形在世界坐标中的变换信息。Triangle变量是存储三角形顶点数据的顶点缓存。注意，我们只需要存储一个三角形，因为我们能用它在世界坐标系中不同位置绘制若干次。 Setup方法创建顶点缓存同时填充上带颜色信息的三角形顶点数据。三角形的第一个顶点填充为全亮度红色（255）第二个填充全亮度绿色（255），第三个填充全亮度蓝色（255）。最后，在这个例子中我们屏蔽掉灯光。值得注意的是该例子使用的是一个新的ColorVertex结构，就象在4.2节中说明的一样。123456789101112131415161718192021222324252627282930313233343536bool Setup()&#123; // create vertex buffer Device-&gt;CreateVertexBuffer( 3 * sizeof(ColorVertex), D3DUSAGE_WRITEONLY, ColorVertex::FVF, D3DPOOL_MANAGED, &amp;Triangle, 0); // fill the buffers with the triangle data ColorVertex* v; Triangle-&gt;Lock(0, 0, (void**)&amp;v, 0); v[0] = ColorVertex(-1.0f, 0.0f, 2.0f, D3DCOLOR_XRGB(255, 0, 0)); v[1] = ColorVertex( 0.0f, 1.0f, 2.0f, D3DCOLOR_XRGB( 0, 255, 0)); v[2] = ColorVertex( 1.0f, 0.0f, 2.0f, D3DCOLOR_XRGB( 0, 0, 255)); Triangle-&gt;Unlock(); // set projection matrix D3DXMATRIX proj; D3DXMatrixPerspectiveFovLH( &amp;proj, D3DX_PI * 0.5f, // 90 - degree (float)Width / (float)Height, 1.0f, 1000.0f); Device-&gt;SetTransform(D3DTS_PROJECTION, &amp;proj); // set the render states Device-&gt;SetRenderState(D3DRS_LIGHTING, false); return true;&#125; Display函数使用不同的着色模式在两个不同的地方分别绘制2个Triangle。每个三角形的位置由世界矩阵World来决定。1234567891011121314151617181920212223242526272829bool Display(float timeDelta)&#123; if( Device ) &#123; Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); Device-&gt;SetFVF(ColorVertex::FVF); Device-&gt;SetStreamSource(0, Triangle, 0, sizeof(ColorVertex)); // draw the triangle to the left with flat shading D3DXMatrixTranslation(&amp;World, -1.25f, 0.0f, 0.0f); Device-&gt;SetTransform(D3DTS_WORLD, &amp;World); Device-&gt;SetRenderState(D3DRS_SHADEMODE, D3DSHADE_FLAT); Device-&gt;DrawPrimitive(D3DPT_TRIANGLELIST, 0, 1); // draw the triangle to the right with gouraud shading D3DXMatrixTranslation(&amp;World, 1.25f, 0.0f, 0.0f); Device-&gt;SetTransform(D3DTS_WORLD, &amp;World); Device-&gt;SetRenderState(D3DRS_SHADEMODE, D3DSHADE_GOURAUD); Device-&gt;DrawPrimitive(D3DPT_TRIANGLELIST, 0, 1); Device-&gt;EndScene(); Device-&gt;Present(0, 0, 0, 0); &#125; return true;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Drawing in Direct3D]]></title>
    <url>%2F2019%2F04%2F11%2Fdrawing-in-direct3d%2F</url>
    <content type="text"><![CDATA[顶点/索引缓存顶点和索引缓存有相似的接口并且共享相似的方法；一个顶点缓存是一块连续的存储了顶点数据的内存。同样的，一个索引缓存是一块连续的存储了索引数据的内存。我们使用顶点和索引缓存保存我们的数据是因为它们能被放置在显存中。渲染显存中的数据要比渲染系统内存中的数据快的多。在代码中，一个顶点缓存是通过IDirect3DVertexBuffer9接口来定义的。类似的，一个索引缓存是通过IDirect3DIndexBuffer9接口来定义。 创建一个顶点和索引缓存我们能使用下面两个方法创建一个顶点缓存和索引缓存：1234567891011121314151617HRESULT IDirect3DDevice9::CreateVertexBuffer( UINT Length, DWORD Usage, DWORD FVF, D3DPOOL Pool IDirect3DVertexBuffer9** ppVertexBuffer, HANDLE* pSharedHandle);HRESULT IDirect3DDevice9::CreateIndexBuffer( UINT Length, DWORD Usage, D3DFORMAT Format, D3DPOOL Pool, IDirect3DIndexBuffer9** ppIndexBuffer, HANDLE* pSharedHandle); 这两个方法大部分参数是相同的，因此我们一起介绍它们。 Length —— 分配给缓存的字节大小。假如想得到一个能存储8个顶点的顶点缓存，那么我们就要在顶点结构中设置这个参数为 8 * sizeof ( Vertex ) 。 Usage —— 指定关于怎样使用缓存的额外信息。这个值可以是0，没有标记，或者是下面标记的一个或多个的组合： D3DUSAGE_DYNAMIC——设置这个参数可以使缓存是动态的。在下一页说明静态和动态缓存。 D3DUSAGE_POINTS——这个参数指定缓存存储原始点。原始点将在第14章粒子系统中介绍。这个参数仅仅用在顶点缓冲中。 D3DUSAGE_SOFTWAREPROCESSING——使用软件顶点处理 D3DUSAGE_WRITEONLY——指定应用程序只能写缓存。它允许驱动程序分配最适合的内存地址作为写缓存。注意如果从创建好的这种缓存中读数据，将会返回错误信息。 FVF —— 存储在缓存中的顶点格式 Pool —— 缓存放置在哪一个内存池中 ppVertexBuffer ——返回创建好的顶点缓存的指针。 pSharedHandle ——没有使用；设置为0。 Format ——指定索引的大小；使用D3DFMT_INDEX16设置16位索引，使用D3DFMT_INDEX32设置32位索引。注意并非所有设备都支持32位索引；请检查设备能力。 ppIndexBuffer ——返回创建好的索引缓存的指针。 注意：不使用D3DUSAGE_DYNAMIC参数创建的缓存被叫做静态缓存。静态缓存通常被放置在显存中，在其中的数据能被很有效的处理。然而，对于静态缓存，从中读取和写入数据是很慢的，因为访问显存是很慢的。因为这个原因我们用静态缓存存储静态数据（不需要被经常改变的数据）。对于静态缓存地形和建筑物是很好的后选例子，因为在应用程序中他们通常不需要被改变。静态缓存应该在应用程序初始话的时候就被填充好，而不是在运行时才做。 注意：使用D3DUSAGE_DYNAMIC参数创建的缓存被叫做动态缓存。动态缓存通常被放在AGP内存中，这种内存中的数据能被很快的更新。处理动态缓存中的数据不会比处理静态缓存中的数据快，因为这些数据必须在渲染前被转移到显存中，动态缓存的好处是它们能够被稍微快点地被更新（比CPU写快）。因此，假如你需要经常更新缓存中的数据，那么你就应该使用动态缓存。对于动态缓存粒子系统是很好的一个应用，因为它们是动态的，并且他们通常每一帧都会被更新。 注意：在程序中读取显存和AGP内存都是非常慢的。因此，假如你在运行时需要读取你的几何物体，最好的方案是指定一块系统内存，都在其中拷贝并且读取数据。 下边是创建一个静态顶点缓存的例子，该缓存能存储8个顶点。12345678IDirect3DVertexBuffer9* vb;device-&gt;CreateVertexBuffer( 8 * sizeof( Vertex ), 0, D3DFVF_XYZ, D3DPOOL_MANAGED, &amp;vb, 0); 访问缓冲内存 为了访问一个顶点/索引缓存，我们需要得到一个指针。我们通过一个指针获得缓存数据必须使用Lock方法。当我们访问完缓存后必须对它解锁。一旦有一个指向内存的指针，我们就能对它进行读写。123456789101112HRESULT IDirect3DVertexBuffer9::Lock( UINT OffsetToLock, UINT SizeToLock, BYTE** ppbData, DWORD Flags);HRESULT IDirect3DIndexBuffer9::Lock( UINT OffsetToLock, UINT SizeToLock, BYTE** ppbData, DWORD Flags); 图3.1 这两个方法的参数都是完全相同的。 OffsetToLock —— 偏移量，以字节为单位，从缓存开始位置到锁定开始位置的距离。如图3.1。 SizeToLock —— 锁定的字节数。 ppbData —— 一个指向锁定内存开始位置的指针。 Flags —— 标记描述怎样锁定内存。它可能是0或者是下面参数中的1个或多个的组合： D3DLOCK_DISCARD——这个参数仅仅会在动态缓存时被使用。它指示硬件丢弃缓存并返回一个指向新分配的缓存的指针。这是很有用，因为当我们存取一个新分配的缓存时它允许硬件继续从丢弃的缓存渲染。这防止了硬件延迟。 D3DLOCK_NOOVERWRITE——这个参数仅仅会在动态缓存时被使用。它声明你将向缓存中添加数据。即，你不能向已经渲染的内存中写数据。这是有好处的因为他允许你在添加新数据到缓存的同时让硬件继续渲染。 D3DLOCK_READONLY——这个参数声明你锁定的缓存只能从中读取数据而不能写数据。这允许一些内在的优化。 用参数D3DLOCK_DISCARD和D3DLOCK_NOOVERWRITE的地址实际上就是缓存的一部分被使用（正在渲染）时它被锁定。假如情况允许这些标记被使用，当在锁定时他们防止渲染停止。 下边的例子展示了通常怎样使用Lock方法。注意当我们使用完以后要调用Unlock方法。Vertex vertices;_vb-&gt;Lock(0, 0, (void*)&amp;vertices, 0); // 锁定整个缓存vertices[0] = Vertex(-1.0f, 0.0f, 2.0f); // 向缓存里写顶点vertices[1] = Vertex( 0.0f, 1.0f, 2.0f);vertices[2] = Vertex( 1.0f, 0.0f, 2.0f);_vb-&gt;Unlock(); // 当你访问完缓存时，解锁缓存3.1.3 找回顶点和索引缓存信息有时我们需要得到顶点/索引缓存信息。下面的例子示范了用于获得这些信息的方法：D3DVERTEXBUFFER_DESC vbDescription;_vertexBuffer-&gt;GetDesc(&amp;vbDescription); // 取得顶点缓存信息 D3DINDEXBUFFER_DESC ibDescription;_indexBuffer-&gt;GetDesc(&amp;ibDescription); //取得索引缓存信息 D3DVERTEXBUFFER_DESC和D3DINDEXBUFFER_DESC结构的定义如下：typedef struct _D3DVERTEXBUFFER_DESC { D3DFORMAT Format; D3DRESOURCETYPE Type; DWORD Usage; D3DPOOL Pool; UINT Size; DWORD FVF;} D3DVERTEXBUFFER_DESC; typedef struct _D3DINDEXBUFFER_DESC { D3DFORMAT Format; D3DRESOURCETYPE Type; DWORD Usage; D3DPOOL Pool; UINT Size;} D3DINDEXBUFFER_DESC;3.2 渲染状态 Direct3D提供了多种渲染状态，它影响几何物体怎样被渲染。渲染状态有默认值，因此假如你的应用程序需要不同于默认设置的渲染时，你仅仅改变它即可。一种渲染效果会一直起作用，直到你下一次改变渲染状态为止。为了设置一个渲染状态，我们使用下面的方法：HRESULT IDirect3DDevice9::SetRenderState( D3DRENDERSTATETYPE State, // 更改的渲染状态 DWORD Value // 新的状态值); 例如，在这一章的例子中我们将使用线框模式渲染我们的物体。因此，我们设置如下的渲染状态：_device-&gt;SetRenderState(D3DRS_FILLMODE, D3DFILL_WIREFRAME);注意：查看DirectX SDK中关于D3DRENDERSTATETYPE的信息。其中详细介绍了所有的渲染状态。3.3 绘制准备 一旦我们创建好一个顶点缓存以及一个索引缓存（可选的）后，我们就为渲染其中的内容准备得差不多了，但是在渲染前我们还有3个步骤必须先做。1、 设置资源流。设置资源流与一个顶点缓存挂钩，此流就是一个流入渲染管线的几何信息的流。 下面的方法是用于设置一个资源流：HRESULT IDirect3DDevice9::SetStreamSource( UINT StreamNumber, IDirect3DVertexBuffer9* pStreamData, UINT OffsetInBytes, UINT Stride); StreamNumber——确定我们的顶点缓存与哪一个资源流挂钩。在这本书中我们不使用多重流；因此我们总是使用0号流。 pStreamData——一个指向我们想与流挂钩的那个顶点缓存的指针。 OffsetInBytes——相对流开始处的偏移量。以字节为单位，它指定被填入渲染管线的顶点数据的开始位置。通过检查D3DCAPS9结构中的D3DDEVCAPS2_STREAMOFFSET标志，假如你的设备支持，那么这个参数就有一些非0值。 Stride——我们在顶点缓存中操作的每个部分的流的字节大小。 例如，假设vb是一个已经填充了顶点信息的顶点缓存：_device-&gt;SetStreamSource( 0, vb, 0, sizeof( Vertex ) ); 2、 设置顶点格式。在这里我们指定后面用来绘图调用的顶点的顶点格式。_device-&gt;SetFVF( D3DFVF_XYZ | D3DFVF_DIFFUSE | D3DFVF_TEX1 ); 3、 设置索引缓存。假如我们使用了索引缓存，我们必须设置后面要用于绘制操作的索引缓存。每次我们只能使用一个索引缓存；因此假如你需要用一个不同的索引缓存绘制一个物体时，你必须转换到另一个上。下面的代码设置一个索引缓存：_device-&gt;SetIndices( _ib ); // 传递一个索引缓存指针的拷贝3.4用顶点/索引缓存绘制 在我们创建好顶点/索引缓存以及做好准备工作以后，我们就能绘制我们的几何物体了。这是通过使用DrawPrimitive或者DrawIndexedPrimitive传送几何信息到达渲染管线。这些方法从顶点流中获得顶点信息以及从索引缓存中获得索引信息。3.4.1 IDirect3DDevice9::DrawPrimitive 这个方法不使用索引信息绘制图元。HRESULT IDirect3DDevice9::DrawPrimitive( D3DPRIMITIVETYPE PrimitiveType, UINT StartVertex, UINT PrimitiveCount); PrimitiveType——我们绘制的图元类型。比如，我们能绘制点和线以及三角形。以后我们使用三角形，用D3DPT_TRIANGLELIST参数。 StartVertex——索引到在顶点流中的一个元素。设置渲染顶点中的开始点。这个参数给予我们一定的机动性，可以绘制一个顶点缓存中的某部分。 PrimitiveCount——绘制图元的个数。 例子：// 绘制4个三角形_device-&gt;DrawPrimitive( D3DPT_TRIANGLELIST, 0, 4);3.4.2 IDirect3DDevice9::DrawIndexedPrimitive 这个方法使用索引信息来绘制图元。HRESULT IDirect3DDevice9::DrawIndexedPrimitive( D3DPRIMITIVETYPE Type, INT BaseVertexIndex, UINT MinIndex, UINT NumVertices, UINT StartIndex, UINT PrimitiveCount); Type——我们绘制的图元类型。比如，我们能绘制点和线以及三角形。以后我们使用三角形，用D3DPT_TRIANGLELIST参数。 BaseVertexIndex——一个基本数字，在调用中用它去加上索引。参看下面的说明。 MinIndex——将被引用的最小索引值。 NumVertices——在此调用中将被引用的顶点数。 StartIndex——索引到索引缓存中的某个位置，它标记开始渲染的开始索引点。 PrimitiveCount——绘制图元的个数。 例子：_device-&gt;DrawIndexedPrimitive(D3DPT_TRIANGLELIST, 0, 0, 8, 0, 12);注意：BaseVertexIndex参数需要一些特别的解释。在解释过程中将会用到的图3.2。 图3.2 在索引缓存中定位顶点相应的也就在顶点缓存中定位了。然而，假设我们想将球，盒子，圆柱体的顶点放置到一个公共的顶点缓存中。对于每一个物体，我们将不得不再计算在公共顶点缓存中的索引。这个新的索引值是通过与一个偏移量相加得到。注意这个偏移量是标准的顶点，而不是字节。 我们需要计算物体在公共顶点缓存中的索引值。Direct3D允许我们通过设置BaseVertexIndex参数得到一个顶点偏移量，随后Direct3D就能利用顶点自身的索引重新计算新的索引。3.4.3 开始/结束场景 最后一点就是所有绘制方法都必须在IDirect3DDevice9::BeginScene和IDirect3DDevice9::EndScene方法之间被调用。例如，我们将这样写：_device-&gt;BeginScene(); // 绘制场景 _device-&gt;DrawPrimitive(…);_device-&gt;EndScene();3.5 D3DX几何物体 通过在代码中建造每个三角形来建造3D物体是一件非常枯燥的事。幸运的是，D3DX库已经为我们提供了一些方法来产生简单3D物体的网格数据。 D3DX库提供如下6种网格生成函数。 D3DXCreateBox D3DXCreateSphere D3DXCreateCylinder D3DXCreateTeapot D3DXCreatePolygon D3DXCreateTorus 图3.3 这6种函数的使用都很类似，并且使用D3DX网格数据结构ID3DXMesh就象使用ID3DXBuffer接口一样。这些接口回在第10章和11章中讲解。现在，我们忽视它们的详细信息，只需简单使用它们即可。HRESULT D3DXCreateTeapot( LPDIRECT3DDEVICE9 pDevice, // 与mesh关联的设备 LPD3DXMESH ppMesh, // 返回的mesh LPD3DXBUFFER ppAdjacency // 现在设成0); 一个使用D3DXCreateTeapot函数的例子：ID3DXMesh mesh = 0;D3DXCreateTeapot(_device, &amp;mesh, 0); 一旦生成了网格数据，我们就能使用ID3DXMesh::DrawSubset方法绘制图形了。这个方法有一个参数，它用来识别网格的一个子集。这个网格是通过上面的D3DXCreate函数中的一个子集创建的，因此可以给这个参数指定0值。一个渲染网格的例子：_device-&gt;BeginScene(); mesh-&gt;DrawSubset(0);_device-&gt;EndScene(); 使用了网格以后，必须释放（release）它：mesh-&gt;Release();_mesh = 0;3.6 实例程序：三角形、立方体、茶壶、D3DXCreate* 这里有4个例子。 三角形——这是非常简单的应用程序，它示范了在线框模式下怎样创建并渲染一个三角形。 立方体——只比三角形稍微复杂一点，这个程序渲染一个线框立方体。 茶壶——这个程序使用D3DXCreateTeapot函数创建并渲染一个纺纱茶壶。 D3DXCreate——这个程序创建并渲染几种不同的能够使用D3DXCreate*函数创建的3D物体。让我们简单讨论一下创建立方体的例子。通过对它的学习你自己就能很快地理解其他例子。 这个简单的绘制和渲染立方体的程序的运行结果如图3.4。 图3.4 首先我们定义下边两个全局变量来保存立方体的顶点和索引数据：IDirect3DVertexBuffer9 VB = 0;IDirect3DIndexBuffer9 IB = 0; 下一步，我们定义两个全局常量，由它们来指定我们的屏幕大小：const int Width = 800;const int Height = 600; 接下来定义我们的顶点结构以及结构中顶点的格式。在这个例子中顶点结构只保存顶点的位置信息：1234567891011struct Vertex&#123; Vertex()&#123;&#125; Vertex(float x, float y, float z) &#123; _x = x; _y = y; _z = z; &#125; float _x, _y, _z; static const DWORD FVF;&#125;;const DWORD Vertex::FVF = D3DFVF_XYZ; 让我们把它迁移到框架程序（见1.53节）上。Setup函数创建顶点和索引缓存，锁定它们，把构成立方体的顶点写入顶点缓存，以及把定义立方体的三角形的索引写入索引缓存。然后把摄象机向后移动几个单位以便我们能够看见在世界坐标系中原点处被渲染的立方体。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889bool Setup()&#123; // 创建顶点、索引缓存 Device-&gt;CreateVertexBuffer( 8 * sizeof(Vertex), D3DUSAGE_WRITEONLY, Vertex::FVF, D3DPOOL_MANAGED, &amp;VB, 0); Device-&gt;CreateIndexBuffer( 36 * sizeof(WORD), D3DUSAGE_WRITEONLY, D3DFMT_INDEX16, D3DPOOL_MANAGED, &amp;IB, 0); // 向立方体的顶点缓存填充数据 Vertex* vertices; VB-&gt;Lock(0, 0, (void**)&amp;vertices, 0); // vertices of a unit cube vertices[0] = Vertex(-1.0f, -1.0f, -1.0f); vertices[1] = Vertex(-1.0f, 1.0f, -1.0f); vertices[2] = Vertex( 1.0f, 1.0f, -1.0f); vertices[3] = Vertex( 1.0f, -1.0f, -1.0f); vertices[4] = Vertex(-1.0f, -1.0f, 1.0f); vertices[5] = Vertex(-1.0f, 1.0f, 1.0f); vertices[6] = Vertex( 1.0f, 1.0f, 1.0f); vertices[7] = Vertex( 1.0f, -1.0f, 1.0f); VB-&gt;Unlock(); // 定义立方体的三角形 WORD* indices = 0; IB-&gt;Lock(0, 0, (void**)&amp;indices, 0); // 前面 indices[0] = 0; indices[1] = 1; indices[2] = 2; indices[3] = 0; indices[4] = 2; indices[5] = 3; // 背面 indices[6] = 4; indices[7] = 6; indices[8] = 5; indices[9] = 4; indices[10] = 7; indices[11] = 6; // 左面 indices[12] = 4; indices[13] = 5; indices[14] = 1; indices[15] = 4; indices[16] = 1; indices[17] = 0; // 右面 indices[18] = 3; indices[19] = 2; indices[20] = 6; indices[21] = 3; indices[22] = 6; indices[23] = 7; // 顶部 indices[24] = 1; indices[25] = 5; indices[26] = 6; indices[27] = 1; indices[28] = 6; indices[29] = 2; // 底部 indices[30] = 4; indices[31] = 0; indices[32] = 3; indices[33] = 4; indices[34] = 3; indices[35] = 7; IB-&gt;Unlock(); // 照相机位置（视图矩阵） D3DXVECTOR3 position(0.0f, 0.0f, -5.0f); D3DXVECTOR3 target(0.0f, 0.0f, 0.0f); D3DXVECTOR3 up(0.0f, 1.0f, 0.0f); D3DXMATRIX V; D3DXMatrixLookAtLH(&amp;V, &amp;position, &amp;target, &amp;up); Device-&gt;SetTransform(D3DTS_VIEW, &amp;V); // 投影矩阵 D3DXMATRIX proj; D3DXMatrixPerspectiveFovLH( &amp;proj, D3DX_PI * 0.5f, // 90 - degree (float)Width / (float)Height, 1.0f, 1000.0f); Device-&gt;SetTransform(D3DTS_PROJECTION, &amp;proj); // 渲染状态（填充模式：框架填充） Device-&gt;SetRenderState(D3DRS_FILLMODE, D3DFILL_WIREFRAME); return true;&#125; Display方法有两个任务；它必须更新场景并且紧接着渲染它。既然想旋转立方体，那么我们将对每一帧增加一个角度使立方体能在这一帧旋转。对于这每一帧，立方体将被旋转一个很小的角度，这样我们看起来旋转就会更平滑。接着我们使用IDirect3DDevice9::DrawIndexedPrimitive方法来绘制立方体。123456789101112131415161718192021222324252627282930313233343536373839bool Display(float timeDelta)&#123; if( Device ) &#123; // 旋转立方体 D3DXMATRIX Rx, Ry; // x轴旋转45弧度 D3DXMatrixRotationX(&amp;Rx, 3.14f / 4.0f); // 每一帧中增加y轴的弧度 static float y = 0.0f; D3DXMatrixRotationY(&amp;Ry, y); y += timeDelta; //当y轴旋转2周时，重新回到0弧度 if( y &gt;= 6.28f ) y = 0.0f; // 结合x轴与y轴的旋转矩阵 D3DXMATRIX p = Rx * Ry; Device-&gt;SetTransform(D3DTS_WORLD, &amp;p); // 清空目标缓存和深度缓存（用0xffffffff, 1.0f） Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0xffffffff, 1.0f, 0); Device-&gt;BeginScene(); // 开始绘制场景 Device-&gt;SetStreamSource(0, VB, 0, sizeof(Vertex)); // 设置资源流 Device-&gt;SetIndices(IB); // 设置索引缓存 Device-&gt;SetFVF(Vertex::FVF); // 设置顶点格式 // 利用索引缓存绘制 Device-&gt;DrawIndexedPrimitive(D3DPT_TRIANGLELIST, 0, 0, 8, 0, 12); Device-&gt;EndScene(); // 结束绘制场景 Device-&gt;Present(0, 0, 0, 0); // 翻转表面 &#125; return true;&#125; 最后，我们释放使用过的所有内存。这意味着释放顶点和索引缓存接口：12345void Cleanup()&#123; d3d::Release&lt;IDirect3DVertexBuffer9*&gt;(VB); d3d::Release&lt;IDirect3DIndexBuffer9*&gt;(IB);&#125;]]></content>
      <categories>
        <category>Direct3D</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图形学习步骤]]></title>
    <url>%2F2019%2F04%2F11%2Fgraphics-learn-step%2F</url>
    <content type="text"><![CDATA[3D图形学分3大块的学习内容:a.空间几何数学: 空间几何变换, 加速算法, 多边形技术, 曲线和曲面, 相交测试, 碰撞测试。b.光照着色系统: 光照, 纹理贴图, 高级象素着色光照, 艺术性渲染.c.程序技术性应用: 公告板, 精灵, 天空盒, 体绘制, 材质系统, 场景图, 渲染队列 在实际学习过程中,3个部分相互制约,故不能单方面突进,应保持一种平衡发展,使得相互促进,深化理解,达到比较流畅的学习曲线. 相对重要性以a,b,c序减(时间将无情淘汰现有的程序技术性应用),深刻掌握图形学基础才是王道。 3个部分都略有小成后,大量快速阅读网上各方面的杂家资料,应用基础知识去分析理解,在短时间内掌握各种程序性技巧。 再次通观全局基础,遍览所有细节,以图有更深的理解. 如何学习API (OpenGL/Direct3D等)首先，我认为API是工具，不是本质，OpenGL/Direct3D的本质是图形学,而不是OpenGL/Direct3D的本身,API的本身只是一些Interface而已.如果你明白图形学的原理.那么你很容易这些接口的作用,以及为什么要有这些接口的存在.所以,我要说的第一点是:你要学习3D编程,不是学会了OpenGL/Direct3D就可以了。甚至会不会这些API都不是那么的重要(虽然这么说,或许很多人不太赞同).最重要的,最根本的是,你要明白这些API背后的图形学的原理—-因为那才是根本中的根本. 下面我来介绍我对API学习的看法. 我认为API的学习有两种方法:一是正向学习.二是反向学习. 一:正向学习,所谓的正向学习,就是学习API的本身.我觉得这种方法是一种Brute Force行为.不是很好.我们只要看看API的特性,有那些部分.就可以了。比如学习Direct3D的时候,我们要知道它如何初始化,以及它和操作系统的结合.它在Direct3D8里引入了VS/PS.最后就是创建一个Direct3D应用的步骤和方法.这些就足够了。要不然.Direct3D那么多的函数,一个几十个参数。每一个都会要了我的命. 正向学习的第二个作用就是你在熟悉了图形学和大概了解了API后,有空就来看看API的细节,然后思索一下API里提供的一些特性对你的程序有什么作用.比如Direct3D里的Two Side Stencil.OpenGL里的TextureCombine等。 二:逆向学习.这是根本的方法,到了这一步,你就可以真正的算是图形学入门了。这要求你要有一定的图形学基础.比如,你现在开始做一个demo.你预计你的demo里有一堆眩眩的效果,当然你也要明白你的这些眩眩的效果要怎么实现的.然后你去找API里对应的功能,我想如果你的想法正常,一般的功能在Direct3D/OpenGL里应该都会有的.当然你也会碰到你想要的功能在这些API里没有,但是这不重要,重要的是你又学到新东西了—-这个特性在XX API里不支持。 通常我是采用先正向,再逆向,同时再进行正向学习的方法.希望以上的建议,对各位初学者有一定的帮助. 关于计算机图形学的学习引言什么是计算机图形学？ 本文尽量避免给它做严格的定义，但是通常来说，计算机图形学是数字图象处理的逆过程，这只是一个不确切的定义，后面我们会看到，实际上，计算机图形学、数字图象处理和计算机视觉在很多地方的区别不是非常清晰的，很多概念是相通的。计算机图形学是用计算机来画东西的学科，数字图象处理是把外界获得的图象用计算机进行处理的学科。如何学习计算机图形学呢？除了计算机图形学的基础知识以外，你还需要有以下的知识。 英语， 你一定要把英语学好，如果你想学习计算机图形学的话，尽量看英文的书籍和资料 数学， 计算机图形学里面的数学用的比较多，，我们可以列举一些常用的：高等数学，数值分析，微分几何，拓扑，概率， 插值理论，（偏）微分方程… 物理， 如果你要进行基于物理的建模，一些物理理论是要学习的：力学（运动学，动力学，流体力学…），光学，有限元… 编程语言： C或C++是计算机图形学最通用的‘普通话’， 数据结构： 你需要数据结构来描述你的图形对象，除了通用的链表、树等数据结构外，图形学还有自己特殊的数据结构 其他类别： 有的时候你需要其他学科的知识，根据你的需要去学习吧 上面列举的不是你必须学习的东西，而是计算机图形学可能会用到的东西，一定要记住，不要指望通过一本教材就学会计算机图形学，它比你想象的要复杂的多。 图形学的问题每个学科都有自己学科的特定问题，图形学要解决的是如何画出图来，得到需要的效果，当然这是图形学最大的一个问题。在开始学习计算机图形学的时候，找一本简单的书看，对计算机图形学有个大概的认识，你就可以开始图形学之旅了： OpenGL Programming Guide: The Official Guide to Learning OpenGL, Version 1.4, Fourth EditionOpenGL SuperBible (3rd Edition) 是比较好的学习计算机图形学的入门教材，在练中去学，一开始就去啃 Foley的Computer Graphics: Principles and Practice, Second Edition in C不是好主意，会看的一头雾水，一本什么都讲的书的结果往往是什么都没讲清楚。当你把OpenGL的基本内容掌握之后，你对图形学就有了大概的了解了 那么下面你可以来学习一下计算机图形学的数据结构和算法，下面的书比较适合Joseph O’Rourke 的Computational Geometry in C，书里面有C的源代码，讲述简单，清晰，适合程序员学习 总的来说，计算机图形学涉及到2大部分：建模和渲染 建模你想画一个东西，首先要有它的几何模型，那么这个几何模型从什么地方来呢？下面的书很不错的：Gerald Farin 的Curves and Surfaces for CAGD: A Practical Guide 这本书算是CAGD (计算机辅助几何设计)的经典图书，CAGD方面的全貌，还有2本很好的讲述曲面的书Bezier和Nurbs的书 Les A. Piegl, Wayne Tiller 的The Nurbs Book书里面有NURBS曲线、曲面的程序伪代码，很容易改成C的，书讲的通俗、易懂，但是你要有耐心看的：） 曲线与曲面的数学这本书是法国人写的中文翻译版，里面还有Bezie本人写的序J，翻译的很不错的，看了你就掌握Bezier曲面技术了注意：在后面会有这样的章节，标明里面是我认为的一些高级话题，跳过他们不影响你学习计算机图形学，但是要学好就要注意了，呵呵还有其他的一些造型技术，比如：隐式曲面(Implicit Surface)的造型：就是用函数形式为F( x ,y ,z ) = 0的曲面进行造型，这样的造型技术适合描述动物器官一样的肉乎乎的东西，有2本书推荐大家Jules Bloomenthal编辑的Introduction to Implicit Surfaces，是一本专著，讲述了Implicit Surface建模型(Modeling)，面片化(Polygonization)，渲染(Rendering)的问题Luiz Velho 的 Implicit Objects Computer Graphics 也是一本专著，讲述个更新的一些进展 细分曲面（Subdivision Surface）造型当用NURBS做造型的时候，曲面拼接是复杂的问题，在动画的时候，可能产生撕裂或者褶皱，Subdivision Surface用来解决这个问题Joe Warren的Subdivision Methods for Geometric Design: A Constructive Approach就是这方面的专著 从实际物体中得到造型，现在的技术可以用三维扫描仪得到物体表面的点，然后根据这些点把物体的表面计算出来，称为重建(Reconstruction)，因为这些技术之在文章中论述，所以我们省略对它的描述下面还是一个高级话题在你的几何模型做好之后，有一些问题需要对这个模型进一步处理，得到适合的模型，当面片很多的时候，或者模型很复杂的时候，需要对几何模型进行简化，才可以满足一些实时绘制的需要，这个技术叫做层次细节（LOD-Level of Detail）。下面的书就是讲这个的：David Luebke编著的 Level of Detail for 3D Graphics 渲染有了模型，怎么把这个几何模型画出来呢？这个步骤就是渲染如果你看了上面的OpenGL的书，那么你就知道一些渲染的知识了，但是别高兴的太早，OpenGL使用的是局部光照模型（Local Illumination Model），不要被这个词吓住了 Local illumination Model指的是在做渲染的时候只考虑光源和物体之间的相互作用，不考虑物体和物体之间的影响，所以OpenGL不支持阴影，一个（半）透明物体的效果..，这些需要考虑物体之间的影响才可以实现。 OpenGL本身不支持，但是通过一些方法可以实现的，用Google搜索一下Shadow Volume, OpenGL就找到答案啦 Global Illumination Model 这类模型考虑的就比较全啦。现在关于Global Illumination的技术有3大类，具体的技术就不在这里介绍了，如果想了解，可以联系我，大家一起讨论： 光线追踪(Ray Tracing)关于Ray Tracing的好书有2本：Andrew Glassner 的An Introduction to Ray tracingGlasser是图形界的名人，这本书也是Ray Tracing的经典R. Keith Morley, Peter Shirley 的Realistic Ray Tracing, Second Edition这本书第一版是伪代码，第二版是C代码。它的结构不是很清楚，虎头蛇尾的感觉。辐射度(Radiosity)关于Radiosity的好书有4本：Michael Cohen 的Radiosity and Realistic Image Synthesis ， Cohen获得SIGGRAPH 1998计算机图形学成就奖，他把Radiosity变成实际可用，现在Cohen在MSR图形 http://research.microsoft.com/~cohen/CohenSmallBW2.jpg Francois X. Sillion的Radiosity and Global Illumination ， Sillion是法国人，他的主要研究方向是Radiosity，这本书写的很不错的，非常清晰 Philip Dutre 的新书Advanced Global Illumination ，看起来还不错，刚拿到手，还没看，呵呵，所以不好评价 Ian Ashdown的Radiosity: A Programmer’s Perspective Photon mappingHenrik Wann Jensen的Realistic Image Synthesis Using Photon MappingHenrik Wann Jensen是Photon mapping技术的发明者 这些也是图形学吗？ 图形和图象的区别模糊了非真实性图形学（Non-Photorealistic Graphics）真实性不是计算机图形学的唯一要求，比如：你给我画一个卡通效果的图出来，或者我要用计算机画水彩画怎么办？或者：把图象用文字拼出来怎么做？，解决这些问题要用到非真实性图形学， 好书继续推荐！！！Bruce Gooch, Amy Ashurst Gooch的 Non-Photorealistic Rendering 体图形学(Volume Graphics)用CT机做很多切片（比如头骨），那么能通过这些切片得到3D的头骨吗？Volume Graphics就是解决这样的问题的Min Chen 编著的Volume Graphics上面的2个图形学技术就和图象的界限不明显了，实际上他们是图形图象的综合 还有其他的书吗Graphics Gems I ~ V，一大帮子人写的书，包括研究人员，程序员…有计算机图形学的各种数据结构，编程技巧 Tomas Akenine-Moller 等人编著的Real-Time Rendering (2nd Edition)许多最新的计算机图形学进展 David Ebert等人的Texturing &amp; Modeling: A Procedural Approach, Third Edition讲述如何通过程序实现纹理、山、地形等图形学要素F. Kenton Musgrave号称分形狂(Fractal Mania)Ken Perlin就是Perlin噪声的发明者，用过3d软件的人对Perlin Noise不会陌生的 关于图形学的特定对象，有特定的专题图书，Evan Pipho Focus On 3D Models,对于图形学的常用模型格式，进行了讲解Trent Polack的 Focus On 3D Terrain Programming ，讲地形的Donald H. House 的Cloth Modeling and Animation ，讲布料的Nik Lever的Real-time 3D Character Animation with Visual C++ ，讲角色动画的 Richard Parent的 Computer Animation: Algorithms and Techniques，当然是讲动画的啦，呵呵。David H. Eberly的3D Game Engine Design : A Practical Approach to Real-Time Computer Graphics ，有代码的啊！呵呵：） 最后，没事情的时候，看看下面的书吧Alan H. Watt， 3D Computer Graphics (3rd Edition) James D. Foley等人的 Computer Graphics: Principles and Practice in C (2nd Edition) ，这本圣经没事的时候再看吧，呵呵 游戏程序员养成计划与玩游戏相比,写游戏要复杂上千万倍,除了需要掌握通用的编程技巧以外，还要有相当的图形学，物理，数学基础，特别是在国内，由于相关资料的缺乏，更是让初学者无从下手。下面总结了一些入门方法和比较容易入手的资料。 首先你要精通一门高级语言，比如C++或者C#，其次，要有良好的英文阅读能力。对游戏开发者来说英文阅读能力是最重要也是最基本的工具之一，因为你遇到的大部分资源都将是英文的，不要总等着别人为你翻译。慢慢尝试着阅读英文资料，你会发现其实也并没有那么难:) 刚开始，你要做的就是选择一门图形API，一般就是DirectX或者OpenGL之间选一个。如果考虑到跨平台，那么OGL是首选. 如果只在ms的平台，则DX是首选。我对OGL并不是很了解，所以下面大部门资料都是和DX相关的。 当然，作为准备工作之一，你首先要到DirectX Develop Center下载最新版的DirectX SDK。 入门书籍非常重要，推荐&lt;&gt;（好像去年出了中文版）也就是传说中的龙书，这可以说是最好的DX入门教材，Frank Luna从浅入深，讨论了DX的方方面面。另外再配上&lt;&lt; Advanced 3D Game Programming With DirectX 9.0&gt;&gt;，书名虽然是advanced，但实际上没有多少advanced级别的内容。看完这两本书，你基本上已经对DirectX比较熟悉了。如果你希望学习XNA，也是一样的，毕竟XNA是以DX为基础。 不要一开始就看图形学的书，这个时候你对图形编程还没有一个基本的感性认识，因此八成看的云里雾里。不要以网上的教程和论坛提问作为主要学习途径，找一本好书，系统学习，效率才最高。不要马上看SDK里的例子，很多图形学的基本原理仅仅通过读代码是不会明白的。某些年代太过久远的书就不要看了，比如《windows游戏编程大师技巧》（总看到有人在找这本书）。有人说基本的思想总是不变的，可惜对于现代GPU来说，很多早期的技术和优化技巧早就过时了。图形编程是发展的非常快的技术，看看GPU的发展速度，1~2年就是一代产品的革新。 好了，入门之后，是你巩固和拓展视野的阶段。现在看计算机图形学就比较合适了。吐血推荐&lt;&gt;,这本书算得上是所有图形程序员的必读书籍和参考手册了。最近刚出了第三版。可惜国内只有第二版，稍微有点老，如果实在找不到第三版，还是值得一读。国内其他所有以图形学命名的书都有一个共同点：枯燥，过时。只需看看其中二维三维变换和曲线曲面表示的部分即可。如果这个时候发现你当年数学没有学好，那么有三本数学书是为游戏程序员量身定制的：&lt;&gt;, &lt;&gt;和&lt;&gt;，第一本书有中文版，最后一本则是08年才出的新书。 其实入门之后，就没有固定的学习路线了，最好根据你感兴趣的方向来学习。 Shader方面：《Cg_tutorial》和《The Complete Effect and HLSL Guide》都是不错的入门材料，当然还有SDK文档。&lt;&gt;有大量入门的例子。&lt;&gt;详细介绍了各种光照模型和技术。&lt;&gt; 1~3册肯定是必读的，虽然有1，2有中文版，但某些翻译并不是很理想，强烈建议直接看英文版。ShaderX系列也是很经典的系列，每年出版一本，包含了最新的实时渲染技术，如今已经出了第6册了。不过网络上只能找到1~3册。1，2册大部分shader都是用asm写的，不过看懂原理，转换为HLSL也并不难。另外Nvidia SDK和ATI SDK也是学习shader的重要资源。最后还有刚出的&lt;&lt; Programming Vertex, Geometry, and Pixel Shaders&gt;&gt; 地形：&lt;&gt;非常全面的讨论了关于地形渲染的各种技术，至少应该把第5~9章都浏览一遍。之后便可以 到virtual terrain查阅近期的地形渲染技术。 模型导入和动画：&lt;&gt;，仅此一本足以。 物理：&lt;&gt;和&lt;&gt;都不错。&lt;&gt;是碰撞检测方面最好的书，可惜目前还没有电子版。LOD：&lt;&gt;Ray tracing:&lt;&lt; Physical-Based Rendering - From Theory to Implementation&gt;&gt;引擎设计：说实话，这方面还没有特别好的书，大概越是核心的内容，越少有人愿意写吧。&lt;&gt;只有第三章值得一读。&lt;&gt;可以选部分感兴趣的章节看看，不过总的来说，讲的比较浅。AI：&lt;&gt;非常不错，好像还有中文版，备选&lt;&gt;。当然&lt;&gt;系列也是必读作品，不过目前网络上只有1～2册。综合：&lt;&gt;系列，不过由于内容涉及的过于广泛，文章质量参差不齐，选择性阅读就可以了。历年GDC, Gamefest t,Siggraph等大型会议的paper也是应该关注的。除了书以外，再推荐一些不错的网络资源：www.GameDev.NET 除了大量教程以外，论坛里多年累计下来的内容保罗万象。好好利用论坛搜索，你会发不管你多厉害，那里总有一些比你强大的人在很久以前就遇到了和你同样的问题，并且给出了解决方案。Nvidia和ATI的开发者中心creators.xna.com XNA官方网站www.gamasutra.com 与GameDev类似www.beyond3d.com 这里的除了讨论软件以外，还能看到对硬件构架的分析www.ziggyware.com 最好的XNA教程网站www.gameres.com 国内唯一比较专业的游戏编程网站，可惜和GameDev相比就显得太寒碜了http://imgtec.eetrend.com/www.alanzucconi.com/category/shader/http://shaderbits.com/blog/tiling-within-subuv-or-volume-textureshttp://www.iquilezles.org/www/index.htmhttp://www.opengpu.org/forum.php?mod=forumdisplay&amp;fid=21https://www.gamedev.net/http://www.flipcode.com/archives/Light_Mapping_Theory_and_Implementation.shtmlhttp://www.realtimerendering.com/http://kesen.realtimerendering.com/]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[标准光照模型]]></title>
    <url>%2F2019%2F04%2F10%2Fdiffuse%2F</url>
    <content type="text"><![CDATA[基本光照模型中漫反射部分的计算公式：$c{diffuse}=(c{light} \cdot m{diffuse})max(0, \vec{n} \cdot I)$从公式可以看出，要计算漫反射需要知道4个参数：入射光线的颜色和强度$c{light}$，表面发现$\vec{n}$以及光源方向$I$。为了防止点击结果为赋值，我们需要使用max操作，而CG提供了这样的函数。在本例中，使用CG的另一个函数可以达到同样的目的，即saturate函数。函数：saturate(x)参数：x：用于操作的标量或矢量，可以是float、float2、float3等类型。描述：把x截取在[0,1]范围内，如果x是一个矢量，那么会对它的每一个分量进行这样的操作。 逐顶点光照123456789101112131415161718192021222324252627282930313233343536373839Shader "Unity/Diffuse Vertex"&#123; Properties &#123; _Diffuse ("Diffuse", Color)=(1,1,1,1) // 材质的漫反射系数 _Specular("Specular", Color)=(1,1,1,1) // 高光系数 &#125; SubShader&#123; Pass&#123; Tasg&#123;"LightMode"="ForwardBase"&#125; // 前向渲染，所有光源都在一个着色器中进行 &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Diffuse; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; &#125;; struct v2f &#123; float4 pos : SV_POSITION; fixed3 color : COLOR; &#125;; v2f vert(a2v v)&#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); float3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz; // 环境光 float3 worldNormal = normalize(mul(v.normal, (float3x3)_World2Object)); // 世界法线 float3 lightNormal = normalize(_WorldSpaceLightPos0.xyz); // 光的方向 float3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, lightNormal)); o.color = diffuse + ambient; return o; &#125; fixed4 frag(v2f o) : COLOR &#123; return fixed4(o.color,1); &#125; &#125; Fallback "Diffuse"&#125; 顶点着色器最基本的任务就是把顶点位置从模型空间转换到裁剪空间中，因此我们需要使用Unity内置的模型*世界*投影矩阵UNITY_MATRIX_MVP来完成这样的坐标转换。通过Unity的内置变量UNITY_LIGHTMODEL_AMBIENT得到了环境光部分。然后，就是真正计算漫反射光照的部分。为了计算慢反射光照我们需要知道4个参数。在前面的步骤中，我们已经知道了材质的漫反射颜色_Diffuse以及顶点发现v.normal。我们还需知道光源的颜色和强度信息以及光源方向。Unity提供给我们一个内置变量_LightColor0来访问该Pass处理的光源的颜色和强度信息（注意，想要得到正确的值需要定义合适的LightMode标签），而光源方向可以由_WorldSpaceLightPos0来得到。需要注意的是，这里对光源方向的计算并不具有通用性。这里，我们假设场景中只有一个光源且该光源的类型是平行光。但如果场景中有多个光源并且类型可能是点光源等其他类型，直接使用_WorldSpaceLightPos0就不能得到正确的结果。 半兰伯特光照模型$c{diffuse}=(c{light}\cdot m_{diffuse})(\alpha (\vec {n}\cdot I)+\beta)$可以看出，与原兰伯特模型相比，半兰伯特光照模型没有使用max操作来防止$\vec {n}$ Blinn-Phong光照模型Blinn模型计算高光反射的公式如下： $c_{specular}=(c_{light} \cdot m_{specular})max(0,\vec{n} \cdot \vec{h})^{m_{glass}}$]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new delete malloc free]]></title>
    <url>%2F2019%2F04%2F10%2Fnew-delete-malloc-free%2F</url>
    <content type="text"><![CDATA[正文每个程序在执行时都会占用一块可用的内存空间，用于存放动态分配的对象，此内存空间成为自由存储区或堆。 new和delete用法如下几行代码： 123int *pi = new int;int *pi = new int();int *pi = new int(1024); 第一行这个new表达式在自由存储区中分配创建了一个整型对象，并返回一个指向该对象的地址来初始化指针pi。第二行将指针pi指向的地址的值进行了初始化为0。第三行初始化为1024.当动态创建的对象用完后必须释放内存，避免造成内存泄漏，可以用delete来完成，new和delete是成对使用的，如下命令释放pi指向的int型对象所占用的内存空间：1delete pi; 此时pi尽管没有定义，但仍然存放了呃它所指向对象的地址，然而pi所指向的内存已经被释放，因此pi不再有效。建议一旦删除指针所指向的对象，立即将指针置为0，这样就清楚的表明指针不再指向任何对象。1p = NULL; 值得注意的是当执行下列表达式：12int pi = &amp;i;delete pi; 编译器一般不会报错，因为编译器通常不能断定一个指针指向什么类型的对象，所以尽管这个语句是错误的，但在大多数编译器上仍然能通过。C++中允许动态创建const对象：1const int *pi = new const int(1024); 动态创建的const对象必须进行初始化，并且进行初始化后的值不能在改变。当创建一个动态数组对象和进行内存释放时，执行以下语句：1234int *pi = new int[]; // pi所指向的数组未初始化int *pi = new int[n]; // pi指向长度为n的数组，未初始化int *pi = new int[](); // 指针pi所指向的地址初始化为0delete [] pi; // 回收pi所指向的数组 malloc和free的用法两个函数的原型如下，他们都在头文件stdlib.h中声明。12void *malloc(size_t size);void free(void *pointer); 示例代码如下：12int *p = (int *)malloc(100); // 指向整型的指针p指向一个大小为100字节的内存的地址int *p = (int *)malloc(25*sizeof(int)); // 指向整型的指针p指向一个25个int整型空间的地址 因为malloc()函数的返回值类型为void *，所以需要在函数前面进行相应的强制类型转换。当int占4个字节内存时，上述的两个语句代码获得的内存空间大小是相同的。分配内存后需要验证内存是否分配成功，完成后free()释放内存，完整语句如下。1234int *p = (int *)malloc(int);if (pi == NULL) printf("Out of memory!\n");free(p); 另外两个分配内存的函数：calloc和realloc，他们的原型如下：12void *calloc(size_t num_elements, size_t element_size);void realloc(void *tr, size_t new_size); malloc和calloc间的主要区别在于后者在返回指向内存的指针之前把它初始化为0。另一个区别是calloc的参数包括所需的元素的数量和每个元素的字节数。relloc函数用于修改一个原先已经分配的内存块大小。可以使一块内存扩大或缩小，如果扩大内存，则原来的内存块保持不变，在内存尾部增加新的内存块，切不进行初始化。如果缩小内存，则原来内存块从尾部进行删减。如果原先的内存块无法扩充，则新开辟一块内存，并复制原先的内存的内容，原先内存块失效无法再进行访问。 new和malloc的区别属性new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持c。 参数使用new操作符申请内存分配时无须指定内存的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。 返回类型new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符号类型安全的操作符。而malloc内存分配成功则返回void ，需要通过强制类型转换将void 指针转换成我们需要的类型。 分配失败new内存分配失败时，会抛出bac_alloc异常。malloc分配内存失败时会返回NULL。 自定义类型new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。 重载C++允许重载new/delete操作符，malloc不允许重载。 内存区域new操作符从自由存储区（free store）上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统锁维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区不等于堆，如上所述，布局new就可以不位于堆中。 在C++/C#中，内存区分为5个区，分别是堆、栈、自由存储区、全局/静态存储区、常量存储区；在C中，内存区分为堆、栈、全局/静态存储区、常量存储区；]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Protocol Buffer]]></title>
    <url>%2F2019%2F04%2F09%2Fprotocol-buffer%2F</url>
    <content type="text"><![CDATA[定义一个消息类型123456message SearchRequest&#123; required string query = 1; optional int32 page_number = 2; optional int32 result_per_page = 3;&#125; 该消息定义了三个字段，两个int32类型和一个string类型的字段，每个字段由字段限制，字段类型，字段名和Tag四部分组成，对于C++，每一个.proto文件经过编译之后都会对应的生成一个.h和一个.cc文件 字段限制字段限制共有3类required:必须赋值的字段optional:可有可无的字段repeated:可重复字段（变长字段），类似于数组由于一些历史原因，repeated字段并没有想象中那么高效，新版本中允许使用特殊的选项来获得更高效的编码： repeated int32 samples = 4 [packet=true]; Tags消息中的每一个字段都由一个独一无二的数值类型的Tag.1到15使用一个字节编码，16到2047使用2个字节编码，所以应该将Tags 1到15留个频繁使用的字段。可以指定的最小的Tag为1，最大位$2^29$-1或536,870,911，但不能使用19000到19999之间的值，这些值是预留给protocol buffer的。 Google Protocol Buffer的EncodingProtobuf序列化所生成的二进制消息非常紧凑，这得益于Protobuf采用的非常巧妙的Encoding方法。考擦消息结构之前，让我首先要介绍一个叫Varint的术语。Varint是一种紧凑的表示数字的方法。它用一个或这个字节来表示一个数字，值越小的数字使用越小的字节数。这能减少用来表示数字的字节数。比如对于int32类型的数字，一般需要4个byte来表示。但是采用Varint，对于很小的int32类型的数字，则可以用1个byte来表示。大的数字则需要5个byte表示。从统计的角度来说，一般不会所有的消息中的数字都是大数，因此大多数情况下，采用Varint后，可以用更少的字节数来吧iaoshi数字信息。下面就详细介绍一下Varint。Varint中的每个byte的最高位bit有特殊的含义，如果该位为1，表示后续的byte也是该数字的一部分，如果该位为0，则结束。其他的7个bit都用来表示数字。因此小于128的数字都可以用一个byte表示。大于128的数字，比如300，会用两个字节来表示：1010 1100 0000 0010下图演示了Google Protocol Buffer如何解析两个bytes。注意到最终计算前将两个byte的位置相互交换过一次，这是因为Google Protocol Buffer字节序采用little-endian的方式。 消息经过序列化会成为一个二进制数据流，该流中的数据为一系列的Key-Value对。如下图所示：采用这种Key-Pair结构无需使用分隔符来分割不通的Field。对于可选的Field，如果消息中不存在该Field，那么在最终的Message Buffer中就没有该field，这些特性都有助于节约消息本身的大小。假如我们生成如下的一个消息Test1： Test1.id = 10; Test1.str = &quot;hello&quot;; 则最终的Message Buffer中有两个Key-Value对，一个对应消息中的id；另一个对应str。Key用来标识具体的field，在解包的时候，Protocol Buffer根据Key就可以知道相应的Value应该对应于消息中那一个Field。Key的定义如下： (field_number&lt;&lt;3)|wire_type 可以看到Key由两部分组成。第一部分是field_number，比如消息Im.helloworld中的field id的field_number为1.第二部分为wire_type。表示Value的传输类型。 Wire Type可能的类型如下表所示： Type Meaning Used For 0 Varint int32,int64,uint32,uint64,sint32,sint64,bool,enum 1 64-bit fixed64,sfixed64,double 在我们的例子中，field id所采用的数据类型为int32，因此对应的wire type为0。可以看到Type 0所能表示的数据类型中有int32和sint32这两个非常类似的数据类型。Google Protocol Buffer区别它们的主要意图也是为了减少encoding后的字节数。在计算内，一个负数一般会被表示为一个很大的整数，因为计算机定义负数的符号位为数字的最高位。如果采用Varint表示一个负数，那么一定需要5个byte。为此Google Protocol Buffer定义了sint32这种类型，采用zigzag编码。Zigzag编码用无符号数来表示有符号数字，正数和负数交错，这就是zigzag这个词的含义了。如图所示： 使用zigzag编码，绝对值小的数字，无论正负都可以采用较少的byte来表示，充分利用了Varint这种技术。其他的数据类型，比如字符串则采用类似数据库中的varchar的表示方法，即用一个varint表示长度，然后将其余部分紧跟在这个长度部分之后即可。通过以上对protobuf Encoding方法的介绍，想必已经发现protobuf消息的内容效，适合网络传输。对于消息Test1，用Protobuf序列化后的字节序为：08 65 12 06 48 65 6C 6C 6F 77而如果用XML，则类似这样31 30 31 3C 2F 69 64 3E 3C 6E 61 6D 65 3E 68 656C 6C 6F 3C 2F 6E 61 6D 65 3E 3C 2F 68 65 6C 6C6F 77 6F 72 6C 64 3E一共55个字节，这些奇怪的数字需要稍微解释一下，其含义用ASCII表示如下： 101 hello 封解包的速度首先我们来了解一下XML的封解包过程。XML需要从文件中读取出字符串，在转换为XML文档对象结构模型。之后，在从XML文档对象结构模型中读取指定节点的字符串，最后再将这个字符串转换成指定类型的变量。这个过程非常复杂，其中将XML文件转换为文档对象结构模型的过程通常需要完成词法文法分等大量消耗CPU的复杂计算。反观Protobuf，它只需要简单地将一个二进制序列，按照指定的格式读取到C++对应的结构类型中就可以了。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua hash]]></title>
    <url>%2F2019%2F04%2F09%2Flua-hash%2F</url>
    <content type="text"><![CDATA[一般哈希表处理冲突有两种方式，拉链法和开放地址法。拉链法就是哈希表的每个元素都是一个链表，如果有冲突的键就放在链表里面。而开放地址法是如果遇到了冲突，就在计算一个哈希值，直到没有冲突位置。拉链法的优点就是实现简单，缺点也是有的：链表会导致低的缓存命中率，并且分配链表节点本身也会对内存分配器产生压力（主要是大量小块内存分配会导致碎片），而且有个更严重的问题：不太好估计哈希表的装载因子，因此不太容易判断啥时候需要扩充哈希表。而开放地址法避免了这些问题，首先因为所有节点都存在哈希表里面，因此很容易就能估计装载因子，其次也不会有内存分配的问题，避免了零散碎片或者实现内存池的必要。不过问题是要找到一个新的地址就需要重新计算哈希，是一个负担，而且如果在对应哈希查不到元素也可能并不是没有元素，而只是之前的冲突导致元素不再它的”主位置”，这样就需要更多复杂的判断。解决主位置的问题其实很简单：可以设置一个”墓碑”，删除的时候并不是直接删除，而是设置一个”墓碑”当发现是墓碑的时候，证明该位置曾经是有元素的，这时按照冲突的方式继续查找。总的来说，如果不考虑装载因子，因为要重复搜索哈希表，开放地址法的查找是会比较慢的。Lua是将拉链法和开放地址法结合在了一起。具体的做法是这样的：Lua的哈希表主体是开放地址法，即所有元素都被存放在表中，而不是在链表里。但是，每个元素也的确有一个链表节点。在开始的时候，Lua维护一个”空闲槽指针”这个指针之后的位置一定都是有元素的。当发现冲突的时候，会将空闲槽指针迁移，以找到一个空闲的槽位，然后元素会被放在这个槽位里，并在主位置通过链表的方式链接进来！即对插入而言，Lua的哈希表采用实际上是不计算哈希的开放地址法（随意找一个槽位），而对于查找而言，因为有链表节点的存在，是按照拉链法的方式进行查找的。这种方法利用了两者的优点，又规避了缺陷。这里面其实还是有一些其它可以优化的地方。比如墓碑还是需要的，这用于在主位置找不到以后，得得到后续节点的一个索引。但是通过在插入/删除节点时，挪动后续的节点的方法，就可以省略掉墓碑和对应的遍历操作。另外这种哈希表判断装载因子的方式也很简单—只要空闲槽指针指向表的第一个元素，就意味着表已经满了，这时就需要rehash了。Lua的哈希函数使用的是通常的DJB法，也叫times33，计算简单，不过可能效果不太好，对随机的字符这种方式产生的哈希是比较平均的。]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dictionary]]></title>
    <url>%2F2019%2F04%2F09%2Fdictionary%2F</url>
    <content type="text"><![CDATA[Entry结构体这是Dictionary存放数据的最小单位，调用Add(Key,Value)方法添加的元素都会被封装在这样的一个结构体中。1234567private struct Entry&#123; public int hashCode; // 除符号位以外的31位hashCode值，如果该Entry没有被使用，那么为-1 public int next; // 下一个元素的下标索引，如果没有下一个就为-1 public TKey key; // 存放元素的键 public TValue value; // 存放元素的值&#125; 其它关键私有变量123456789private int[] buckets; // Hash桶private Entry[] entries; // Entry数组，存放元素private int count; // 当前entries的index位置private int version; // 当前版本，防止迭代过程中集合被更改private int freeList; // 被删除Entry在entries中下标index，这个位置是空闲的private int freeCount; // 有多少个被删除的Entry，有多少个空闲的位置private IEqualityComparer&lt;TKey&gt; comparer; // 比较器private KeyCollection keys; // 存放key的集合private ValueCollection values; // 存放Value的集合 Add操作首先我们用图的形式来描述一个Dictionary的数据结构，其中只画出了关键的地方。桶大小为4以及Entry大小也为4的一个数据结构。假设需要执行一个Add操作，dictionary.Add(“a”,”b”)，其中key=”a”，value=”b”。 根据key的值，计算出它的hashCode。我们假设”a”的hash值为6(GetHashCode(“a”)=6)。 通过对hashCode取余运算，计算出该hashCode落在哪一个buckets桶中。现在桶的长度(buckets.Length)为4，那么就是6%4最后落在index为2的桶中，也就是buckets[2]。 接下来将hashCode、key、value等信息存入entries[count]中，因为count位置是空闲的；继续count++指向下一个空闲位置。上图中第一个位置，index=0就是空闲的，所以就存放在entries[0]的位置。 将Entry的下标entryIndex赋值给buckets中对应下标的bucket。步骤3中存放在entries[0]的位置，所以buckets[2]=0。 最后version++，集合发生了变化，所以版本需要+1。只有增加、替换和删除元素才会更新版本。 完成上面Add操作后，数据结构更新成了下图这样的形式。这样是理想情况下的操作，一个bucket中只有一个hashCode没有碰撞的产生，但是实际上是会经常产生碰撞；那么Dictionary类中又是如何解决碰撞的呢。我们继续执行一个Add操作，dictionary.Add(“c”,”d”)，假设GetHashCode(“c”)=6，最后6%4=2。最后桶的index也是2，按照之前的步骤1~3是没有问题的，执行完后数据结构如下图所示。如果继续执行步骤4那么bucket[2] = 1，然后原来的buckets[2]=&gt;entries[0]的关系就会丢失，这是我们不愿意看到的。现在Entry中的next就发挥大作用了。 如果对应的buckets[index]有其它元素已经存在，那么会执行以下两条语句，让新的entry.next指向之前的元素，让buckets[index]指向现在的新元素，就构成了一个单链表。123entries[index].next = buckets[targetBucket];...buckets[targetBucket] = index; 实际上步骤4也就是做一个这样的操作，并不会去判断是不是有其它元素，因为buckets中桶初始值就是-1，不会造成问题。 经过上面的步骤以后，数据结构就更新成了下图这个样子]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表]]></title>
    <url>%2F2019%2F04%2F09%2Fhash%2F</url>
    <content type="text"><![CDATA[散列表（Hash table，也叫哈希表），是根据关键码值（key value）而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。给定表M，存在函数f(key)，对任意给定的关键值key，代入函数后若能得到包含该关键字的记录在表中的地址，则称表M为哈希（Hash）表，函数f（key）为哈希（Hash）函数。 基本概念 若关键字为k，则其值存放在f(k)的存储位置上。由此，不需比较便可直接取得所查记录。称这个对应关系f为散列函数，按这个思想建立的表为散列表。 对不同的关键字可能得到同一散列地址，即$k1 \neq k2$，而f(k1)=f(k2)，这种现象称为冲突（Collision）。具有相同函数值的关键字对该散列函数来说称作同义词。综上所述，根据散列函数f(k)和处理冲突的方法将一组关键字映射到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便成为散列表，这一映射过程称为散列造表或散列，所得的存储位置成散列地址。 若对于关键字集合中的任一个关键字，经散列函数映射到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数（Uniform Hash function），这就是关键字经过散列函数得到一个“随机的地址”，从而减少冲突。 常用方法散列函数能使对一个数据序列的访问过程更加迅速有效，通过散列函数，数据元素将被更快地定位。实际工作需视不通的情况采用不同的哈希函数，通常考虑的因素有： 计算哈希函数所需时间 关键字的长度 哈希表的大小 关键字的分布情况 记录的查找频率 直接寻址法：取关键字或关键字的某个线性函数值为散列地址。即H(key)=key或H(key)=a·key + b，其中a和b为常数（这种散列函数叫做自身函数）。若其中H(key)中已经有值了，就往下一个找，直到H(key)中没有值了，就放进去。 数字分析法：分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构建散列地址，则冲突的几率就会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。 平方取中法：当无法确定关键字中哪几位分布较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为哈希地址。这是因为：平方后中间几位和关键字中每一位都相关，故不同关键字会以较高的概率产生不同的哈希地址。例：我们把英文字母在字母表中的位置序号作为该英文字母的内部编码。例如K的内部编码为11，E的内部编码为05，Y的内部编码为25，A的内部编码为01，B的内部编码为02。由此组成关键字“KEYA”的内部代码为1105201，同理我们可以得到关键字“KYAB”、“AKEY”、“BKEY”的内部编码。之后对关键字进行平方运算后，取出第7位到第9位作为该关键字哈希地址，如下图所示 关键字 内部编码 内部编码的平方值 H(k)关键字的哈希地址 KEYA 11052501 122157778355001 778 KEYB 11250102 126564795010404 795 AKEY 01110525 001233265775625 265 BKEY 02110525 004454315775625 315 折叠法：将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（去除进位）作为散列地址。数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐，然后相加；间界叠加是从一端向另一端分割界来回折叠，然后对齐相加。 随机数法：选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。 除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即H(key)=key MOD p,p &lt;= m。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生同义词。 Hash桶算法说到Hash算法就会想到hash表，一个key通过hash函数运算后可快速得到hashCode，通过hashCode的映射可直接获取Value，但是hashCode一般取值都是非常大的，经常是$2^32$以上，不可能对每个hashCode都指定一个映射。因为这样一个问题，所以将hashCode以分段的形式来映射，把每一段称之为一个Bucket(桶)，一般常见的Hash桶就是直接将结果取余。 处理冲突 开放寻址法：Hi=(H(key)+di)MOD m,i=1,2,…,k(k&lt;=m-1)，其中H(key)为散列函数，m为散列表长，di为增量序列，可有下列3种取法：1.1. di=1,2,3,…,m-1，称线性探测在散列；1.2. $di=1^2,-1^2,2^2,-2^2,…,k^2,-k^2(k&lt;=m/2)$称为二次探测在散列；1.3. di=伪随机数序列，称伪随机探测在散列。 再散列法：Hi=RHi(key),i\1,2,…,k RHi均是不通的散列函数，即在同义词产生地址冲突时计算另一个散列函数地址，直到冲突不再发生，这种方法不易产生“聚集”，但增加了计算时间。 链地址法（拉链法）：这种方法的思路是将产生冲突的元素建立一个单链表，并将头指针地址存储到hash表对应桶的位置。这样定位到Hash表桶的位置后可通过遍历单链表的形式查找元素。 建立一个公共溢出区 查找性能散列表的查找过程基本上和造表过程相同。一些关键码可通过散列函数转换的地址直接找到，另一些关键码在散列函数得到的地址上产生了冲突，需要按处理冲突的方法进行查找。在介绍的三种处理冲突的方法中，产生冲突后的查找仍然是给定值与关键码进行比较的过程。所以，对散列表查找效率的量度，依然用平均查找长度来衡量。查找过程中，关键码的比较次数，取决于产生冲突的多少，产生的冲突少，查找效率就高，产生的冲突多，查找效率就低。因此，影响产生冲突多少的因素，也就是影响查找效率的因素。影响产生冲突多少有以下3个因素： 散列函数是否均匀； 处理冲突的方法； 散列表的装填因子；散列表的装填因子定义为：$\alpha$=填入表中的元素个数/散列表的长度$\alpha$是散列表装满程度的标志因子。由于表长是定值，$\alpha$与“填入表中的元素个数”成正比，所以，$\alpha$越大，填入表中的元素较多，产生冲突的可能性就越大；$\alpha$越小，填入表中的元素较少，产生冲突的可能性就越小。实际上，散列表的平均查找长度是装填因子$\alpha$的函数，只是不同处理冲突的方法有不同的函数。 常见的hash函数MD4MD4(RFC 1320)是MIT的Ronald L.Rivest在1990年设计的，MD是Message Digest的缩写。它适用在32位字长的处理器上用高速软件实现，它是基于32位操作数的位操作来实现的。 MD5MD5(RFC 1321)是Rivest于1991年对MD4的改进版本。它对输入仍以512位分组，其输出是4个32位字的级联，与MD4相同。MD5比MD4来的复杂，并且速度较之要慢一点，但更安全，在抗分析和抗差分方面表现更好 SHA-1SHA1是由NIST NSA设计为同DSA一起使用的，它对长度小于264的输入，产生长度为160bit的散列值，因此抗穷举（bruteforce）性更好。SHA-1设计时基于和MD4相同原理，并且模仿了该算法。 用途文件校验我们比较熟悉的校验算法有奇偶校验和CRC校验，这两种校验并没有抗数据篡改的能力，它们一定程度上能检测出数据传输中信道误码，但却不能防止对数据的恶意破坏。MD5 Hash算法的“数字指纹”特性，使它成为目前应用最广发的一种文件完整性校验和（Checksum）算法，不少Unix系统有提供计算md5 checksum的命令。 数字签名Hash算法也是现代密码体系中的一个重要组成部分。由于非对称算法的运算速度较慢，所以在数字签名协议中，单向散列函数扮演了一个重要的角色。对hash值，又称“数字摘要”进行数字签名，在统计上可以认为与对文件本身进行数字签名是等效的。 鉴权协议如下的鉴权协议又被称作挑战—认证模式：在传输信道是可被侦听，但不可被篡改的情况下，这是一种简单而安全的方法。 MD5、SHA1的破解2004年8月17日，在美国国际密码大会上MD5、HAVAL-128、MD4和RIPEMD等四个著名密码算法的破译结果。2005年宣布破解SHA-1密码。 字符串（ELFhash算法）12345678910111213int ELFhash(char* key)&#123; unsigned long h = 0; while(*key) &#123; h = (h&lt;&lt;4)+*key++; unsigned long g = h &amp; 0xF0000000L; if (g) h ^= g &gt;&gt; 24; h &amp;= ~g; &#125; return h % MOD;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[透明物体的深度写入问题]]></title>
    <url>%2F2019%2F04%2F09%2Falpha-depth-write%2F</url>
    <content type="text"><![CDATA[通常来说，透明物体是不需要写深度的，例如： 透明物体与非透明物体间的渲染不会有问题，因为所有透明物体会在所有非透明物体之后渲染。 大多数情况下，透明物体之间的渲染也不会有问题，因为，所有透明物体按由远及近的顺序渲染，所以不会出现前面的透明物体挡住后面的透明物体，导致后面的透明物体不显示。 但有些情况下，透明物体必须要写深度，例如： 两个透明无间有交叉，如果不写深度，深度则无法正确比较，就会出现遮挡关系错误的现象。 图1为俯视角度看两面片]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AssetBundle基本原理]]></title>
    <url>%2F2019%2F04%2F09%2Fassetbundle-fundamentals%2F</url>
    <content type="text"><![CDATA[概述AssetBundle系统提供了将一个或多个文件存储到Unity能够进行索引和序列化的档案格式的方法，它是Unity用来在应用程序安装之后进行分发和更新非代码内容的首选工具。通过AssetBundle，开发者可以提交更小的程序安装包、最小化运行时内存压力以及根据终端用户设备选择性地加载优化内容。 AssetBundle布局简单来说，一个AssetBundle中包含两部分：数据头和数据段。数据头中含有AssetBundle的相关信息，例如标志符（Identifier）、压缩类型（Compression Type）和配置文件（Manifest）。配置文件是一个以Object名称为键的查找表，表中的每个条目头提供了一个用于标识Object在数据段中的位置的byte索引。在大多数平台上，这个查找表是用平衡查找树实现的，在Windows和OSX衍生平台（包括IOS）上的查找表是使用红黑树实现的。因此，构建配置文件所需的时间随着AssetBundle中的Asset数量而增长的速度大于线性增长。 数据段中含有由序列化AsseBundle中的Asset而生成的原始数据。如果指定了压缩方案为LZMA，所有序列化的Asset会被压缩成一个字节数组中；如果指定了压缩方案为LZ4，不同的Asset的字节数据会被单独压缩；如果没有使用任何压缩，数据段会保留原始的字节流数据。 在Unity5.3之前的版本中，AssetBundle中的Object不能被单独压缩。因此，在5.3之前的版本的Unity中，如果要从已压缩的AssetBundle中读取Object，引擎必须压缩整个AssetBundle。通常情况下，Unity会缓存一份解压后的AssetBundle副本，以此来提高加载性能。 加载AssetBundleAssetBundle可以通过不同的API来加载，这些API会受下面的两种因素的影响而产生不同的行为； AssetBundle使用了LZMA压缩方式或者LZ4压缩方式或者没有进行压缩 进行加载AssetBundle的平台 这些API是： AssetBundle.LoadFromMemory（可选择异步模式）Unity不推荐使用这个API AssetBundle.LoadFromFile（可选择异步模式） AssetBundle.LoadFromStream（可选择异步模式） UnityWebRequest的DownloadHandlerAssetBundle 通过这些API获取的AssetBundle引用可以随意混用，也就是说，通过UnityWebRequest加载的AssetBundle可以兼容通过AssetBundle.LoadFromFile或者AssetBundle.LoadFromMemoryAsync加载的AssetBundle。 AssetBundle.LoadFromMemoryAsync从托管代码的字节数组（C#中的byte[]）中加载AssetBundle。该方法总是将托管代码中的源数据赋值到新分配的连续的内存块中。如果AssetBundle使用了LZM压缩，在赋值过程中AssetBundle会被解压；如果使用了LZ4压缩或者没有压缩，AssetBundle会被逐字复制（be copied verbatim）。 这个API占用内存的峰值至少是他处理的AssetBundle大小的两倍：一份由此API创建在本机内存中的副本和一份传递给此API的位于托管字节数组的副本。通过此API从AssetBundle加载的Asset会在内存中复制3次；在托管代码中的字节数组、本机内存中的副本以及在GPU或系统内存中的Asset本体。]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity UI优化（一）-Unity UI的基本原理]]></title>
    <url>%2F2019%2F04%2F09%2Ffundamentals-unity-ui%2F</url>
    <content type="text"><![CDATA[术语画布（Canvas）是以原生代码编写的Unity组件，它给Unity的渲染系统按层划分的几何系统，可以在其内部或其上层绘制其他几何形状。画布负责将其内部的几何形状合并到批处理、生成合适的渲染指令并发送到Unity图形系统。这些操作都是由原生C++代码完成，这杯成为重新批处理（rebatch）或批处理构建（batch build）。当一个画布被标记为含有需要重新批处理的几何形状时，称这个画布为脏（dirty）画布。由CanvasRenderer组件向画布提供几何形状。子画布（Sub-canvas）是嵌套在其他画布组件内部的画布组件。子画布能够将其孩子节点与其画布隔离开，一个被标记为脏的子节点不会迫使其父画布重新构建几何内容，反之亦然。有几种特殊情况会使上述情形失效，比如，改变父画布导致子画布改变尺寸。Graphic类是由Unity UI系统的C#库提供的基类，所有的画布系统提供可绘制几何内容的UI系统C#类都继承它。大多数内置的UI系统绘制类都是通过MaskableGraphic子类实现的，这个子类实现了IMaskable接口，可以被遮罩。Drawable类的主要子类是Image和Text，它们能提供与其名称相对应的内容。 Layout组件控制RectTransform的尺寸和位置，它通常用于创建具有复杂布局并且内部组件需要相对尺寸或者相对位置的UI。Layout组件只依赖RectTransform并且只影响与其关联的RectTransform的属性。他们不依赖Graphic类，并且可以独立于UI系统的Graphic类使用。Graphic和Layout组件都依赖]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unity性能优化-图形渲染优化]]></title>
    <url>%2F2019%2F04%2F09%2Foptimizing-graphics-rendering-unity-games%2F</url>
    <content type="text"></content>
      <categories>
        <category>渲染优化</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity-Asset-Bundle-Browser-tool]]></title>
    <url>%2F2019%2F04%2F08%2FUnity-Asset-Bundle-Browser-tool%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[托管堆与非托管堆的释放]]></title>
    <url>%2F2019%2F04%2F04%2Fmemory-release%2F</url>
    <content type="text"><![CDATA[托管堆垃圾回收器每隔一段时间.net就会检查托管堆，当检查到需要清理堆时，.net就调用垃圾回收器。垃圾回收器会扫描堆上的对象的引用，不再有引用的对象就被删除。垃圾回收器调用的时间是不确定的，除非代码中有调用垃圾回收器（System.GC.Collect()）。 内存碎片的处理由于堆的释放时刻是由堆上对象的生存周期决定的，这就决定了堆的释放顺序是不定的，必然产生内存碎片。就像操作系统的磁盘分配机制一样，若需要给一个新的对象分配空间，CLR需要搜索堆，直到找到足够大的空间来存储新对象。实际上垃圾回收器会避免堆出现碎片的现象。回收器在一次释放动作结束会将堆上剩余的对象在堆顶移动，回收器会更新被移动对象的存储地址。这就又形成了整块的未分配的空间。虽然移动对象并更新地址会消耗一定的性能，但是由于分配速度和访问速度会快很多，足以弥补消耗。 非托管堆回收器不知道如何释放非托管资源，如文件句柄，网络连接、数据库连接等。当非托管对象被托管对象引用时，托管对象被释放时应确保其相关的非托管对象被释放。以下两种方法可解决释放非托管资源的问题： 在定义类时，声明一个析构函数 在类中实现System.IDisposable接口1234567class MyClass:IDispose&#123; public void Dispose() &#123; // 释放非托管资源 &#125;&#125; 两种调用方式 using关键字方式，对象声明周期结束时会自动调用Dispose函数。此using与命名空间无关 1234using (MyClass classA = new MyClass())&#123; // do something&#125;// 对象的声明周期结束 主动调用 123456789try&#123; MyClass classA = new MyClass(); // do something&#125;finally&#123; classA.Dispose();//显示调用&#125;]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HideFlags]]></title>
    <url>%2F2019%2F04%2F03%2FHideFlags%2F</url>
    <content type="text"><![CDATA[DontSave 保留对象到新场景 如果GameObject对象被HideFlags.DontSave标识，则在新Scene中GameObject的所有组件将被保留下来，但其子类GameObject对象不会被保留到新Scene中。 不可以对GameObject对象的某个组件如Transform进行HideFlags.DontSave标识，否则无效。 即使程序已经退出，被HideFlags.DontSave标识的对象会一直存在于程序中，造成内存泄漏，对HideFlags.DontSave标识的对象在不需要或程序退出时需要使用DestroyImmediate手动销毁。 HideAndDontSave 61The GameObject is not shown in the Hierarchy,not saved to to Scenens,and not unloaded by Resources.UnloadUnusedAssets.]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[半透明渲染]]></title>
    <url>%2F2019%2F04%2F03%2Ftransparent%2F</url>
    <content type="text"><![CDATA[半透明物体的特征是什么？半透明物体需要显示被它遮挡的物体。场景中物体大致就分为本透明物体和不透明物体。在shader中，我们可以设置渲染类型，设置渲染队列值，渲染队列值表示该物体的绘制顺序。引擎在渲染时有一个规则，]]></content>
      <categories>
        <category>Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中堆栈的区别]]></title>
    <url>%2F2019%2F04%2F02%2Fcplusplus-stack-heap%2F</url>
    <content type="text"><![CDATA[管理方式堆中资源由代码控制（通过malloc/free、new/delete，容易产生memory leak），栈资源由编译器自动管理。 系统响应对于堆，系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个大于所申请空间的堆结点，删除空闲链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存空间，另外，系统会将多余的情况重新放入空闲链表中）。对于栈，只要占得剩余空间大于所申请空间，系统就会为程序分配内存，否则报异常出现栈溢出。 空间大小堆是不连续的内存区域（因为系统使用链表来存储空闲内存地址的，自然不是连续），堆的大小受限于计算机系统中有效的虚拟内存（32位机器理论上是4G大小），所以堆的空间比较灵活，比较大。栈是一块连续的内存区域，大小是操作系统预定好的，windows下栈大小是2M（也有是1M，在编译时确定，VC中可设置）。 碎片问题对于堆，频繁的new/delete会造成大量内存碎片化，降低程序效率，对于栈，它是一个先进后出（first-in-last-out）结构，进出一一对应，不会产生碎片化。 生长方向堆向上，由高地址方向增长；栈向下，向低地址方向增长。 分配方式堆是动态分配（没有静态分配的堆）。栈有静态分配和动态分配，静态分配由编译器完成（如函数局部变量），动态分配由allocal函数分配，但栈的动态分配资源由编译器自动释放，无需程序员实现。 分配效率堆由C/C++函数库提供，机制很复杂，因此堆的效率比栈低很多。栈是机器系统提供的数据结构，计算机在底层对栈提供支持，分配专门的寄存器存放栈地址，提供栈操作专门的指令。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Overdraw]]></title>
    <url>%2F2019%2F04%2F02%2Foverdraw%2F</url>
    <content type="text"><![CDATA[Overdraw在某个背景上有个按钮，要将按钮绘制在背景上，这个就是Overdraw，Overdraw无法避免，只能优化降低 性能参数 总填充数峰值：单帧总填充像素数量最大值 填充倍数峰值：单帧最大填充倍数（10.0X就是该帧刷新10遍） 单帧填充倍数：该帧总填充数/该帧渲染相机分辨率 优化方案 控制绘制顺序：PC上资源无限，一般都是从后往前绘制，但在移动上，尽量从前往后绘制。在Unity中，那些Shader中被设置为“Geometry”队列的对象总是从前往后绘制的，而其他固定队列（如”Transparent”，”Overlay”）的物体，则都是从后往前绘制的。这意味着，我们可以尽量把物体的队列设置为”Geometry”。 尽量减少过度绘制区域：实在需要多层绘制的地方，要尽量减少各部分过度绘制区域，使重合区小，绘制的像素点也就少一点。 过大的不必要的绘制尽量代码实现：例如点击屏幕空白区域返回功能，加透明image会增加很多 UI设计上尽可能减少重叠 文字部分主要原因是使用了Outline，Outline实现方式是将Text的四个顶点传过去复制4份，设置4份偏移量实现效果，将偏移量设置很大之后，可以看到一个Text周围有4个相同的Text 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Outline : Shadow&#123; protected Outline() &#123;&#125; public override void ModifyVertices(List&lt;UIVertex&gt; verts) &#123; if (!IsActive()) return; var start = 0; var end = verts.Count; ApplyShadow(verts, effectColor, start, verts.Count, effectDistance.x, effectDistance.y);// 右上 start = end; end = verts.Count; ApplyShadow(verts, effectColor, start, verts.Count, effectDistance.x, -effectDistance.y); // 右下 start = end; end = verts.Count; ApplyShadow(verts, effectColor, start, verts.Count, -effectDistance.x, effectDistance.y); // 左上 start = end; end = verts.Count; ApplyShadow(vertx, effectColor, start, verts.Count, -effectDistance.x, -effectDistance.y); // 左下 &#125; protected void ApplyShadow(List&lt;UIVertex&gt; verts, Color32 color, int start, int end, float x, float y) &#123; UIVertex vt; var neededCpacity = verts.Count * 2; if (verts.Capacity &lt; neededCapacity) verts.Capacity = neededCapacity; for (int i = start; i &lt; end; ++i) &#123; vt = verts[i]; verts.Add(vt); Vector3 v = vt.position; v.x += x; v.y += y; vt.position = v; var newColor = color; if (m_UseGrahpicAlpha) newColor.a = (byte)((newColor.a * verts[i].color.a) / 255); vt.color = newColor; verts[i] = vt; &#125; &#125;&#125; 解决方法 不使用或者使用Shadow(Shadow通过为图像或者文字的mesh添加顶点实现阴影效果，Outline继承Shadow，在对象四个角个添加一个Shadow) 使用Textmesh Pro(Unity5.5)需要制作相应的字体文件，对于动态生成的文字效果不好，固定字体很好。 修改Mesh的UV坐标，提取文字原始UV坐标，扩大文字绘图区域，对文字纹理周围像素点采样，新旧颜色融合 Mask组件Unity的Mask组件会增加一层Overdraw，还会增加4个DrawCall解决方法： 使用RectMask2D代替，缺点是只能用于矩形 对于多边形，用MeshMask，红色为UnityMask，蓝色是MeshMask，UnityMask消耗15个DrawCall，Overdraw2次，MeshMask消耗1个DrawCall，1层OverDraw Image的slide属性对于slide九宫格图片，可以看情况取消fill center属性，那样中心区域不会渲染，中心区域也就镂空，重合面积也会小。 无用的Image]]></content>
      <categories>
        <category>优化</category>
      </categories>
      <tags>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perlin噪声]]></title>
    <url>%2F2019%2F04%2F01%2Fperlin%2F</url>
    <content type="text"><![CDATA[Perlin噪声Ken Perlin在1993年提出了一种渐变噪声，Perlin在1985年的SIGGRAPH有该算法的描述，称之为经典Perlin噪声（Classical Perlin Noise）。为了简化计算，方便使用硬件实现，并解决经典Perlin噪声中存在的错误，到2001年，Ken Perlin再次对原始的噪声算法进行了改进，称之为Simplex噪声（Simplex Noise），这两种算法都可以成为Perlin噪声。但是，我们有时候也把分形噪声成为Perlin噪声，甚至在严肃的学术论文中都有这种叫法。为了避免歧义，本文指的Perlin噪声特指经典的Perlin噪声和Simplex噪声。 Stefan Gustavson指出：Simplex噪声有更小的算法复杂度，要求更少的乘法，在N维空间上，经典Perlin噪声的算法复杂度为$log(2^N)$，但是Simplex噪声的算法复杂度为$log(N^2)$。 经典Perlin噪声经典Perlin噪声是Ken Perlin在1983年提出的噪声，Ken Perlin提供了一维、二维、三维算法的C实现。代码如下： 12345678910111213#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;math.h&gt;#define B 0x100#define BM 0xff#define N 0x1000#define NP 12 /* 2^M */#define NM 0xfffstatic p[B + B + 2];static float g3[]]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shadertoy]]></title>
    <url>%2F2019%2F04%2F01%2Fshadertoy%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879Shader "Shadertoy/Template" &#123; Properties &#123; iMouse ("Mouse Pos", Vector) = (100, 100, 0, 0) iChannel0("iChannel0", 2D) = "white" &#123;&#125; iChannelResolution0 ("iChannelResolution0", Vector) = (100, 100, 0, 0) &#125; CGINCLUDE #include "UnityCG.cginc" #pragma target 3.0 #define vec2 float2 #define vec3 float3 #define vec4 float4 #define mat2 float2x2 #define mat3 float3x3 #define mat4 float4x4 #define iGlobalTime _Time.y #define mod fmod #define mix lerp #define fract frac #define texture2D tex2D // 屏幕分辨率 #define iResolution _ScreenParams // 归一化屏幕坐标 #define gl_FragCoord ((_iParam.scrPos.xy/_iParam.scrPos.w) * _ScreenParams.xy) #define PI2 6.28318530718 #define pi 3.14159265358979 #define halfpi (pi * 0.5) #define oneoverpi (1.0 / pi) fixed4 iMouse; sampler2D iChannel0; fixed4 iChannelResolution0; struct v2f &#123; float4 pos : SV_POSITION; float4 scrPos : TEXCOORD0; &#125;; v2f vert(appdata_base v) &#123; v2f o; o.pos = UnityObjectToClipPos (v.vertex); o.scrPos = ComputeScreenPos(o.pos); return o; &#125; vec4 main(vec2 fragCoord); fixed4 frag(v2f _iParam) : COLOR0 &#123; vec2 fragCoord = gl_FragCoord; return main(gl_FragCoord); &#125; vec4 main(vec2 fragCoord) &#123; return vec4(1, 1, 1, 1); &#125; ENDCG SubShader &#123; Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // 使用低精度来提升片段着色器的运行速度 #pragma fragmentoption ARB_precision_hint_fastest ENDCG &#125; &#125; FallBack Off &#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[剧情编辑器]]></title>
    <url>%2F2019%2F04%2F01%2Fcinema%2F</url>
    <content type="text"></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图形学-噪声]]></title>
    <url>%2F2019%2F04%2F01%2Fgraphics-noise%2F</url>
    <content type="text"><![CDATA[由程序产生噪声的方法大致可以分为两类 类别 名称 基于晶格的方法（Lattice based） 又可细分为两种：第一种是梯度噪声（Gradient noise），包括Perlin噪声，Simplex噪声，Wavelet噪声等；第二种是Value噪声（Value noise）。 基于点的方法（Point based） Worley噪声 白噪声噪声的基础是随机数，如果给屏幕上的每个像素点赋予一个0和1之间的随机数来表示像素点的亮度，就会得到一副杂乱无章的图片。这就是白噪声， Perlin噪声实现步骤： 定义一个晶格结构，每个晶格的顶点有一个“伪随机”的梯度向量。对于二维的Perlin噪声来说，晶格结构就是一个平面网络，三维的就是一个立方体网格。 输入一个点（二维的话就是二维坐标，三维就是三维坐标），我们找到和它相邻的那些晶格顶点（二维下有4个，三维下有8个，n维下有$2^n$个），计算该点到各个晶格顶点的距离向量，在分别与顶点上的梯度向量做点乘，得到$2^n$个点乘结果。 使用缓和曲线（ease curves）来计算它们的权重和。在原始的Perlin噪声实现中，缓和曲线是$s(t) = 3t^2 - 2t^2$，在2002年论文中，Perlin改进为$s(t) = 6t^5 - 15t^4 + 10t^3$。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114Shader "Shadertoy/Template" &#123; Properties &#123; iMouse ("Mouse Pos", Vector) = (100, 100, 0, 0) iChannel0("iChannel0", 2D) = "white" &#123;&#125; iChannelResolution0 ("iChannelResolution0", Vector) = (100, 100, 0, 0) &#125; CGINCLUDE #include "UnityCG.cginc" #pragma target 3.0 #define vec2 float2 #define vec3 float3 #define vec4 float4 #define mat2 float2x2 #define mat3 float3x3 #define mat4 float4x4 #define iTime _Time.y #define mod fmod #define mix lerp #define fract frac #define texture2D tex2D #define iResolution _ScreenParams #define gl_FragCoord ((_iParam.scrPos.xy/_iParam.scrPos.w) * _ScreenParams.xy) #define PI2 6.28318530718 #define pi 3.14159265358979 #define halfpi (pi * 0.5) #define oneoverpi (1.0 / pi) fixed4 iMouse; sampler2D iChannel0; fixed4 iChannelResolution0; struct v2f &#123; float4 pos : SV_POSITION; float4 scrPos : TEXCOORD0; &#125;; v2f vert(appdata_base v) &#123; v2f o; o.pos = UnityObjectToClipPos (v.vertex); o.scrPos = ComputeScreenPos(o.pos); return o; &#125; vec4 main(vec2 fragCoord); fixed4 frag(v2f _iParam) : COLOR0 &#123; vec2 fragCoord = gl_FragCoord; return main(gl_FragCoord); &#125; vec3 hash3(vec2 p) &#123; vec3 q = vec3(dot(p, vec2(127.1,311.7)),dot(p,vec2(269.5,183.3)),dot(p,vec2(419.2,317.9))); return fract(sin(q)*43758.5453); &#125; float iqnoise(in vec2 x, float u, float v) &#123; vec2 p = floor(x); vec2 f = fract(x); float k = 1.0+63.0*pow(1.0-v,4.0); float va = 0.0; float wt = 0.0; for (int j = 0; j &lt; 3; ++j) &#123; for (int i = 0; i &lt; 3; ++i) &#123; vec2 g = vec2(float(i),float(j)); vec3 o = hash3(p + g)*vec3(u,u,1.0); vec2 r = g - f + o.xy; float d = dot(r,r); float ww = pow(1.0-smoothstep(0.0,1.414,sqrt(d)),k); va += o.z*ww; wt += ww; &#125; &#125; return va/wt; &#125; vec4 main(vec2 fragCoord) &#123; vec2 uv = fragCoord.xy / iResolution.xx; vec2 p = 0.5 - 0.5*sin(iTime*vec2(1.01,1.71)); if (iMouse.w &gt; 0.001) p = vec2(0.0, 1.0) + vec2(1.0, -1.0)*iMouse.xy/iResolution.xy; p = p*p*(3.0-2.0*p); p = p*p*(3.0-2.0*p); p = p*p*(3.0-2.0*p); float f = iqnoise(24.0*uv,p.x,p.y); return vec4(f, f, f, 1); &#125; ENDCG SubShader &#123; Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma fragmentoption ARB_precision_hint_fastest ENDCG &#125; &#125; FallBack Off &#125;]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[溶解]]></title>
    <url>%2F2019%2F03%2F31%2FDissolveEffect%2F</url>
    <content type="text"><![CDATA[溶解，也就是让这个模型逐渐消失。那么，最简单的，直接让这个像素的Fragment Shader操作discard，这个像素就消失了。然后，我们要做的就是让这个溶解的对象一部分消失，另一部分存在，所以，这个时候我们就需要一个Mask图进行控制，然后用这个Mask值与我们设定的一个阀值来进行比较，小于阀值的部分discard，大于的部分正常计算。最终，我们将这个阀值从0逐渐增加到1，就可以实现模型的一部分像素先消失，直至整个模型完全消失的效果。]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader 后处理：Bloom全屏泛光]]></title>
    <url>%2F2019%2F03%2F30%2FShader-Bloom%2F</url>
    <content type="text"><![CDATA[全屏Bloom效果，也叫Glow效果，中文称作“全屏泛光”，这是一种可以模拟出HDR的全屏后处理效果，但是实现原理和HDR相差很远，效果比HDR差一下，但是性能高很多。 HDRHDR(High Dynamic Range)，高动态范围。High值得是亮度的范围更高。正常屏幕上一个像素是由RGB三原色组成的，每个通道用八位二进制表示，也就是0-255，而真实世界的亮度的最大值要远远超过屏幕上能够显示的最大亮度值，比如太阳的亮度会是屏幕亮度的几万倍，这个就是所谓的High。HDR可以模拟高范围的亮度分布。实现这样功能的技术叫做ToneMapping，翻译为色调映射技术。这种技术会让画面对比度更加柔和，将高的亮度范围更加平滑地缩放到0-255这一低光照范围，主要运用的原理是局部适应性。人眼在比较暗的地方，也能看清东西，但是突然到了一个比较亮的地方，就会感觉模糊，需要一会儿才能适应当前的亮度水平。 BloomBloom可以模拟出HDR的效果，但是原理上和HDR是截然不同的。HDR实际上是通过映射技术，来达到整体调整全局亮度属性的，这种调整是颜色、强度等都可以进行调整，而Bloom仅仅是能够将光照范围调高达到过饱和，也就是让亮的地方更亮。不过Bloom效果实现起来简单，性能效果也小，却可以达到不错的效果。 实现原理：首先需要设置一个泛光的亮度阀值，第一遍处理时，需要对原场景图进行帅选，所有小于这个阀值的像素都被筛掉，所有大于该值的像素都被留下，这样，我们就得到了一张只包含需要泛光部分的贴图，其余部分是黑色的；泛光效果是由衍射效果产生的，我们现实世界中看到的泛光效果，最亮的地方实际上是会向暗的地方扩散的，也就是说在亮的地方，边界是不明显的，所以我们就需要对泛光也就是上一步操作的结果图片进行模糊操作，达到光移除的效果，最后，我们将处理过的图像和原图像紧急性叠加，就得到了最终的效果。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using UnityEngine;[ExecuteAlways]public class RenderImage : MonoBehaviour&#123; // 分辨率 public int downSample = 1; public float grayScaleAmout = 1.0f; public Material curMaterial; // 高亮部分提取阀值 public Color colorThreshold = Color.gray; // 采样率 public int samplerScale = 1; // Bloom泛光颜色 public Color bloomColor = Color.white; // Bloom权值 [Range(0.0f, 1.0f)] public float bloomFactor = 0.5f; void OnRenderImage(RenderTexture src, RenderTexture dest) &#123; // 申请两块RT，并且分辨率按照downSample降低 RenderTexture temp1 = RenderTexture.GetTemporary(src.width &gt;&gt; downSample, src.height &gt;&gt; downSample); RenderTexture temp2 = RenderTexture.GetTemporary(src.width &gt;&gt; downSample, src.height &gt;&gt; downSample); // 直接将场景图拷贝到低分辨率的RT上达到降分辨率的效果 Graphics.Blit(src, temp1); // 根据阀值提取高亮部分，使用pass0进行高亮提取 curMaterial.SetVector("_colorThresshold", colorThreshold); Graphics.Blit(temp1, temp2, curMaterial, 0); // 高斯模糊，两次模糊，横向纵向，使用pass1进行高斯模糊 curMaterial.SetVector("_offsets", new Vector4(0, samplerScale, 0, 0)); Graphics.Blit(temp2, temp1, curMaterial, 1); curMaterial.SetVector("_offset", new Vector4(samplerScale, 0, 0, 0)); Graphics.Blit(temp1, temp2, curMaterial, 1); // Bloom，将模糊后的图作为Material的Blur图参数 curMaterial.SetTexture("_BlurTex", temp2); curMaterial.SetVector("_bloomColor", bloomColor); curMaterial.SetFloat("_bloomFactor", bloomFactor); // 使用pass2进行景深效果计算，清晰场景图直接从source输入到shader的_MainTex中 Graphics.Blit(src, dest, curMaterial, 2); // 释放申请的RT RenderTexture.ReleaseTemporary(temp1); RenderTexture.ReleaseTemporary(temp2); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161Shader "Hidden/BloomEffect"&#123; Properties &#123; _MainTex ("Texture", 2D) = "white" &#123;&#125; _BlurTex("BlurTex", 2D) = "white" &#123;&#125; &#125; CGINCLUDE #include "UnityCG.cginc" // 用于阀值提取亮度部分 struct v2f_threshold &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; &#125;; // 用于blur struct v2f_blur &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; float4 uv01 : TEXCOORD1; float4 uv23 : TEXCOORD2; float4 uv45 : TEXCOORD3; &#125;; // 用于bloom struct v2f_bloom &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; float2 uv1 : TEXCOORD1; &#125;; sampler2D _MainTex; float4 _MainTex_TexelSize; sampler2D _BlurTex; float4 _BlurTex_TexelSize; float4 _offsets; float4 _colorThreshold; float4 _bloomColor; float _bloomFactor; // 高亮部分提取shader v2f_threshold vert_threshold(appdata_img v) &#123; v2f_threshold o; o.pos = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord.xy; //dx中纹理从左上角为初始坐标，需要反向#if UNITY_UV_STARTS_AT_TOP if (_MainTex_TexelSize.y &lt; 0) o.uv.y = 1 - o.uv.y;#endif return o; &#125; fixed4 frag_threshold(v2f_threshold i) : SV_Target &#123; fixed4 color = tex2D(_MainTex, i.uv); // 仅当color大于设置阀值的时候才输出 return saturate(color - _colorThreshold); &#125; // 高斯模糊 vert shader v2f_blur vert_blur(appdata_img v) &#123; v2f_blur o; _offsets *= _MainTex_TexelSize.xyxy; o.pos = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord.xy; o.uv01 = v.texcoord.xyxy + _offsets.xyxy * float4(1,1,-1,-1); o.uv23 = v.texcoord.xyxy + _offsets.xyxy * float4(1,1,-1,-1)*2.0; o.uv45 = v.texcoord.xyxy + _offsets.xyxy * float4(1,1,-1,-1)*3.0; return o; &#125; // 高斯模糊 pixel shader fixed4 frag_blur(v2f_blur i) :SV_Target &#123; fixed4 color = fixed4(0,0,0,0); color += 0.40 * tex2D(_MainTex, i.uv); color += 0.15 * tex2D(_MainTex, i.uv01.xy); color += 0.15 * tex2D(_MainTex, i.uv01.zw); color += 0.10 * tex2D(_MainTex, i.uv23.xy); color += 0.10 * tex2D(_MainTex, i.uv23.zw); color += 0.05 * tex2D(_MainTex, i.uv45.xy); color += 0.05 * tex2D(_MainTex, i.uv45.zw); return color; &#125; // Bloom效果 vertex shader v2f_bloom vert_bloom(appdata_img v) &#123; v2f_bloom o; o.pos = UnityObjectToClipPos(v.vertex); o.uv.xy = v.texcoord.xy; o.uv1.xy = o.uv.xy;#if UNITY_UV_STARTS_AT_TOP if (_MainTex_TexelSize.y &lt; 0) o.uv.y = 1 - o.uv.y;#endif return o; &#125; fixed4 frag_bloom(v2f_bloom i) : SV_Target &#123; // 取原始清晰图片进行uv采样 fixed4 ori = tex2D(_MainTex, i.uv1); // 取模糊图片进行uv采样 fixed4 blur = tex2D(_BlurTex, i.uv); // 输出 = 原始图像叠加bloom权值*bloom颜色*泛光颜色 fixed4 final = ori + _bloomFactor * blur * _bloomColor; return final; &#125; ENDCG SubShader &#123; // pass 0: 提取高光部分 Pass &#123; ZTest Off Cull Off ZWrite Off Fog&#123; Mode Off &#125; CGPROGRAM #pragma vertex vert_threshold #pragma fragment frag_threshold ENDCG &#125; // pass 1: 高斯模糊 Pass &#123; ZTest Off Cull Off ZWrite Off Fog&#123; Mode Off &#125; CGPROGRAM #pragma vertex vert_blur #pragma fragment frag_blur ENDCG &#125; // pass 2: 泛光颜色 Pass &#123; ZTest Off Cull Off ZWrite Off Fog &#123; Mode Off &#125; CGPROGRAM #pragma vertex vert_bloom #pragma fragment frag_bloom ENDCG &#125; &#125;&#125;]]></content>
      <categories>
        <category>Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>后处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity2018照明流程]]></title>
    <url>%2F2019%2F03%2F30%2FUnity-2018-Lighting%2F</url>
    <content type="text"><![CDATA[目前Unity提供了多种渲染管道，两种全局照明系统，四种照明模式，三种灯光模式，以及两种Shadowmask模式，为开发者在创建面向高配PC，主机，移动和XR设备项目的过程中提供了高度灵活性。 渲染管线决定对象如何在场景中呈现出来，分为以下三个阶段第一阶段：剔除（Culling）。在此阶段列出需要被渲染的对象，优先呈现摄像机可见的范围，以及未被其它物体遮挡的对象。第二阶段：渲染（rendering）。在此阶段，根据光照设置以及相关的灯光属性，将对象绘制到基于像素的缓冲区种。第三阶段：后处理（post-processing）。一般在缓冲区上执行操作，比如应用ColorGrading、Bloom、Depth of Field等效果，将最终输出到每一帧。]]></content>
      <categories>
        <category>Unity-2018</category>
      </categories>
      <tags>
        <tag>Unity-2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity-2018]]></title>
    <url>%2F2019%2F03%2F30%2FUnity-2018%2F</url>
    <content type="text"><![CDATA[Shader中使用”UsePass”引用同一个Shader的另外一个SubShader的Pass会导致崩溃，这个是Bug还是就是不能这么写？我使用的版本是2017.4.6f1。例如这样：12345678910111213141516171819Shader "Unlit/NewUnlitShader 1"&#123; Properties &#123; _MainTex("Texture". 2D) = "white"&#123;&#125; &#125; SubShader &#123; Tags&#123;"RenderType"="Oparque"&#125; LOD 100 UsePass "Unlit/NewUnlitShader 1/TEST" Pass &#123; Name "test" &#125; &#125;&#125; UsePass主要是用来实现不同的Shader中的代码复用的，查看文档的话也可以看到相关描述：Some of the shaders conld reuse existing passes from other shaders, reducing code duplication所以不要用UsePass引用同一个Shader中的Pass]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity-2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity GI LightMap]]></title>
    <url>%2F2019%2F03%2F30%2FUnity-GI-LightMap%2F</url>
    <content type="text"><![CDATA[全局光照全局光照（GI）是一种系统，用于模拟光如何从表面反射到其他表面（间接光），而不仅限于直接从光源击中表面的光（直接光）。相反，物体的光照颜色计算只限于自身，直接从光源击中表面的光（直接光）即使局部光照（local illumination）。一个典型的例子是“彩色渗色”，例如，阳光击中红色沙发会导致红灯反弹到其后面的墙上。另一个是当阳光在洞穴的开口处撞击地板并且在内部弹起时，洞穴的内部部分也被照亮。传统上，视频游戏和其它实时图形应用仅限于直接照明，而间接照明所需计算太慢，因此它们只能用于非实时场景，如CG动画电影。解决这个限制的游戏方法是计算间接光，只能用于提前知道的物体和表面，不能移动（静态）。这样，慢的计算可以提前完成，但是由于对象不移动，所以以这种方式预先计算的间接光在运行时仍然是正确的。Unity支持这种称为烘烤GI（也称为烘烤光图）的技术，以“烘烤”命名-间接光被预先计算和存储的过程（烘烤）。除间接光之外，烘烤GI还可以利用更多的计算时间，从区域灯和间接光产生比通常可以通过实时技术实现的更真实的软阴影。烘烤GI和预计算实时GI都有限制，只有静态对象可以包含在烘培/预计算中，所以移动物体不能将光反射到其它物体上，反之亦然。 光照图对一些静态的物体和光，预先计算存储，不必实时计算，这个过程叫做baking。baking的结果就是一张lightmapping贴图。针对光照稳定的静态物体。 烘培Lightmapping场景包含大量物体时，实时光照的阴影对有戏性能有很大的影响。使用烘培技术，可以将光线效果预渲染成贴图再作用到物体上模拟光影，从而提高性能。步骤1： 游戏物体及地面设置为Static； 选择Window-&gt;Lightmapping-&gt;Bake Scene静态物体的影子只能烘培在静态物体上]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NetworkStream]]></title>
    <url>%2F2019%2F03%2F30%2FNetworkStream%2F</url>
    <content type="text"><![CDATA[作用：如果服务器和客户端之间基于TCP连接的，他们之间能够依靠一个稳定的字节流进行相互传输信息。命名空间：System.Net.Sockets注意事项： NetworkSteam只能用在具有TCP/IP协议之中，如果用在UDP中编译不抱错，会有异常 NetworkStream是面向连接的 在网络中利用流的形式传递信息 必须借助Socket（也称为流失Socket），或使用一些返回的返回值 用法和普通流方式几乎一模一样，但具有特殊性 TCP/IP（Transmission Control Protocol/Internet Protocol）（传输控制协议/因特网互联协议） IPAddress命名空间:System.Net1IPAddress ip = IPAddress.Parse("192.168.1.1");]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[判断点和多边形关系]]></title>
    <url>%2F2019%2F03%2F29%2Fpoint-polygon%2F</url>
    <content type="text"><![CDATA[本文讨论如何判断一个点是在多边形内部，边上还是在外部。为了方便，这里的多边形默认为有向多边形，规定沿多边形的正向，边的左侧为多边形的内测域，即多边形按逆时针方向遍历，不考了自交等复杂情况。 比较常见的判断点与多边形关系的算法有射线法、面积法、点线判断法和弧长法等，算法复杂度都为O(n)，不过只有射线法可以正确用于凹多边形，其他3个只可以用于凸多边形。 射线法射线法是使用最广泛的算法，这是由于相比较其他算法而言，它不但可以正确使用在凹多边形上，而且不需要考虑精度误差问题。该算法思想是从点出发向右水平做一条射线，计算该射线与多边形的边的相交个数，当点不在多边形上时，如果是奇数，那么点就一定在多边形内部，否则，在外部。123456789101112131415for (int i = 0; i &lt; nCount; ++i)&#123; Vector3 p1 = mNodes[i]; Vector3 p2 = mNodes[(i + 1) % nCount]; if (p1.z == p2.z) //p1p2与y=p0.y平行; continue; if (pt.z &lt; Mathf.Min(p1.z, p2.z)) // 交点在p1p2延长线上; continue; if (pt.z &gt;= Mathf.Max(p1.z, p2.z)) // 交点在p1p2延长线上; continue; // 求交点的X坐标; float x = (pt.z - p1.z) * (p2.x - p1.x) / (p2.z - p1.z) + p1.x; if (x &gt; pt.x) // 只统计单边交点; ++nCross;&#125; 上面代码利用三角形原理，p1和p2的组成的直角三角形和p1和p组成直角三角形 面积法面积法的思想是如果点在多边形内部或者边上，那么点与多边形所组成的三角形面积和等于多边形面积。多边形的面积公式可以使用叉积计算，不过计算面积是会有一定误差的，需要设置精度的误差范围。 点线判断法对于多边形，如果一个点在它所有边的左边，那么这个点一定在多边形内部。利用叉积正好可以判断点与给定边的关系，即点在边的左边右边还是边上。 弧长法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#中静态字段和类成员的执行顺序]]></title>
    <url>%2F2019%2F03%2F29%2FCSharpClassFieldSort%2F</url>
    <content type="text"><![CDATA[先进行细分：类的成员分为：字段、属性、方法、构造方法成员的修饰符：静态成员、实例成员层次结构：父类、子类 先不考虑继承关系，执行顺序为： 静态字段 静态构造方法 实例字段 实例构造方法 在考虑继承关系，执行顺序为： 子类的静态字段 子类的静态构造方法 子类的实例字段 父类的静态字段 父类的静态构造方法 父类的实例字段 父类的实例构造方法 子类的实例构造方法 类的静态字段变量初始值设定项对应于一个赋值序列，这些赋值按照他们在相关的类声明中出现的文本顺序执行。如果类中存在静态构造函数，则静态字段初始值设定项的执行在该构造函数即将执行前发生。否则，静态字段初始值设定项在第一次使用该类的静态字段之前被执行，但实际执行时间依赖于具体的实现。]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试解析]]></title>
    <url>%2F2019%2F03%2F29%2Finterview-parse%2F</url>
    <content type="text"><![CDATA[冰川网络 牛蛙互动 点和多边形相交（曲线相交）？ 编译会直接过不去，提示字段初始值设定无法引用非静态字段、方法或属性将b = a + 10，改为b = c + 10，输出如下结果a = 10, b = 20, c = 10, d = 10考点：C#执行顺序 设计一种存储结构实现字典查找。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gamma]]></title>
    <url>%2F2019%2F03%2F29%2FGamma%2F</url>
    <content type="text"><![CDATA[Unity在UnityCG.cginc头文件中提供了GammaToLinearSpace和LinearToGammaSpace进行空间转化，其中的算法是近似算法，效率比较高1234567891011121314151617181920inline half3 GammaToLinearSpace(half3 sRGB)&#123; return sRGB * (sRGB * (sRGB * 0.305306011h + 0.682171111h) + 0.012522878h); // 精确版，用来调试 // return half3(GammToLinearSpaceExact(sRGB.r), GammaToLinearSpaceExact(sRGB.g), GammaToLinearSpaceExact(sRGB.b));&#125;inline half3 LinearToGammaSpace(half3 linRGB)&#123; linRGB = max(linRGB, half3(0h,0h,0h)); return max(1.055h*pow(linRGB,0.416666667h) - 0.055h, 0h);&#125;inline bool IsGammaSpace()&#123;#if defined(UNITY_NO_LINEAR_COLORSPACE) return true;#else return unity_ColorSpaceLuminance.w == 0;#endif&#125;]]></content>
      <categories>
        <category>渲染</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGUI]]></title>
    <url>%2F2019%2F03%2F28%2FNGUI%2F</url>
    <content type="text"><![CDATA[UIDrawCallUpdateGeometry()通过顶点，UV，颜色，贴图等信息绘制UI图形。 填充顶点UIBasicSprite12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152protected void Fill(BetterList&lt;Vector3) verts, BetterList&lt;Vector2&gt; uvs, BetterList&lt;Color32&gt; cols, Rect outer, Rect inner)&#123; switch(type) &#123; case Type.Simple: SimpleFill(verts, uvs, cols, outer, inner); break; case Type.Sliced: SlicedFitt(verts, uvs, cols, outer, inner); break; case Type.Filled: FilledFill(verts, uvs, cols, outer, inner); break; case Type.Tiled: TiledFill(verts, uvs, cols, outer, inner); break; case Type.Advanced: AdvancedFill(verts, uvs, cols, outer, inner); break; &#125;&#125;void SimpleFill(BetterList&lt;Vector3&gt; verts, BetterList&lt;Vector2&gt; uvs, BetterList&lt;Color32&gt; cols, Rect mOuterUV, Rect mInnerUV)&#123; Vector4 v = drawingDimensions; Vector4 u = MakeDrawingUVs(mOuterUV, mInnerUV); verts.Add(new Vector3(v.x, v.y)); verts.Add(new Vector3(v.x, v.w)); verts.Add(new Vector3(v.z, v.w)); verts.Add(new Vector3(v.z, v.y)); uvs.Add(new Vector2(u.x, u.y)); uvs.Add(new Vector2(u.x, u.w)); uvs.Add(new Vector2(u.z, u.w)); uvs.Add(new Vector2(u.z, u.y)); if (!mApplyGradient) &#123; Color32 c = drawingColor; cols.Add(c); cols.Add(c); cols.Add(c); cols.Add(c); &#125; else &#123; AddVertexColours(cols, 1, 1); AddVertexColours(cols, 1, 2); AddVertexColours(cols, 2, 2); AddVertexColours(cols, 2, 1); &#125;&#125; UIWidget排序函数，大于0的要交换1234567891011121314static public int PanelCompareFunc(UIWidget left, UIWidget right)&#123; if (left.mDepth &lt; right.mDepth) return -1; if (left.mDepth &gt; right.mDepth) return 1; Material leftMat = left.material; Material rightMat = right.material; if (leftMat == rightMat) return 0; if (leftMat == null) return 1; if (rightMat == null) return -1; return (leftMat.GetInstanceID() &lt; rightMat.GetInstanceID()) ? -1 : 1;&#125;]]></content>
      <categories>
        <category>NGUI</category>
      </categories>
      <tags>
        <tag>NGUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mesh.SetTriangles]]></title>
    <url>%2F2019%2F03%2F28%2FMesh-SetTriangles%2F</url>
    <content type="text"><![CDATA[1public void SetTriangle(int[] triangles, int submesh, bool calculateBounds = true, int baseVertex = 0);]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C和C++混合编程（__cplusplus与external "c"的使用）]]></title>
    <url>%2F2019%2F03%2F28%2Fcplusplus%2F</url>
    <content type="text"><![CDATA[第一种理解比如说你用C++开发了一个DLL库，为了能够让C语言也能够调用你的DLL输出（Export）的函数，你需要用extern “C”来强制编译器不要修改你的函数名。通常，在C语言的头文件中经常可以看到类似下面这种形式的代码：1234567#ifdef __cplusplusextern "C" &#123;#endif/*some declaration or so*/#ifdef __cplusplus&#125;#endif 那么这种写法有什么用呢？实际上，这是为了让CPP能够在C环境下使用而采取的一种语法形式。之所以采用这种方式，是因为两种语言之间的一些差异。由于CPP支持多态性，也就是具有相同函数名的函数可以完成不同的功能，CPP通常是通过参数区分具体调用的是哪一个函数。在编译的时候，CPP编译器会将参数类型和函数名连接再也一起，于是在程序编译成为目标文件以后，CPP编译器可以直接根据目标文件中的符号名，将多个目标文件连接成一个目标文件或者可执行文件。但是在C语言中，由于完全没有多态性的概念，C编译器在编译时除了会在函数名钱添加一个下划线之外，什么也不会做。由于这种原因，当采用CPP与C混合编程的时候，就可能出现问题。假设一个头文件定义了这样的函数：1int foo(int a,int b);]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua GC 的源码剖析（1）]]></title>
    <url>%2F2019%2F03%2F27%2Flua-gc-1%2F</url>
    <content type="text"><![CDATA[Lua采用一个简单标记清楚算法的GC系统。在Lua中，一共只有9就数据类型，分别为nil、boolean、lightuserdata、number、string、table、function、userdata和thread。其中，只有string table function thread四种在vm中以引用方式共享，是需要被GC管理回收的对象。其它类型都以值形式存在。但在Lua的实现中，还有两种类型的对象需要被GC管理。分别是proto（可以看作未绑定upvalue的函数），upvalue（多个upvalue会引用同一个值）。Lua是以union+type的形式保存值。具体定义可见lobject.h的100-107行：123456789101112131415161718/*** Union of all Lua values*/typedef union Value&#123; GCObject *gc; /* collectable objects */ void *p; /* light userdata */ int b; /* booleans */ lua_CFunction f; /* light C functions */ lua_Integer i; /* integer numbers */ lua_Number n; /* float numbers */&#125;Value;#define TValuefields Value valua_; int tt_typedef struct lua_TValue &#123; TValuefields;&#125;TValue; 我们看到，Value以union方式定义。如果是需要被GC管理的对象，就以GCObject指针形式保存，否则直接保值。在代码的其它部分，并不直接使用Value类型，而是TValue类型。它比Value多了一个类型标识。用int tt_记录。通常的系统中，每个TValue长度为12个字节。所有的GCObject都有一个相同的数据头，叫做CommonHeader，在lobject.h里79行以宏形式定义出来。使用宏是源于使用上的某种遍历。C语言不支持结构的继承。1234/*** Common Header for all collectable objects (in maro form, to be included in other objecs)*/#define CommonHeader GCObject *next; lu_byte tt; lu_byte marked 从这里我们可以看到：所有的GCObject都用一个单向量表串了起来。每个对象都以tt来识别其类型。marked域用于标记清除工作。标记清除算法是一种简单的GC算法。每次GC过程，先以若干根节点开始，逐个把直接以及间接和它们相关的节点都做上标记。对于Lua，这个过程很容易实现。因为所有的GObject都在同一个链表上，当标记完成后，遍历这个链表，把未被标记的节点—删除即可。Lua在实际实现时，其实不只用一条链表维系所有的GCObject。这是因为string类型有其特殊性。所有的string放在一张大的hash表中。它需要保证系统中不会有值相同的string被创建两份。顾string是被单独管理的，而不串在GCObject的链表中。回头来看看lua_State这个类型。这是写C和Lua交互时用的最多的数据类型。顾名思义，它表示lua vm的某种状态。从实现上说，更接近lua的一个thread以及其包含的相关数据（堆栈、环境等）。事实上一个lua_State也是一个类型的thread的GCObject。见lstate.h。12345678910sturct lua_State &#123; CommonHeader; unsigned short nci; /* number of items in 'ci' list */ lu_byte status; StkId top; /* first free slot in the stack */ global_State *l_G; CallInfo *ci; /* call info for current function */ const Instruction *oldpc; /* last pc traced */ StkId stack_last; /* last free slot in the stack */&#125;]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ExecuteAlways]]></title>
    <url>%2F2019%2F03%2F25%2FExecuteAlways%2F</url>
    <content type="text"><![CDATA[描述使脚本的实例始终执行，作为Play Mode的一部分和Editing。 默认情况下，MonoBehaviours仅在Play Mode下执行。 当希望脚本作为编辑器工作的一部分执行某些操作时，可以使用[ExecuteAlways]属性，该工具不一定与构建 仅在Scene发生改变是调用Update 当Game 试图接收到它不使用的非编辑器事件（例如，EventType.ScrollWheel）会调用OnGUI 在场景试图或者Game试图的每次重绘都会调用OnRenderObject和其他渲染回调函数]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>UnityEngine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ExecuteInEditMode]]></title>
    <url>%2F2019%2F03%2F25%2FExecuteInEditMode%2F</url>
    <content type="text"><![CDATA[描述使脚本实例可以在编辑模式运行默认的情况下，MonoBehaviours只能在Play模式下工作。通过添加这个属性，任何MonoBehaviour实例的回调函数也会在Edit模式下执行。此属性正在逐步淘汰，因为它不考虑预制模式。如果在预制模式下编辑了具有此属性的MonoBehavi的预制体，并且输入了播放模式，则编辑器将退出预制模式，以防止意外修改仅用于播放模式的逻辑引起的预制体。 要指示MonoBehaviour正确考虑预制模式并且在播放模式下预制模式下打开是安全的，可以使用属性ExecuteAlways而不是ExecuteInEdiMode。 Update：在Scene发生变化时被调用OnGUI：在Game视图接受到Event时被调用OnRenderImage：在Scene视图或Game视图重绘时被调用]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高斯函数]]></title>
    <url>%2F2019%2F03%2F25%2FGaussian%2F</url>
    <content type="text"><![CDATA[一维高斯函数高斯函数，Gaussian Function，也简称为Gaussian，一维形式如下： $f(x)=ae^{(x-b) \over 2c^2}$高斯的一维图是特征对称“bell curve”形状，a是曲线尖峰的高度，b是尖峰中心c的坐标，c称为标准方差，表征的是bell钟状的宽度。从以上图可以看出，高斯函数是一个指数函数，其log函数是对数凹函数]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Opencv]]></title>
    <url>%2F2019%2F03%2F25%2Fopencv%2F</url>
    <content type="text"><![CDATA[平滑处理“平滑处理”（smoothing）也称“模糊处理”（bluring），是一项简单且使用频率很高的图像处理方法。平滑处理的用途很多，最常见的是用来减少图像上的噪点或者失真。在涉及到降低图像分辨率时，平滑处理是非常好用的方法。 图像滤波和滤波器图像滤波：即在尽量保留图像细节特征的条件下对目标图像的噪声进行抑制，是图像预处理中不可缺少的操作，其处理效果的好坏将直接影响到后续图像处理和分析的有效性和可靠性。消除图像中噪声成为叫做图像的平滑化或滤波操作。信号或图像的能量大部分几种在幅度谱的低频和中频段是很常见的，而在较高频段，信息经常被噪声淹没。因此一个能减低高频成分幅度的滤波器就能够减弱噪声的影响。图像滤波的目的有两个：一个是抽出对象的特征作为图像识别的特征模式；另一个是为适应图像处理的要求，消除图像数字化时所混入的噪声。而对滤波处理的要求也有两条：一是不能损坏图像的轮廓及边缘等重要信息；二是使图像清晰视觉效果好。 平滑滤波是低频增强的空间域滤波技术。它的目的有两类：一类是模糊；另一类是消除噪音。 滤波和模糊滤波可分为低通滤波和高通滤波两种。而高斯滤波是指用高斯函数作为滤波函数的滤波操作，至于是不是模糊，要看是高斯低通还是高斯高通，低通就是模糊，高通就是锐化。高斯滤波是指用高斯函数作为滤波函数的滤波操作。高斯模糊就是高斯低通滤波。 高斯滤波高斯滤波是一种线性平滑滤波，适用于消除高斯噪声，广泛应用于图像处理的减噪过程。]]></content>
      <categories>
        <category>Opencv</category>
      </categories>
      <tags>
        <tag>Opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[屏幕后处理效果]]></title>
    <url>%2F2019%2F03%2F25%2Fgauss%2F</url>
    <content type="text"><![CDATA[屏幕后处理，通常指的是在渲染整个场景得到屏幕图像后，再对这个图像进行一系列操作，实现各种屏幕特效。使用这种技术，可以为游戏画面添加更多的艺术效果，例如景深（Depth of Field）、运动模糊（Motion Blur）等。因此，想要实现屏幕后处理的基础在于得到渲染后的屏幕图像，即抓取屏幕，而Unity为我们提供了这样一个方便的接口，OnRenderImage函数。它的函数声明如下：1void OnRenderImage(RenderTexture src, RenderTexture dest) 当我们在脚本中声明此函数后，Unity会把当前渲染得到的图像存储在第一个参数对应的渲染纹理中，通过函数的一系列操作后，在把目标渲染纹理，即第二个桉树对应的渲染纹理显示到屏幕上。在OnRenderImage函数中，我们通常是利用Graphics.Blit函数来完成对渲染纹理处理。它有3中函数声明：12345678910namespace UnityEngine&#123; public class Graphics &#123; public static void Blit(Texture src, RenderTexture dest); public static void Blit(Texture source, RenderTexture dest, int sourceDepthSlice, int destDet\pthSlice); public static void Blit(Texture src, RenderTexture dest, Material mat, int pass, int destDepthSlice); public static void Blit(Texture src, Material mat); &#125;&#125; 其中，参数src对应了源纹理，在屏幕后处理技术中，这个参数通常就是当前屏幕的渲染纹理或是上一步处理后得到的渲染纹理。参数dest是目标渲染纹理，如果它的值为null就会直接将结果显示在屏幕上。参数mat是我们使用的材质，这个材质使用的Unity Shader将会进行各种屏幕后处理操作，而src纹理将会被传递给Shader中名为_MainText的纹理属性。参数pass的默认值为-1，表示将会依次调用Shader内的所有Pass。否则，只会调用给定索引的Pass。在默认情况下，OnRenderImage函数会在所有的不透明和透明的Pass执行完毕后调用，以便对场景中所有游戏对象都产生影响。但有时，我们希望在不透明的Pass（即渲染队列小于等于2500的Pass，内置的Background，Geometry和AlphaTest渲染队列均在此范围内）执行完毕后立即调用OnRenderImage函数，从而不对透明物体产生任何影响。此时，我们可以在OnRenderImage函数钱添加ImageEffectOpaque属性来实现这样的目的。因此，要在Unity中实现屏幕后处理效果，过程通常如下：我们首先需要在摄像机中添加一个用于屏幕后处理的脚本。在这个脚本中，我们会实现OnRenderImage函数来获取当前屏幕的渲染纹理。然后，再调用Graphics.Blit函数使用特定的Unity Shader来对当前图像进行处理，在把返回的渲染纹理显示到屏幕上。对于一些复杂的屏幕特效，我们可能需要多次调用Graphics.Blit函数来对上一步的输出结果进行下一步处理。 高斯滤波高斯模糊（Gaussian Blur），也叫高斯平滑，高斯滤波，其通常用它来减少图像噪声以及降低细节层次，尝尝也被用于对图像进行模糊。通俗的讲，高斯模糊就是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和领域内的其他像素经过加权平均后得到。高斯模糊的具体操作是：用一个模版（或称卷积、掩模）扫描图像中的每一个像素，用模版确定的领域内像素的加权平均灰度值去替代模版中心像素点的值。高斯模糊同样利用了卷积计算，它适用了卷积核名为高斯核。高斯核是一个正方形大小的滤波器，其中每个元素的计算都是基于下面的高斯方程：$G(x,y)= {1 \over 2\pi\delta^2}^{e^{x^2+y^2 \over 2\delta^2}}$其中，$\delta$是标准方差（一般取值为1），x和y分别对应了当前位置到卷积核中心的整数距离。要构建一个高斯核，我们只需要计算高斯核中各个位置对应的高斯值。为了保证滤波后的图像不会变暗，我们需要对高斯核中的权重进行归一化，既让每个权重除以所有权重的和，这样可以保证所有权重的和为1。因此，高斯函数中e前面的系数实际不会对结果有任何影响。 高斯方程很好地模拟了领域每个像素对当前处理像素的影响程度，距离越近，影响越大。高斯核的维数越高，模糊程度越大。使用一个NxN的高斯核对图像进行卷积滤波，就需要NxNxWxH（W和H分别是图像的宽和高）次纹理采样。当N的大小不断增加时，采样次数就会变得非常巨大。幸运的是，我们可以把这个二维高斯函数拆分成两个一维函数。也就是说，我们可以使用两个一维的高斯核（图12.8中的右图）先后对图形进行滤波，它们得到的结果和直接利用二维高斯核是一样的，但采样次数只需要2xNxWxH。我们可以进一步观察到，两个一维高斯核中包含了很多重复的权重。对于一个大小为5的一维高斯核，我们实际只需要记录3个权重值即可。在本节，我们将会使用5x5的高斯核对原图进行高斯模糊。我们将先后调用两个Pass，第一个Pass将会使用竖直方向的一维高斯核对图像进行滤波，第二个Pass在使用水平方向的一维高斯核对图像进行滤波，得到最终的目标图像。在实现中，我们将还利用图像缩放进一步提高性能，并通过调整高斯滤波的应用次数来控制模糊程度（次数越多，图像越模糊）。 实现12345678910// Blur iterations - larger number means more blur.[Range(0, 4)]public int iterations = 3;// Blur spread for each iteration - larger value means more blur [Range(0.2f, 3.0f)]public float bludSpread = 0.6f;[Range(1, 8)]public int downSample = 2; blurSpread和downSample都是出于性能的考虑。在高斯核维数不变的情况下，_BlurSize越大，模糊程度越高，但采样数却不会受到影响。但过大的_BlurSize值会造成虚影，这可能并不是我们希望的。而downSample越大，需要处理的像素数越少，同时也能进一步提高模糊程度，但过大的downSample可能会使图像像素化。 最后，我们需要定义关键的OnRenderImage函数。我们首先来看第一个版本，也就是最简单的OnRenderImage的实现：1234567891011121314151617/// 1st edition: just apply blurvoid OnRenderImage(RenderTexture src, RenderTexture dest) &#123; if (material != null) &#123; int rtW = src.width; int rtH = src.height; RenderTexture buffer = RenderTexture.GetTemporary(rtW, rtH, 0); // Render the vertical pass Graphics.Blit(src, buffer, material, 0); // Render the horizontal pass Graphics.Blit(buffer, dest, material, 0); RenderTexture.ReleaseTemporary(buffer); &#125; else &#123; Graphics.Blit(src, dest); &#125;&#125;]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AssetBundles]]></title>
    <url>%2F2019%2F03%2F24%2FAssetBundlesIntro%2F</url>
    <content type="text"><![CDATA[AssetBundlesAssetBundle是一个包含模型，纹理，预制，音频剪辑，甚至整个场景的可以在运行中加载的档案文件。AssetBundles可以表达彼此之间的依赖关系；例如，AssetBundle A中的Matrial可以引用AssetBundle B中的纹理。为了通过网络进行有效传递，可以根据用例需求使用内置算法选择压缩AssetBundle。AssetBundles可用于：可下载的内容更新（DLC）、降低初始安装包大小、针对用户平台进行最优资源加载，以及降低运行时内存压力。 压缩格式(BuildAssetBundleOptions) None 无需任何特殊选项即可构建assetBundle UncompressedAssetBundle 创建ab包时不压缩数据 DisableWriteTypeTree 不再ab中包含类型信息 DeterministicAssetBundle 使用存储在asset中的id的hash构建ab ForceRebuildAssetBundle 强制rebuild ab IgnoreTypeTreeChanges 执行增量构建检查时忽略类型树的改变 AppendHashToAssetBundleName 将hash附加到assetBundle名称 ChunkBasedCompression 创建AssetBundle时使用基于块LZ4压缩 StricMode 如果在其中报告任何错误，则不允许构建成功 DryRunBuild 只编译 DisableLoadAssetByFileName 禁用掉通过文件名加载ab DisableLoadAssetByFileNameWithExtension 禁用掉通过文件名后缀加载ab Unity5的BuildAssetBundleOptions有CollectionDependencies但是在Unity2018.3中已经废弃了，原因是2018.3默认收集资源的依赖资源。这个特性十分的方便，我们只需要将所有东西都做成prefab，将prefab作为资源指定给AssetBundle，由Unity自己去收集所用到的资源就好了。但实际项目中仅仅如此是不够的，原因在复用的资源上。如果多个prefab使用了同一个资源，会出现什么问题呢？我们来试验一下。 而image下面的Dependencies是空的，也就是它没有任何依赖了。 然后此时我在将资源也打包，此时的Dependencies就出来了，但是路径是绝对路径。这其实就是AssetBundle的链式结构和增量打包了。一个小的部分改变了，它将会改变的只有总的AssetBundle.manifest，还有直接依赖它本身的manifest。其他不依赖的部分是不需要重新打包的。还有一点需要注意的地方是，除了manifest文件以外，还有一个没有后缀名称的AssetBundle文件。这个文件其实才是包含了所有依赖关系的总的依赖关系的配置文件，刚才我们能用txt打开的manifest文件，都只是用来做本地依赖关系和增量打包的时候用的。我们加载AssetBundle的时候，完全不需要加载那么manifest文件的，只需要那个没有后缀名称的AssetBundle文件（具体名字和你导出的文件夹有关）就行了。它代表的是该项目的所有AssetBundle依赖关系。所以，刚才我们看到的manifest里面用的都是本地绝对路劲，那是针对你本地打包时用的，和加载无关。]]></content>
      <tags>
        <tag>Unity</tag>
        <tag>AssetBundle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DirectX 9 3D游戏设计入门]]></title>
    <url>%2F2019%2F03%2F24%2FDirectX93DGame%2F</url>
    <content type="text"><![CDATA[三维空间中的向量 几何学中，我们用有向线段表示向量，如图1。向量的两个属性是他的长度和他的顶点所指的方向。因此，可以用向量来模拟既有大小又有方向的物理模型。例如，以后我们要实现的粒子系统。我们用向量来模拟粒子的速度和加速度。在3D计算机图形学中我们用向量不仅仅模拟方向。例如我们常常想知道光线的照射方向，以及在3D世界中的摄象机。向量为在3维空间中表示方向的提供了方便。 向量与位置无关。有同样长度和方向的两个向量是相等的，即使他们在不同的位置。观察彼此平行的两个向量，例如在图1中u和v是相等的。 我们继续学习左手坐标系。图2显示的是左手坐标系和右手坐标系。两者不同的是Z轴的方向。在左手坐标系中Z轴是向书的里面去的，而右手坐标系是向书的外边去的。 图2 因为向量的位置不能改变它的性质，我们可以把所有向量平移使他们的尾部和坐标系的原点重合。因此，当一个向量在标准位置我们能通过头点来描述向量。图3显示的是图1中的向量在标准位置的样子。 图3 我们通常用小写字母表示一个向量，但有时也用大写字母。如2、3和4维向量分别是： u = (ux, uy), N = (Nx, Ny, Nz), c = (cx, cy, cz, cw)。 我们现在介绍4个特殊的3D向量，就象图4显示的。首先是都由含有0的零向量；它被表示成加粗的0 = (0, 0, 0)。接下来3个特殊的向量标准基向量。它们被叫做i, j和k向量，分别沿着坐标系的x轴,y轴和z轴，并且有1的单位长：i = (1, 0, 0), j = (0, 1, 0), and k = (0, 0, 1)。注意：只有1个单位长度的向量叫做单位向量（模长为1的向量）。 图4在D3DX库中，我们能用D3DXVECTOR3类表示3维空间中的向量。它的定义是：1234567891011121314151617181920212223242526272829303132333435typedef struct D3DXVECTOR3 : public D3DVECTOR&#123;public: D3DXVECTOR3() &#123;&#125;; D3DXVECTOR3( CONST FLOAT * ); D3DXVECTOR3( CONST D3DVECTOR&amp; ); D3DXVECTOR3( CONST D3DXFLOAT16 * ); D3DXVECTOR3( FLOAT x, FLOAT y, FLOAT z ); // casting operator FLOAT* (); operator CONST FLOAT* () const; // assignment operators D3DXVECTOR3&amp; operator += ( CONST D3DXVECTOR3&amp; ); D3DXVECTOR3&amp; operator -= ( CONST D3DXVECTOR3&amp; ); D3DXVECTOR3&amp; operator *= ( FLOAT ); D3DXVECTOR3&amp; operator /= ( FLOAT ); // unary operators D3DXVECTOR3 operator + () const; D3DXVECTOR3 operator - () const; // binary operators D3DXVECTOR3 operator + ( CONST D3DXVECTOR3&amp; ) const; D3DXVECTOR3 operator - ( CONST D3DXVECTOR3&amp; ) const; D3DXVECTOR3 operator * ( FLOAT ) const; D3DXVECTOR3 operator / ( FLOAT ) const; friend D3DXVECTOR3 operator * ( FLOAT, CONST struct D3DXVECTOR3&amp; ); BOOL operator == ( CONST D3DXVECTOR3&amp; ) const; BOOL operator != ( CONST D3DXVECTOR3&amp; ) const;&#125; D3DXVECTOR3, *LPD3DXVECTOR3; 注意D3DXVECTOR3是从D3DVECTOR继承的。它的定义是：123typedef struct _D3DVECTOR &#123; float x, y, z;&#125; D3DVECTOR; 向量有它们自己的算法，就像你在D3DXVECTOR3定义中看到的数学运算。现在你不需要知道它们怎么使用。以后介绍这些向量运算以及一些有用的函数和关于向量的重要的详细资料。注意：在3D图形程序中，虽然我们主要关心3D向量，但有时也会用到2D和4D向量。在D3DX库中提供了D3DXVECTOR2和D3DXVECTOR4类来分别表现2D和4D向量。不同维数的向量有着和3D向量一样的性质，也就是它们描述大小和方向，仅仅是在不同的维数中。所有这些向量的数学运算对于不同维数向量都有效只是有一个除外，就是向量积。这些运算我们可通过论述3D向量扩展到2D, 4D甚至n维向量。 向量相等 几何学上，有同样方向和长度的两个向量相等。数学上，我们说有同样维数和分量的向量相等。例如：如果ux = vx, uy = vy, 且 uz = vz.那么(ux, uy, uz) = (vx, vy, vz)。在代码中我们能够用“==”判断两个向量相等。123D3DXVECTOR u(1.0f, 0.0f, 1.0f);D3DXVECTOR v(0.0f, 1.0f, 0.0f);if( u == v ) return true; 同样的，我们也能用“！=”判断两个向量不相等。1if( u != v ) return true; 注意：当比较浮点数时，必须注意。因为浮点数不是精确的，我们认为相等的两个浮点数是有细微差别的；因此，我们测试它们近似相等。我们定义一个常数EPSILON，把它当作非常小的“buffer”。假如两个数和EPSILON相差很小我们说它们近似相等。换句话说，EPSILON让浮点数有一定的精度。接下来的实例函数是怎样用EPSILON比较两个浮点数相等。12345bool Equals(float lhs, float rhs)&#123; // if lhs == rhs their difference should be zero return fabs(lhs - rhs) &lt; EPSILON ? true : false;&#125; 当我们用D3DXVECTOR3类时不必担心，因为它已经帮我们处理了，但是在一般情况下适当注意比较两个浮点数是很重要的。 计算向量大小（向量的模） 几何学上，向量的大小是有向线段的长度。知道向量的分量，利用下面的公式我们就能计算出向量的大小。 $||u||=\sqrt{u{x}^2+u{y}^2+u_{z}^2}$‖u‖表示向量u的长度。例如：计算向量u = (1, 2, 3)和v = (1, 1)的大小。根据公式（1），我们得到： $||u||=\sqrt{1^2+2^2+3^2} = \sqrt{1+4+9}=\sqrt{14}$ 我们利用D3DX库中下面的函数便能计算向量的大小。12345FLOAT D3DXVec3Length( // Returns the magnitude. CONST D3DXVECTOR3* pV // The vector to compute the length of.);D3DXVECTOR3 v(1.0f, 2.0f, 3.0f);float magnitude = D3DXVec3Length( &amp;v ); // = sqrt(14) 标准化向量 标准化向量是让向量的大小等于1，即被叫作单位向量。我们能利用向量大小以及各个分量把一个向量标准化，就像这样： $\hat{u} ={u \over ||u||} = {({u_x \over ||u||}, {u_y \over ||u||}, {u_z \over ||u||})}$我们这样表示单位向量$\hat{u}$。如：标准化向量u = (1, 2, 3) 和 v = (1, 1)。解答方法：根据(2)和(3)我们得到‖u‖=√14 和 ‖v‖=√2,因此： 我们利用D3DX库中下面的函数能标准化向量。1234D3DXVECTOR3 *D3DXVec3Normalize( D3DXVECTOR3* pOut, // Result. CONST D3DXVECTOR3* pV // The vector to normalize.); 注意：这个函数返回一个指针，因此它可以作为一个参数传递给另一个函数。大数情况下，除非另作说明，D3DX数学函数返回的结果是一个指针。但不是所有函数都这样。 向量相加 我们能够通过分别把两个向量的各个分量相加得到向量之和，注意在相加之前必须保证它们有相同的维数。$u + v = ({u_x + v_x, u_y + v_y, u_z + v_z})$图5显示的是几何学上的向量相加。 两个向量相加的代码，我们使用重载的加法操作符：12345D3DXVECTOR3 u(2.0f, 0.0f, 1.0f);D3DXVECTOR3 v(0.0f, -1.0f, 5.0f);// (2.0 + 0.0, 0.0 + (-1.0), 1.0 + 5.0)D3DXVECTOR3 sum = u + v; // = (2.0f, -1.0f, 6.0f) 向量相减 和加法类似，通过分别把两个向量的各个分量相减得到向量之差。再次重声两个向量必须是相同维数。 $u + v = ({u_x - v_x, u_y - v_y, u_z - v_z})$图6显示的是几何学上的向量相减。两个向量相减的代码，我们使用重载的减法操作符：123D3DXVECTOR3 u(2.0f, 0.0f, 1.0f);D3DXVECTOR3 v(0.0f, -1.0f, 5.0f);D3DXVECTOR3 difference = u - v; // = (2.0f, 1.0f, -4.0f) 图6显示，向量减法得到一个从v向量终点到u向量终点的向量。假如我们解释u和v的分量，我们能用向量相减找到从一个点到另一个点的向量。这是非常方便的操作，因为我们常常想找到从一个点到另一个点的方向向量。 标量与向量的乘积我们能用一个标量与向量相乘，就象名字暗示的一样，向量按比例变化。这种运算不会改变向量的方向，除非标量是负数，这种情况向量方向相反。 $ku=(ku_x,ku_y,ku_z)$D3DXVECTOR3类提供了向量与标量乘法的操作符。12D3DXVECTOR3 u(1.0f, 1.0f, -1.0f);D3DXVECTOR3 scaledVec = u * 10.0f; // = (10.0f, 10.0f, -10.0f) 点积 数学上定义点积是两个向量的乘积。按下面等式计算： $u \cdot v = u{x}v_x+u{y}vy+u{z}v_z = S$ 上面的等式不能很明显的体现几何上的意义。利用余弦定律，我们能够发现它们的关系。 u · v =|u||v|cosθ，表示两个向量的点积是它们的模和夹角的余弦之积。因此，如果u和v都是单位向量，那么u·v就是它们夹角的余弦。一些点积中有用的特性 ■ 假如u · v = 0，那么u⊥v。 ■ 假如u · v &gt; 0，那么两个向量的角度θ小于90度。 ■ 假如u · v &lt; 0，那么两个向量的角度θ大于90度。 我们使用下面的D3DX函数计算两个向量的点积：123456789FLOAT D3DXVec3Dot( // Returns the result. CONST D3DXVECTOR3* pV1, // Left sided operand. CONST D3DXVECTOR3* pV2 // Right sided operand.);D3DXVECTOR3 u(1.0f, -1.0f, 0.0f);D3DXVECTOR3 v(3.0f, 2.0f, 1.0f);// 1.0*3.0 + -1.0*2.0 + 0.0*1.0// = 3.0 + -2.0float dot = D3DXVec3Dot( &amp;u, &amp;v ); // = 1.0 叉积 第二种乘法在向量数学中叫叉积。不像点积，结果值是一个标量，叉积的结果值是另一个向量。通过把两个向量u和v相乘得到另一的向量p，向量p垂直于u和v。也就是说向量p垂直于u并且垂直于u。十字相乘就像这样计算：$p=u \times v=[(u{y}v_z-u{z}v{y}),(u{z}vx-u{x}v{z}),(u{x}vy-u{y}v{x})]$$p_x = (u{y}vz-u{z}v{y})$$p_y = (u{z}vx-u{x}v{z})$$p_z = (u{x}vy-u{y}v_{x})$ 如：发现j = k×i = (0, 0, 1)×(1, 0, 0) 并且j同时垂直于k和i.因此，j = (0, 1, 0)。回忆一下上节的标题“叉积”，是说如果u · v = 0，那么u⊥v。同样的如果j · k = 0并且j · i = 0那么我们便能知道j既垂直于k又垂直于i的。我们使用下面的D3DX函数计算两个向量的叉积：12345D3DXVECTOR3 *D3DXVec3Cross( D3DXVECTOR3* pOut, // Result. CONST D3DXVECTOR3* pV1, // Left sided operand. CONST D3DXVECTOR3* pV2 // Right sided operand.); 从下图很明显，向量-p与u和v也都相互垂直。我们执行叉积的命令，确定得到的的结果不管是p或者-p。换句话说，u×v = -(v×u)。这说明叉积是不可交换的。你能通过左手法则确定叉积返回的向量。按照第一个向量指向第二个向量弯曲你的左手，这时拇指所指的方向就是向量所指的方向。 矩阵在这一部分我们关注的焦点是数学中的矩阵。它们在3D图形学中的应用将在下一部分讲解。一个m×n的矩阵是由m行和n列的数字组成的矩阵列。行和列的数字就是这个矩阵的维数。我们通过写在下方的数字识别矩阵清单，数字中的第一个表示行第二个表示列。例如下边的M是3×3矩阵，B是2×4矩阵, C是3×2矩阵。$M=\begin{bmatrix} m{11} &amp; m{12} &amp; m{13} \ m{21} &amp; m{22} &amp; m{23} \ m{31} &amp; m{32} &amp; m{33} \\end{bmatrix}$ $B=\begin{bmatrix} b{11} &amp; b{12} &amp; b{13} b{14} \ b{21} &amp; b{22} &amp; b{23} b{24} \\end{bmatrix}$ $C=\begin{bmatrix} c{11} &amp; c{12} \ c{21} &amp; c{22} \c{31} &amp; c{32} \\end{bmatrix}$我们使用加粗的大写字母表示矩阵。有时一个矩阵只包含一行或者一列。我们用行矩阵和列矩阵这个特殊的名称来称呼。例如下边就是行和列矩阵：$V = \begin{bmatrix} v{1} &amp; v{2} &amp; v{3} v{4} \\end{bmatrix}$ $U = \begin{bmatrix} u{x} \ v{y} \ v{z} \\end{bmatrix}$当使用行或列矩阵时，我们只用一个下标，有时我们还用字母表示。 相等、数乘矩阵以及相加这部分我们将用到下边4个矩阵： $A = \begin{bmatrix} 1 &amp; 5 &amp; -2 3 \\end{bmatrix}$ $B = \begin{bmatrix} 6 &amp; 2 &amp; 5 -8 \\end{bmatrix}$ $C = \begin{bmatrix} 1 &amp; 5 &amp; -2 3 \\end{bmatrix}$ $D = \begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 \ -6 &amp; 3 &amp; 0 &amp; 0 \\end{bmatrix}$ ■假如两个矩阵维数和成员都相同那么它们就相等。例如，A = C 因为A和C有同样的维数并且他们的成员都相等。A≠B同时A≠D因为他们的成员或者维数是不相同的。 ■我们能通过标量与矩阵的每个成员相乘得到标量与矩阵相乘。如矩阵D与k相乘： $kD = \begin{bmatrix} k(1) &amp; k(2) &amp; k(-1) &amp; k(3) \ k(-6) &amp; k(3) &amp; k(0) &amp; k(0) \\end{bmatrix}$假如k = 2,那么： $kD = 2D = \begin{bmatrix} 2(1) &amp; 2(2) &amp; 2(-1) &amp; 2(3) \ 2(-6) &amp; 2(3) &amp; 2(0) &amp; 2(0) \\end{bmatrix} = \begin{bmatrix} 2 &amp; 4 &amp; -2 &amp; 6 \ -12 &amp; 6 &amp; 0 &amp; 0 \\end{bmatrix}$ ■当两个矩阵的维数相同时才能把它们相加。和是把两个矩阵相应的成员相加得到。如： $A+B=\begin{bmatrix} 1 &amp; 5 \ -2 &amp; 2(3) &amp; 2(0) &amp; 2(0) \\end{bmatrix} + \begin{bmatrix} 2(1) &amp; 2(2) &amp; 2(-1) &amp; 2(3) \ 2(-6) &amp; 2(3) &amp; 2(0) &amp; 2(0) \\end{bmatrix}$ ■矩阵有加法当然也就有减法，前提是有相同的维数。矩阵减法如图所示： 乘法 矩阵相乘在3D计算机图形学中是非常重要的运算。通过矩阵相乘，我们能变换向量并且，将不同向量转换到一起。变换是下一节的内容。 为了得到矩阵之积AB，A的列数必须等于B的行数。假如这个条件不满足，就不能相乘。考虑下边两个矩阵，A 和 B，分别是2×3 和 3×3，如： 我们看乘积AB是可以计算的，因为A的列数等于B的行数。注意乘积BA,它们是不能计算的，因为B的列数不等于A的行数。由此说明：一般情况下矩阵乘法不满足乘法交换律（也就是, AB≠BA）。我们说“一般不可交换”因为有一些矩阵乘法的实例还是可以的。 知道了矩阵乘法的计算方法，现在我们就能给出精确的定义：假如A是一个m×n的矩阵，B是一个n×p的矩阵，那么它们之积AB可计算并且是一个m×p 的矩阵C, C的成员ij 等于A的第i个与B的第j个相乘： 例如，求解： 我们检查知道乘法是可计算的，因为A的列数等于B的行数。也知道计算的结果是一个2×2的矩阵。根据公式（4），我们得到： 作为练习，检查AB≠BA。更一般的例子： 单位矩阵 有一种特殊矩阵叫做单位矩阵。单位矩阵是除了对角（左上到右下）以外所有成员都是0，对角都是1的方矩阵。例如，下边是2×2, 3×3, 和 4×4的单位矩阵： 单位矩阵有如下特性：MI = IM=M即，用单位矩阵乘以矩阵不会改变矩阵。此外，这是一个特例：用单位矩阵进行乘法运算满足乘法交换律。单位矩阵可以看作矩阵运算中的数字“1”。 例如：验证2×2矩阵M与单位矩阵相乘得到的结果是M。 逆转下面列举了关于逆矩阵的重要信息。 只有正方形的矩阵（方阵）才能求逆，因此当我们说矩阵求逆，那么它就是方矩阵。 n×n矩阵M的逆矩阵是一个n×n矩阵表示为M–1 不是每个方矩阵都有逆矩阵 矩阵和他的逆矩阵相乘得到一个单位矩阵：M M–1 = M–1M = I。注意当我们进行这样的操作时矩阵是可交换的。 逆矩阵用来解决与其他矩阵相等是非常有用的。例如，考虑等式p’= pR 并且假设我们知道p’和R想求p。首先找到R–1，一旦求得R–1，我们便能求出p，就象这样： 求逆矩阵的方法已经超出了本书的范围，但是这在任何一本线性代数书上都有讲解。在“基本变换”一节我们给出一个特定矩阵的逆矩阵。在“D3DX 矩阵”部分我们将学习一个为我们求逆矩阵的D3DX函数。 我们介绍几个有用的推论：(AB) –1 = B–1 A–1。这个性质前提是：假定A和B都能求逆并且它们都是有相同维数的方矩阵。矩阵的转置 矩阵的转置是相互交换矩阵的行和列。因而，m×n的矩阵的转置是一个n×m的矩阵。我们把矩阵M的转置记作MT。例如：求下面两个矩阵的转置： 重声一下，转置是交换矩阵的行和列。因此： D3DX 矩阵 当设计Direct3D应用程序时，使用4×4矩阵和1×4行矩阵（向量）是有代表性的。注意使用这两种矩阵意味着可以进行下列定义的矩阵乘法。 向量-矩阵乘法。即，假如1×4的单行矩阵V，和4×4的矩阵T，那么积VT可计算并且返回的结果是一个1×4的单行矩阵（向量）。 矩阵-矩阵乘法。即，假如4×4的矩阵T，和4×4的矩阵R，那么积TR和RT可计算并且两者返回的结果都是一个4×4的矩阵。注意因为矩阵乘法不满足交换律所以TR和RT不一定相等。 在D3DX中表示1×4的行矩阵（向量），我们用D3DXVECTOR3和D3DXVECTOR4向量类。当然D3DXVECTOR3只有3个成员，不是4个。然而，第4个成员缺省是1或0（在下一部分有更多信息）。 在D3DX中表示4×4的矩阵，我们用D3DXMATRIX类，定义如下： 12345678910111213141516171819202122232425262728293031323334typedef struct D3DXMATRIX : public D3DMATRIX &#123;public: D3DXMATRIX() &#123;&#125;; D3DXMATRIX( CONST FLOAT * ); D3DXMATRIX( CONST D3DMATRIX&amp; ); D3DXMATRIX( FLOAT _11, FLOAT _12, FLOAT _13, FLOAT _14, FLOAT _21, FLOAT _22, FLOAT _23, FLOAT _24, FLOAT _31, FLOAT _32, FLOAT _33, FLOAT _34, FLOAT _41, FLOAT _42, FLOAT _43, FLOAT _44 ); // access grants FLOAT&amp; operator () ( UINT Row, UINT Col ); FLOAT operator () ( UINT Row, UINT Col ) const; // casting operators operator FLOAT* (); operator CONST FLOAT* () const; // assignment operators D3DXMATRIX&amp; operator *= ( CONST D3DXMATRIX&amp; ); D3DXMATRIX&amp; operator += ( CONST D3DXMATRIX&amp; ); D3DXMATRIX&amp; operator -= ( CONST D3DXMATRIX&amp; ); D3DXMATRIX&amp; operator *= ( FLOAT ); D3DXMATRIX&amp; operator /= ( FLOAT ); // unary operators D3DXMATRIX operator + () const; D3DXMATRIX operator - () const; // binary operators D3DXMATRIX operator * ( CONST D3DXMATRIX&amp; ) const; D3DXMATRIX operator + ( CONST D3DXMATRIX&amp; ) const; D3DXMATRIX operator - ( CONST D3DXMATRIX&amp; ) const; D3DXMATRIX operator * ( FLOAT ) const; D3DXMATRIX operator / ( FLOAT ) const; friend D3DXMATRIX operator * ( FLOAT, CONST D3DXMATRIX&amp; ); BOOL operator == ( CONST D3DXMATRIX&amp; ) const; BOOL operator != ( CONST D3DXMATRIX&amp; ) const;&#125; D3DXMATRIX, *LPD3DXMATRIX; D3DXMATRIX类是从单数结构D3DMATRIX继承的复数形式。D3DMATRIX的定义是：1234567891011typedef struct _D3DMATRIX &#123; union &#123; struct &#123; float _11, _12, _13, _14; float _21, _22, _23, _24; float _31, _32, _33, _34; float _41, _42, _43, _44; &#125;; float m[4][4]; &#125;;&#125; D3DMATRIX; 观察D3DXMATRIX类发现有很多有用的运算符，比如对矩阵检测相等，矩阵相加和矩阵相减，标量与矩阵相乘，铸造（casting），以及非常重要的两个D3DXMATRIXs相乘。因为矩阵相乘是非常重要的，我们给出一段实例代码：123D3DXMATRIX A(…); // initialize AD3DXMATRIX B(…); // initialize BD3DXMATRIX C = A * B; // C = AB D3DXMATRIX类另一个重要的运算符是小括号，它允许我们非常方便的为矩阵成员赋值。注意当使用小括号时我们的下标就象C语言数组下标一样是从0开始的。例如，为一个矩阵的ij = 11 赋值，我们写成：12D3DXMATRIX M;M(0, 0) = 5.0f; // Set entry ij = 11 to 5.0f. D3DX库也提供下列有用的函数：将D3DXMATRIX转化为单位矩阵，转置D3DXMATRIX矩阵以及求逆矩阵。1234567891011121314D3DXMATRIX *D3DXMatrixIdentity( D3DXMATRIX *pout // 将矩阵转换为单位矩阵);D3DXMATRIX M;D3DXMatrixIdentity( &amp;M ); // M = 单位矩阵D3DXMATRIX *D3DXMatrixTranspose( D3DXMATRIX *pOut, // 输出的转置矩阵 CONST D3DXMATRIX *pM // 原矩阵);D3DXMATRIX A(...); // 初始化矩阵AD3DXMATRIX B;D3DXMatrixTranspose( &amp;B, &amp;A ); // B = 输出的转置矩阵 假如我们将不能求逆的矩阵用求逆函数，那么函数将会返回null.同样的，这本书我们忽视第二个参数，并且总是把它设置为0。12345678D3DXMATRIX *D3DXMatrixInverse( D3DXMATRIX *pOut, // 输出的逆矩阵 FLOAT *pDeterminant, // 除非是必需的，一般设为0 CONST D3DXMATRIX *pM // 原矩阵);D3DXMATRIX A(...); // 初始化矩阵D3DXMATRIX B;D3DXMatrixInverse( &amp;B, 0, &amp;A ); // B = A的逆矩阵 基本变换 当用Direct3D编程时，我们使用4×4矩阵来进行矩阵变换。用它的原因是：我们设置一个4×4矩阵X是为了更精确的描述矩阵变换。同样我们设置一个相匹配的点或者把向量的分量放置到一个1×4的行矩阵V中。VX的乘积返回一个新的向量V’。例如：让X沿着x轴平移10个单位同时V = [2, 6, –3, 1]，乘积VX = V’= [12, 6, –3, 1]。 有一些东西需要阐明。我们使用4×4矩阵是因为这样的大小能表现我们需要的所有变换。最初看来一个3×3的好象更适合3D。然而这里有很多种我们喜欢用的变换是不能用一个3×3的矩阵来表示的，比如平移、投影、反射。我们使用向量-矩阵相乘来工作，因此我们至少要通过一个矩阵乘法来完成相应的变化。增大到4×4的矩阵后，它允许我们用一个矩阵描述更多的变换，并且向量-矩阵乘法是可行的。 我们说过把一个相匹配的点或者一个向量的成员放置到一个1×4的行矩阵中。但是点和向量是3D的！为什么我们要用一个1×4的行矩阵呢？我们必需把3D点/向量增大为4D的单行矩阵，是为了符合向量与矩阵的乘法定义，而1×3的单行矩阵和4×4的矩阵相乘是不允许的。 那么，我们怎么使用第四个成员（我们用w来表示）呢？当我们把一个点放置到一个1×4的行矩阵中时，我们设置w为1。允许对点进行适当的平移。因为向量和位置无关，所以向量的平移没有被定义，如果试图这样做会返回一个无意义的向量。为了防止对向量进行平移，当在把一个向量放置到一个1×4行矩阵中时我们把w设置为0。例如：把点p = (p1, p2, p3)放置到一个单行矩阵中就象这样：[p1, p2, p3, 1]，同样把向量v = (v1, v2, v3) 放置到一个单行矩阵中就象这样：[v1, v2, v3, 0]。 注意：我们设置w = 1是为了让点可以被恰当的移动，同样我们设置w = 0是为了防止向量被平移。当我们检查矩阵实际平移时这是一个非常清晰的模型。 有时一个矩阵变换时我们改变向量成员w的值，即w≠0 且 w≠1。考虑下边例子： $p = \begin{bmatrix} p_1 &amp; p_2 &amp; p_3 &amp; 1 \\end{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; 1 &amp; 1 \ 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} = \begin{bmatrix} p_1, p_2, p_3, p_3 \\end{bmatrix} = p`$ 因为p3≠0 且 p3≠1。 我们注意w =p3。当w≠0 且 w≠1时，我们说我们有一个向量在同类空间中，与3维空间中的向量是相对的。我们能通过把向量的每个分量与w相除将同类空间中的向量映射到3维空间中来。例如把同类空间中向量(x, y, z, w) 映射到3维空间中的向量x，我们这样做： ${x \over w}, {y \over w}, {z \over w}, {w \over w}$ 在3D图形程序设计中，从齐次坐标空间映射到3D空间时使用投影透视。矩阵平移 图8 我们能通过与下面的矩阵相乘把向量(x, y, z, 1)沿x轴移动px个单位，沿y轴移动py 个单位，沿z轴移动pz个单位： 将矩阵平移的D3DX函数是：D3DXMATRIX D3DXMatrixTranslation( D3DXMATRIX pOut, // 返回平移后的矩阵. FLOAT x, // x轴移动的单位 FLOAT y, // y轴移动的单位 FLOAT z // z轴移动的单位); 练习：让T(p)做为一个平移变换矩阵，v = [v1, v2, v3, 0]是也个任意向量。验证vT(p) = v（即，假如w = 0，验证通过平移不会改变向量）。 平移矩阵求逆只需要简单的将向量p取反即可： 矩阵旋转图9 我们能用下面的矩阵把一个向量围绕x,y 和z轴旋转δ弧度。注意：当我们俯视绕轴原点时，角度是指顺时针方向的角度。 将矩阵饶着x轴旋转的D3DX函数是：D3DXMATRIX D3DXMatrixRotationX( D3DXMATRIX pOut, // 返回旋转后的矩阵 FLOAT Angle // Angle是旋转的弧度); 将矩阵饶着y轴旋转的D3DX函数是：1234D3DXMATRIX *D3DXMatrixRotationY( D3DXMATRIX* pOut, // 返回旋转后的矩阵 FLOAT Angle // Angle是旋转的弧度); 将矩阵饶着z轴旋转的D3DX函数是：1234D3DXMATRIX *D3DXMatrixRotationZ( D3DXMATRIX* pOut, // 返回旋转后的矩阵 FLOAT Angle // Angle是旋转的弧度); 旋转矩阵R的逆矩阵等于它的转置矩阵：RT= R-1。这样的矩阵我们说它们是互相垂直的。矩阵缩放图10 我们能通过与下面的矩阵相乘把向量沿x轴缩放qx个单位，沿y轴缩放qy 个单位，沿z轴缩放qz个单位： $S(q) = \begin{bmartix}q_x &amp; 0 &amp; 0 &amp; 0 \ 0 q_y &amp; 0 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; q_z 0 \ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmartix}$将矩阵缩放的D3DX函数是：D3DXMATRIX D3DXMatrixScaling( D3DXMATRIX pOut, // 返回缩放后的矩阵 FLOAT sx, // x轴缩放的比例 FLOAT sy, // y轴缩放的比例 FLOAT sz // z轴缩放的比例.); 缩放矩阵求逆只需要将每个缩放因子取倒即可： 综合变换 常常我们要对一个向量进行一系列的变换。比如，我们可能先缩放一个向量，然后旋转它，最后把它平移到指定的位置。 例如：先把向量p = [5, 0, 0, 1] 在所有轴上缩小为原来的1/5，然后沿着y轴旋转π/4，最后把它在x轴上移动1个单位，在y轴上移动2个单位，在z轴上移动3个单位。 解答：注意我们必须完成缩放，沿y轴旋转，以及移动。我们设缩放、旋转、移动的变换矩阵分别是S, Ry, T，如下： 应用缩放，旋转，以及平移一系列变换，我们得到： 我们能用矩阵乘法把几个变换矩阵转换成一个矩阵，它是非常有益的矩阵。比如，重新考虑这部分开始的例子。通过使用矩阵相乘把3个变换矩阵合成一个矩阵。注意我们必须按实际应用的顺序来进行矩阵相乘。 那么 pQ = [1.707, 2, –3.707, 1]。 联合变换有提高效率的能力。假如我们需要对一组数量巨大的向量（在3D图形任务中是很普遍的）进行同样的缩放，旋转以及移动变换。替换这一系列的变换，即就象等式(5)中对每一个向量的做法，我们能把所有3个变换转换到一个矩阵中，即就象在等式(6)中的做法。这样我们只需要对每一个向量进行一次乘法就可以实现3种变换。这就减少了大量的向量-矩阵乘法操作。一些向量变换函数 D3DX库分别提供了下边两个对点和向量的变换函数。D3DXVec3TransformCoord函数变换点同时设置向量第4个成员为1（用于变换点向量）。D3DXVec3TransformNormal函数变换向量并且设置第4个成员为0（用于变换方向向量）。D3DXVECTOR3 D3DXVec3TransformCoord( D3DXVECTOR3 pOut, // 返回的点向量 CONST D3DXVECTOR3 pV, // 点向量 CONST D3DXMATRIX pM // 变换矩阵 );D3DXMATRIX T(…); // 初始化矩阵D3DXVECTOR3 p(…); // 初始化点D3DXVec3TransformCoord( &amp;p, &amp;p, &amp;T); // 变换一个点 D3DXVECTOR3 WINAPI D3DXVec3TransformNormal( D3DXVECTOR3 pOut, //返回的方向向量 CONST D3DXVECTOR3 pV, // 方向向量 CONST D3DXMATRIX pM //变换矩阵);D3DXMATRIX T(…); // 初始化变换矩阵D3DXVECTOR3 v(…); // 初始化方向向量D3DXVec3TransformNormal( &amp;v, &amp;v, &amp;T); // 变换方向向量注意：D3DX库也提供D3DXVec3TransformCoordArray和D3DXVec3TransformNormalArray来分别变换一个点数组和向量数组平面 一个平面能通过一个向量n和平面上的一个点p0来描述。这个向量n垂直于平面，它被称为此平面的法向量（如图11）。 图11 在图12中我们能够发现平面上任意一点p都满足如下等式。即：假如p、p0都是平面上一点，那么向量（p - p0）垂直于平面的法向量。 图12 当我们通过法向量n和平面上一个已知点来描述一个平面时，等式（7）又被写成这样： 这时d = –n·p0。 D3DX平面在代码中描述一个平面：仅仅需要一个法向量n和常数d就可以了。因此我们就使用一个4D向量（我们记录成(n, d)）来实现它。D3DX库中用如下的结构来定义一个平面：1234567891011121314151617181920typedef struct D3DXPLANE&#123;#ifdef __cpluspluspublic: D3DXPLANE() &#123;&#125; D3DXPLANE( CONST FLOAT* ); D3DXPLANE( CONST D3DXFLOAT16* ); D3DXPLANE( FLOAT a, FLOAT b, FLOAT c, FLOAT d ); // casting operator FLOAT* (); operator CONST FLOAT* () const; // unary operators D3DXPLANE operator + () const; D3DXPLANE operator - () const; // binary operators BOOL operator == ( CONST D3DXPLANE&amp; ) const; BOOL operator != ( CONST D3DXPLANE&amp; ) const;#endif //__cplusplus FLOAT a, b, c, d;&#125; D3DXPLANE, *LPD3DXPLANE; 对照等式（8）可知：这里a, b和c是平面法向量n的成员，d就是那个常数。 点和平面的空间关系我们判定点和平面的关系主要是利用等式(8)来实现。例如，假设平面(n, d)，我们能判定点p和平面的关系： 假如n·p + d = 0，那么点p与平面共面。 假如n·p + d &gt;0，那么点p在平面的前面且在平面的正半空间里。 假如n·p + d &lt;0，那么点p在平面的背面且在平面的负半空间里。 下边的D3DX函数就是利用n·p + d 来判定点和平面的关系的函数：123456789101112FLOAT D3DXPlaneDotCoord( CONST D3DXPLANE *pP, // 平面 CONST D3DXVECTOR3 *pV // 点);// 测试点相对于平面的位置D3DXPLANE p(0.0f, 1.0f, 0.0f, 0.0f);D3DXVECTOR3 v(3.0f, 5.0f, 2.0f);float x = D3DXPlaneDotCoord( &amp;p, &amp;v );if( x approximately equals 0.0f ) // v在平面.上if( x &gt; 0 ) // v在正半空间if( x &lt; 0 ) // v在负半空间 创建平面我们能通过两种方法创建平面。第一种方法，直接用指定法线和点创建平面。假设法线n和在平面上的已知点p0,我们就能求出d：$n \cdot P_0 + d = 0$$n \cdot P_0 = -d$$-n \cdot P_0 = d$ D3DX库提供如下函数来完成创建平面的任务：12345D3DXPLANE *D3DXPlaneFromPointNormal( D3DXPLANE* pOut, // Result. CONST D3DXVECTOR3* pPoint, // Point on the plane. CONST D3DXVECTOR3* pNormal // The normal of the plane.); 第二种方法，我们能通过在平面上的3个点创立一个平面。假如有点p0, p1, p2，那么我们就能得到平面上的两个向量：$u = p_1 - p_0$$v = p_2 - p_0$因此我们能通过把平面上的两个向量进行十字相乘得到平面的法线。回忆左手坐标系。$n = u \times v$那么–(n·p0) = d.D3DX库提供如下函数来完成通过同一平面上的3个点确定一个平面：123456D3DXPLANE *D3DXPlaneFromPoints( D3DXPLANE* pOut, // Result. CONST D3DXVECTOR3* pV1, // Point 1 on the plane. CONST D3DXVECTOR3* pV2, // Point 2 on the plane. CONST D3DXVECTOR3* pV3 // Point 3 on the plane.); 标准化平面有时我们可能想标准化一个平面的法向量，即标准化平面。初一想，好象我们只需象标准化其他向量一样标准化平面的法向量就可以了。但是回忆在等式n·p + d = 0中的d = –n·p0。我们明白法向量的长度将影响常数d。因此，假如我们标准化法向量，我们必须重新计算d.注意${d \over ||n||} = -{n \over ||n||} \cdot P_0$ 因此，我们有下边公式来标准化平面(n, d)的法向量： 我们能用下面的D3DX函数来标准化一个平面：1234D3DXPLANE *D3DXPlaneNormalize( D3DXPLANE *pOut, // Resulting normalized plane. CONST D3DXPLANE *pP // Input plane.); 变换平面我们能够通过如下处理来变换一个面（n, d），就象一个4D向量通过乘以它渴望得到变换的变换矩阵的逆矩阵一样来达到变换目的。注意平面的法向量必须首先被标准化。我们能用下面的D3DX函数来完成操作：12345D3DXPLANE *D3DXPlaneTransform( D3DXPLANE *pOut, // Result CONST D3DXPLANE *pP, // Input plane. CONST D3DXMATRIX *pM // Transformation matrix.); 示例代码：12345678D3DXMATRIX T(...); // Init. T to a desired transformation.D3DXMATRIX inverseOfT;D3DXMATRIX inverseTransposeOfT;D3DXMatrixInverse( &amp;inverseOfT, 0, &amp;T );D3DXMatrixTranspose( &amp;inverseTransposeOfT, &amp;inverseOfT );D3DXPLANE p(...); // Init. Plane.D3DXPlaneNormalize( &amp;p, &amp;p ); // make sure normal is normalized.D3DXPlaneTransform( &amp;p, &amp;p, &amp;inverseTransposeOfT ); 点到平面上最近的点 假如我们在空间中有一个点p并且想找到在平面( n, d)上的与p最接近一个点q。注意如果平面的法向量是单位长度，这将简化问题。 图13 从图13我们能看出q = p + (–k_n)，k是有符号之分的从点p到平面的距离，也就是点p和q之间的有向距离。假如平面的法向量n是单位长度，那么n·p + d 就是从平面到点p有向距离. 射线 一条射线能用一个起点和方向来描述。射线的参数方程是： $p(t)=p_{0} + tu$ 图14 p0 是射线的起点，u是射线的方向，t是参数。通过赋予不同的t值，我们能计算出在射线上不同的点。要描述一条射线，参数t范围就必须在[0, ∞)之间。实际上，假如我们让t∈(–∞, ∞),那么我们就能得到一条3维空间直线。 线/面相交 假设一条射线p(t) = p0 + tu 和 一个平面n·p + d = 0，我们想知道射线是否与平面相交，以及相交的交点信息（如果相交的话）。照这样做，我们把射线代入平面方程并且求满足平面方程的参数t，解答出来的参数就是相交的点。 假如t 不在[0, ∞)之间，那么射线与平面不相交。 假如t 在[0, ∞)之间，那么射线与平面相交。且把参数代入射线方程就能找到交点： 初始化Direct3D (Direct3D Initialization)Direct3D概述 Direct3D是一种底层图形API，它能让我们利用3D硬件加速来渲染3D世界。我们可以把Direct3D看作是应用程序和图形设备之间的中介。例如通知图形设备清空屏幕，应用程序将调用Direct3D的IDirect3DDevice9::Clear方法。图1.1显示了应用程序、Direct3D和图形设备之间的关系。 图1.1中Direct3D所表示的是Direct3D中已定义的，供程序员使用的Direct3D接口和函数的集合。这些接口和函数代表了当前版本的Direct3D所支持的全部特性。注意：仅仅因为Direct3D支持某种特性，并不意味着你所使用的图形硬件（显卡）也能支持它。 如图1.1所示，在Direct3D和图形设备之间有一层中介——叫做硬件抽象层（HAL，Hardware Abstraction Layer）。Direct3D不能直接作用于图形设备，因为现在市面上的显卡种类实在是太多了并且每种显卡都有不同的性能和处理事件的方式。例如，两种不同的显卡实现清屏的方式也可能是不同的。因此，Direct3D要求设备制造商实现HAL。HAL是一组指示设备执行某种操作的特殊设备代码的集合。用这种方法，Direct3D避免了必须去了解某个设备的特殊细节，使它能够独立于硬件设备。 设备制造商在HAL中实现他们的产品所支持的所有特性。HAL将不会实现那些Direct3D支持但硬件产品不支持的特性。调用一个HAL中没有实现的Direct3D的函数将会出错，除非它是顶点处理操作，因为这个功能可以由软件模拟来实现。因此当使用某些仅由市面上少数显卡所支持的高级特性时，必须检测一下设备是否支持。（设备的功能将在1.3.8节中讲解） REF设备 你也许想把一些你的设备不支持的Direct3D函数写入程序。为了达到这个目的，Direct3D提供了REF设备,它用软件模拟了所有的Direct3D API。这允许你写并测试那些你的显卡不支持的Direct3D特性的代码。例如在本书的第四部分，某些人的显卡可能会不支持顶点和像素着色器。如果你的显卡不支持着色器，你仍然能够使用RE设备测试示例代码。懂得RE设备仅仅是为了发展，这是很重要的。它只会和DirectX SDK一起被装载，而不会发布给最终用户。 另外，RE设备实在是太慢了，除了测试以外它没有任何利用价值。 D3DDEVTYPE 在代码中，我们用D3DDEVTYPE_HAL来定义HAL设备，它是D3DDEVTYPE枚举类型的一个成员。同样的，REF设备则由D3DDEVTYPE_REF来定义，它也属于D3DDEVTYPE枚举类型。记住这些类型很重要，因为在创建设备的时候我们需要指定我们将要使用的类型。 COM 组件对象模型（COM, Component Object Model）是一种能使DirectX独立于编程语言和具有向下兼容性的技术。我们通常把COM对象作为一个接口，你可以把它当作达到某种目的的C++类来使用它。当使用C++写DirectX程序的时候，COM的大部分细节对我们来说是透明。但是有一件事，我们必须知道，那就是我们通过某个特殊的COM接口的函数或指针获得了另一个COM接口指针，而不是通过C++的新关键字来创建它。当我们使用完某个接口后，调用它的Release方法比直接Delete它更好。COM对象具有它们自己的内存管理。 对COM来说还有很多细节可以了解，但是掌握这些细节对于我们有效的使用DirectX不是必须的。注意：COM接口都具有前缀大写字母“I”，例如表示一个表面的COM接口叫做IDirect3DSurface9。 一些准备工作 Direct3D的初始化过程要求我们对图形学基础知识和Direct3D类型有一定了解。本节将介绍这些知识和类型，以确保下一节能把焦点集中在讨论Direct3D的初始化上。 表面 表面是一个像素点阵，在Direct3D中主要用来存储2D图形数据。图1.2指明了表面的一些成分。由图可以看出表面数据就像一个矩阵，像素数据实际上存储在线性数组里面。 表面的Width和Height是按像素计算的。Pitch以字节为单位。而且Pitch有可能比Width大且依赖于低层硬件，所以不能单纯的认为Pitch = Width * sizeof (pixelFormat)。 在代码中，我们可以使用IDirect3DSurface9接口来描述表面。这个接口提供若干方法来直接读写表面数据并且还有一个方法用来返回表面信息。IDirect3DSurface9中最重要的方法是： LockRect——使用这个方法，我们将获得一个指向表面内存的指针，然后，通过一系列指针运算，我们可以对表面上任一个像素点进行读、写操作。 UnlockRect——当你调用了LockRect和完成了对表面内存的访问后，你必须调用这个方法给表面解锁。 GetDesc——这个方法将通过填充D3DSURFACE_DESC结构来返回表面的描述信息。最初锁定表面和改写每一像素看来稍微有点迷茫。下面的代码表示锁定表面并将每一像素染成红色：12345678910111213141516171819202122232425262728// 假定_surface是一个指向IDirect3DSurface9接口的指针// 假定每个像素为：32-bit的像素格式// 取得表面描述D3DSURFACE_DESC surfaceDesc;_surface-&gt;GetDesc(&amp;surfaceDesc);// 取得被锁定表面的像素数据的指针D3DLOCKED_RECT lockedRect;_surface-&gt;LockRect( &amp;lockedRect, // 指向被锁定表面的数据 0, // 0表示锁定全部表面 0); // 0表示没有指定锁定标记// 遍例表面上的每个像素，将它们设为红色DWORD* imageData = (DWORD*)lockedRect.pBits;for(int i = 0; i &lt; surfaceDesc.Height; i++)&#123; for(int j = 0; j &lt; surfaceDesc.Width; j++) &#123; // 取得纹理索引, 注意我们用pitch 除以4是因为pitch的单位是像素， // 并且一个DWORD类型占为4 bytes空间 int index = i * lockedRect.Pitch / 4 + j; imageData[index] = 0xffff0000; // 每个像素设为红色 &#125;&#125;_surface-&gt;UnlockRect(); 程序中D3DLOCKED_RECT结构的定义如下：1234typedef struct _D3DLOCKED_RECT &#123; INT Pitch; // 表面深度 void *pBits; // 指向表面开始处的内存&#125; D3DLOCKED_RECT; 在这里有一些关于表面锁定代码的一些说明。32-bit像素格式这个设定很重要，我们把bits转换成DWORDs。这让我们能把每一个DWORD视为表示一个像素。 Multisampling由于使用像素矩阵来表示图像，在显示时会出现锯齿状，Multisampling就是使其变得平滑的技术。它的一种最普通的用法即为——全屏抗锯齿。 D3DMULTISAMPLE_TYPE枚举类型使我们可以指定全屏抗锯齿的质量等级： D3DMULTISAMPLE_NONE——不使用全屏抗锯齿。 D3DMULTISAMPLE_1_SAMPLE…D3DMULTISAPLE_16_SAMPLE——设定1-16级的等级。 本书的示例程序中没有使用全屏抗锯齿的功能，因为它大大的降低了程序运行速度。如果你实在很想使用它的话，要记住使用IDirect3D9::CheckDeviceMultisampleType来检测你的显卡是否支持。 像素格式当我们创建一个表面或纹理时，经常需要指定这些Direct3D资源的像素格式。它是由D3DFORMAT枚举类型的一个成员来定义的。这里例举一部分： D3DFMT_R8G8B8——表示一个24位像素，从左开始，8位分配给红色，8位分配给绿色，8位分配给蓝色。 D3DFMT_X8R8G8B8——表示一个32位像素，从左开始，8位不用，8位分配给红色，8位分配给绿色，8位分配给蓝色。 D3DFMT_A8R8G8B8——表示一个32位像素，从左开始，8位为ALPHA通道，8位分配给红色，8位分配给绿色，8位分配给蓝色。 D3DFMT_A16B16G16R16F——表示一个64位浮点像素，从左开始，16位为ALPHA通道，16位分配给蓝色，16位分配给绿色，16位分配给红色。 D3DFMT_A32B32G32R32F——表示一个128位浮点像素，从左开始，32位为ALPHA通道，32位分配给蓝色，32位分配给绿色，32位分配给红色。想了解全部的像素格式请查看SDK文档中的D3DFORMAT部分。注意：这前三种格式（D3DFMT_R8G8B8、D3DFMT_X8R8G8B8、D3DFMT_A8R8G8B8）是最常用并为大部分显卡所支持。但浮点像素格式或其它一些类型的支持并不是很广泛，在使用它们前请先检测你的显卡，看是否支持。 内存池表面和其它一些Direct3D资源被放在多种内存池中。内存池的种类由D3DPOOL枚举类型的一个成员来指定。可用到的内存池有下列几种： D3DPOOL_DEFAULT——表示Direct3D将根据资源的类型和用途把它们放在最合适的地方。这有可能是显存、AGP内存或者系统内存中。值得注意的是，这种内存池中的资源必须要在IDirect3DDevice9::Reset被调用之前消毁掉，并且再次使用时必须重新初始化。 D3DPOOL_MANAGED——资源将由Direct3D管理并且按设备的需要来指定放在显存还是放在AGP内存中。当应用程序访问和改变资源时它先把这些资源拷贝到系统内存中，当需要时Direct3D会自动把它们拷贝到显存里。 D3DPOOL_SYSTEMMEM——指定资源放在系统内存中。 D3DPOOL_SCRATCH——指定资源放在系统内存中，它与D3DPOOL_SYSTEMMEM不同之处在于使用这些资源不必受图形设备的限制。因此，参数使图形设备不能访问该内存池的资源，但资源可以相互拷贝。1.3.5 交换链和页面切换 Direct3D通常创建2~3个表面组成一个集合，即为交换链，通常由IDirect3DSwapChain接口来表示。我们不必去了解它更详细的细节。我们也很少去管理它，通常Direct3D会自己去管理。所以我们只要大概的了解一下它就可以了。 交换链以及页面切换技巧被用在使两帧动画之间过度更平滑。图1.4展示的是一个有两个绘制表面的交换链。 图1.4 如图1.4，在Front Buffer中的表面将用来在屏幕上显示。显示器不能即时显示Front Buffer中表示的图像；通常情况下，它是每六十分之一秒刷新显示一次，即刷新率为60赫兹。应用程序的帧率经常与监视器的刷新率不同步（比如应用程序的渲染帧速度可能比显示器的刷新速度快）。然而，我们不能在显示器显示完成当前帧之前就更新有下一帧动画的Front Buffer内容，但是我们又不想让程序停止渲染而去等待显示器显示。因此，我们渲染另一个屏幕表面Back Buffer。当监视器将Front Buffer显示出来后，Front Buffer就被放到交换链的末端，即变成图中的Back Buffer，而Back Buffer就会变成交换链中的Front Buffer。这个过程就叫做presenting。图1.5表示了交换的整个过程。 图1.5 因此，我们绘图代码的结构就会像下面这样：1． Render to back buffer2． Present the back buffer3． Goto (1)1.3.6 深度缓冲 深度缓冲也是一个表面，但它不是用来存储图像数据的，而是用来记录像素的深度信息。它将确定哪一个像素最后被绘制出来。所以，如果要绘制640480分辨率的图片，那么就会有640480个深度值。 图1.6图1.6展示了一个简单的场景，在这个场景里，一个物体把将另一个物体的一部分遮住了。为了使Direct3D能确定物体的前后关系并正确的绘制出来，我们使用一种深度缓冲，又叫做z-buffering的技术。 深度缓冲为每一个像素计算深度值，并进行深度测试。通过深度测试，我们可以比较出哪个像素离照相机更近，并将它画出来。这样就可以只绘制最靠近照相机的像素，被遮住的像素就不会被画出来。 深度缓冲的格式决定着深度测试的精确性。一个24位的深度缓冲比16位的深度缓冲更精确。通常，应用程序在24位深度缓冲下就能工作的很好，但是Direct3D也同时支持32位的深度缓冲。 D3DFMT_D32——表示32位深度缓冲 D3DFMT_D24S8——表示24位深度缓冲并保留8位模版缓冲（stencil buffer） D3DFMT_D24X8——表示24位深度缓冲 D3DFMT_D24X4S4——表示24位深度缓冲并保留4位模版缓冲 D3DFMT_D16——表示16位深度缓冲 注意：关于模版缓冲的问题将在第八章详细说明。1.3.7 顶点处理 顶点是3D图形学的基础，它能够通过两种不同的方法被处理，一种是软件方式（software vertex processing），一种是硬件方式（hardware vertex processing），前者总是被支持且永远可用，后者必须要显卡硬件支持顶点处理才可用。 使用硬件顶点处理总是首选，因为它比软件方式更快，而且不占用CPU资源，这意味CPU至少可以有更多的空闲时间进行别的计算。注意：如果一块显卡支持硬件顶点处理的话，也就是说它也支持硬件几何转换和光源计算。1.3.8 设备能力 Direct3D支持的每一项特性都对应于D3DCAPS9结构的一个数据成员。初始化一个D3DCAPS9实例应该以你的设备实际支持特性为基础。因此，在我们的应用程序里，我们能够通过检测D3DCAPS9结构中相对应的某一成员来检测设备是否支持这一特性。 下面将举例说明，假设我们想要检测显卡是否支持硬件顶点处理（换句话说，就是显卡是否支持硬件几何转换和光源计算）。通过查阅SDK中的D3DCAPS9结构，可以得知数据成员D3DCAPS9::DevCaps中的D3DDEVCAPS_HWTRANSFORMANDLIGHT位表示硬件是否支持硬件顶点处理即硬件几何变换和光源计算。程序如下：12345678910111213bool supportsHardwareVertexProcessing;// 如果为真，意味着硬件设备支持它if( caps.DevCaps &amp; D3DDEVCAPS_HWTRANSFORMANDLIGHT )&#123; // 支持 supportsHardwareVertexProcessing = true;&#125;else&#123; // 不支持 hardwareSupportsVertexProcessing = false;&#125; 注意：DevCaps即为“device capabilities” 下一节将学习怎样根据硬件的实际情况来初始化D3DCAPS9 我们建议你阅读SDK中关于D3DCAPS9的结构，它完整的列出了Direct3D支持的特性。1.4 初始化Direct3D 下面几点说明怎样初始化Direct3D。根据下边的步骤你能初始化Direct3D：1． 获得一个IDirect3D9接口指针。这个接口用于获得物理设备的信息和创建一个IDirect3DDevice9接口，它是一个代表我们显示3D图形的物理设备的C++对象。2． 检查设备能力（D3DCAPS9），搞清楚主显卡是否支持硬件顶点处理。我们需要知道假如它能支持，我们就能创建IDirect3DDevice9接口。3． 初始化一个D3DPRESENT_PARAMETERS结构实例，这个结构包含了许多数据成员允许我们指定将要创建的IDirect3DDevice9接口的特性。4． 创建一个基于已经初始化好的D3DPRESENT_PARAMETERS结构的IDirect3DDevice9对象。它是一个代表我们显示3D图形的物理设备的C++对象。请注意，本书使用主显示设备绘制3D图形，如果你的机子只有一块显卡，那它就是主显示设备。如果你有多个显卡，那么你当前使用的显卡将会成为主显示设备（如：用来显示Windows桌面的显卡）。1.4.1获得IDirect3D9接口 Direct3D的初始化是从获得一个IDirect3D9接口指针开始的。使用一个专门的Direct3D函数来完成这个工作是非常容易的，代码如下：IDirect3D9 _d3d9;_d3d9 = Direct3DCreate9(D3D_SDK_VERSION); Direct3DCreate9的唯一一个参数总是D3D_SDK_VERSION，这可以保证应用程序通过正确的头文件被生成。如果函数调用失败，那么它将返回一个空指针。 IDirect3D9对象通常有两个用途：设备列举和创建IDirect3DDevice9对象。设备列举即为查明系统中显示设备的技术特性，显示模式、格式，以及其它每一种显卡各自支持的特性。创建代表物理设备的IDirect3DDevice9对象，我们需要利用这个物理设备的显示模式结构和格式来创建它。为了找到一个工作配置，我们必须使用IDirect3D9的列举方法。 然而，设备列举实在太慢了，为了使Direct3D运行得尽可能快，我们通常不使用这个测试，除了下一节所谈到的一项测试。为了安全跳过它，我们可以选择总是被所有显卡都支持的“安全”配置。1.4.2 检测硬件顶点处理 当我们创建一个IDirect3DDevice9对象来表示主显示设备时，必须要设定其顶点处理的类型。如果可以的话，当然要选用硬件顶点处理，但是由于并非所有显卡都支持硬件顶点处理，因此我们必须首先检查显卡是否支持。 首先我们要根据主显示设备的技术特性来初始化D3DCAPS9实例。可以使用如下方法：HRESULT IDirect3D9::GetDeviceCaps( UINT Adapter, D3DDEVTYPE DeviceType, D3DCAPS9 pCaps); Adapter——指定要获得哪个显示适配器的特性 DeviceType——指定设备类型（硬件设备（D3DDEVTYPE_HAL），软件设备（D3DDEVTYPE_REF）） PCaps——返回一个已初始化的D3DCAPS9结构 然后，我们就可以象1.3.8部分那样检测显卡的能力了。下面就是代码片段：// 填充主显示设备的能力（D3DCAPS9结构）123456789101112131415161718D3DCAPS9 caps;d3d9-&gt;GetDeviceCaps( D3DADAPTER_DEFAULT, // 主显示设备 deviceType, // 设备类型，一般是D3DDEVTYPE_HAL. &amp;caps); // 返回填充后的D3DCAPS9 结构，包含主显示设备的能力// 是否可以使用硬件顶点处理?int vp = 0;if( caps.DevCaps &amp; D3DDEVCAPS_HWTRANSFORMANDLIGHT )&#123; // 是，支持硬件顶点处理 vp = D3DCREATE_HARDWARE_VERTEXPROCESSING;&#125;else&#123; // 不，只能用软件顶点处理 vp = D3DCREATE_SOFTWARE_VERTEXPROCESSING;&#125; 观察代码，我们使用变量vp来存储顶点处理类型。这是因为在稍后创建IDirect3DDevice9对象时要求指定其顶点处理的类型。注意：标识符D3DCREATE_HARDWARE_VERTEXPROCESSING和D3DCREATE_SOFTWARE_VERTEXPROCESSING是预定义的值，它们分别代表硬件顶点处理和软件顶点处理。 技巧：若我们开发有一些新的，高级特性的程序，在使用前我们总是先检查硬件是否支持这些特性。注意：如果一个应用程序在你的机子上不能运行，说明它用到的一些特性可能你的显卡并不支持，可以试试把设备类型换成REF。1.4.3 填充D3DPRESENT_PARAMETERS结构初始化过程的下一步是填充一个D3DPRESENT_PARAMETERS结构的实例。这个结构用于设定我们将要创建的IDirect3DDevice9对象的一些特性，它的定义如下：12345678910111213141516typedef struct _D3DPRESENT_PARAMETERS_ &#123; UINT BackBufferWidth; UINT BackBufferHeight; D3DFORMAT BackBufferFormat; UINT BackBufferCount; D3DMULTISAMPLE_TYPE MultiSampleType; DWORD MultiSampleQuality; D3DSWAPEFFECT SwapEffect; HWND hDeviceWindow; BOOL Windowed; BOOL EnableAutoDepthStencil; D3DFORMAT AutoDepthStencilFormat; DWORD Flags; UINT FullScreen_RefreshRateInHz; UINT PresentationInterval;&#125; D3DPRESENT_PARAMETERS; 下面介绍其比较重要的数据成员，至于更详细的信息，请查阅SDK：BackBufferWidth——后备缓冲表面的宽度（以像素为单位）BackBufferHeight——后备缓冲表面的高度（以像素为单位）BackBufferFormat——后备缓冲表面的像素格式（如：32位像素格式为D3DFMT——A8R8G8B8）BackBufferCount——后备缓冲表面的数量，通常设为“1”，即只有一个后备表面MultiSampleType——全屏抗锯齿的类型，详情请看SDKMultiSampleQuality——全屏抗锯齿的质量等级，详情看SDKSwapEffect——指定表面在交换链中是如何被交换的，取D3DSWAPEFFECT枚举类型中的一个成员。其中D3DSWAPEFFECT_DISCARD是最有效的hDeviceWindow——与设备相关的窗口句柄，你想在哪个窗口绘制就写那个窗口的句柄Windowed——BOOL型，设为true则为窗口模式，false则为全屏模式EnableAutoDepthStencil——设为true，D3D将自动创建深度/模版缓冲AutoDepthStencilFormat——深度/模版缓冲的格式Flags——一些附加特性，设为0或D3DPRESENTFLAG类型的一个成员。下列两个最常用的标志全部的标志请查阅SDK： D3DPRESENTFLAG_LOCKABLE_BACKBUFFER——设定后备表面能够被锁定，这会降低应用程序的性能 D3DPRESENTFLAG_DISCARD_DEPTHSTENCIL——深度/模版缓冲在调用IDirect3DDevice9::present方法后将被删除，这有利于提升程序性能FullScreen_RefreshRateInHz——刷新率，设定D3DPRESENT_RATE_DEFAULT使用默认刷新率PresentationInterval——属于D3DPRESENT成员，又有两个常用标志，其余请查SDK： D3DPRESENT_INTERVAL_IMMEDIATE——立即交换 D3DPRESENT_INTERVAL_DEFAULT——D3D选择交换速度，通常等于刷新率填充示例如下：123456789101112131415D3DPRESENT_PARAMETERS d3dpp;d3dpp.BackBufferWidth = 800;d3dpp.BackBufferHeight = 600;d3dpp.BackBufferFormat = D3DFMT_A8R8G8B8; //像素格式d3dpp.BackBufferCount = 1;d3dpp.MultiSampleType = D3DMULTISAMPLE_NONE;d3dpp.MultiSampleQuality = 0;d3dpp.SwapEffect = D3DSWAPEFFECT_DISCARD;d3dpp.hDeviceWindow = hwnd;d3dpp.Windowed = false; // fullscreend3dpp.EnableAutoDepthStencil = true;d3dpp.AutoDepthStencilFormat = D3DFMT_D24S8; // depth formatd3dpp.Flags = 0;d3dpp.FullScreen_RefreshRateInHz = D3DPRESENT_RATE_DEFAULT;d3dpp.PresentationInterval = D3DPRESENT_INTERVAL_IMMEDIATE; 1.4.4 创建IDirect3DDevice9对象 在填充完了D3DPRESENT_PARAMETERS结构后，我们就可以用下面的方法创建一个IDirect3DDevice9对象了：HRESULT IDirect3D9::CreateDevice( UINT Adapter, D3DDEVTYPE DeviceType, HWND hFocusWindow, DWORD BehaviorFlags, D3DPRESENT_PARAMETERS pPresentationParameters, IDirect3DDevice9* ppReturnedDeviceInterface); Adapter——指定对象要表示的物理显示设备 DeviceType——设备类型，前面说过 hFocusWindow——同我们在前面d3dpp.hDeviceWindow的相同 BehaviorFlags——设定为D3DCREATE_SOFTWARE_VERTEXPROCESSING或者D3DCREATE_HARDWARE_VERTEXPROCESSING pPresentationParameters——指定一个已经初始化好的D3DPRESENT_PARAMETERS实例 ppReturnedDeviceInterface——返回创建的设备例子：12345678910111213IDirect3DDevice9* device = 0;hr = d3d9-&gt;CreateDevice( D3DADAPTER_DEFAULT, // primary adapter D3DDEVTYPE_HAL, // device type hwnd, // window associated with device D3DCREATE_HARDWARE_VERTEXPROCESSING, // vertex processing type &amp;d3dpp, // present parameters &amp;device); // returned created deviceif( FAILED(hr) )&#123; ::MessageBox(0, "CreateDevice() - FAILED", 0, 0); return 0;&#125; 1.5 初始化Direct3D实例在本章的例程中，初始化了一个Direct3D应用程序并用黑色填充显示窗口（如图1.7）。 图1.7 本书所有的应用程序都包含了d3dUtility.h和d3dUtility.cpp这两个文件，它们所包含的函数实现了所有Direct3D应用程序都要去做的一些常见的功能。例如：创建一个窗口、初始化Direct3D、进入程序的消息循环等。将这些功能封装在函数中能使示例程序更加突出该章的主题。另外，在我们学习本书的过程中还会在这两个文件中加上一些通用的代码。 1.5.1 d3dUtility.h/cpp 在开始本章的例程之前，让我们先熟悉一下d3dUtility.h/cpp所提供的函数。d3dUtility.h如下：// 包含主要的Direct3DX头文件，这将包含我们需要的另外的Direct3D头文件12345678910111213141516171819202122232425262728293031323334353637#include &lt;d3dx9.h&gt;namespace d3d&#123; bool InitD3D( HINSTANCE hInstance, // [in] 应用程序实例 int width, int height, // [in] Back buffer尺寸 bool windowed, // [in] 是否全屏 D3DDEVTYPE deviceType, // [in] HAL 或 REF IDirect3DDevice9** device); // [out] 创建的设备 int EnterMsgLoop( bool (*ptr_display)(float timeDelta)); LRESULT CALLBACK WndProc( HWND hwnd, UINT msg, WPARAM wParam, LPARAM lParam); template&lt;class T&gt; void Release(T t) &#123; if( t ) &#123; t-&gt;Release(); t = 0; &#125; &#125; template&lt;class T&gt; void Delete(T t) &#123; if( t ) &#123; delete t; t = 0; &#125; &#125;&#125; InitD3D——初始化一个应用程序主窗口并进行Direct3D的初始化。如果成功，则输出IDirect3DDevice9接口指针。从它的参数我们可以发现，我们能够设置窗口的大小和以窗口模式运行还是全屏模式运行。要知道它实现的细节，请看示例代码。EnterMsgLoop——这个函数封装了应用程序的消息循环。它需要输入一个显示函数的函数指针，显示函数为程序中绘制图形的代码块，这样做是为了使显示函数能够在空闲的时候被调用并显示场景，它的实现如下：1234567891011121314151617181920212223int d3d::EnterMsgLoop( bool (*ptr_display)(float timeDelta) )&#123; MSG msg; ::ZeroMemory(&amp;msg, sizeof(MSG)); static float lastTime = (float)timeGetTime(); while(msg.message != WM_QUIT) &#123; if(::PeekMessage(&amp;msg, 0, 0, 0, PM_REMOVE)) &#123; ::TranslateMessage(&amp;msg); ::DispatchMessage(&amp;msg); &#125; else &#123; float currTime = (float)timeGetTime(); float timeDelta = (currTime - lastTime)*0.001f; ptr_display(timeDelta); // call display function lastTime = currTime; &#125; &#125; return msg.wParam;&#125; 与“time”有关的代码用于计算每次调用显示函数的时间间隔，即是每帧的时间。Release——这个模版函数能方便的释放COM接口并将它们的值设为NULLDelete——这个模版函数能方便的删除一个对象并将指向其的指针设为NULLWndProc——应用程序主窗口的回调函数1.5.2 实例框架 通过实例框架，我们形成了一种通用的方法去构造本书的示例程序。每一个例程都含有三个函数的实现，当然这不包括回调函数和WinMain主函数。这三个函数用特定的代码实现特定的功能。这三个函数是： bool Setup()——在这个函数里，我们将准备一切该程序需要用到的东西，包括资源的分配，检查设备能力，设置应用程序的状态 void Clearup()——这个函数将释放Setup()中分配的资源，如分配的内存。 bool Display(float timeDelta)——这个函数包含所有与我们绘图和显示有关的代码。参数timeDelta为每一帧的间隔时间，用来控制每秒的帧数。1.5.3 D3D Init实例 这个示例程序将创建并初始化一个Direct3D应用程序，并用黑色填充屏幕。注意，我们使用了通用函数简化了初始化过程。 首先，我们要包含d3dUtility.h头文件，并为设备声明一个全局变量：include “d3dUtility.h” IDirect3DDevice9* Device = 0; 然后实现我们的框架函数：123456789bool Setup()&#123; return true;&#125;void Cleanup()&#123;&#125; 在这个程序中，我们不需要使用任何资源或触发任何事件，所以这两个函数都为空。12345678910bool Display(float timeDelta)&#123; if( Device ) &#123; Device-&gt;Clear(0, 0, D3DCLEAR_TARGET | D3DCLEAR_ZBUFFER, 0x00000000, 1.0f, 0); Device-&gt;Present(0, 0, 0, 0); // 页面切换 &#125; return true;&#125; Display方法调用了IDirect3DDevice::Clear方法，分别用黑色和1.0填充后备表面和深度/模版缓冲。如果应用程序不停止的话，我们会一直执行这个操作。IDirect3DDevice::Clear声明如下：12345678HRESULT IDirect3DDevice9::Clear( DWORD Count, const D3DRECT* pRects, DWORD Flags, D3DCOLOR Color, float Z, DWORD Stencil); Count——pRects组中的矩形的个数 pRects——将要清除的屏幕矩形的数组，这使我们可以清除屏幕的某一部分 Flags——指定在哪些表面上执行清除表面的操作 D3DCLEAR_TARGET——目的表面，通常为后备表面 D3DCLEAR_ZBUFFER——深度缓冲 D3DCLEAR_STENCIL——模版缓冲 Color——使用什么颜色填充清除的表面 Z——设置深度缓冲的值 Stencil——设置模版缓冲的值 屏幕被填充后，要调用IDirecte3DDevice9::Present方法进行后备表面的交换。 Windows 回调函数为一组事件集，即，我们可按ESC键让程序退出。123456789101112131415LRESULT CALLBACK d3d::WndProc(HWND hwnd, UINT msg, WPARAM wParam, LPARAM lParam)&#123; switch( msg ) &#123; case WM_DESTROY: ::PostQuitMessage(0); break; case WM_KEYDOWN: if( wParam == VK_ESCAPE ) ::DestroyWindow(hwnd); break; &#125; return ::DefWindowProc(hwnd, msg, wParam, lParam);&#125; 最后，WinMain按如下步骤运行： 初始化主显示窗口和Direct3D 调用Setup进行程序的准备工作 使用Display函数作为参数进入消息循环 清除应用程序最后释放IDirecte3DDevice9对象123456789101112131415161718192021int WINAPI WinMain(HINSTANCE hinstance, HINSTANCE prevInstance, PSTR cmdLine,int showCmd)&#123; if(!d3d::InitD3D(hinstance, 800, 600, true, D3DDEVTYPE_HAL, &amp;Device)) &#123; ::MessageBox(0, "InitD3D() - FAILED", 0, 0); return 0; &#125; if(!Setup()) &#123; ::MessageBox(0, "Setup() - FAILED", 0, 0); return 0; &#125; d3d::EnterMsgLoop( Display ); Cleanup(); Device-&gt;Release(); return 0;&#125; 就像你所看到的，我们的例程的模板结构是相当简洁的：有效的操作窗口函数、 Direct3D的初始化过程。这本书中的大部分程序，都是通过执行Setup, Cleanup, 和Display这三个函数来实现。 注意：不要忘了在你的工程中加入d3d9.lib、d3dx9.lib、winmm.lib 这三个库！ 第二章 渲染管线(The Rendering Pipeline) 本章的主题是渲染管线。它是用来创建为3D世界进行几何描述的2D图形并设定一个虚拟照相机确定这个世界中哪一部分将被透视投影到屏幕上。 图2.1目标 要弄清楚我们怎样在Direct3D中表示3D物体 学习怎样模拟虚拟照相机 弄懂渲染管线——这个过程是用几何学来表现3D场景和用它来产生2D图象。2.1表现模型 一个场景是多个物体或模型的集合。一个物体可以用三角形网格（triangle mesh）来近似表示，如图2.2所示。由三角形网格建立一个物体，我们称之为建模。3D世界中最基本的图元就是三角形，但是Direct3D也支持点图元和线图元但我们都不常用到。不过在学到第14章的粒子系统的时候，将会用到点图元。 图2.2 一个多边形的两边相交的点叫做顶点。为了描述一个三角形，我们通常指定三个点的位置来对应三角形的三个顶点（如图2.3），这样我们就能够很明确的表示出这个三角形了。 图2.32.1.1 顶点格式 我们以前定义的点在数学上来说是正确的，但是当我们在Direct3D环境中使用它的时候就会觉得很不完善。这是因为在Direct3D中的顶点包含了许多附加的属性，而不再单纯的只有空间位置的信息了。例如：一个顶点可以有颜色和法线向量属性（这两个属性分别在第四章和第五章介绍）。Direct3D让我们可以灵活的构造自己的顶点格式。换句话说，我们可以自己定义顶点的成员。 为了创建一个自定义的顶点结构，我们首先要创建一个包含能存放我们选择的顶点数据的结构。例如，下面我们举出两种不同顶点数据类型的例子，一种包含了位置和颜色信息，第二种则包含了位置，法线向量，纹理坐标信息（“纹理”见第六章）。123456789101112struct ColorVertex&#123; float _x, _y, _z; // 位置 DWORD _color; // 颜色&#125;;struct NormalTexVertex&#123; float _x, _y, _z; // 位置 float _nx, _ny, _nz; // 法线向量 float _u, _v; // 纹理坐标&#125;; 一旦我们有了完整的顶点格式，我们就要使用灵活顶点格式（FVF）的组合标志来描述它。例如第一个顶点结构，我们要使用如下的顶点格式： define FVF_COLOR (D3DFVF_XYZ | D3DFVF_DIFFUSE) 上面的顶点结构表明它包含位置和颜色属性。 而第二种结构则要使用： define FVF_NORMAL_TEX (D3DFVF_XYZ | D3DFVF_NORMAL | D3DFVF_TEX1) 上面的顶点结构表明它包含了位置，法线向量，纹理坐标的属性（这些常量是D3D内置的）。 有一点要注意，你的标志的顺序必须要和你的顶点结构的顺序一一对应。如果想知道所有的D3DFVF标志，请查阅SDK文档。2.1.2 三角形 三角形是构建3D物体的基本图形。为了构造物体，我们创建了三角形列表（triangle list）来描述物体的形状和轮廓。三角形列包含了我们将要画的每一个三角形的数据信息。例如为了构造一个矩形，我们把它分成两个三角形，如图2.4所示，最后指定每个三角形的顶点。 图2.4Vertex rect[6] = {v0, v1, v2, // 三角形0 v0, v2, v3}; // 三角形1注意：指定三角形顶点的顺序是很重要的，将会按一定顺序环绕排列，这会在2.3.4节学习相关的内容。2.1.3 索引 3D物体中的三角形经常会有许多共用顶点。如图2.4所表示的矩形。虽然现在仅有两个点被重复使用，但是当要表现一个更精细更复杂的模型的时候，重复的顶点数将会变得很大。例如图2.5所示的立方体，仅有八个顶点，但是当用三角形列表示它的时候，所有的点都被重复使用。 图2.5 为了解决这个问题，我们引入索引（indices）这个概念。它的工作方式是：我们创建一个顶点列表和一个索引列表（index list）。顶点列表包含所有不重复的顶点，索引列中则用顶点列中定义的值来表示每一个三角形的构造方式。回到那个矩形的示例上来，它的顶点列表的构造方式如下：Vertex vertexList[4] = {v0, v1, v2, v3}; 索引列表则定义顶点列中的顶点是如何构造这两个三角形的：WORD indexList[6] = {0, 1, 2, //三角形0 0, 2, 3}; //三角形1 也就是说，用顶点列表中的0（vertexList[0]）、1（vertexList[1]）和2（vertexList[2]）顶点构成三角形0；用顶点列表中的0（vertexList[0]）、2（vertexList[2]）和3（vertexList[3]）顶点构成三角形1。 2.2虚拟照相机 照相机确定3D世界中的哪部分是可见的，因而需要将哪部分转换为2D图形。在3D世界中照相机被放置和定向，并且定义其可视体，图2.6展示了我们的照相机模型。 图2.6 可视体是由可视角度和前裁剪面（Near Plane）与后裁剪面（Far Plane）定义的一个平截头体。之所以要选择平截头体构造可视体，是因为我们的显示器都是矩形的。在可视体中不能被看见的物体都会被删除，删除这种数据的过程就叫做“裁剪”。 投影窗口（Projection Window）是可视体内的3D几何图形投影生成的用来显示3D场景的2D图像的2D区域。重要的是要知道，我们使用min=(-1,-1)和max=(1,1)来定义投影窗口的大小。 为了简化本书接下来的部分绘制，我们使前裁剪面与投影窗口在同一平面上。并且，注意Direct3D中定义的投影平面（即投影窗口所在的平面）是Z = 1的平面。 2.3 渲染管线一旦我们描述几何学上的3D场景和设置了虚拟照相机，我们要把这个场景转换成2D图象显示在显示器上。这一系列必须完成的操作就叫做渲染管线。图2.7展示了一个简化的渲染管线，随后将详细解释图中的每一部分。 图2.7渲染管线中的许多级都是从一个坐标系到另一个坐标的几何变换。这些变换都通过矩阵变换来实现。Direct3D为我们进行变换计算并且如果显卡支持硬件变换的话那就更有利了。使用Direct3D进行矩阵变换，我们唯一要做的事就是提供从一个系统变换到另一个系统的变换矩阵就可以了。我们使用IDirect3DDevice9::SetTranform方法提供变换矩阵。它输入一个表示变换类型的参数和一个变换矩阵。如图2.7所示，为了进行一个从自身坐标系到世界坐标系的变换，我们可以这样写：Device-&gt;SetTransform(D3DTS_WORLD, &amp;worldMatrix); 2.3.1自身坐标系（Local Space） 自身坐标系又叫做建模空间，这是我们定义物体的三角形列的坐标系。自身坐标系简化了建模的过程。在物体自己的坐标系中建模比在世界坐标系中直接建模更容易。例如，在自身坐标系中建模不像在世界坐标系中要考虑本物体相对于其他物体的位置、大小、方向关系。 图2.82.3.2世界坐标系（World Space） 一旦我们构造了各种模型，它们都在自己的自身坐标系中，但是我们需要把它们都放到同一个世界坐标系中。物体从自身坐标系到世界坐标系中的换叫做世界变换。世界变换通常是用平移、旋转、缩放操作来设置模型在世界坐标系中的位置、大小、方向。世界变换就是通过各物体在世界坐标系中的位置、大小和方向等相互之间的关系来建立所有物体。 图2.9 世界变换由一个矩阵表示，并且在Direct3D中调用IDirect3DDevice9::SetTransform方法设置它，记住将转换类型设为D3DTS_WORLD。例如我们要在世界坐标系中放置一个立方体定位在（-3，2，6）和一个球体定位在（5，0，-2），我们可以这样写程序：//创建立方体的世界矩阵（一个平移矩阵）D3DXMATRIX cubeWorldMatrix;D3DXMatrixTranslation(&amp;cubeWorldMatrix, -3.0f, 2.0f, 6.0f); //创建球体的世界矩阵（一个平移矩阵）D3DXMATRIX sphereWorldMatrix;D3DXMatrixTranslation(&amp;sphereWorldMatrix, 5.0f, 0.0f, -2.0f); // 变换立方体，然后绘制它Device-&gt;SetTransform(D3DTS_WORLD, &amp;cubeWorldMatrix);drawCube(); // draw the cube // 因为球体使用一个不同的世界变换，我们必须更改世界矩阵为球体的～，// 如果不更改，球体将绘制在上一个世界矩阵的位置上（立方体的世界矩阵）Device-&gt;SetTransform(D3DTS_WORLD, &amp;sphereWorldMatrix);drawSphere(); // 绘制球体 这是个非常简单的实例，没有用到矩阵的旋转和缩放。但是一般很多物体都需要进行这些变换，不过这个例子也还是展示了世界变换是怎样进行的。2.3.3视图坐标系（View Space） 世界坐标系中的几何图与照相机是相对于世界坐标系而定义的，如图2.10所示。然而在世界坐标系中当照相机是任意放置和定向时，投影和其它一些操作会变得困难或低效。为了使事情变得更简单，我们将照相机平移变换到世界坐标系的源点并把它的方向旋转至朝向Z轴的正方向，当然，世界坐标系中的所有物体都将随着照相机的变换而做相同的变换。这个变换就叫做视图坐标系变换（view space transformation）。 图2.10 视图坐标的变换矩阵可以通过如下的D3DX函数计算得到：D3DXMATRIX D3DXMatrixLookAtLH( D3DXMATRIX pOut, // 指向返回的视图矩阵 CONST D3DXVECTOR3 pEye, // 照相机在世界坐标系的位置 CONST D3DXVECTOR3 pAt, // 照相机在世界坐标系的目标点 CONST D3DXVECTOR3* pUp // 世界坐标系的上方向(0, 1, 0)); pEye参数指定照相机在世界坐标系中的位置，pAt参数指定照相机所观察的世界坐标系中的一个目标点，pUp参数指定3D世界中的上方向，通常设Y轴正方向为上方向，即取值为（0，1，0）。 例如：假设我们要把照相机放在点（5，3，-10），并且目标点为世界坐标系的中点（0，0，0），我们可以这样获得视图坐标系变换矩阵：D3DXVECTOR3 position(5.0f, 3.0f, –10.0f);D3DXVECTOR3 targetPoint(0.0f, 0.0f, 0.0f);D3DXVECTOR3 worldUp(0.0f, 1.0f, 0.0f); D3DXMATRIX V;D3DXMatrixLookAtLH(&amp;V, &amp;position, &amp;targetPoint, &amp;worldUp); 视图坐标系变换也是通过IDirect3DDevice9::SetTransform来实现的，只是要将变换类型设为D3DTS_VIEW，如下所示：Device-&gt;SetTransform(D3DTS_VIEW, &amp;V);2.3.4背面拣选（Backface Culling） 一个多边形有两个表面，我们将一个标为正面，一个为背面。通常，后表面总是不可见的，这是因为场景中大多数物体是密封的。例如盒子、圆柱体、箱子、characters等，并且我们也不能把照相机放入物体的内部。因此照相机永不可能看到多边形的背面。这是很重要的，如果我们能看背面，那么背面拣选就不可能工作。 图2.11表示了一个物体在视图坐标系中的正面。一个多边形的边都是面向照相机叫正面多边形，而一个多边形的边都背对照相机叫背面多边形。 图2.11 由图2.11可知，正面多边形挡住了在它后面的背面多边形，Direct3D将通过拣选（即删除多余的处理过程）背面多边形来提高效率，这种方法就叫背面拣选。图2.12展示了背面拣选之后的多边形，从照相机的观察点来看，仍将绘制相同的场景到后备表面，那些被遮住的部分无论如何都永远不会被看见的。 图2.12 当然，为了完成这项工作，Direct3D需要知道哪个多边形是正面，哪个是背面。Direct3D中默认顶点以顺时针方向（在观察坐标系中）形成的三角形为正面，以逆时针方向形成的三角形为背面。如果我们不想使用默认的拣选状态，我们可以通过改变D3DRS_CULLMODE来改变渲染状态：Device-&gt;SetRenderState(D3DRS_CULLMODE, Value);Value可以是如下一个值： D3DCULL_NONE——完全不使用背面拣选 D3DCULL_CW——拣选顺时针方向环绕的三角形 D3DCULL_CCW——拣选逆时针方向环绕的三角形，这是默认值。 2.3.5光源（Lighting） 光源定义在世界坐标系中然后被变换到视图坐标系中。视图坐标系中光源给物体施加的光照大大增加了场景中物体的真实性，至于光照的相关函数的细节将会在第五章学习。在本书的第四部分，我们将使用可编程管线实现自己的光照。 2.3.6裁剪（Clipping）我们拣选那些超出了可视体范围的几何图形的过程就叫做裁剪。这会出现三种情况： 完全包含——三角形完全在可视体内，这会保持不变，并进入下一级 完全在外——三角形完全在可视体外部，这将被拣选 部分在内（部分在外）——三角形一部分在可视体内，一部分在可视体外，则三角形将被分成两部分，可视体内的部分被保留，可视体之外的则被拣选 图2.13展示了上面三种情况： 图2.13 2.3.7投影（Projection）视图坐标系的主要任务就是将3D场景转化为2D图像表示。这种从n维转换成n-1维的过程就叫做投影。投影的方法有很多种，但是我们只对一种特殊的投影感兴趣，那就是透视投影。因为透视投影可以使离照相机越远的物体投影到屏幕上后就越小，这可以使我们把3D场景更真实的转化为2D图像。图2.14展示了一个3D空间中的点是如何通过透视投影到投影窗口上去的。 图2.14 投影变换的实质就是定义可视体，并将可视体内的几何图形投影到投影窗口上去。投影矩阵的计算太复杂了，这里我们不会给出推导过程，而是使用如下的Direct3D函数通过给出平截头体的参数来求出投影矩阵。 图2.151234567D3DXMATRIX *D3DXMatrixPerspectiveFovLH( D3DXMATRIX* pOut, // 返回的投影矩阵 FLOAT fovY, // 用弧度表示的视野角度vertical field of view angle in radians FLOAT Aspect, // 宽高比 FLOAT zn, // 前裁剪面距离 FLOAT zf // 后裁剪面距离); （fovY定义镜头垂直观察范围，以弧度为单位。对于这个参数，下面是我的理解：如果定义为D3DX_PI/4（90度角），那么就是表示以摄像机的观察方向为平分线，上方45度角和下方45度角就是摄像机所能看到的垂直范围了。嗯，可以想象一下自己的眼睛，如果可以把自己眼睛的fovY值设为D3DX_PI/2（180度角），那么我们就可以不用抬头就看得见头顶的东西了。如果设为D3DX_PI的话。。。我先编译一下试试（building…）。哈哈，结果啥也看不见。很难想象如果自己能同时看到所有方向的物体，那么将是一个怎样的画面啊） Aspect参数为投影平面的宽高比例值，由于最后都为转换到屏幕上，所以这个比例一般设为屏幕分辨率的宽和高的比值（见2.3.8节）。如果投影窗口是个正方形，而我们的显示屏一般都是长方形的，这样转换后就会引起拉伸变形。 我们还是通过调用IDirect3DDevice9::SetTranform方法来进行投影变换，当然，要把第一个投影类型的参数设为D3DTS_PROJECTION。下面的例子基于一个90度视角、前裁剪面距离为1、后裁剪面距离为1000的平截头体创建投影矩阵：D3DXMATRIX proj;D3DXMatrixPerspectiveFovLH( &amp;proj, PI * 0.5f, (float)width / (float)height, 1.0, 1000.0f);Device-&gt;SetTransform(D3DTS_PROJECTION, &amp;proj);2.3.8视口变换（Viewport Transform） 视口变换主要是转换投影窗口到显示屏幕上。通常一个游戏的视口就是整个显示屏，但是当我们以窗口模式运行的时候，也有可能只占屏幕的一部分或在客户区内。视口矩形是由它所在窗口的坐标系来描述的，如图2.16。 图2.16 在Direct3D中，视口矩形通过D3DVIEWPORT9结构来表示。它的定义如下：typedef struct _D3DVIEWPORT9 { DWORD X; DWORD Y; DWORD Width; DWORD Height; DWORD MinZ; DWORD MaxZ;} D3DVIEWPORT9; 前四个参数定义了视口矩形与其所在窗口的关系。MinZ成员指定最小深度缓冲值，MaxZ指定最大深度缓冲值。Direct3D使用的深度缓冲的范围是0~1，所以如果不想做什么特殊效果的话，将它们分别设成相应的值就可以了。 一旦我们填充完D3DVIEWPORT9结构后，就可以如下设视口：D3DVIEWPORT9 vp{ 0, 0, 640, 480, 0, 1 };Device-&gt;SetViewport(&amp;vp);这样，Direct3D就会自动为我们处理视口变换。现在还是给出视口变换矩阵作为参考： 光栅化（Rasterization）在把三角形每个顶点转换到屏幕上以后，我们就画了一个2D三角形。光栅化是计算需要显示的每个三角形中每个点颜色值（如图2.17）。图2.17光栅化过程是非常繁重的计算，它应该通过硬件图形处理来完成。它的处理结果就是把2D图象显示在显示器上。]]></content>
      <tags>
        <tag>计算机图形学</tag>
        <tag>Direct3D 9</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图]]></title>
    <url>%2F2019%2F03%2F23%2Fmap%2F</url>
    <content type="text"><![CDATA[图看起来就像下图这样： 一个图就是一些顶点的集合，这些顶点通过边连接。顶点用圆圈表示，边就是这些圆圈之间的连线。顶点之间通过边连接。 注意：顶点有时也被称为节点或者交点，边有时也称为链接。图有两种表示方法：邻接列表和邻接矩阵。邻接列表：在邻接列表实现中，每一个顶点会存储一个从它这里开始的边的列表。比如，如果顶点A有一条边到B、C和D，那么A的列表中会有3条边 邻接列表只描述了指向外部的边。A有一条边到B，但是B没有边到A，所以A没有出现在B的邻接列表中。查找两个顶点之间的边或者权重会比较费时，因为遍历邻接列表知道找到为止。 邻接矩阵：在邻接矩阵实现中，由行和列都表示顶点，由两个顶点所决定的矩阵对应元素表示这里两个顶点是否相连、如果相连这个值表示的是相连边的权重。例如，如果从顶点A到顶点B有一条权重为5.6的边，那么矩阵中第A行第B列的位置的元素值应该是5.6：往这个图中添加顶点的成本非常昂贵，因为新的矩阵结果必须重新按照新的行/列创建，然后将已有的数据复制到新的矩阵中。所以使用哪一个呢？大多数的时候，选择邻接列表是正确的。下面是两种方法更详细的的比较。假设V表示图中的顶点的个数，E表示边的个数。 操作 邻接列表 邻接矩阵 存储空间 O(V+E) O(V^2) 添加顶点 O(1) O(V^2) 添加边 O(1) O(1) 检查相邻行 O(V) O(1) “检查相邻性”是指对于给定的顶点，尝试确定它是否是另一个顶点的邻居。在邻接列表中检查相邻性的时间复杂度是O(V)，因为最坏的轻快是一个顶点与每一个顶点都相连。 在稀疏图的情况下，每一个顶点都只会和少数几个顶点相连，这种情况下相邻列表是最佳选择。如果这个图比较密集，每一个顶点都和大多数其他顶点相连，那么相邻矩阵更合适。 图可分为有向图和无向图。有向图的所有边都有方向，即确定了顶点到顶点的一个指向；而无向图的所有边都是双向的，即无向边所连接的两个顶点可以互相到达。顶点的度是指和该顶点相连的边的条数。特别是对于有向图来说，顶点的出边条数成为该顶点的出度，顶点的入边条数成为该顶点的入度。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android开发入门]]></title>
    <url>%2F2019%2F03%2F23%2Fandroid-GettingStarted%2F</url>
    <content type="text"></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AssetBundles 工作流程]]></title>
    <url>%2F2019%2F03%2F22%2FAssetBundles-Workflow%2F</url>
    <content type="text"><![CDATA[AssetBundle工作流程要开始使用AssetBundles，请按照以下步骤操作。有关每个工作流程的更多详细信息，请参阅本文的其他页面。 将资产分配给AssetBundles分配给定资产Assetbundle的，请按照下列步骤操作： 从项目视图中选择要分配给捆绑包的资产 检查检查器中的对象 在检查器的底部，您应该看到一个分配AssetBundles和Variants的部分 左侧下拉分配AssetBundle，而右侧下拉分配变量 单击左侧下拉列表，显示”无”，以显示当前已注册的AssetBundle名称 单击”新建…”以创建新的AssetBundle 输入所需的AssetBundle名称。请注意，AssetBundle名称确实支持一种文件夹结构，具体取决于您键入的内容。要添加子文件夹，请用”/“分割文件夹名称。例如：AssetBundle名称”environment/forest”将在环境子文件夹下创建名forest的包 一旦选择或创建了AssetBundle名称，您可以重复此过程以右手下拉以分配或创建变体名称（如果需要）。构建AssetBundle不需要变体名称 构建AssetBundles在Asset文件夹中创建一个名为Editor的文件夹，并将包含以下内容的脚本放在该文件夹中：1234567891011121314151617using UnityEditor;using UnityEngine;using System.IO;public class CreateAssetBundles&#123; [MenuItem(&quot;Assets/Build AssetBundles&quot;)] static void BuildAllAssetBundles() &#123; if (!Directory.Exists(Application.streamingAssetsPath)) &#123; Directory.CreateDirectory(Application.streamingAssetsPath); &#125; BuildPipeline.BuildAssetBundles(Application.streamingAssetsPath, BuildAssetBundleOptions.None, BuildTarget.Android); AssetDatabase.Refresh(); &#125;&#125; 此脚本将在Assets菜单底部创建一个名为”Build AssetBundles”的菜单项，该菜单项将执行与该标记关联的函数中的代码。单击”Build AssetBundles”时，将显示一个带有构建对话框的进度条。这将获取您使用AssetBundle名称标记的所有资产，并将它们放在assetBundleDirectory定义的路径中的文件夹中。 将AssetBundles上传到场外存储此步骤对每个用户都是唯一的，而不是Unity可以告诉您如何操作的步骤。如果您打算将AssetBundles上传到第三方托管网站，请在此执行此操作。如果您正在进行严格的本地开发并打算将所有AssetBundle都放在磁盘上，请跳到下一步。 加载AssetBundle和Assets对于打算从本地存储加载的用户，您将对AssetBundles.LoadFromFile API感兴趣。如下：1234567891011121314public class LoadFromFileExample : MonoBehaviour &#123; void Start() &#123; var myLoaderAssetBundle = AssetBundle.LoadFromFile(Path.Combine(Application.streamingAssetsPath, &quot;myassetBundle&quot;)); if (myLoaderAssetBundle == null) &#123; Debug.Log(&quot;Failed to load AssetBundle!&quot;); return; &#125; var prefab = myLoaderAssetBundle.LoadAsset&lt;GameObject&gt;(&quot;MyObject&quot;); Instantiate(prefab); &#125;&#125; LoadFromFile 获取bundle文件的路径。如果您自己托管AssetBundles并需要将它们下载到游戏中，您将对UnityWebRequest API感兴趣。这是一个例子：1234IEnumerator InstantiateObject()&#123; string uri = &quot;file:///&quot;&#125;]]></content>
      <categories>
        <category>Unity-2018-3</category>
      </categories>
      <tags>
        <tag>Unity AssetBundles</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity 文件路径]]></title>
    <url>%2F2019%2F03%2F22%2FUnity-Path%2F</url>
    <content type="text"><![CDATA[ResourcesResources文件夹是Unity里自动识别的一种文件夹，可在Unity编辑器的Project窗口创建，并将资源放置在里面。Resources文件夹下的资源不管是否有用，全部会打包进.apk或者.ipa，并且打包时会将里面的资源压缩处理。加载方法是Resources.Load(文件名)，需要注意：文件名不包括扩展名，打包后不能更改Resources下的资源内容，但是从Resources文件夹中加载出来的资源可以更改。 Application.dataPath这个属性返回的是程序的数据文件所在的文件夹，例如在Editor中就是项目的Assets文件夹的路径，通过这个路径可以访问项目中任何文件夹中的资源，但是在移动端它是完全没用。 Application.streamingAssetsPath这个属性用于返回流数据的缓存目录，返回路径为相对路径，适合设置一些外部数据文件的路径。在Unity工程的Assets目录下起一个名为”StreamingAssets”的文件夹即可，然后用Application.streamingAssetsPath访问，这个文件夹中的资源在打包时会原封不动的打包进去，不会压缩，一般放置一些资源数据。在PC/MAC中可实现对文件的“增删改查”等操作，但在移动端是一个只读路径。 IOS Android Windows Mac Application.dataPath 只读不写 Application/xxxxxx/xxx.app/Data /data/app/xxx.xxx.xxx.apk /Assets Assets Application.streamAssetsPath 只读不写，首包资源目录 Application/xxxxxx/xxx.app/Data/Raw jar:file:///data/app/xxx.xxx.xxx.apk/!/assets Assets/StreamingAssets Assets/StreamingAssets Application.peristentDataPath 可读可写，更新资源包目录 Application/xxxxxx/xxx.app/Documents /data/data/xxx.xxx.xxx/files C:/Users/Admin/AppData/LocalLow/CompanyName/ProductName /Users/xxxx/Library/Caches/CompanyName/ProductName Application.temproaryCachPath Application/xxxxxx/xxx.app/Library/Caches /data/data/xxx.xxx.xxx/cache C:/Users/Admin/AppData/Local/Temp/CompanyName/ProductName /var/folders/57/6b4_9w8113x2fsmzx_yhrhvh0000gn/T/CompanyName/Product]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最短路径算法简介（Dijkstra算法，A*算法，D*算法）]]></title>
    <url>%2F2019%2F03%2F21%2FNav%2F</url>
    <content type="text"><![CDATA[最短路径计算分静态最短计算和动态最短路径计算。静态最短路径算法是外界环境不变，计算最短路径。主要有Dijkstra算法，A（A Star）算法。动态最短路径算法是外界环境不断发生变化，即不能计算预测的情况下计算最短路径。如在游戏中敌人或障碍物不断移动的情况下。典型的有D算法。 这是Drew程序实现的10000个节点的随机路网三条互不相交最短路径 真实路网计算K条路径示例：节点5696到节点3006，三条最快路径，可以看出路径基本上走环线或主干路。黑线为第一条，蓝线为第二条，红线为第三条。约束条件系数为1.2。共享部分路段。 Dijkstra算法求最短路径Dijkstra算法是典型的最短路径算法，用于计算一个节点到其他所有节点的最短路径。主要特点是起始点为中心向外层层层扩展，直到扩展到终点位置。Dijkstra算法能得出最短路径的最优解，但由于它遍历计算的节点很多，所以效率低。 Dijkstra算法是很有代表性的最短路径算法。 Dijkstra一般的表述通常有两种方式，一种用永久和临时标号方式，一种是用OPEN，CLOSE表方式，Drew为了和下面要介绍的A算法和D算法表述一致，这里均采用OPEN，CLOSE表的方式。 大概过程：创建两个表，OPEN，CLOSE。 访问路网中里起始点最近且没有被检查过的点，把这个点放入OPEN组中等待检查。 从OPEN表中找出距离起始点最近的点，找出这个点的所有子节点，把这个点放到CLOSE表中。 遍历考察这个点的子节点。求出这些子节点距离起起始点的距离值，放子节点到OPEN表中。 重复2、3步。直到OPEN表为空，或找到目标点。 动态路由，最短路径算法D* 先用Dijstra算法从目标节点G向起始节点搜索。存储路网中目标点到各个节点的最短路和该位置到目标点的实际值h,k（k为所有变化h之中最小的值，当前为k=h。每个节点包含上一节到目标点的最短路信息1（2），2（5），5（4））]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx]]></title>
    <url>%2F2019%2F03%2F15%2Fnginx%2F</url>
    <content type="text"><![CDATA[启动 /usr/sbin/nginx -c /etc/nginx/nginx.conf 重新加载配置文件 /usr/sbin/nginx -s reload]]></content>
  </entry>
  <entry>
    <title><![CDATA[IL2CPP]]></title>
    <url>%2F2019%2F03%2F13%2FL2CPP%2F</url>
    <content type="text"><![CDATA[什么是IL2CPP从技术层面上来说，IL2CPP包含两个部分：一个进行预先编译（ahead-of-time，又叫AOT）的编译器；一个支持虚拟机的运行时库。 AOT编译器IL2CPP AOT编译器实际的执行文件是il2cpp.ext。在Windows平台你可以在Unity安装路径的Editor\Data\il2cpp目录下找到。il2cpp.exe这个工具是一个托管代码可执行文件，其完全由C#编码。在开发IL2CPP的过程中，我们同时使用.NET和Mono编译器对其进行编译。 il2cpp接受来自Unity自带的或者由Mono编译器产生的托管程序集，将这些程序集转换成C++代码。这些转化出的C++代码最终由部署目标平台的C++编译器进行编译。 你可以参照下图理解IL2CPP工具链的作用： 运行时库IL2CPP的另外一个部分就是对虚拟机提供支持的运行时库。我们基本上是用C++代码来实现整个运行时库的（其实里面还是有一些和平台相关的代码使用了程序集）。我们把运行时库称之为libli2cpp，它是作为一个静态库被连接到最终的游戏可行性文件中。这么做的一个主要的好处是可以使得整个IL2CPP技术是简单并且是可移植的。 AOT编译器将由.Net输出的中间语言IL代码生成C++代码。运行时库则提供诸如垃圾回收，与平台无关的线程，IO以及内部调用（C++原生代码直接访问托管代码结构）这样的服务层和抽象层。]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图形学]]></title>
    <url>%2F2019%2F03%2F13%2Fgraphics%2F</url>
    <content type="text"><![CDATA[向量积模长：（在这里$\theta$表示两向量之间的夹角（共起点的前提下）（$0^。\le \theta \le 180^。$），它位于这两个矢量所定义的平面上。）向量积满足交换律。 $|\vec a \times \vec b| = |\vec a| \cdot |\vec b| \cdot sin\theta$ 方向：a向量与b向量的向量积的方向与这两个向量所在平面垂直，且遵守右手定则。（一个简单的确定满足“右手定则”的结果向量的方向的方法是这样的：若坐标系是满足右手定则的，当右手的四指从a以不超过180度的转角转向b时，竖起的大拇指指向的方向就是c的方向。） 计算多边形面积设多边形有n个顶点$V{0}(X_0,Y_0),V{1}(X1,Y_1)…V{n-1}(Xn-1,Y_n-1)$，从原点O(0,0)与每条边做三角形，计算的面积和就是多边形面积。三角形的面积可以用叉积计算，比如$OV{0}V_1$面积为： $S{0}=0.5 * OV{0} \cdot OV{1} = 0.5 * (X{0}Y{1} - X{1}Y_{0})$ 判断两线段是否相交判断线段是否相交一般分为两步进行 快速排序设有线段$P{1}P{2}$和$Q{1}Q{2}$，以线段$P{1}P{2}$为对角线的矩形为R，以线段$Q{1}Q{2}$为对角线的矩形为T，如果R和T不想交，显然两线段不会相交，否则进入第二步。 跨立实验如果两线段先交，那么两线段必然互相跨立对方。 复数把刑辱z=a+bi（a，b均为实数）的数成为复数，其中a称为实部，b称为虚部，i称为虚数单位。当虚部等于零时，这个复数可以视为实数；当z的虚部不等于零时，实部等于零时，常称z为纯虚数。 数集扩展到实数范围内，仍有些运算无法进行（比如对复数开偶数次方），为了使方程有解，我们将数集再次扩充。在实数域上定义二元有序对z=(a,b)，并规定有序对之间有运算”+”、”x”(记$z{1}=(a,b),z){2}=(c,d)$):$z{1}+z{2}=(a+c,b+d)$$z{1} \times z_{2}=(ac-db,bc+ad)$ 四元数四元数是简单的超复数。复数是由实数加上虚数单位i组成，其中i^2=-1。相似地，四元数都是由实数加上三个虚数单位i、j、k组成，而且它们有如下的关系：i^2=j^2=k^2=-1，i^0=j^0=k^0=1，每个四元数都是1、i、j和k的线性组合，既是四元数一般可表示为a+bi+cj+dk，其中a、b、c、d是实数。]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Light Reflect]]></title>
    <url>%2F2019%2F03%2F12%2FLight-Reflect%2F</url>
    <content type="text"><![CDATA[假设我们有一个发着光的太阳，太阳底下有一个“理想镜面”，如下图：这时候我们抽象成数学图来进行计算，如下图：这幅图可以看出，我们计算反射光线OB，则转换成了计算OP，这里OP是AO在法向量N上的投影，接下来我们推导投影向量的计算，如下图：我们根据点积计算出$cos\theta$，然后通过$OA’ = |OA| \cdot cos\theta \cdot n$(n是单位法向量)就能得到，向量的投影公式。这个时候我们在回过头来推导$OB = AO + 2OP$的结果，如下图：]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shader用到的三角函数]]></title>
    <url>%2F2019%2F03%2F09%2Ftrigonometric-function%2F</url>
    <content type="text"><![CDATA[正弦、余弦、正切 正弦、余弦曲线 正弦曲线公式可表示为$y = Asin({\omega}x+\phi)+k$A：振幅，最高和最低的距离（shader中理解为离圆心最近和最远的距离）W：角速度，用于控制周期（shader中理解为圈数）K：偏距，曲线整体上下偏移量（shader中理解为多边形整体大小） 余弦（正弦）曲线和圆的基本关系 根据余弦（或正弦）曲线与园的基本关系。${\omega}t={\omega}x=角度$]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>Unity Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MathJax]]></title>
    <url>%2F2019%2F03%2F09%2FMathJax%2F</url>
    <content type="text"><![CDATA[希腊字母 序号 小写 Tex 大写 Tex 汉语注音 1 $\alpha$ \alpha 阿尔法 2 $\beta$ \beta 贝塔 3 $\gamma$ \gamma $\Gamma$ \Gamma 伽马 4 $\delta$ \delta $\Delta$ \Delta 德尔塔 5 $\epsilon$ \epsilon 伊普西隆 6 $\zeta$ \zeta 泽塔 7 $\eta$ \eta $\theta$ \theta $\upsilon$ \upsilon $\phi$ \phi $\omega$ \omega $\Omega$ \Omega $\in$ \in $\lambda $ \lambda $\Lambda$ \Lambda $\varrho$ \varrho $\varsigma$ \varsigma $\varphi$ \varphi 若需要大写希腊字母，将命令首字母大写即可。 \Omega 呈现为 $\Omega$ 需需要斜体希腊字母，将命令前面加上var。\varpi 呈现为 $\varPi$ 字母修饰上下标 上标：^ 下标：_ 举例：c_n^2呈现为$c_n^2$ 分数有两种方法来显示分数，一种是 \frac a b 显示$\frac a b$，另一种是用\over，如{a+1 \over b+1}显示${a+1 \over b+1}$ 求和与积分\sum用来表示求和符号，其下标表示求和上线，商标表示上限。如\sum_1^n：$\sum_1^n$ \int \int_0^\infty{fxdx} 呈现为$\int_0^\infty{fxdx}$ 特殊符号和记号 \lt \gt \le \ge \neq 表示 $\lt \gt \le \ge \neq$，还可以在不等号上加\not，如\not\lt 表示 $\not\lt$ \times \div \pm \mp 表示 $\times \div \pm \mp$，点乘用\cdot表示，如 x \cdot y 表示 $x \cdot y$ $\in$ : \in 矢量\vec{a} \cdot \vec{b} = 0 显示 $\vec{a} \cdot \vec{b} = 0$ 如何插入公式大括号123456789方法一：$ f(x)=\left\&#123;\begin&#123;aligned&#125;x &amp; = &amp; \cos(t) \\y &amp; = &amp; \sin(t) \\z &amp; = &amp; \frac xy\end&#123;aligned&#125;\right.$ 方法一：$ f(x)=\left{\begin{aligned}x &amp; = &amp; \cos(t) \y &amp; = &amp; \sin(t) \z &amp; = &amp; \frac xy\end{aligned}\right.$ 开方\sqrt{a+b} : $\sqrt{a+b}$ 矩阵\begin{matrix}...\end{matrix}，每一行以\结尾，hexo markdown中\\\\。&amp;分割矩阵元素。括号除了上面的\left…\right方式外，还可以pmatrix $\begin{pmatrix} 1&amp;2\\3&amp;4 \end{pmatrix}$，bmatrix $\begin{bmatrix} 1&amp;2\\3&amp;4 \end{bmatrix}$，Bmatrix $\begin{Bmatrix} 1&amp;2\\3&amp;4 \end{Bmatrix}$，vmatrix $\begin{vmatrix} 1&amp;2\\3&amp;4 \end{vmatrix}$，Vmatrix $\begin{Vmatrix} 1&amp;2\\3&amp;4 \end{Vmatrix}$。]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader:优化GPU代码，用step()代替if sele等条件语句]]></title>
    <url>%2F2019%2F03%2F09%2FUS-Step%2F</url>
    <content type="text"><![CDATA[普通的卡通着色Shader先看一个Shader，卡通着色。由于卡通着色需要对不同渲染区域进行判定，比较适合做案例。]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Avatar]]></title>
    <url>%2F2019%2F03%2F08%2FUnity-Avatar%2F</url>
    <content type="text"></content>
      <categories>
        <category>Unity3D</category>
      </categories>
      <tags>
        <tag>Unity3D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Reflection]]></title>
    <url>%2F2019%2F03%2F06%2FUnity-Reflection%2F</url>
    <content type="text"><![CDATA[概念反射是.NET中的重要机制，通过反射，可以在运行时获得程序或者程序集中每一个类型（包括类、结构、委托、接口和枚举等）的成员和成员的信息。另外还可以直接创建对象，即使这个对象的类型在编译时还不知道。 用途 使用Assembly定义和加载程序集，加载在程序集清单中列出模块，从此程序集中查找类型并创建并创建该类型的实例。 使用Module了解包含模块的程序集以及模块中的类等，还可以获取在模块上定义的所有全局方法或其他特定的非全局方法。 使用ConstructorInfo了解构造函数的名称，参数，访问修饰符（如public或private）和实现详细信息（如abstract或virtual）等。 使用MethodInfo了解方法的名称，返回类型，参数，访问修饰符（如public或private）和实现详细信息（如abstract或virtual）等。 使用FieldInfo了解字段的名称、访问修饰符（如public或private）和实现相信信息（如static）等，并获取或设置字段值。 使用EventInfo了解事件的名称、事件处理程序数据类型、自定义属性、声明类型和反射类型等，添加或移除事件处理程序。 使用PropertyInfo了解属性的名称、数据类型、声明类型、反射类型和只读或可写状态等，获取或设置属性值。 使用ParameterInfo了解参数的名称、数据类型、是输入参数还是输出参数，以及参数在方法签名中的位置等。 需要的namespaceSystem.Reflection; System.Type; System.Reflection.Assembly; 主要类System.Type // 通过这个类可以访问任何给定数据类型的信息 System.Reflection.Assembly; // 访问或者加载程序集的信息 System.TypeSystem.Type类对于反射起着核心的作用。它是一个抽象的基类，Type有与每种数据类型对应的派生类。1234567891011121314151617181920212223242526272829// 属性string Name &#123;get;&#125; // 数据类型名string FullName &#123;get;&#125; // 数据类型的完全限定名（包括命名空间）string Namespace; // 命名空间名bool IsAbstract; // 是否抽象bool IsArray; // 是否数组bool IsClass; // 是否类bool IsEnum; // 是否枚举bool IsInterface; // 是否接口bool IsPublic; // 是否是公有的类型bool IsSealed; // 是否是密封类bool IsValueType; // 是否是指类型// 方法// 用于取得该类的构造函数的信息public ConstructorInfo GetConstructor();// 同上public ConstructorInfo[] GetConstructors();// 取得该类的事件信息public EventInfo GetEvent();public EventInfo[] GetEvents();public FieldInfo GetField();public FieldInfo[] GetFields();public InterfaceInfo GetInterFace();public InterfaceInfo[] GetInterFaces();public MemberInfo GetMember();public MemberInfos GetMembers();public PropertyInfo GetProperty();public PropertyInfo[] GetProperties();// 调用上述成员，方式是调用Type的InvokeMember()方法，或者调用MethodInfo，PropertyInfo的Invoke方法 123456789101112// 查看类的构造方法NewClass nc = new NewClass();Type t = nc.GetType();ConstructorInfo[] ci = t.GetConstructors(); // 获取类的所有构造函数foreach (ConstructorInfo c in ci)&#123; ParamterInfo[] ps = c.GetParameters(); foreach (ParamterInfo pi in ps) &#123; Debug.Log("&#123;0&#125;\t&#123;1&#125;", pi.ParamterType.ToString(), pi.Name); &#125;&#125; 1234567891011// 用构造函数动态生成对象Type t = typeof(NewClass);Type[] pt = new Type[2];pt[0] = typeof(string);pt[1] = typeof(string);// 根据参数类型获取构造函数ConstructorInfo ci = t.GetConstructor(pt);// 构造Object数组，作为构造函数的输入参数object[] obj = new object[2]&#123;"Liyanfeng", "Hello World"&#125;;// 调用构造函数生成对象object o = ci.Invoke(obj); 1234// 用Activator生成对象Type t = typeof(NewClass);// 用Activator的CreateInstance静态方法，生成新对象object o = Activator.CreateInstance(t, "Liyanfeng", "Hello World"); 获取给定类型的Type引用有3中常用方式123456789101112// 使用typeof运算啊Type t = typeof(string);// 使用对象GetType()方法string s = "Liyanfeng";Type t = s.GetType();// 调用Type类的静态方法GetType()Type t = Type.GetType("System.String");foreach(MemberInfo mi in t.GetMembers())&#123; Debug.Log("&#123;0&#125;/t&#123;1&#125;", mi.MemberType, mi.Name);&#125;]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图形渲染及优化-Batch]]></title>
    <url>%2F2019%2F03%2F05%2FBatch%2F</url>
    <content type="text"><![CDATA[批处理（Batch）就是对某对象进行批量的处理，本文介绍一下Batch的基本概念、]]></content>
      <tags>
        <tag>Graphics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C# Jobs System]]></title>
    <url>%2F2019%2F03%2F05%2FCsharpJobSystem%2F</url>
    <content type="text"><![CDATA[Unity C＃ Job System允许用户编写与Unity其余部分良好交互的多线程代码，并使编写正确的代码变得更加容易。编写多线程代码可以提供高性能的好处。其中包括显着提高帧速率和延长移动设备的电池寿命。C＃ Job System的一个重要方面是它与Unity内部使用的集成（Unity的native jobsystem）。用户编写的代码和Unity共享工作线程。这种合作避免了导致争用CPU资源的问题，并且可以创建比CPU核心更多的线程。 多线程在单线程计算机系统中，一次只能进入一条指令，并且只能得出一个结果。加载和完成程序的时间取决于CPU需要完成的工作量。多线程是一种编程，它利用CPU在多个内核上同时处理多个线程的能力，它不是一个接一个地执行任务或指令，而是同时运行的。默认情况下，一个线程在程序的开头运行。这是“主线程”。主线程创建新线程来处理任务。这些新线程彼此并行运行，并且通常在完成后将其结果与主线程同步。如果有一些运行很长时间的任务，这种多线程方法很有效。但是，游戏开发代码通常包含许多一次执行的小指令。如果为每个小指令创建一个线程，最终可能会有许多线程，每个线程的生命周期都很短。这可以推动CPU和操作系统处理能力的极限。通过拥有一个线程池可以缓解线程生存期的问题。但是，即使使用线程池，也可能同时激活大量线程。线程数多于CPU核心导致线程相互争用CPU资源，导致频繁的上下文切换。上下文切换是通过执行保存线程状态的过程，然后处理另一个线程，然后重新构建第一个线程，以便继续处理它。上下文切换是资源密集型的，因此您应尽可能避免使用它。大多数使用多线程代码的人都知道编写线程安全代码很难，线程争抢资源可能会发生，但机会非常少，如果程序员没有想到这个问题，可能会导致潜在的严重错误。除此之外，上下文切换的成本很高，因为学习如何平衡工作负载已尽可能高效地运行是很困难的。 Job SystemJob System通过创建Job而不是线程来管理多线程代码。Job System跨多个核心管理一组工作线程。它通常每个逻辑CPU核心有一个工作线程，以避免上下文切换（尽管它可能为操作系统或其他专用应用程序保留一些核心）。Job System将Job放入作业队列中用来执行。Job System中的工作线程从作业队列中获取Job并执行它们。作业系统管理依赖关系并确保作业以适当的顺序执行。 我们来看一下简单的子弹运动系统，大多数程序员都会为GameObject编写一个管理器，如Bullet Manager，通常，这些管理器会管理一个GameObjects列表，并每帧更新场景中所有子弹活动的位置。这非常符合使用C# Jobs System的条件，由于子弹运动可以单独处理，因此非常适合并行化，借助C# Jobs System，可以轻松地将此功能拉出来，并行运行不通的数据块，作为开发人员，只需要专注游戏逻辑代码即可。 JobJob是完成一项特定任务的一小部分工作。Job接收参数并对数据进行操作，类似于方法调用的行为方式。Job可以是独立的，也可以是依赖的（需要等其他作业完成后，然后才能运行。） Job 依赖在复杂的系统中，如游戏开发所需的系统，每个工作都不可能是独立的。一项工作通常是为下一份工作准备数据。作业了解并支持依赖关系以使其发挥作用。如果jobA对jobB依赖，则Job System确保在完成jobA之前不会开始执行jobB。 安全编写多线程代码时，总是存在竞争条件的风险。当一个操作的输出取决于其控制之外的另一个过程的时间的时候，就会发生竞争条件。竞争条件并不总是一个bug，但是它不确定行为的来源，当竞争条件导致bug的时候，总是比较难以找到问题的根源。因为它取决于时间，因此你可能极少数情况下会复现问题。调试的时候可能会导致问题消失。因此调试和日志可能会改变bug的发生条件。竞争条件是编写多线程的时候面临的比较大的挑战。 为了更容易编写多线程代码，Job System可以检测所有潜在的竞争条件，并保护你免受可能导致的bug的影响。例如：如果Job System将主线程中代码中的数据引用发送到Job中，则无法验证作业在写入数据的时候同时读取数据，这种情况就会创建竞争条件。 Job System通过向每个作业发送它需要的操作的数据的副本来解决这个问题，而不是对主线程中的数据的引用，这种拷贝隔离了数据，从而消除了竞争条件。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UnityHub破解]]></title>
    <url>%2F2019%2F03%2F03%2FUnity-Hub%2F</url>
    <content type="text"><![CDATA[退出UnityHub npm install -g asar cd C:\Program Files\Unity Hub\resources asar extract .\app.aser app rm -rf app.asar cd app/src/services/licenseService vim licenseClient.js 1234567getLicenseInfo(callback)&#123; // load license // get latest data from licenseCore //licenseInfo.activated = licenseCore.getLicenseToken().length &gt; 0; // 注释这行 licenseInfo.activated = true; // 新增这行 licenseInfo.flow = licenseCore.getLicenseKind();&#125; vim licenseCore.js 12345678verifyLicenseData(xml)&#123; return new Promise((resolve, reject)=&gt; resolve(true); //新增这行 if (xml === &apos;&apos;)&#123; &#125; )&#125;]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO多路复用之select、poll、epoll详解]]></title>
    <url>%2F2019%2F03%2F02%2FNetSocket%2F</url>
    <content type="text"><![CDATA[目前支持I/O多路复用的系统调用有select,pselect,poll,epoll,I/O多路复用就是通过一种机制，一个进程可以监听多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），就能够通知程序进行相应的读写操作。但select,pselect,poll,epoll本质上都是同步I/O，因为他们都需要在读写时间就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这一步有性能开销）与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减少了系统的开销。 使用场景IO多路复用是指内核一旦发生进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合：1）当客户处理多个描述符时（一般是交互式输入和网络套接口），必须适用I/O复用。2）当一个客户同时处理多个套接口，这种情况是可能的，但很少出现。（貌似没见过）3）如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用I/O复用。（这是最常见的方式，貌似没有其他取代方式？）4）如果一个服务器既要处理TCP，又要处理UDP，一般要使用I/O复用。5）如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 select、poll、epoll简介epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核都支持，其中epoll是Linux所特有，而select则应该是POSIX规定。基本流程，如图所示：select目前几乎在所有的平台上支持，其良好的跨平台支持也是它的一个优点。select的一个缺点在与单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。select本质上是通过设置或者检查存放fb标志位的数据结构来进行下一步处理。这样所带来的的缺点是：1.select最大的缺陷就是单个进程打开的DF是有一定限制的，它由FD_SETSIZE设置，默认值是1024。一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max查看。32位默认1024个，64位默认2048个。我查了一下自己的虚拟机Centos6.0 是95979，从数量上分析来看，对于游戏来说，select模型个人感觉这点可以忽视了。2.对socket进行扫描是线性扫描，即采用轮询的方法，效率较低。当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。（这可太扯了）这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。3.需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销很大。 pollpoll是select的一种改良，最突出的改良有两点：1.文件描述符数量没有上限2.将输入输出参数进行分离，不用每次设定缺点：1.和select一样，poll返回后，需要轮询pollfd来获取就绪的描述符2.每次调用poll都需要大把大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epoll1.文件描述符没有上限，通过epoll_ctl()来注册一个文件描述符，内核中使用红黑树的数据结构来管理所有需要监控的文件描述符。2.基于时间就绪通知方式，一旦被监听的某个文件描述符就绪，内核会采用类似于callback的回调机制，迅速激活这个文件描述符，这样随着文件描述符数量的增加，也不会影响判定就绪的性能。3.维护就绪队列，当文件描述符就绪，就会被放到内核中的一个就绪队列中，这样调用epoll_wait获取就绪文件描述符的时候，只要取队列中的元素即可，操作的时间复杂度恒为O(1)。4.epoll内存映射机制，即内核将就绪队列通过mmap的方式映射到用户态，避免了拷贝内存这样的额外性能开销。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序]]></title>
    <url>%2F2019%2F02%2F25%2FQuickSort%2F</url>
    <content type="text"><![CDATA[快速排序快速排序(Quick Sort)使用分治法策略。它的基本思想是：选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，在按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 一趟快速排序的算法是： 设置两个变量i、j，排序开始的时候，i=0，j=N-1； 以第一个数组元素作为关键数据，赋值给key，即key=A[0] 从j开始向前搜索，即由后开始向前搜索（j—），找到第一个小于key的值A[j]，将A[j]=A[i]的值交换； 从i开始向后搜索，即由钱开始向后搜索（i++），找到第一个大于key的值A[i]，将A[i]和A[j]的值交换； 重复第3、4步，直到i=j；123456789101112131415161718192021222324252627282930313233343536void Sort(int *arr, int low, int high)&#123; if (low &gt;= high) return; int i = low, j = high; int key = arr[i]; while (true) &#123; while (j &gt; i) &#123; if (key &gt; arr[j]) &#123; break; &#125; j--; &#125; while (i &lt; j) &#123; if (key &lt; arr[i]) &#123; break; &#125; i++; &#125; if (i &gt;= j)break; int temp = arr[j]; arr[j] = arr[i]; arr[i] = temp; &#125; int temp = arr[j]; arr[j] = arr[low]; arr[low] = temp; Sort(arr, low, i); Sort(arr, i + 1, high);&#125; 归并排序基本思想归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分支（divide-and-conquer）策略（分治法将问题分(divide)成一些小问题然后在递归求解，而治(conquer)的阶段则将分的阶段得到的各答案“修补”在一起，即分而治之）。 可以看到这种结构很像一颗完全二叉树，本文的归并排序我们采用递归去实现，递归深度为$log_{2^n}$ 合并相邻有序子序列再来看看治阶段，我们需要将两个已经有序的子序列合并成一个有序序列，比如上图中的最后一次合并，要将[4,5,7,8]和[1,2,3,6]两个已经有序的子序列，合并为最终序列[1,2,3,4,5,6,7,8]，来看下实现步骤。 复杂度归并排序比较占用内存，但却是一种高效且稳定的算法。时间复杂度：$O(n \cdot log^n)$空间复杂度：T(n) 二叉堆（binary heap）二叉堆是一种特殊的堆，二叉堆是完全二叉树（二叉树）或者近似完全二元树（二叉树）。二叉堆有两种：最小堆和最大堆。最大堆：父节点的键值总是大于或等于任何一个子节点的键值；最小堆：父结点的键值总是小于或等于任何一个子节点的键值。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++]]></title>
    <url>%2F2019%2F02%2F25%2FC%2B%2B%2F</url>
    <content type="text"><![CDATA[虚函数 对于一个class，产生一堆指向virtual functions的指针，虚函数表指针通常放在对象实例的最前面的位置。编译报错的时候没有vtable，表示该纯虚函数没有实现。 每一个对象添加一个指针，指向相关的virtual table。这个指针被称作虚函数表指针。 C/C++中static关键字作用总结先来介绍它的第一条也是最重要的一条：隐藏。（static函数，static变量均可）当同事编译多个文件时，所有未加static前缀的全局变量和函数都具有全局可见性。举例来说明。同时编译两个源文件，一个是a.c，另一个是main.c。123456789101112131415//a.cchar a = 'A'; // global variablevoid msg()&#123; printf("Hello\n");&#125;// main.cint main()&#123; extern char a; // extern variable must be declared before use printf("%c", a); (void)msg(); return 0;&#125; 程序运行结果是：A Hello为什么在a.c中定义的全局变量a和函数msg能在main.c中使用？前面说过，所有未加static前缀的全局变量和函数都具有全局可见性，其它的源文件也能访问。此例中，a是全局变量，msg是函数，并且都没有加static前缀，因此对于另外的源文件main.c是可见的。如果加了static，就会对其它源文件隐藏。例如在a和msg的定义前加上了static，main.c就看不到它们了。利用这一特性可以再不同的文件中定义同名函数和同名变量，而不必担心命名冲突。static可以用作函数和变量的前缀，对于函数来讲，static的作用仅限于隐藏。 static的第二个作用是保持内容的持久。（static变量中的记忆功能和全局生存期）存储在静态数据区的变量会在程序刚开始运行时就完成初始化，也是唯一的一次初始化。共有两种变量存储在静态存储区：全局变量和static变量，只不过和全局变量比起来，static可以控制变量的可见范围，说到底static还是用来隐藏的，虽然这种用法不常见PS：如果作为static局部变量在函数内定义，它的生存期为整个源程序，但是其作用域仍与自动变量相同，只能定义该变量的函数内使用该变量。退出该函数后，尽管该变量还继续存在，但不能使用它。 程序举例：12345678910111213141516#include &lt;stdio.h&gt;int fun()&#123; static int count = 10; //在第一次进入这个函数的时候，变量a被初始化为10！并接着自减1，以后每次进入该函数，a就不会再次被初始化了，仅进行自减1的操作；在static发明前，要达到同样的功能，则只能使用全局变量； return count--;&#125;int count = 1;int main(void)&#123; printf("global\t\tlocal static\n"); for(;count&lt;=10;++count) &#123; printf("%d\t\t%d\n",count,fun()); &#125; return 0;&#125; 基于以上两点可以得出一个结论：把局部变量改变为静态变量后是改变了它的存储方式即改变了它的生存期。把全局变量改变为静态变量后是改变了它的作用域，限制了它的使用范围。因此static这个说明符在不同的地方所起的作用是不同的。 static的第三个作用是默认初始化为0（static变量）其实全局变量也具备这一属性，因为全局变量也存储在静态数据区。在静态数据区，内存中所有的字节默认值都是0x00，某些时候这一特点可以减少程序员的工作量。比如初始化一个稀疏举证，我们可以一个一个地把所有元素都置0，然后把不是0的几个元素赋值。如果定义成静态的，就省去了一开始置0的操作。再比如把一个字符数组当字符串来用，但又觉得每次在字符数组末尾加’\0’；太麻烦。如果把字符串定义成静态的，就省去了这个麻烦，因为那里本来就是’\0’; 最后对static的三条作用做一句话总结。首先static的最主要功能是隐藏，其次因为static变量存放在静态存储区，所以它具备持久性和默认值0。 static的第四个作用：C++中的类成员声明static（有些地方与以上作用重叠）在类中声明static变量或者函数时，初始化时使用作用域运算符来标明它所属类，因此，静态数据成员是类的成员，而不是对象的成员，这样就出现以下作用：（1）类的静态成员函数是属于整个类而非类的对象，所以它没有this指针，这就导致了它仅能访问类的静态数据和静态成员函数。（2）不能将静态成员函数定义为虚函数。（3）由于静态成员声明于类中，操作于其外，所以对其取地址操作，就多少有些特殊，变量地址是指向其数据类型的指针，函数地址类型是一个”nonmember函数指针”。（4）由于静态成员函数没有this指针，所以就差不多等同于nonmember函数，结果就产生了一个意想不到的好处：成为一个callback函数，使得我们得以将C++和C-based XWindow系统结合，同时也成功的应用于线程函数身上。（这条没遇见过）（5）static并没有增加程序的时空开销，相反它还缩短了子类对父类静态成员的访问时间，节省了子类的内存空间。（6）静态数据成员在&lt;定义或说明&gt;时前面加关键字static。（7）静态数据成员是静态存储的，所以必须对它进行初始化。（程序员手动初始化，否则编译时一般不会报错，但是Link时会报错误）（8）静态成员初始化与一般数据成员初始化不同：初始化在类体外进行，而前面不加static，以免与一般静态变量或对象相混淆；初始化时不加该成员的访问权限控制符private,public等；初始化时使用作用域来标明它所属类；所以我们得出静态数据成员初始化的格式：&lt;数据类型&gt; &lt;类名&gt;::&lt;静态数据成员名&gt;=&lt;值&gt;（9）为了防止父类的影响，可以在子类定一个与父类相同的静态变量，以屏蔽父类的影响。这里有一点需要注意：我们说静态成员为父类和子类共享，但我们有重复定义了静态成员，这会不会引起错误呢？不会，我们的编译器采用了一种绝妙的手法：name-mangling用以生成唯一的标志。 C++智能指针shared_ptrshared_ptr使用引用计数，每一个shared_ptr的拷贝都指向相同的内存。 weak_ptrweak_ptr没有共享资源，它的构造不会引起指针引用计数的增加 unique_ptr“唯一”拥有其所指对象，同一时刻只能有一个unique_ptr指向给定对象 虚函数通过一张虚函数表（Virtual Table）来实现sizeof不统计虚函数表 C/C++内存对齐什么是内存对齐32位系统下，int占4byte，char占1byte，那么将它们放到一个结构体中实际上占8byte，这就是内存对齐导致的。 inline什么是内联函数？内联函数是指那些定义在类体内部的成员函数，即该函数的函数体放在类体内。一般来说，inline适用的函数有两种，一种是类内定义的成员函数，另一种是类内声明，类外定义的成员函数，对于这两种情况inline的使用有一些不同； 内联函数的优缺点：优点：1.inline定义的类的内联函数，函数的代码被放入符号表中，在使用时直接进行替换，（像宏一样展开），没有了调用的开销，效率也很高。2.inline也是真正的函数，编辑器在调用一个内联函数时，会首先检查它的参数的类型，保证调用正确。然后进行一系列的相关检查，就像对待任何一个正在的函数一样。这样就消除了它的隐患和局限性。（宏替换不会检查参数类型，安全隐患较大）缺点：1.内联函数具有一定的局限性，inline函数的函数体一般来说不能太大，如果太大，一般的编译器会放弃内联方式，而采用普通的方式调用函数。（换句话说，你使用内联函数，只不过是向编译器提出一个申请，编译器可以拒绝你的申请），这样，内联和普通函数执行效率一样了。2.inline对编译器来说只是一种简易，编译器可以选择忽略这个建议。 注意事项1.内联函数不能宝库欧复杂的控制语句，如循环语句和switch语句； 接口（抽象类）接口描述了类的行为和功能，而不需要完成类的特定实现。 视C++为一个语言联邦 C语言 面向对象 C++模版 STL容器 尽量用const，enum，inline替换#define const的好处：define直接常量替换，出现编译错误不易定位（不知道常量是哪个变量，这个其实还好，工程规范点的都不存在这个问题）；define没有作用域，const有作用域提供了封装性（这个同上，不过这两点都是人为的避开了） enum的好处：提供了封装性，编译器肯定不会分配额外的内存空间（其实const也不会，难道define会？至于封装性，undef，所以这么多年了，虽然说避免，但是工程上用的还是比较多的） inline的好处：define宏函数容易造成误用 宏实现工厂设计模式 需要一个全局map用于存储类的信息以及创建实例的函数 需要调用全局对象的构造函数用于注册 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// ConsoleApplication1.cpp : 此文件包含 &quot;main&quot; 函数。程序执行将在此处开始并结束。//#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;typedef void *(*register_fun)();class CCFactory&#123;public: static void *NewInstance(string class_name) &#123; auto it = map_.find(class_name); if (it == map_.end()) &#123; return NULL; &#125; else &#123; return it-&gt;second(); &#125; &#125; static void Register(string class_name, register_fun func) &#123; map_[class_name] = func; &#125;private: static map&lt;string, register_fun&gt; map_;&#125;;map&lt;string, register_fun&gt; CCFactory::map_; // 体外初始化#define REGISTER_CLASS(class_name); \ CCFactory::Register(#class_name, []()-&gt;void *&#123;return (new class_name);&#125;);class Product&#123;public: virtual void Say() = 0;&#125;;class Register : public Product // 注册者，就是产品，虽然不喜欢设计模式这坨东西，但是研究起来还是挺好玩的&#123;public: void Say() &#123; std::cout &lt;&lt; &quot;Say What?\n&quot;; &#125;&#125;;void Init()&#123; REGISTER_CLASS(Register);&#125;void Release()&#123;&#125;int main()&#123; Init(); Register* a = (Register*)CCFactory::NewInstance(&quot;Register&quot;); a-&gt;Say(); Release();&#125; 没写完，但是感觉做个池还是挺好玩的。 尽可能使用const const定义接口，防止误用 const成员函数，代表这个成员函数承诺不会改变对象值（const成员只能调用const成员函数(加-fpermissive编译选项就可以了)，非const成员可以调用所有成员函数） 确定对象使用前被初始化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// ConsoleApplication1.cpp : 此文件包含 &quot;main&quot; 函数。程序执行将在此处开始并结束。//#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;typedef void *(*register_fun)();class CCFactory&#123;public: static void *NewInstance(string class_name) &#123; auto it = map_.find(class_name); if (it == map_.end()) &#123; return NULL; &#125; else &#123; return it-&gt;second(); &#125; &#125; static void Register(string class_name, register_fun func) &#123; map_[class_name] = func; &#125;private: static map&lt;string, register_fun&gt; map_;&#125;;map&lt;string, register_fun&gt; CCFactory::map_; // 体外初始化#define REGISTER_CLASS(class_name); \ CCFactory::Register(#class_name, []()-&gt;void *&#123;return (new class_name(#class_name));&#125;);class Product&#123;public: virtual void Say() = 0;&#125;;class Register : public Product // 注册者，就是产品，虽然不喜欢设计模式这坨东西，但是研究起来还是挺好玩的&#123;public: void Say() &#123; std::cout &lt;&lt; name.c_str() &lt;&lt; &quot;: Say What?\n&quot;; &#125; void Run() const // 表明这个函数不会对类对象的数据成员（准确地说是非静态数据成员）作任何改变 &#123; &#125; int b; const string name; // 必须在初始化的时候赋值 Register(string _y) : name(_y) &#123; &#125;&#125;;void Init()&#123; REGISTER_CLASS(Register);&#125;void Release()&#123;&#125;int main()&#123; Init(); Register* a = (Register*)CCFactory::NewInstance(&quot;Register&quot;); a-&gt;Say(); Release();&#125; 构造、析构、赋值运算如果类中没有定义，程序却调用了，编译器会产生一些函数 一个default的构造函数 一个copy构造函数 一个copy assignment 操作符 一个析构函数(non virtual) 如果自己构造了带参数的构造函数，编译器不会产生default构造函数 base class如果把拷贝构造函数或者复制操作符设置为private，不会产生这两个函数 含有引用成员变量或者const成员变量不产生复制操作符 若不想使用编译器自动生成的函数，就该明确拒绝将默认生成的函数声明为private，或者C++ 11新特性”=delete”123456class UncopyTable&#123;private: UncopyTable(const UncopyTable&amp;); UncopyTable&amp; operator=(const UncopyTable&amp;);&#125;; 静态类型上下文无关，在编译时就可以确定其类型。 动态类型基类指针指向的对象在编译的时候无法确定 动态绑定与静态绑定静态绑定：编译时绑定，通过对象调用动态绑定：运行时绑定，通过地址实现 要触发动态绑定，需满足两个条件 只有虚函数才能惊醒动态绑定，非虚函数不能进行动态绑定 必须通过基类类型的引用或指针进行函数调用 为多态基类声明virtual析构函数 给多态基类应该主动声明virtual析构函数 非多态基类，没有virtual函数，不要声明virtual析构函数 复制对象时勿忘其每个成分 实现拷贝构造函数和赋值操作符的时候，调用base的相关函数 可以让拷贝构造函数和赋值操作符调用一个共同的函数，比如Init 资源管理以对象管理资源 为了防止资源泄漏，请使用RAII对象，在构造函数里面获得资源，在析构函数里面释放资源 shared_ptr，unique_lock都是RAII对象 在资源管理类小心copy行为 常见的RAII对象copy行为 禁止copy 引用计数 深度赋值 转移资源拥有权 头文件搜索目录#include &quot;headfile.h&quot; 搜索顺序为： 当前目录 -I指定目录 gcc的环境变量CPLUS_INCLUDE_PATH（C程序使用的是C_INCLUDE_PATH） gcc内定目录/usr/include/usr/local/include/usr/lib/gcc/x86_64-redhat-linux/4.1.1/include]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序章]]></title>
    <url>%2F2018%2F12%2F09%2Ffiction%2F</url>
    <content type="text"><![CDATA[芩也不是一开始就知道这个世界是黑白的，是他的父亲告诉他的。父亲说，芩，你长大了，父亲要走了。芩问，父亲你去哪里？父亲说，我也不知道，我总觉得有人在召唤我，我该上路了。我们每个人都会上路的，包括你，芩。芩说，父亲，我可以陪你一起上路吗？父亲回答，我们每个人的路都是不一样的，你以后会有你自己的路走的，或许是明天，或许是明年，或许是更久。芩没说话，六岁的他不知道该说什么，也不太明白父亲对他说的话。他只知道，父亲要走了。要去很远的地方，一个他找不到的地方。而他，再也见不到父亲了。从那天起，我的天空里再也没有太阳，总是黑夜，但并不暗，因为有东西代替了太阳。虽然没有太阳那么明亮，但对我来说已经足够。凭借着这份光，我便能把黑夜当成白天。我从来就没有太阳，所以不怕失去。]]></content>
      <tags>
        <tag>混沌</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PowerVR Performance Recommendations]]></title>
    <url>%2F2018%2F11%2F23%2FPowerVR-Performance-Recommendations%2F</url>
    <content type="text"><![CDATA[IntroductionPowerVR SGX and PowerVR Rogue are Graphics Core architectures from Imagination Technologies designed specifically for shader-based APIs such as OpenGL ES 2.0,3.x,and Vulkan.Due to their scalable architectures,the PowerVR family spans a huge performance range. Document OverviewThis purpose of this document is to serve as recommendation and advice for developers who wish to get the best graphics performance from a PowerVR SGX or PowerVR Rogue enabled device. Throughout the document, the specific recommendations for PowerVR SGX and PowerVR Rogue are marked as appropriate. The Golden RulesThe Golden Rules are a set of more generic performance recommendations that developers should seek to implement,as well as observe as many of the techniques and principles mentioned.This should help produce well-behaved,high performance graphics applications.These rules are detailed in the document entitled “PowerVR Performance Recommendations: The Golden Rules”,which is supplied with the PowerVR SDK.]]></content>
      <categories>
        <category>Graphics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader第三部分]]></title>
    <url>%2F2018%2F10%2F22%2FUnity-Shader-IntrodutionToTopic-2%2F</url>
    <content type="text"><![CDATA[透明效果透明是游戏中经常要使用的一种效果。在实时渲染中要实现透明效果，通常会在渲染模型时控制它的透明通道（Alpha Channel）。当开启透明混合后，当一个物体被渲染到屏幕上时，每个片元除了颜色值和深度值之外，它还有透明度。当透明度为1时，表示该像素是完全不透明的，而当其为0时，则表示该像素完全不会显示。在Unity中，我们通常使用两种方法来实现透明效果：第一种是使用透明度测试（Alpha Test），这种效果其实无法得到真正的半透明效果；另一种是透明度混合（Alpha Blending）。在之前的学习中，我们从没有强调过渲染顺序的问题。也就是说，当场景中包含很多模型时，我们并没有考虑是先渲染A，在渲染B，最后在渲染C，还是按照其他的顺序来渲染。事实上，对于不透明（opaque）物体，不考虑它们的渲染顺序也能得到正确的排序效果，这是由于强大的深度缓冲（depth buffer，也被称为z-buffer）的存在。在实时渲染中，深度缓冲是用于解决可见性（visibility）问题的，它可以决定哪个物体的哪些部分会被渲染在前面，而哪些部分会被其他物体遮挡。它的基本思想是：根据深度缓冲中的值来判断该片元距离摄像机的距离，当渲染一个片元时，需要把它的深度值和已经存在于深度缓冲中的值进行比较（如果开启了深度测试），如果它的值距离摄像机更远，那么说明这个片元不应该被渲染到屏幕上（有物体遮挡住了它）；否则，这个片元应该覆盖掉此时颜色缓冲中的像素值，并把它的深度值更新到深度缓冲中（如果开启了深度写入）。 透明度混合透明度混合的实现要比透明度测试复杂一些，这是因为我们在处理透明度测试时，实际上跟对待普通的不透明物体几乎是一样的，只是在片元着色器中增加了对透明度判断并裁剪片元的代码。而想要实现透明度混合就没这么简单了。我们回顾之前提到的透明度混合的原理。透明度混合：这种方法可以得到真正的半透明效果。它会使用当前片元的透明度作为混合因子，与已经存储在颜色缓冲区种的颜色进行混合，得到新的颜色。但是，透明度混合需要关闭深度写入，这使得我们要非常小心物体的渲染顺序。为了进行混合，我们需要使用Unity提供的混合命令Blend。Blend是Unity提供的设置混合模式的命令。想要实现半透明的效果就需要把当前自身的颜色和已经存在于颜色缓冲区种的颜色值进行混合，混合时使用的函数就是由该指令决定的。 语义 描述 Blend Off 关闭混合 Blend SrcFactor DstFactor 开启混合，并设置混合因子。源颜色（该片元产生的颜色）会乘以SrcFactor，而目标颜色（已经存在于颜色缓存的颜色）会乘以DstFactor，然后把两者相加后在存入颜色缓冲中 Blend SrcFactor DstFactor, SrcFactorA DstFractorA 和上面一样，只是使用不同的因子来混合透明通道 BlendOp BlendOperation 并非是把源颜色和目标颜色简单相加后混合，而是使用BlendOperation对它们进行其他操作 我们介绍第二种语义，即Blend SrcFactor DstFactor来进行混合。需要注意的是，这个命令在设置混合因子的同时也开启了混合模式。这是因为，只有开启了混合之后，设置片元的透明通道才有意义，而Unity在我们使用Blend命令的时候就自动帮我们打开了。很多初学者抱怨为什么自己的模型没有任何透明效果，这往往是因为他们没有在Pass中使用Blend命令，一方面是没有设置混合因子，更重要的是没有打开混合模式。我们会把源颜色的混合因子SrcFactor设为SrcAlpha，而目标颜色的混合因子DstFactor设为OneMinusSrcAlpha。这意味着，经过混合后新的颜色是： $DstColor{new} = SrcAlphaSrcColor+(1-SrcAlpha)DstColor{old}$ 开启深度写入的半透明效果ShaderLab的混合命令混合等式和参数混合操作常见和混合类型双面渲染的透明效果透明度测试的双面渲染透明度混合的双面渲染渲染路径Rendering Path LightMode 描述 Always 不管使用哪种渲染路径，该Pass总是会被渲染，但不会计算任何光照 ForwardBase 用于前向渲染。该Pass会计算环境光、最重要的平行光、逐顶点/SH光源和Lightmaps ForwardAdd 用于前向渲染。该Pass会计算额外的逐像素光源，每个Pass对应一个光源 Deferred 用于延迟渲染。该Pass会渲染G缓冲（G-buffer） ShadowCaster 把物体的深度信息渲染到阴影映射纹理（shadowmap）或一张深度纹理中 PrepassBase 用于遗留的延迟渲染。该Pass会渲染法线和高光反射的指数部分 PrepassFinal 用于遗留的延迟渲染。该Pass通过合并纹理、光照和自发光来渲染得到最后的颜色 Vertex、VertexLMRGBM和VertexLX 用于遗留的顶点照明渲染 Unity在处理多光源的情况时为我们提供了三种模式；修改的地方在Edit-&gt;Project Settings—Player—Other Settings—Redering Path 顶点光Vertex Lit 方向性Forward(默认) 延迟照明 Deferred Lighting shader默认使用Forward 前向渲染路径每进行一次完整的前向渲染，需要渲染该对象的渲染图元，并计算两个缓冲区的信息：一个是颜色缓冲区，一个是深度缓冲区。利用深度缓冲区来决定一个片元是否可见，如果可见就更新颜色缓冲区的的颜色值。我们可以用下面的伪代码来描述前向渲染路径的大致过程： 12345678910111213141516171819Pass &#123; for (each primitive in this model) &#123; if (failed in depth test) &#123; // 如果没有通过深度测试，说明该片元是不可见的 discard; &#125; else &#123; // 如果该片元可见 // 就进行光照计算 float4 color = Shading(materialInfo, pos, normal, lightDir, viewDir); // 更新帧缓冲 writeFrameBuffer(fragment, color); &#125; &#125;&#125; 对于每个逐像素光源，我们都需要进行上面一次完整的渲染流程。如果一个物体在多个逐像素光源的影响区域内，那么该物体就需要执行多个Pass，每个Pass计算一个逐像素光源的光照结果，然后在帧缓冲中把这些光照结果混合起来得到最终的颜色值。假设，场景中有N个物体，每个物体物体受M个光源的影响，那么要渲染整个场景一共需要N*M个Pass。可以看出，如果有大量逐像素光照，那么需要执行的Pass数目也会很大。因此，渲染引擎通常会限制每个物体的逐像素光照的数目。 Unity中的前向渲染事实上，一个Pass不仅仅可以用来计算逐像素光照，它也可以用来计算逐顶点等其他光照。这取决于光照计算所处流水线阶段以及计算时使用的数学模型。当渲染一个物体时，Unity会计算哪些光源照亮了它，以及这些光源照亮该物体的方式。在Unity中，前向渲染路径有3种处理光照（即照亮物体）的方式：逐顶点处理、逐像素处理，球谐函数（Spherical Harmonics, SH）处理。 顶点照明渲染路径延迟渲染路径这是一种可以按照你的需求在场景中使用任意数目的光源的方法，而且这个方法还能同时保证性能仍然保持在一个合理的范围。它也不限制阴影的数量，如果场景中的对象实在光照范围之内的话，也不会增加额外的渲染批次（如果对象投影阴影的话则是例外）。 在游戏中的实时光照，一般有三种常用的方法 一遍渲染多个光源：所有光源都在一个着色器中进行。但一个着色器指令数量有限，所以这个技术只适用于光源数量较少的情况。 多遍渲染多光源 延迟渲染 广告牌广告牌技术的本质就是构建旋转矩阵，而我们知道一个变换矩阵需要3个基向量。广告牌技术使用的基向量通常就是表面法线（normal）、指向上的方向（up）以及指向右的方向（right）。除此之外，我们还需要指定一个锚点（anchor location），这个锚点在旋转过程中是固定不变的，以此来确定多边形在空间中的位置。广告牌技术的难点在于，如何根据需求构建3个相互正交的基向量。计算过程通常是，CPU写法：12345678public Vector3 Normal;Quaternion direction;void Start () &#123; direction = Quaternion.FromToRotation(new Vector3(0, 0, 1), Normal);&#125;void Update () &#123; transform.rotation = Camera.main.transform.rotation * direction;&#125; 屏幕后处理效果建立一个基本的屏幕后处理脚本系统MonoBehaviour.OnRenderImage(RenderTexture src, RenderTexture dest); 当在脚本中声明该函数后，Unity会把当前渲染得到的图像存储在第一个参数对应的源渲染纹理中，把第二参数对应的渲染纹理显示到屏幕上。 public static void Blit(Texture src, RenderTexture dest); public static void Blit(Texture src, RenderTextrue dest, Material mat, int pass = -1); public static void Blit(Texture src, Material mat, int pass = -1); 参数pass的默认值胃-1，表示将会依次调用Shader内的所有Pass。否则，只会调用给定索引的Pass。 使用深度和法线纹理消融噪声纹理+透明度测试，我们使用对噪声纹理采样的结果和某个控制消融程度的阀值比较，如果小于阀值，就使用clip函数把它对应的像素裁减掉。 12345678910111213141516171819202122Shader &quot;Test&quot;&#123; Properties &#123; _BurnAmount(&quot;Burn Amount&quot;, Range(0.0, 1.0)) = 0.0 // 控制消融程度，0为正常，1完全消融 _LineWith(&quot;Burn Line Width&quot;, Range(0.0, 0.2)) = 0.1 // 模拟烧焦效果的线宽，值越大，火焰边缘的蔓延范围越宽 _MainText (&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; &#123;&#125; // 漫反射纹理 _BumpMap (&quot;Normal Map&quot;, 2D) = &quot;bump&quot; &#123;&#125; // 法线纹理 _BurnFirstColor(&quot;Burn First Color&quot;, Color) = (1,0,0,1) // 火焰边缘颜色 _BurnSecondColor(&quot;Burn Second Color&quot;, Color) = (1,0,0,1) // 火焰边缘颜色 _BurnMap(&quot;Burn Map&quot;, 2D) = &quot;white&quot; &#123;&#125; // 消融纹理 &#125; SubShader &#123; Pass &#123; CGPROGRAM #pragma vertex vert #pragma vertex frag ENDCG &#125; &#125; &#125; 水波效果在模拟实时水面的过程中，往往也会使用噪声纹理。此时，噪声纹理通常会用作一个高度图，以不断修改水面的法线方向。为了模拟水不断流动的效果，我们会使用和时间相关的变量来对噪声纹理进行采样，当得到法线信息后，在进行正常的反射+折射计算，得到最后的水面波动效果。1234SubShader &#123; Tags &#123;&quot;Queue&quot;=&quot;Transparent&quot; &quot;RenderType&quot;=&quot;Opaque&quot;&#125; GrabPass &#123;&quot;_RefractionTex&quot;&#125;&#125; 首先把SubShader的标签中渲染队列设置成Transparent，并把后面的RenderType设置为Opaque。把Queue设置成Transparent可以确保该物体渲染时，其他所有不透明的物体都已经被渲染到屏幕上了，否则就可能无法正确得到“透过水面看到的图像”。而设置RenderType则是为了在使用着色器替换（Shader Replacement）时，该物体可以在需要时被正确渲染。]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader第二部分]]></title>
    <url>%2F2018%2F10%2F21%2FUnity-Shader-IntroductionToTopic1%2F</url>
    <content type="text"><![CDATA[光源在光学里，我们使用辐照度（irradiance）来量化光。对于平行光来说，它的辐照度可通过计算在垂直于l的单位平面上的单位时间内穿过的能量来得到。 吸收和散射光线由光源发射出来后，就会与一些物体相交。通常，相交的结构有两个：散射（scattering）和吸收（absorption）。散射只改变光线的方向，但不改变光线的密度和颜色。而吸收只改变光线的密度和颜色，但不改变光线的方向。 BRDF光照模型我们已经了解了光线在和物体表面相交时会发生哪些现象。当已知光源位置和方向、视角方向时，我们就需要知道一个表面是和光照进行交互的。例如，当光线从某个方向照射到一个表面时，有多少光线被反射？反射的方向有哪些？而BRDF（Bidirectional Reflectance Distribution Function）就是用来回答这些问题的。当给定模型表面上的一个点时，BRDF包含了对该点外观的完整的描述。在图形学种，BRDF大多使用一个数学公式来表示，并且提供了一些参数来调整材质属性。通俗来讲，当给定入射光线的方向和辐照度后，BRDK可以给出某个出射方向上的光照能量分布。本章涉及的BRDF都是对真实场景进行理想化和简化后的模型，也就是说，它们并不能真实地反映物体和光线之间地交互，这些光照模型被成为是经验模型。尽管如此，这些经验模型仍然在实时渲染领域被应用了多年。 标准光照模型基本方法是，把进入到摄像机的光线分为4部分，每个部分使用一种方法来计算它的贡献度 自发光(emissive) 高光反射(specular) 漫反射(diffuse) 环境光(ambient) 环境光在标准光照模型中，使用一种被称为环境光的部分来近似模拟间接光照。环境光的计算非常简单，它通常是一个全局变量，即场景中的所有物体都使用这个环境光。下面的等式给出了计算环境光的部分： $c{ambient}=g{ambient}$ 自发光光线也可以直接由光源发射进入摄像机，而不需要经过任何物体的反射。标准光照模型使用自发光来计算这个部分的贡献度。它的计算也很简单，就是直接使用了该材质的自发光颜色： $c{emissive}=m{emissive}$ 通常在实时渲染中，自发光的表面往往并不会照亮周围的表面，也就是说，这个物体并不会被当成一个光源。 漫反射漫反射光照是用于对那些被物体表面随机散射到各个方向的辐射度进行建模的。在漫反射中，视角的位置是不重要的，因为反射是完全随机的，因此可以认为在任何反射方向上的分布都是一样的。但是，入射光线的角度很重要。漫反射光照符合兰伯特定律（Lambert’s law）：反射光线的强度与表面发现和光源方向之间夹角的余弦值成正比。因此，漫反射部分的计算如下： $c{diffuse} = (c{light} \cdot m_{diffuse})max(0, n \cdot I)$ 高光反射这里的高光反射是一种经验模型，也就是说，它并不完全符合真实世界中的高光反射现象。它可用于计算那些沿着完全镜面反射方向被反射的光线，这可以让物体看起来是有光泽的，例如金属材质。计算高光反射需要知道的信息比较多，如表面法线、视角方向、光源方向、反射方向等。反射计算公式：$r = 2(\vec{n} \cdot I)\vec{n} - I$推导公式见Light Reflect这样，我们就可以利用Phong模型来计算高光反射的部分： $c{spscular} = (c{light} \cdot m{specular})max(0, \vec{v} \cdot r)^{m{glass}}$其中，$m{gloss}$是材质的光泽度（gloss），也被称为反光度（shinness）。它用于控制高光区域的“亮点”有多宽，$m{gloss}$越大，亮点就越小。$m{spscular}$是材质的高光反射颜色，它用于控制该材质对于高光反射的强度和颜色。$c{light}则是光源的颜色和强度。$ 逐像素还是逐顶点总结单张纹理实践纹理的属性凹凸映射高度纹理法线纹理实践法线纹理类型渐变纹理遮罩纹理实践其他遮罩纹理]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader第一部分]]></title>
    <url>%2F2018%2F10%2F20%2FUnity-Shader-IntroductionToTopic%2F</url>
    <content type="text"><![CDATA[像素光 Pixel LightUnity中将平行光称作为像素光，第一个像素光是基础平行光，以LightMode=ForwardBase标签修饰，每多一个像素光都以LightMode=ForwardAdd标签修饰。并不是所有的光源在运行时都会反射到物体上，而是根据Project的Quality中设置的像素光数量来渲染的。默认的像素光的数量应该是2，我们有更多的平行光照在物体上，就需要在Edit-&gt;Project Setting-&gt;Quality中去调节像素光的数量Pixel Light Count当场景中的实际像素光数量超过这个设定值的时候，Unity只会渲染最重要的光。 关于像素光的叠加原理片段着色器是要将mesh组件传递的信息最终计算为颜色(或者深度)存储在帧缓存(Frame Buffer)中。每个Pass之间输出的颜色通过一定的公式进行混合。在这里我们简单使用一比一的模式进行颜色混合，即混合指令为：Blend One One第二个Pass的代码同样的也直接复制第一个Pass即可，相应的将Tags标签中LightMode=ForwardBase修改为LightMode=ForwordAdd。 12345Shader &quot;Custom/Multi-Light Diffuse&quot; &#123; Properties &#123; // 材料颜色默认为黑色， &#125;&#125; 渲染流水线渲染流水线的工作任务在于由一个三维场景触发、生成（或者说渲染）一张二维图像。换句话说，计算机需要从一系列的顶点数据、纹理等信息出发，把这些信息最终转换成一张人眼可以看到的图像。而这个工作通常是由CPU和GPU共同完成的。《Render-Time Rendering, Third Edition》将一个渲染流程分成3个阶段：应用阶段(Application Stage)、几何阶段(Geometry Stage)、光栅化阶段(Rasterizer Stage)。 应用阶段（CPU处理）这一阶段是由开发者主导的，在这一阶段中开发都有3个主要的任务：首先，需要准备好场景数据（摄像机位置，视锥体，模型和光源等）接着，还需要做粗粒度的剔除工作最后，需要设置好每个模型的渲染状态（使用的材质，使用的纹理，使用的Shader等）这一阶段最重要的输出是渲染所需的几何信息，即渲染图元，渲染图元可以是点，线，三角面等。 几何阶段（GPU处理）几何阶段主要用于处理所有和我们绘制的几何相关的事情。几何阶段负责和每个渲染图元打交道，进行逐顶点，逐多边形的操作。这个阶段可以进一步分成更小的流水线阶段。几何阶段的一个重要任务就是把顶点坐标变换到屏幕空间中，再交给光栅器进行处理。总结：输入的渲染图元-&gt;屏幕空间的二维顶点坐标、每个顶点对应深度、着色等信息 光栅化阶段（GPU处理）将会使用上一个阶段传递的数据来产生屏幕上的像素，并渲染出最终的图像。主要任务是决定每个渲染图元中的那些像素应该被绘制在屏幕上。顶点着色器（Vertex Shader）是完全可编程的，它通常用于实现顶点的空间变换、顶点着色等功能。曲面细分着色器（Tessellation Shader）是一个可选的着色器，几何着色器（Geometry Shader）同样是一个可选的着色器，它可以被用于执行逐图元（Per-Pimitive）的着色操作，或者被用于产生更多的图元。下一个流水线是裁剪（Clipping），这一阶段的目的是将那些不在摄像机视野内的顶点裁剪掉，并剔除某些三角图元的面片。这个阶段是可配置的。例如，我们可以使用自定义的裁剪平面来配置裁剪区域，也可以通过指令控制裁剪三角图元的正面还是背面。几何概念阶段的最后一个流水线阶段是屏幕映射（Screen Mapping）。这一阶段是不可配置和编程的，它负责把每个图元的坐标转换到屏幕坐标系中。光栅化概念阶段中的三角形设置（Triangle Setup）和三角形遍历（Triangle Traversal）阶段也都是固定函数（Fixed-Function）的阶段。接下来的片元着色器（Fragment Shader），则是完全可编程的，它用于实现逐片元（Per-Fragment）的着色操作。最后，逐片元操作（Per-Fragment Operations）阶段负责执行很多重要的操作，例如修改颜色、深度缓冲、进行混合等，它不是可编程，但具有很高的可配置型。Unity内置的DiffuseShader,也就是说我们创建一个Material出来时默认的Shader也是多光源的，所以这篇文章完成的Shader与默认的diffuse shader基本效果一致。 2.2 CPU与GPU之间的通信渲染流水线的起点是CPU，即应用阶段。应用阶段可以分为下面3个阶段： 把数据加载到显存中 设置渲染状态 调用Draw Call 2.2.1 把数据加载到显存中基本步骤就是纹理、网格等数据从硬盘加载到系统内存在加载到显存中。数据记载到显存后系统内存中的数据就可以被移除了，但是对于一些数据来说CPU需要访问他们，例如用于碰撞检测用的网格数据，这些数据则会被保留。 2.2.3 设置渲染状态渲染状态指的是场景中的网格是如何被渲染的，例如使用哪个Vertex Shader或者哪个Fragment Shader、光源属性、材质等。 2.2.3 调用Draw CallDraw Call指的是一个命令，发起方为CPU，接收方为GPU。当给定了一个Draw Call时，GPU会根据渲染状态（例如材质、纹理、着色器等）和所有输入的顶点数据来进行计算，最终输出成屏幕上显示的那些漂亮的像素。而这个计算过程，就是我们下一节要讲的GPU流水线。 2.3 GPU流水线当GPU从CPU那里得到渲染命令后，就会进行一系列流水线操作，最终把图元渲染到屏幕上。 2.3.1 概述在上一节中，我们解释了在应用阶段，CPU是如何和GPU通信，并通过调用Draw Call来命令GPU进行渲染。GPU渲染的过程就是GPU流水线。 对于概念阶段的后两个阶段，即几何阶段和光栅化阶段，开发者无法拥有绝对的控制权，其实现的载体是GPU。GPU通过实现流水线化，大大加快了渲染速度。虽然我们无法完全控制这两个阶段的实现细节，但GPU向开发者开放了很多控制权。在这一节中，我们将具体了解GPU是如何实现这两个概念阶段的。 几何阶段和光栅化阶段可以分为若干更小的流水线阶段，这些流水线阶段由GPU来实现，每个阶段GPU提供了不同的可配置性或可编程性。 从应用程序阶段模型数据给顶点着色器时支持的语义 语义 描述 POSITION 模型空间的顶点位置，通常是float4类型 NORMAL 顶点法线，通常是float3类型 TANGENT 顶点切线，通常是float4类型 TEXCOORDn,如TEXCOORD0、TEXCOORD1 该顶点的纹理坐标，TEXCOORD0表示第一组纹理坐标，依次类推，通常是float2或float4类型 其中TEXCOORDn中的数目是和Shader Model有关的，例如一般在Shader Model 2(即Unity默认编译到的Shader Model版本)和Shader Model 3中，n等于8，而在Shader Model 4 和Shader Model 5中，n等于16.通常情况下，一个模型的纹理坐标数组一般不超过2，即我们往往只只用TEXCOORD0和TEXCOORD1。在Unity内置的数据结构体appdata_full中，它最多使用了6个坐标纹理。 从顶点着色器传递数据给片元着色器时的语义 语义 描述 SV_POSITION 裁剪空间中的顶点坐标，结构体中必须包含一个用该语义修饰的变量。等同于Direct9中的POSITION，但最好使用SV_POSITION COLOR0 通常用于输出第一组顶点颜色，但不是必须的 COLOR1 通常用于输出第二组顶点颜色，但不是必须的 TEXCOORD0~TEXCOORD7 通常用于输出纹理坐标，但不是必须的 上面的语义中，除了SV_POSITION是有特别含意外，其他语义对变量的含义没有明确要求，也就是说，我们可以存储任意值到这些描述变量中。 片元着色器输出时Unity支持的常用语义 语义 描述 点和矢量的区别点是一个没有大小之分的空间中的位置，而矢量是一个有模和方向但是没有位置的量。 齐次坐标对于一个点，从三维坐标转换成齐次坐标是把w分量设为1，而对于方向矢量来说，需要把w分量设为0。 平移矩阵我们可以使用矩阵乘法来表示对一个点进行平移变换： $\begin{bmatrix}{1}&amp;{0}&amp;{0}&amp;{t{x}}\{0}&amp;{1}&amp;{0}&amp;{t{y}}\{0}&amp;{0}&amp;{1}&amp;{t{z}}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}\begin{bmatrix}{x}\{y}\{z}\{1}\\end{bmatrix} =\begin{bmatrix}{x+t{x}}\{y+t{y}}\{z+t{z}}\{1}\\end{bmatrix}$ 从结果来看我们可以很容易看出为什么这个矩阵有平移的效果：点的x、y、z分量分别增加了一个位置偏移。在3D中的可视化效果是，把点$(x,y,z)$在空间中平移了$(t{x},t{y},t_{z})$。如果我们对一个方向矢量进行平移变换，结果如下： $\begin{bmatrix}{1}&amp;{0}&amp;{0}&amp;{t{x}}\{0}&amp;{1}&amp;{0}&amp;{t{y}}\{0}&amp;{0}&amp;{1}&amp;{t_{z}}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}\begin{bmatrix}{x}\{y}\{z}\{0}\\end{bmatrix} =\begin{bmatrix}{x}\{y}\{z}\{0}\\end{bmatrix}$可以发现，平移变换不会对方向矢量产生任何影响。因为矢量没有位置属性，也就是说它可以位于空间中的任意一点，因此对位置的改变不应该对四维矢量产生影响。 缩放矩阵我们可以对一个模型沿空间的x轴、y轴和z轴进行缩放。 $\begin{bmatrix}{k{x}}&amp;{0}&amp;{0}&amp;{0}\{0}&amp;{k{y}}&amp;{0}&amp;{0}\{0}&amp;{0}&amp;{k{z}}&amp;{0}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}\begin{bmatrix}{x}\{y}\{z}\{1}\\end{bmatrix} =\begin{bmatrix}{k{x}x}\{k{y}y}\{k{z}z}\{1}\\end{bmatrix}$ 如果缩放系数$k{x}=k{y}=k_{z}$，我们把这样的缩放称为统一缩放（uniform scale），否则称为非同一缩放（nonuniform scale）。从外观看，统一缩放是扩大整个模型，而非同一缩放会拉伸或挤压模型。更重要的是，统一缩放不会改变角度和比例信息。 复合变换在绝大多数情况下，我们约定变换的顺序就是先缩放，再旋转，最后平移。变换矩阵如下：(注意，矩阵是从右往左算的)$M{translation}M{rotation}M{scale} =\begin{bmatrix}{1}&amp;{0}&amp;{0}&amp;{t{x}}\{0}&amp;{1}&amp;{0}&amp;{t{y}}\{0}&amp;{0}&amp;{1}&amp;{t{z}}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}$当我们直接给出$(\theta{x}, \theta{y}, \theta_{z})$这样的旋转角度时，需要定义一个旋转顺序。在Unity中，这个旋转顺序是zxy。 顶点的坐标空间变化在渲染流水线中，一个顶点要经过多个坐标空间的变换才能最终被画在屏幕上。一个顶点最开始是在模型空间中定义的，最后它将会变换到屏幕空间中，得到真正的屏幕像素坐标。 模型空间模型空间（model space），是和某个模型或者说是对象有关的。有时模型空间也被称为对象空间（object space）或局部空间（local space）。每个模型都有自己独立的坐标空间，当它移动或旋转的时候，模型空间也会跟着它移动和旋转。顶点变换的第一步，就是将顶点坐标从模型空间变换到世界空间中。这个变换通常叫做模型变换（model transform）。 世界空间顶点变换的第一步，就是将顶点坐标从模型空间变换到世界空间中。这个变换通常叫做模型变换（model transform）。变换矩阵如下：$M{model} = \begin{bmatrix}{1}&amp;{0}&amp;{0}&amp;{t{x}}\{0}&amp;{1}&amp;{0}&amp;{t{y}}\{0}&amp;{0}&amp;{1}&amp;{t{z}}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}\begin{bmatrix}{cos\theta}&amp;{0}&amp;{sin\theta}&amp;{0}\{0}&amp;{1}&amp;{0}&amp;{0}\{-sin\theta}&amp;{0}&amp;{cos\theta}&amp;{0}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}\begin{bmatrix}{k{x}}&amp;{0}&amp;{0}&amp;{0}\{0}&amp;{k{y}}&amp;{0}&amp;{0}\{0}&amp;{0}&amp;{k{z}}&amp;{0}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix} =\begin{bmatrix}{k{x}cos\theta}&amp;{0}&amp;{k{z}sin\theta}&amp;{t{x}}\{0}&amp;{k{y}}&amp;{0}&amp;{t{y}}\{-k{x}sin\theta}&amp;{0}&amp;{k{z}cos\theta}&amp;{-t_{z}}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}$注意：上述变换顺序是不能互换的，即先进行缩放，在进行旋转，最后是平移。因为每个Transform的平移旋转缩放都是不一样的，所以他们的矩阵也是不一样的。 观察空间观察空间（view space）也被称为摄像机空间（camera space）。顶点变换的第二步，就是将顶点坐标从世界空间变换到观察空间中。这个变换叫做观察变换（view transform）。 裁剪空间裁剪空间（clip space，也称齐次裁剪空间），这个用于变换的矩阵叫做裁剪矩阵（clip matrix），也称为投影矩阵（projection matrix）。裁剪空间的目标是能够方便地对渲染图元进行裁剪：完全位于这块空间内部的图元将会被保留，完全位于这块空间外部的图元将会被剔除，而与这块空间边界相交的图元就会被裁剪。这块空间是由视锥体来决定的。视锥体指的是空间中的一块区域，这块区域决定了摄像机可以看到的空间。视锥体由六个平面包围而成，这些平面也被称为裁剪平面（clip planes）。视锥体有两种类型，一种是正交投影（orthographic projection），一种是透视投影（perspective projection）。在视锥体的6块裁剪平面中，有两块裁剪平面比较特殊，它们分别被称为近裁剪平面（near clip plane）和远裁剪平面（far clip plane）。它们决定了摄像机可以看到的深度范围。 透视投影视锥体的意义在于定了场景中的一块三维空间。所有位于这块空间内的物体将会被渲染，否则就会被剔除或裁剪。这块区域是由6个裁剪平面组成，在Unity中，它们由Camera组件中的参数和Game视图中横纵比共同决定Camera组件的Field of View（简称FOV）属性来改变视锥体竖直方向的张开角度，而Clipping Planes中的Near和Far参数可以控制视锥体的近裁剪面和远裁剪面距离相机的远近。这样，我们可以求出视锥体近裁剪面和远裁剪面的高度 $nearClipPlaneHeight = 2 \cdot Near \cdot tan {FOV \over 2}$ $farClipPlaneHeight = 2 \cdot Far \cdot tan {FOV \over 2}$ 透视投影的横向信息，可以通过相机的横纵比得到。在Unity中，一个摄像机的横纵比由Game视图的横纵比和Viewport Rect中的W和H属性共同决定（实际上，Unity允许我们在脚本里通过Camera.aspect进行更改）。假设，当前相机的横纵比为Aspect，则： $Aspect = {nearClipPlaneWidth \over nerClipPlaneHeight}$ $Aspect = {farClipPlaneWidth \over farClipPlaneHeight}$ 现在，我们可以根据已知的Near、Far、FOV和Aspect的值来确定透视投影的投影矩阵。如下： $M{frustum} = \begin{bmatrix}{cot{FOV \over 2} \over Aspect}&amp;{0}&amp;{0}&amp;{0}\{0}&amp;{cot{FOV \over 2}}&amp;{0}&amp;{0}\{0}&amp;{0}&amp;{-{Far+Near \over Far-Near}}&amp;{-{2 \cdot Far \cdot Near \over Far-Near}}\{0}&amp;{0}&amp;{-1}&amp;{0}\\end{bmatrix}$这里针对的是观察空间是右手坐标系，使用列矩阵在矩阵右侧相乘的，且变换后z分量范围在[-w,w]之间的情况。而一个顶点和上述投影矩阵相乘后，可以由观察空间变换到裁剪空间中，结果如下$P{clip} = M{frustum}P{view} =\begin{bmatrix}{cot{FOV \over 2} \over Aspect}&amp;{0}&amp;{0}&amp;{0}\{0}&amp;{cot{FOV \over 2}}&amp;{0}&amp;{0}\{0}&amp;{0}&amp;{-{Far+Near \over Far-Near}}&amp;{-{2 \cdot Far \cdot Near \over Far-Near}}\{0}&amp;{0}&amp;{-1}&amp;{0}\\end{bmatrix}\begin{bmatrix}{x}\{y}\{z}\{1}\\end{bmatrix}=\begin{bmatrix}{x{cot{FOV \over 2} \over Aspect}}\{y{cot{FOV \over 2}}}\{-z{Far+Near \over Far-Near}-{2 \cdot Near \cdot Far \over Far-Near}}\{-z}\\end{bmatrix}$从这个结果来看，这个投影矩阵本质就是对x、y和z分量进行了不同程度的缩放（z分量还有一个平移），缩放的目的是为了方便裁剪。此时顶点的w分量不再是1，而是原先z分量的取反结果。现在，我们就可以按如下不等式来判断一个变换后的顶点是否位于视锥体内。如果一个顶点在视锥体内，那么它变换后的坐标必须满足：$-w \le x \le w$$-w \le y \le w$$-w \le z \le w$任何不满足上述条件的图元都需要被剔除或者裁剪。下图显示了经过上述投影矩阵后，视锥体的变化。从上图还可以注意到，裁剪矩阵会改变空间的旋向行；空间从右手坐标系变换到了左手坐标系。这意味着，离摄像机越远，z值将越大。 正交投影 正交投影的6个裁剪面和透视投影类似，在Unity中，它们也是由Camera组件中的参数和Game视图的横纵比共同决定。正交投影的视锥体是一个长方体，因此计算上相比透视投影来说更加简单。由图可以看出，我们可以通过Camera组件的Size属性来改变视锥体竖直方向上高度的一般，而Clipping Planes中的Near和Far参数可以控制视锥体的近裁剪面和远裁剪面距离相机的远近。这样，可以求出视锥体近裁剪面和远裁剪面的高度，也就是：$newClipPlaneHeight=2 \cdot Size$$farClipPlaneHeight=nearClipPlaneHeight$ 现在我们还缺乏横向的信息。同样，我们可以通过摄像机的横纵比得到。假设，当前摄像机的横纵比为Aspect，那么：$nearClipPlaneWidth=Aspect \cdot nearClipPlaneHeight$$farClipPlaneWidth=nearClipPlaneWidth$现在，我们可以根据已知的Near、Far、Size和Aspect的值来确定正交投影的裁剪矩阵。如下：$M_{prtho} =\begin{bmatrix}{1 \over Aspect \cdot Size}&amp;{0}&amp;{0}&amp;{0}\{0}&amp;{1 \over Size}&amp;{0}&amp;{0}\{0}&amp;{0}&amp;{-{2 \over Far-Near}}&amp;{-{Far+Near} \over {Far-Near}}\{0}&amp;{0}&amp;{0}&amp;{1}\\end{bmatrix}$ 屏幕空间经过投影矩阵的变换后，我们可以进行裁剪操作。当完成了所有的裁剪工作后，就需要进行真正的投影了，也就是说，我们需要把视锥体投影到屏幕空间（screen space）中。经过这一步变换，我们会得到真正的像素位置，而不是虚拟的三维坐标。屏幕空间是一个二维空间，因此，我们必须把顶点从裁剪空间投影到屏幕空间中，来生成对应的2D坐标。这个过程可理解成有两个步骤。首先，我们需要进行标准齐次除法（homogeneous division），也被称为透视除法（perspective division）。虽然这个步骤听起来很陌生，但是它实际上非常简单，就是用齐次坐标系的w分量去除以x、y、z分量。在OpenGL中，我们把这一步得到的坐标叫做归一化的设备坐标（Normalized Device Coordinates，NDC）。经过这一步，我们可以把坐标从齐次裁剪坐标空间转换到NDC中。经过透视投影变换后的裁剪空间，经过齐次除法会变换到一个立方体内。按照OpenGL的传统，这个立方体的x、y、z分量的范围都是[-1,1]。但在DirectX这样的API中，z分量的范围会是[0,1]。而Unity选择了OpenGL这样的齐次裁剪空间。 一个最简单的顶点/片元着色器顶点/片元着色器的基本结构Unity Shader的基本结构包含了Shader、Properties、SubShader、Fallback等语义块。顶点/片元着色器的结构与之大体类似，它的结构如下： 123456789101112131415161718192021222324252627282930Shader &quot;MyShaderName&quot; &#123; Properties &#123; // 属性 &#125; SubShader &#123; // 针对显卡A的SubShader Pass &#123; // 设置渲染状态和标签 // 开始CG代码片段 CGPROGRAM // 该片段的编译指令，例如: #pragma vertex vert #pragma fragment frag // CG代码写在这里 ENDCG // 其他设置 &#125; // 其他需要的Pass &#125; SubShader &#123; // 针对显卡B的SubShader &#125; // 上述SubShader都失败后用于回调的Unity Shader Fallback &quot;VertexLit&quot;&#125; 其中，最重要的部分是Pass语义块，我们绝大部分的代码都是写在这个语义块里面的。下面我们就来创建一个最简单的顶点/片元着色器。1234567891011121314151617Shader &quot;Shader/Simple&quot; &#123; SubShader &#123; Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag float4 vert(float4 v : POSITION) : SV_POSITION &#123; return UnityObjectToClipPos(v); &#125; fixed4 frag() : SV_Target&#123; return fixed4(1.0, 1.0, 1.0, 1.0); &#125; ENDCG &#125; &#125;&#125; 12345678910111213141516Shader &quot;Shader/Simple1&quot;&#123; SubShader&#123; Pass&#123; CGPROGRAM #pragma vertex vert #pargma fragment frag // 使用一个结构体来定义顶点着色器的输入 struct a2v &#123; // POSITION语义告诉Unity，用模型空间的顶点坐标填充vertex变量 float4 vertex : POSITION; &#125; ENDCG &#125; &#125;&#125; 模型数据从哪里来顶点着色器和片元着色器之间如何通信如何使用属性Unity提供的内置文件和变量内置的包含文件内置的变量Unity提供的CG/HLSL语义Unity支持的语义 语义 描述 POSITION 模型空间的顶点位置，通常是float4类型 NORMAL 顶点法线，通常是float3类型 TANGENT 顶点切线，通常是float4类型 $TEXCOORD_{n}$，如TEXCOORD0、TEXCOORD1 该顶点的纹理坐标，TEXCOORD0表示第一组纹理坐标，依此类推。通常是float2或float4类型 COLOR 顶点颜色，通常是fixed4或float4类型 如何定义复杂的变量类型使用假彩色图形float、half还是fixed在本书中，我们使用CG/HLSL来编写Unity Shader中的代码。而在CG/HLSL中，有3中精度的数值类型：float、half和fixed。这些精度将决定计算结果的数值范围。表5.8给出了这3中精度在通常情况下的数值范围。 CG/HLSL中3种精度的数值类型 类型 精度 float 最高精度的浮点值。通常使用32位来存储 half 中等精度的浮点值。通常用16位来存储，精度范围是-60000~+60000 fixed 最低精度的浮点值。通常使用11位来存储，精度方位是-2.0~+2.0]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader Manual]]></title>
    <url>%2F2018%2F10%2F15%2FUnity-Shader-Manual%2F</url>
    <content type="text"><![CDATA[Properties123456789101112Shader &quot;ShaderLab Tutorials/TestShader&quot;&#123; Properties &#123; _Range (&quot;My Range&quot;, Range(0.02, 0.15)) = 0.07 // sliders _Color (&quot;My Color&quot;, Color) = (.34, .85, .92, 1) // color _2D (&quot;My Texture 2D&quot;, 2D) = &quot;&quot; &#123;&#125; // texture _Rect (&quot;My Rectangle&quot;, Rect) = &quot;name&quot; &#123;&#125; _Cube (&quot;My Cubemap&quot;, Cube) = &quot;name&quot; &#123;&#125; _Float (&quot;My Float&quot;, Float) = 1 _Vector (&quot;My Vector&quot;, Vector) = (1,2,3,4) &#125;&#125; Shader在Unity编辑器暴露给美术的参数，通过Properties来实现。 所有可能的参数如上所示。主要也就是Float、Vector和Texture这3类。 除了通过编辑器编辑Properties，脚本也可以通过Material的接口（比如SetFloat、SetTexture编辑） 之后的Shader程序通过[name]（固定管线）或者直接name（可编程Shader）访问这些属性。 在每一个Property前面也能类似C#那样添加Attribute，以达到额外UI功能。详见SemanticsSubShaderTags{“TagName1”=”Value1” “TagName2”=”Value2”}Tag的语法结构，通过Tags{}来表示需要添加的标识，大括号可以添加多组Tag（所以才叫Tags嘛），名称(TagName)和值（Value）是成对出现的，并且全部用字符串表示。 Queue渲染队列直接影响性能中的重复绘制，合理的队列可极大的提升渲染效率。渲染队列数目小于2500的对象都被认为是不透明的物体（从前往后渲染），高于2500的被任务是半透明物体（后后往前渲染）。“Queue”=”Geometry+1”可通过值后加数字的方式来改变队列。 Queue标签 解释 “Queue”=”Background” 值为1000，此队列的对象最先进行渲染 “Queue”=”Geometry” 默认值，值为2000，通常用于不透明对象，比如场景中的物体与角色等 “Queue”=”AlphaTest” 值为2450，要么完全透明要么完全不透明，多用于利用贴图来实现边缘透明的效果，也就是美术常说的透贴 “Queue”=”Transparent” 值为3000，常用于半透明对象，渲染时从后往前进行渲染，建议需要混合的对象放入此队列 “Queue”=”Overlay” 值为4000，此渲染队列用于叠加选过。最后渲染的东西应该放在这里（例如镜头光晕等） RenderType用来区分这个Shader要渲染的对象是属于什么类型的，你可以想象成事我们把不同的物体按我们需要的类型来进行分类一样。当然你也可以根据需要改成自定义的名称，这样并不会影响到Shader的选过。此Tag多用于摄像机的替换材质功能（Camera.SetReplacementShader）。 标签 释义 “RenderType”=”Opaque” 大多数不透明着色器 “RenderType”=”Transparent” 大多数半透明着色器，比如粒子、特效、字体等。 “RenderType”=”TransparentCutout” 透贴着色器，多用于植被等。 “RenderType”=”Background” 多用于天空盒着色器。 “RenderType”=”Overlay” GUI、光晕着色器等。 “RenderType”=”TreeOpaque” Terrain地形中的树干。 “RenderType”=”TreeTransparentCutout” Treeain地形中的树叶。 “RenderType”=”TreeBillboard” Terrain地形中的永对面树。 “RenderType”=”Grass” Terrain地形中的草。 “RenderType”=”GrassBillboard” Terrain地形中的用对面草。 指定RenderType的名称，主要是为了配合使用替代渲染的方法。 Camera.SetReplacementShader(&quot;shader&quot;, &quot;RenderType&quot;) DisableBatching在利用Shader在模型的定点本地坐标下做一些位移动画，而当此模型有批处理时会出现效果不正确的情况，这是因为批处理将所有模型转换为世界坐标空间，因为”本地坐标空间”将丢失。 批处理标签 解释 “DisableBatching”=”True” 禁止批处理 “DisableBatching”=”False” 不禁用批处理 Mathdot(a,b)点乘，a和b必须为三维向量或者四维向量，其计算结果是两个向量夹角的余弦值，相当于a.x*b.x+a.y*b.y+a.z*b.za和b的位置无所谓前后，结果都是一样的 Miscellaneousfloat3 objCenterPos = mul(unity_ObjectToWorld, float4(0,0,0,1)).xyz; 在Shader中获取当前模型的中心点，其实就是将(0,0,0)点从本地坐标转换到世界空间坐标下即可。 内置函数 Syntax Description abs(x) Absolute value (per component)(每个组件). acos(x) Returns the arccosine(反余弦) of each component of x. ceil(x) Returns the smallest integer(最小整数) which is greater(大于) than or equal to x. clip(x) Discards(抛弃) the current pixel,if any component of x is less than zero. cross(x,y) x向量和y向量的向量积（叉积） frac(x) 返回x的小数部分 lerp(x,y,s) Returns x + s(y-x) noise(x) Generates a random value using the Perlin-noise algorithm. pow(x,y) Returns $x^y$ saturate(x) x: 为用于操作的标量或矢量，可以是float、float2、float3等类型。把x截取在[0,1]范围内，如果x是一个矢量，那么会对它的每一个分量进行这样的操作。 smoothstep(min,max,x) 如果x比min小，返回0；如果x比max大，返回1；如果x处于范围[min,max]中，则返回0和1之间的值（返回值在min和max间的比例）。 step(a,b) Returns (b&gt;=a)?1:0 (一般用这个取代if else) tex2D(s, t) 2D texture lookup. reflect(I,N) 根据入射光方向向量I，和顶点法向量N，计算反射光方向向量。其中I和N必须被归一化，需要非常注意的是，这个I是指向顶点的；函数只对三元向量有效 Tex2DProj(sampler2D tex, float3 sq) 二维投影纹理查询 Tex2DProj(sampler2D tex, float4 szq) 二维投影纹理查询，并进行深度值比较 #pragma fragementoption ARB_precision_hint_fastestARB_precision_hint_fastest 是用最快的方式，以最低的精度运行，提升片段着色器的运行速度，减少时间。（通常是指FP16,16bit，半精度）牺牲表现换取运行速度。 UnpackNormalhalf3 normal = UnpackNormal(tex2D(_NormalMap, IN.uv_NormalMap));UnpackNormal是定义在UnityCG.cginc文件中的方法，UnpackNormal接受一个fixed4的输入，并将其转换为所对应的法线值(fixed3)。 TANGENT_SPACE_ROTATION12float3 binormal = cross(v.normal,v.tangent.xyz)*v.tangent.w;flaot3x3 rotation = float3x3(v.tangent.xyz,binormal,v.normal); 也就是构造出tangent space的坐标系，定义转换world space的向量到tangent space的rotation矩阵。 UNITY_MATRIX_IT_MV专门用于将发现从模型空间变换到观察空间，为UNITY_MATRIX_MV的逆转置矩阵，]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TSF4G]]></title>
    <url>%2F2018%2F09%2F21%2FTSF4G%2F</url>
    <content type="text"><![CDATA[https://github.com/johnnyluo586/TSF4G.git Tbus简介Tbus是tsf4g(Tencent ServiceFramework for Game,腾讯游戏服务框架)中的基础组件之一，主要的目的是为上层业务提供统一的线程或进程间通信接口，屏蔽本地进程间通信以及远程进程通信的细节，让开发人员可以集中精力关注业务逻辑，是tsf4g重要组成部分。 Tbus原理 Tbus基于共享内存构建无锁双通循环消息队列，发送的双方通过专用的读写队列完成数据收发，实现本地进程或者远程进程间通信。通信双方使用的两个队列称之为tbus通道(channel)，每一组通讯的双方就需要有一个tbus通道。 进程A发送消息后，消息被存储到Host A的发送队列中，部署于Host A的tbusd发现队列中存在消息，则从队列中把消息取出，通过tcp发送到Host B上。Host B上的tbusd接收到消息后，把消息写入本地的接收队列，以供进程B读取。 为了能完成通信，Tbus还有以下几个特点： 通信双方具备全局唯一的tbus通信地址，该地址是一个点分十进制的字符串，与IP地址类型，总长度为32bit，分为4段，每段bit位数可以自定义，总长度不超过32bit。例如：128.1.100.1,5.0.200.1。 Tbus通道以及消息是存储在共享内存中，必须要使用相应的工具提前创建，进程才能绑定与使用。而当业务进程异常退出后，由于消息是存储在共享内存中，只要不主动清理共享内存、重启服务器或损坏共享内存，通道的消息就不会丢失。]]></content>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity-Lua-Manual]]></title>
    <url>%2F2018%2F09%2F18%2FUnity-Lua-Manual%2F</url>
    <content type="text"><![CDATA[GameObjectGO_namegameObject.GO_name = &quot;name&quot; 设置或者获取游戏对象的名字 GO_selfgameObject.GO_self 绑定到自己身上的Lua模块指针 GO_activegameObject.GO_active = true/false 设置游戏对象的显式或者隐藏 GO_parentgameObject.GO_parent = parent 设置游戏对象的父节点 GO_childCountgameObject.GO_childCount 获取游戏对象的子节点对象，不递归 GO_AddComponentgameObject:GO_AddComponent(“UILabel&quot;) 给游戏对象添加组件 GO_GetComponentgameObject:GO_GetComponent(&quot;UILabel&quot;) gameObject:GO_GetComponent(&quot;UILabel&quot;, &quot;Sprite/Label&quot;) 方法一：获取游戏对象的组件方法二：获取子节点上的组件，参数二表示相对于父节点的路径 GO_FindgameObject:GO_Find(&quot;Sprite/Label&quot;) 获取子节点对象 GO_AddChildgameObject:GO_AddChild(&quot;UI/ui_node&quot;) gameObject:GO_AddChild(ui_node) 方法一：通过相对于Resources下的路径来给游戏对象添加子节点方法二：通过实例对象来给游戏对象添加子节点如果是UI节点，请使用UI_AddChild UI_AddChildgameObject:UI_AddChild(&quot;UI/ui_node&quot;) gameObject:UI_AddChild(ui_node) 方法一：通过相对于Resources下的路径来给游戏对象添加子节点方法二：通过实例对象来给游戏对象添加子节点 GO_DelChildgameObject:GO_DelChild(idx) 删除游戏对象的子节点，idx是下标从0开始的索引（顺序是检视面板显示的顺序） GO_DestroySelfgameObject:GO_DestroySelf() 销毁自己 GO_RemoveAllChildrengameObject:GO_RemoveAllChildren() 销毁所有的子节点 GO_ShowAllChildrengameObject:GO_ShowAllChildren(ture/false) 显示或者隐藏自己所有的子节点 GO_GetLocalPositionlocal x,y,z = gameObject:GO_GetLocalPosition() 获取自己的localPosition GO_SetLocalPositiongameObject:GO_SetLocalPosition(x,y [,z]) 设置自己的localPosition,[] 表示可选参数,当未指定时表示使用之前的z GO_GetLocalRotationlocal x,y,z = gameObject:GO_GetLocalRotation() 获取自己的localRotation GO_SetLocalRotationgameObject:GO_SetLocalRotation(x,y [,z]) 设置自己的localRotation,[]表示可选参数,当未指定时表示使用之前的z GO_SetLocalScalegameObject:GO_SetLocalScale(x,y,z) 设置自己的localScale GO_UpdateAllAnchorsgameObject:GO_UpdateAllAnchors() 手动刷新自身的锚点 UI_activegameObject.UI_active = true/false 递归刷新自己和子节点的显示和隐藏，如无特殊要求请使用GO_active UI_onClickgameObject.UI_onClick = function() end 添加点击事件，游戏对象需要添加boxcollider2D UIToggle_onChangegameObject.UIToggle_onChange = function() end 添加Toggle状态改变的回调函数，游戏对象需要添加UIToggle UILabel_textgameObject.UILabel_text = &quot;Hello, World!&quot; 设置或者读取游戏对象的UILabel文本，游戏对象需要添加UILabel UILabel_colorgameObject.UILabel_color = Color.FromHex(&quot;C4C4C4FF&quot;) 设置或者读取文本颜色，返回值是Color UISprite_spriteNamegameObject.UISprite_spriteName = &quot;btn_blue&quot; 设置或者读取精灵的名字，游戏对象需要添加UISprite组件 UISprite_colorgameObject.UISprite_color = Color.FormHex(&quot;6f4f3fff&quot;) 设置或者读取精灵的颜色，游戏对象需要添加UISprite组件 UIToggle_valuegameObject.UIToggle_value = true/false 设置UIToggle的值 UIWidget_colorgameObject.UIWidget_color = Color.FormHex(&quot;6f4f3fff&quot;) 设置UIWidget或者继承他的子类（UILabel,UISprite)的颜色 UIWidget_widthgameObject.UIWidget_width = 100 设置UIWidget或者继承他的子类（UILabel,UISprite)的宽度 UIWidget_heightgameObject.UIWidget_height = 100 设置UIWidget或者继承他的子类的高度 UIGrid_RepositiongameObject:UIGrid_Reposition() 使Grid重新排序，一般给Grid添加了子节点后使用 Tween_PlaygameObject:Tween_Play() 播放Tween动画 MBMB.LogMB.Log(&quot;Hello,World!&quot;) 打印日志 MB.PCallMB.PCall(function() end) 安全的调用函数，当函数内部发生错误的时候，不会中断当前执行环境 MB.LoadModuleMB.LoadModule(&quot;ui_task&quot;) 加载一个lua模块 MB.ShowTheTipMB.ShowTheTip(&quot;Hello,World!&quot;, 2) 弹出Tips，第二个参数表示时长单位是秒 String.CSFormatString.CSFormat(&quot;id={0},name={1}&quot;,10,&quot;test&quot;) 调用C#的格式化函数 MB.GetStringXMB.GetStringX(bytes[], 10, &quot;test&quot;) 调用C#的格式化函数，第一个参数是byte数组，一般来说表格中的字段用它 MB.GetExcelListMB.GetExcelList(&quot;NewTaskResConf&quot;) 读取表格 MB.GO_GetResourceself.u_testSprite.atlas = MB.GO_GetResource(&quot;UI/01Common&quot;) 获取资源 参数表示相对于Resources的路径，返回的是GameObject UITextureSetTexturePathtexture:SetTexturePath(&quot;Texture/UI/Chapter1&quot;) 设置texture的资源路径，路径相对于Resources，texture是通过gameObject获取的组件 SetMattexture:SetMat(path) 设置texture的材质，path表示相对Resources路径 UILabletextlabel.text = &quot;Hello, World！&quot; 设置或者读取Label的文本 colorlabel.color = Color.FromHex(&quot;6F4F3FFF&quot;) 设置或者读取Label的颜色 effectColorlabel.effectColor = Color.FromHex(&quot;6F4F3FFF&quot;) 设置或者读取Label的效果颜色 fontSizelabel.fontSize = 20 设置或者读取字体的大小 UISpritespriteNamesprite.spriteName = &quot;btn_red&quot; 设置或者读取Sprite的名字（图集中的） widthsprite.width = 100 设置或者读取Sprite的宽度 heightsprite.height = 100 设置或者读取Sprite的高度 atlassprite.atlas = MB.GO_GetResource(&quot;UI/01Common&quot;) 设置或者读取图集 LuaEventC#中 LuaEvent.CallEvent((int)eLuaEvnet.eLuaEvent_PlayerTaskUpdate, param1, param2, param3); lua中 lua_event.InvokeEvent(lua_def.eLuaEvent_PlayerTaskUpdate, param1, param2, param3) lua_event.InsertEvent(lua_def.eLuaEvent_PlayerTaskUpdate, callback, name, 0) function callback(param1, param2, param3) end CallEvent表示C#事件通知LuaInvokeEvent表示Lua事件通知LuaLuaEvent.CallEvent中的第一个参数表示类型在obj_def.cs中定义，后面是需要传递给lua的参数 lua_netSendBinlua_net.SendBin(lua_def.CS_CMD_GET_TASK_LIST_REQ, {Page = 1, Type = 4}, callback) function callback(msg) end 发送二进制包，第一个参数是消息ID，第二个参数是相对于数据结构类型，callback是回调函数，可选类型回调函数中的msg表示一个json的xml中结构。 Sendlua_net.Send(lua_def.eCTS_UI_Task, {op = &quot;get&quot;}) 发送JSON包，第一个参数是cts_def.cs中定义的消息，第二个参数是lua table Registerlua_net.Register(lua_def.eSTC_UI_Task, OnUITaskHandle, signal, -1) function OnUITaskHandler(msg) end lua_net.Register(lua_def.CS_CMD_GET_TASK_LIST_RES, OnGetTaskListRes, signal, -1) function OnGetTaskListRes(msg) -- msg是xml生成的数据结构，传到lua里面是一个json table end 注册一个消息回调，signal表示一个回调的唯一句柄，-1表示调用该回调函数的顺序，默认是0 lua_timerlua_timer.Timer(self.gameObject, span, onTick, count, name) — 创建Timer对象— go : 指定挂到某个gameObject上— span : 时间间隔，毫秒— onTick : 回调函数(timer, dt)，回调的dt参数是超时的时间，一般也用不上— count : 重复次数，缺省是1，如果是-1则无限循环。— return : 返回一个lua table作为Timer]]></content>
  </entry>
  <entry>
    <title><![CDATA[luajit]]></title>
    <url>%2F2018%2F09%2F10%2Fluajit%2F</url>
    <content type="text"><![CDATA[JIT = Just In TimeIOS中禁止使用（不让自主申请内存） 解释执行： 效率低 代码暴露 静态编译 不够灵活，无法热更新 平台兼容性差 JIT： 效率：高于解释执行，低于静态编译。 安全性：一般都先转换成字节码 热更新：无论源码还是字节码本质都是自愿文件。 兼容性：虚拟机会处理平台差异，对用户透明。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Andorid NDK]]></title>
    <url>%2F2018%2F07%2F21%2FAndroid-NDK%2F</url>
    <content type="text"><![CDATA[JNIJNI的全称是Java Native Interface，Java原生接口。提供别的代码调用的一组函数。首先使用C++写出了一些函数，然后将这些函数在Java类中再声明一次（加上关键字native），这样Java类中的函数和C++中的函数就匹配到一起了，我们使用Java类中的函数，其实就是使用C++中的函数。这个在Java类中声明的函数就是一个JNI。 NDKNDK的全称是Native Development Kit，原生开发工具包。 交叉编译交叉编译就是在一个平台上生成另一个平台上的可执行代码。]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Manual]]></title>
    <url>%2F2018%2F07%2F21%2FAndroidManifest%2F</url>
    <content type="text"><![CDATA[AndroidManifest 为应用的JAVA软件包命名。软件包名称充当应用的唯一标识符 描述应用的各个组件，包括构成应用的Activity、服务、广播接收器和内容提供程序。它还为实现每个组件的类命名并发布其功能，例如它们可以处理Intent消息。这些声明向Android系统告知有关组件以及可以启动这些组件的条件的信息。 确定托管应用组件的进程。 声明应用必须具备哪些权限才能访问API中受保护的部分并与其他应用交互。还声明其他应用与该应用组件交互所需具备的权限。 列出Instrumentation类，这些类可在应用运行时提供分析和其他信息。这些声明只会在应用处于开发阶段时出现在清单中，在应用发布之前会将移除。 声明应用所需的最低Android API级别。 列出应用必须链接到的库 元素首先，所有的xml都必须包含&lt;manifest&gt;元素。这是文件的根节点。它必须要包含&lt;application&gt;元素，并且指明xmlns:android和package属性。 xmlns:android这个属性定义了Android命名空间。必须设置成”http://schemas.android.com/apk/res/android&quot;。不要手动修改。 package这是一个完整的Java语言风格包名。包名由英文字母（大小写均可）、数字和下划线组成。每个独立的名字必须以字母开头。 构建APK的时候，构建系统使用这个属性来做两件事：生成R.java类时用这个名字作为命名空间（用于访问APP的资源）比如：package被设置成net.pixelgame.unity3d android:name该属性以字符串形式指定了APP要用的硬件或软件功能。 android:required andorid:glEsVersion &lt;application&gt;元素 此元素描述了应用的配置。这是一个必备的元素，它包含了很多子元素来描述应用的组件，它的属性影响到所有的子组件。 Android Studio快捷键 在当前窗口查找文本Ctrl+F 在当前窗口查找文本Ctrl+Shift+F 查找类Ctrl+N 查找文件Ctrl+Shitf+N 查找项目中的方法或变量Ctrl+Shitf+Alt+N 查找类/方法/变量引用的地方,先定位光标,右键选择”Find Usages”(或者快捷键Alt+F7) Ctrl+o查看所有可以重写的地方 在类中快速定位某个方法或属性Ctrl+F12 Android分辨率2018.1月手机分辨率2560144019201080(16:9)1280720 (16:9)296014402040*1080 如何连接木木模拟器并查看log123456adb connect 127.0.0.1:7555 # 连接木木模拟器adb connect 127.0.0.1:62001 # 连接夜神模拟器adb shelllogcat-----adb devices]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protocol Buffer]]></title>
    <url>%2F2018%2F07%2F21%2FProtocol%2F</url>
    <content type="text"><![CDATA[高效的二进制方式存储Varint是一种紧凑的表示数字的方法。它用一个或多个字节来表示一个数字，值越少的数字使用越少的字节数。采用这种Key-Pair结构无需使用分隔符来分割不同的Field。 Type Meaning Used For 0 Varint int32,int64,uint32,uint64,sint32,sint64,bool,enum 1 64-bit fixed64 sfixed64,double 2 Length-delimi string,bytes,embedded messages,packed repeated fields 3 Start group Groups(deprecated) 4 End group Groups(deprecated) 5 32-bit fixed32,sfixed32,float 在计算机内，一个负数一般会被表示一个很大的整数，因为计算机定义负数的符号位为数字的最高位。如果采用Varint表示一个负数，那么一定需要5个byte。为此Google Protocol Buffer定义了sint32这种类型，采用zigzag编码。 Zigzag编码用无符号来表示有符号数字，正数和负数交错，这就是zigzag这个词的含义了。 使用zigzag编码，绝对值小的数字，无论正负都可以采用较少的byte来表示，充分利用了Varint这种技术。 其他的数据类型，比如字符串则采用类似数据库中的varchar的表示方法，即用一个varint表示长度，然后其余部分紧跟在这个长度部分之后即可。 封解包的速度首先来了解一下XML的封解包过程。XML需要从文件中读取字符串，再转换为XML文档对象结构模型。之后，再从XML文档对象结构模型中读取指定节点的字符串，最后再将这个字符串转换成指定类型的变量。这个过程非常复杂，其中将XML文件转换为文档对象结构模型的过程通常需要完成词法文法分析等大量消耗CPU的复杂计算。 反观Protobuf，它只需要简单地将一个二进制序列，按照指的格式读取到C++对应的结构类型中就可以了。从上一节的描述可以看到消息的decoding过程也可以通过几个位移操作组成的表达式计算即可完成。速度非常快。 T-L-V的数据存储方式Tag-Lenght-Value,标识-长度-字段值存储方式 标识-长度-字段值表示单个数据，最终将所有数据拼接成一个字节流，从而实现数据存储的功能 其中Length可选存储，如存储Varint编码数据就不需要存储Length]]></content>
  </entry>
  <entry>
    <title><![CDATA[CameraEditor]]></title>
    <url>%2F2018%2F07%2F11%2FCameraEditor%2F</url>
    <content type="text"><![CDATA[Floder:Editor\Mono\Inspector123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748// Unity C# reference source// Copyright (c) Unity Technologies. For terms of use, see// https://unity3d.com/legal/licenses/Unity_Reference_Only_Licenseusing System.Collections.Generic;using System.Text;using UnityEngine;using UnityEngine.Rendering;using AnimatedBool = UnityEditor.AnimatedValues.AnimBool;using UnityEngine.Scripting;using UnityEditor.Modules;namespace UnityEditor&#123; [CustomEditor(typeof(Camera))] [CanEditMultipleObjects] public class CameraEditor : Editor &#123; public sealed class Settings &#123; private SerializedObject m_SerializedObject; public Settings(SerializedObject so) &#123; m_SerializedObject = so; &#125; // Manually entered rendering path names/values, since we want to show them // in different order than they appear in the enum. private static readonly GUIContent[] kCameraRenderPaths = &#123; EditorGUIUtility.TrTextContent("Use Graphics Settings"), EditorGUIUtility.TrTextContent("Forward"), EditorGUIUtility.TrTextContent("Deferred"), EditorGUIUtility.TrTextContent("Legacy Vertex Lit"), EditorGUIUtility.TrTextContent("Legacy Deferred (light prepass)") &#125;; private static readonly int[] kCameraRenderPathValues = &#123; (int)RenderingPath.UsePlayerSettings, (int)RenderingPath.Forward, (int)RenderingPath.DeferredShading, (int)RenderingPath.VertexLit, (int)RenderingPath.DeferredLighting &#125;; public SerializedProperty clearFlags &#123; get; private set; &#125; public SerializedProperty backgroundColor &#123; get; private set; &#125; public SerializedProperty normalizedViewPortRect &#123; get; private set; &#125; public SerializedProperty fieldOfView &#123; get; private set; &#125; public SerializedProperty orthographic &#123; get; private set; &#125; public SerializedProperty orthographicSize &#123; get; private set; &#125; public SerializedProperty depth &#123; get; private set; &#125; public SerializedProperty cullingMask &#123; get; private set; &#125; public SerializedProperty renderingPath &#123; get; private set; &#125; public SerializedProperty occlusionCulling &#123; get; private set; &#125; public SerializedProperty targetTexture &#123; get; private set; &#125; public SerializedProperty HDR &#123; get; private set; &#125; public SerializedProperty allowMSAA &#123; get; private set; &#125; public SerializedProperty allowDynamicResolution &#123; get; private set; &#125; public SerializedProperty stereoConvergence &#123; get; private set; &#125; public SerializedProperty stereoSeparation &#123; get; private set; &#125; public SerializedProperty nearClippingPlane &#123; get; private set; &#125; public SerializedProperty farClippingPlane &#123; get; private set; &#125; public SerializedProperty targetDisplay &#123; get; private set; &#125; public SerializedProperty targetEye &#123; get; private set; &#125; private static readonly GUIContent[] kTargetEyes = &#123; EditorGUIUtility.TrTextContent("Both"), EditorGUIUtility.TrTextContent("Left"), EditorGUIUtility.TrTextContent("Right"), EditorGUIUtility.TrTextContent("None (Main Display)"), &#125;; private static readonly int[] kTargetEyeValues = &#123; (int)StereoTargetEyeMask.Both, (int)StereoTargetEyeMask.Left, (int)StereoTargetEyeMask.Right, (int)StereoTargetEyeMask.None &#125;; public void OnEnable() &#123; clearFlags = m_SerializedObject.FindProperty("m_ClearFlags"); backgroundColor = m_SerializedObject.FindProperty("m_BackGroundColor"); normalizedViewPortRect = m_SerializedObject.FindProperty("m_NormalizedViewPortRect"); nearClippingPlane = m_SerializedObject.FindProperty("near clip plane"); farClippingPlane = m_SerializedObject.FindProperty("far clip plane"); fieldOfView = m_SerializedObject.FindProperty("field of view"); orthographic = m_SerializedObject.FindProperty("orthographic"); orthographicSize = m_SerializedObject.FindProperty("orthographic size"); depth = m_SerializedObject.FindProperty("m_Depth"); cullingMask = m_SerializedObject.FindProperty("m_CullingMask"); renderingPath = m_SerializedObject.FindProperty("m_RenderingPath"); occlusionCulling = m_SerializedObject.FindProperty("m_OcclusionCulling"); targetTexture = m_SerializedObject.FindProperty("m_TargetTexture"); HDR = m_SerializedObject.FindProperty("m_HDR"); allowMSAA = m_SerializedObject.FindProperty("m_AllowMSAA"); allowDynamicResolution = m_SerializedObject.FindProperty("m_AllowDynamicResolution"); stereoConvergence = m_SerializedObject.FindProperty("m_StereoConvergence"); stereoSeparation = m_SerializedObject.FindProperty("m_StereoSeparation"); targetDisplay = m_SerializedObject.FindProperty("m_TargetDisplay"); targetEye = m_SerializedObject.FindProperty("m_TargetEye"); &#125; public void Update() &#123; m_SerializedObject.Update(); &#125; public void ApplyModifiedProperties() &#123; m_SerializedObject.ApplyModifiedProperties(); &#125; public void DrawClearFlags() &#123; EditorGUILayout.PropertyField(clearFlags, EditorGUIUtility.TextContent("Clear Flags|What to display in empty areas of this Camera's view.\n\nChoose Skybox to display a skybox in empty areas, defaulting to a background color if no skybox is found.\n\nChoose Solid Color to display a background color in empty areas.\n\nChoose Depth Only to display nothing in empty areas.\n\nChoose Don't Clear to display whatever was displayed in the previous frame in empty areas.")); &#125; public void DrawBackgroundColor() &#123; EditorGUILayout.PropertyField(backgroundColor, EditorGUIUtility.TextContent("Background|The Camera clears the screen to this color before rendering.")); &#125; public void DrawCullingMask() &#123; EditorGUILayout.PropertyField(cullingMask); &#125; public void DrawProjection() &#123; ProjectionType projectionType = orthographic.boolValue ? ProjectionType.Orthographic : ProjectionType.Perspective; EditorGUI.BeginChangeCheck(); EditorGUI.showMixedValue = orthographic.hasMultipleDifferentValues; projectionType = (ProjectionType)EditorGUILayout.EnumPopup(EditorGUIUtility.TextContent("Projection|How the Camera renders perspective.\n\nChoose Perspective to render objects with perspective.\n\nChoose Orthographic to render objects uniformly, with no sense of perspective."), projectionType); EditorGUI.showMixedValue = false; if (EditorGUI.EndChangeCheck()) orthographic.boolValue = (projectionType == ProjectionType.Orthographic); if (!orthographic.hasMultipleDifferentValues) &#123; if (projectionType == ProjectionType.Orthographic) EditorGUILayout.PropertyField(orthographicSize, new GUIContent("Size")); else EditorGUILayout.Slider(fieldOfView, 1f, 179f, EditorGUIUtility.TextContent("Field of View|The width of the Camera’s view angle, measured in degrees along the local Y axis.")); &#125; &#125; public void DrawClippingPlanes() &#123; EditorGUILayout.PropertiesField(EditorGUI.s_ClipingPlanesLabel, new[] &#123;nearClippingPlane, farClippingPlane&#125;, EditorGUI.s_NearAndFarLabels, EditorGUI.kNearFarLabelsWidth); &#125; public void DrawNormalizedViewPort() &#123; EditorGUILayout.PropertyField(normalizedViewPortRect, EditorGUIUtility.TextContent("Viewport Rect|Four values that indicate where on the screen this camera view will be drawn. Measured in Viewport Coordinates (values 0–1).")); &#125; public void DrawDepth() &#123; EditorGUILayout.PropertyField(depth); &#125; public void DrawRenderingPath() &#123; EditorGUILayout.IntPopup(renderingPath, kCameraRenderPaths, kCameraRenderPathValues, EditorGUIUtility.TempContent("Rendering Path")); &#125; public void DrawTargetTexture(bool deferred) &#123; EditorGUILayout.PropertyField(targetTexture); // show warning if we have deferred but manual MSAA set // only do this if the m_TargetTexture has the same values across all target cameras if (!targetTexture.hasMultipleDifferentValues) &#123; var targetTexture = this.targetTexture.objectReferenceValue as RenderTexture; if (targetTexture &amp;&amp; targetTexture.antiAliasing &gt; 1 &amp;&amp; deferred) &#123; EditorGUILayout.HelpBox("Manual MSAA target set with deferred rendering. This will lead to undefined behavior.", MessageType.Warning, true); &#125; &#125; &#125; public void DrawOcclusionCulling() &#123; EditorGUILayout.PropertyField(occlusionCulling); &#125; public void DrawHDR() &#123; EditorGUILayout.PropertyField(HDR, EditorGUIUtility.TempContent("Allow HDR")); &#125; public void DrawMSAA() &#123; EditorGUILayout.PropertyField(allowMSAA); &#125; public void DrawDynamicResolution() &#123; EditorGUILayout.PropertyField(allowDynamicResolution); &#125; public void DrawVR() &#123; if (PlayerSettings.virtualRealitySupported) &#123; EditorGUILayout.PropertyField(stereoSeparation); EditorGUILayout.PropertyField(stereoConvergence); &#125; &#125; public void DrawMultiDisplay() &#123; if (ModuleManager.ShouldShowMultiDisplayOption()) &#123; int prevDisplay = targetDisplay.intValue; EditorGUILayout.Space(); EditorGUILayout.IntPopup(targetDisplay, DisplayUtility.GetDisplayNames(), DisplayUtility.GetDisplayIndices(), EditorGUIUtility.TempContent("Target Display")); if (prevDisplay != targetDisplay.intValue) GameView.RepaintAll(); &#125; &#125; public void DrawTargetEye() &#123; EditorGUILayout.IntPopup(targetEye, kTargetEyes, kTargetEyeValues, EditorGUIUtility.TempContent("Target Eye")); &#125; &#125; private class Styles &#123; public static GUIContent iconRemove = EditorGUIUtility.IconContent("Toolbar Minus", "|Remove command buffer"); public static GUIStyle invisibleButton = "InvisibleButton"; &#125; readonly AnimatedBool m_ShowBGColorOptions = new AnimatedBool(); readonly AnimatedBool m_ShowOrthoOptions = new AnimatedBool(); readonly AnimatedBool m_ShowTargetEyeOption = new AnimatedBool(); private Camera camera &#123; get &#123; return target as Camera; &#125; &#125; private static bool IsDeferredRenderingPath(RenderingPath rp) &#123; return rp == RenderingPath.DeferredLighting || rp == RenderingPath.DeferredShading; &#125; private bool wantDeferredRendering &#123; get &#123; bool isCamDeferred = IsDeferredRenderingPath(camera.renderingPath); bool isTierDeferred = IsDeferredRenderingPath(Rendering.EditorGraphicsSettings.GetCurrentTierSettings().renderingPath); return isCamDeferred || (camera.renderingPath == RenderingPath.UsePlayerSettings &amp;&amp; isTierDeferred); &#125; &#125; enum ProjectionType &#123; Perspective, Orthographic &#125;; private Camera m_PreviewCamera; protected Camera previewCamera &#123; get &#123; if (m_PreviewCamera == null) m_PreviewCamera = EditorUtility.CreateGameObjectWithHideFlags("Preview Camera", HideFlags.HideAndDontSave, typeof(Camera), typeof(Skybox)).GetComponent&lt;Camera&gt;(); m_PreviewCamera.enabled = false; return m_PreviewCamera; &#125; &#125; private RenderTexture m_PreviewTexture; // should match color in GizmosDrawers.cpp private static readonly Color kGizmoCamera = new Color(233f / 255f, 233f / 255f, 233f / 255f, 128f / 255f); private const float kPreviewNormalizedSize = 0.2f; private bool m_CommandBuffersShown = true; private Settings m_Settings; protected Settings settings &#123; get &#123; if (m_Settings == null) m_Settings = new Settings(serializedObject); return m_Settings; &#125; &#125; bool clearFlagsHasMultipleValues &#123; get &#123; return settings.clearFlags.hasMultipleDifferentValues; &#125; &#125; bool orthographicHasMultipleValues &#123; get &#123; return settings.orthographic.hasMultipleDifferentValues; &#125; &#125; int targetEyeValue &#123; get &#123; return settings.targetEye.intValue; &#125; &#125; public void OnEnable() &#123; settings.OnEnable(); var c = (Camera)target; m_ShowBGColorOptions.value = !clearFlagsHasMultipleValues &amp;&amp; (c.clearFlags == CameraClearFlags.SolidColor || c.clearFlags == CameraClearFlags.Skybox); m_ShowOrthoOptions.value = c.orthographic; m_ShowTargetEyeOption.value = targetEyeValue != (int)StereoTargetEyeMask.Both || PlayerSettings.virtualRealitySupported; m_ShowBGColorOptions.valueChanged.AddListener(Repaint); m_ShowOrthoOptions.valueChanged.AddListener(Repaint); m_ShowTargetEyeOption.valueChanged.AddListener(Repaint); &#125; internal void OnDisable() &#123; m_ShowBGColorOptions.valueChanged.RemoveListener(Repaint); m_ShowOrthoOptions.valueChanged.RemoveListener(Repaint); m_ShowTargetEyeOption.valueChanged.RemoveListener(Repaint); &#125; public void OnDestroy() &#123; if (m_PreviewCamera != null) DestroyImmediate(m_PreviewCamera.gameObject, true); &#125; private void DepthTextureModeGUI() &#123; // Camera's depth texture mode is not serialized data, so can't get to it through // serialized property (hence no multi-edit). if (targets.Length != 1) return; var cam = target as Camera; if (cam == null || cam.depthTextureMode == DepthTextureMode.None) return; List&lt;string&gt; buffers = new List&lt;string&gt;(); if ((cam.depthTextureMode &amp; DepthTextureMode.Depth) != 0) buffers.Add("Depth"); if ((cam.depthTextureMode &amp; DepthTextureMode.DepthNormals) != 0) buffers.Add("DepthNormals"); if ((cam.depthTextureMode &amp; DepthTextureMode.MotionVectors) != 0) buffers.Add("MotionVectors"); if (buffers.Count == 0) return; StringBuilder sb = new StringBuilder("Info: renders "); for (int i = 0; i &lt; buffers.Count; ++i) &#123; if (i != 0) sb.Append(" &amp; "); sb.Append(buffers[i]); &#125; sb.Append(buffers.Count &gt; 1 ? " textures" : " texture"); EditorGUILayout.HelpBox(sb.ToString(), MessageType.None, true); &#125; static Rect GetRemoveButtonRect(Rect r) &#123; var buttonSize = Styles.invisibleButton.CalcSize(Styles.iconRemove); return new Rect(r.xMax - buttonSize.x, r.y + (int)(r.height / 2 - buttonSize.y / 2), buttonSize.x, buttonSize.y); &#125; /** * Draws the 2D bounds of the camera when in 2D mode. */ [DrawGizmo(GizmoType.NonSelected)] static void DrawCameraBound(Camera camera, GizmoType gizmoType) &#123; var sv = SceneView.currentDrawingSceneView; if (sv != null &amp;&amp; sv.in2DMode) &#123; if (camera == Camera.main &amp;&amp; camera.orthographic) CameraEditor.RenderGizmo(camera); &#125; &#125; private void CommandBufferGUI() &#123; // Command buffers are not serialized data, so can't get to them through // serialized property (hence no multi-edit). if (targets.Length != 1) return; var cam = target as Camera; if (cam == null) return; int count = cam.commandBufferCount; if (count == 0) return; m_CommandBuffersShown = GUILayout.Toggle(m_CommandBuffersShown, GUIContent.Temp(count + " command buffers"), EditorStyles.foldout); if (!m_CommandBuffersShown) return; EditorGUI.indentLevel++; foreach (CameraEvent ce in (CameraEvent[])System.Enum.GetValues(typeof(CameraEvent))) &#123; CommandBuffer[] cbs = cam.GetCommandBuffers(ce); foreach (CommandBuffer cb in cbs) &#123; using (new GUILayout.HorizontalScope()) &#123; // row with event &amp; command buffer information label Rect rowRect = GUILayoutUtility.GetRect(GUIContent.none, EditorStyles.miniLabel); rowRect.xMin += EditorGUI.indent; Rect minusRect = GetRemoveButtonRect(rowRect); rowRect.xMax = minusRect.x; GUI.Label(rowRect, string.Format("&#123;0&#125;: &#123;1&#125; (&#123;2&#125;)", ce, cb.name, EditorUtility.FormatBytes(cb.sizeInBytes)), EditorStyles.miniLabel); // and a button to remove it if (GUI.Button(minusRect, Styles.iconRemove, Styles.invisibleButton)) &#123; cam.RemoveCommandBuffer(ce, cb); SceneView.RepaintAll(); GameView.RepaintAll(); GUIUtility.ExitGUI(); &#125; &#125; &#125; &#125; // "remove all" button using (new GUILayout.HorizontalScope()) &#123; GUILayout.FlexibleSpace(); if (GUILayout.Button("Remove all", EditorStyles.miniButton)) &#123; cam.RemoveAllCommandBuffers(); SceneView.RepaintAll(); GameView.RepaintAll(); &#125; &#125; EditorGUI.indentLevel--; &#125; public override void OnInspectorGUI() &#123; settings.Update(); var c = (Camera)target; m_ShowBGColorOptions.target = !clearFlagsHasMultipleValues &amp;&amp; (c.clearFlags == CameraClearFlags.SolidColor || c.clearFlags == CameraClearFlags.Skybox); m_ShowOrthoOptions.target = !orthographicHasMultipleValues &amp;&amp; c.orthographic; m_ShowTargetEyeOption.target = targetEyeValue != (int)StereoTargetEyeMask.Both || PlayerSettings.virtualRealitySupported; settings.DrawClearFlags(); if (EditorGUILayout.BeginFadeGroup(m_ShowBGColorOptions.faded)) settings.DrawBackgroundColor(); EditorGUILayout.EndFadeGroup(); settings.DrawCullingMask(); EditorGUILayout.Space(); settings.DrawProjection(); settings.DrawClippingPlanes(); settings.DrawNormalizedViewPort(); EditorGUILayout.Space(); settings.DrawDepth(); settings.DrawRenderingPath(); if (m_ShowOrthoOptions.target &amp;&amp; wantDeferredRendering) EditorGUILayout.HelpBox("Deferred rendering does not work with Orthographic camera, will use Forward.", MessageType.Warning, true); settings.DrawTargetTexture(wantDeferredRendering); settings.DrawOcclusionCulling(); settings.DrawHDR(); settings.DrawMSAA(); settings.DrawDynamicResolution(); DisplayCameraWarnings(); settings.DrawVR(); settings.DrawMultiDisplay(); if (EditorGUILayout.BeginFadeGroup(m_ShowTargetEyeOption.faded)) settings.DrawTargetEye(); EditorGUILayout.EndFadeGroup(); DepthTextureModeGUI(); CommandBufferGUI(); serializedObject.ApplyModifiedProperties(); &#125; private void DisplayCameraWarnings() &#123; Camera camera = target as Camera; if (camera != null) &#123; string[] warnings = camera.GetCameraBufferWarnings(); if (warnings.Length &gt; 0) EditorGUILayout.HelpBox(string.Join("\n\n", warnings), MessageType.Warning, true); &#125; &#125; public virtual void OnOverlayGUI(Object target, SceneView sceneView) &#123; if (target == null) return; // cache some deep values var c = (Camera)target; Vector2 previewSize = GameView.GetMainGameViewTargetSize(); if (previewSize.x &lt; 0f) &#123; // Fallback to Scene View of not a valid game view size previewSize.x = sceneView.position.width; previewSize.y = sceneView.position.height; &#125; // Apply normalizedviewport rect of camera Rect normalizedViewPortRect = c.rect; previewSize.x *= Mathf.Max(normalizedViewPortRect.width, 0f); previewSize.y *= Mathf.Max(normalizedViewPortRect.height, 0f); // Prevent using invalid previewSize if (previewSize.x &lt;= 0f || previewSize.y &lt;= 0f) return; float aspect = previewSize.x / previewSize.y; // Scale down (fit to scene view) previewSize.y = kPreviewNormalizedSize * sceneView.position.height; previewSize.x = previewSize.y * aspect; if (previewSize.y &gt; sceneView.position.height * 0.5f) &#123; previewSize.y = sceneView.position.height * 0.5f; previewSize.x = previewSize.y * aspect; &#125; if (previewSize.x &gt; sceneView.position.width * 0.5f) &#123; previewSize.x = sceneView.position.width * 0.5f; previewSize.y = previewSize.x / aspect; &#125; // Get and reserve rect Rect cameraRect = GUILayoutUtility.GetRect(previewSize.x, previewSize.y); if (Event.current.type == EventType.Repaint) &#123; // setup camera and render previewCamera.CopyFrom(c); // also make sure to sync any Skybox component on the preview camera var dstSkybox = previewCamera.GetComponent&lt;Skybox&gt;(); if (dstSkybox) &#123; var srcSkybox = c.GetComponent&lt;Skybox&gt;(); if (srcSkybox &amp;&amp; srcSkybox.enabled) &#123; dstSkybox.enabled = true; dstSkybox.material = srcSkybox.material; &#125; else &#123; dstSkybox.enabled = false; &#125; &#125; var previewTexture = GetPreviewTextureWithSize((int)cameraRect.width, (int)cameraRect.height); previewTexture.antiAliasing = Mathf.Max(1, QualitySettings.antiAliasing); previewCamera.targetTexture = previewTexture; previewCamera.pixelRect = new Rect(0, 0, cameraRect.width, cameraRect.height); Handles.EmitGUIGeometryForCamera(c, previewCamera); GL.sRGBWrite = QualitySettings.activeColorSpace == ColorSpace.Linear; previewCamera.Render(); GL.sRGBWrite = false; Graphics.DrawTexture(cameraRect, previewTexture, new Rect(0, 0, 1, 1), 0, 0, 0, 0, GUI.color, EditorGUIUtility.GUITextureBlit2SRGBMaterial); &#125; &#125; private RenderTexture GetPreviewTextureWithSize(int width, int height) &#123; if (m_PreviewTexture == null || m_PreviewTexture.width != width || m_PreviewTexture.height != height) &#123; m_PreviewTexture = new RenderTexture(width, height, 24, RenderTextureFormat.Default, RenderTextureReadWrite.Linear); &#125; return m_PreviewTexture; &#125; [RequiredByNativeCode] static float GetGameViewAspectRatio() &#123; Vector2 gameViewSize = GameView.GetMainGameViewTargetSize(); if (gameViewSize.x &lt; 0f) &#123; // Fallback to Scene View of not a valid game view size gameViewSize.x = Screen.width; gameViewSize.y = Screen.height; &#125; return gameViewSize.x / gameViewSize.y; &#125; static float GetFrustumAspectRatio(Camera camera) &#123; Rect normalizedViewPortRect = camera.rect; if (normalizedViewPortRect.width &lt;= 0f || normalizedViewPortRect.height &lt;= 0f) return -1f; float viewportAspect = normalizedViewPortRect.width / normalizedViewPortRect.height; return GetGameViewAspectRatio() * viewportAspect; &#125; // Returns near- and far-corners in this order: leftBottom, leftTop, rightTop, rightBottom // Assumes input arrays are of length 4 (if allocated) static bool GetFrustum(Camera camera, Vector3[] near, Vector3[] far, out float frustumAspect) &#123; frustumAspect = GetFrustumAspectRatio(camera); if (frustumAspect &lt; 0) return false; if (far != null) &#123; far[0] = new Vector3(0, 0, camera.farClipPlane); // leftBottomFar far[1] = new Vector3(0, 1, camera.farClipPlane); // leftTopFar far[2] = new Vector3(1, 1, camera.farClipPlane); // rightTopFar far[3] = new Vector3(1, 0, camera.farClipPlane); // rightBottomFar for (int i = 0; i &lt; 4; ++i) far[i] = camera.ViewportToWorldPoint(far[i]); &#125; if (near != null) &#123; near[0] = new Vector3(0, 0, camera.nearClipPlane); // leftBottomNear near[1] = new Vector3(0, 1, camera.nearClipPlane); // leftTopNear near[2] = new Vector3(1, 1, camera.nearClipPlane); // rightTopNear near[3] = new Vector3(1, 0, camera.nearClipPlane); // rightBottomNear for (int i = 0; i &lt; 4; ++i) near[i] = camera.ViewportToWorldPoint(near[i]); &#125; return true; &#125; // Called from C++ when we need to render a Camera's gizmo internal static void RenderGizmo(Camera camera) &#123; var near = new Vector3[4]; var far = new Vector3[4]; float frustumAspect; if (GetFrustum(camera, near, far, out frustumAspect)) &#123; Color orgColor = Handles.color; Handles.color = kGizmoCamera; for (int i = 0; i &lt; 4; ++i) &#123; Handles.DrawLine(near[i], near[(i + 1) % 4]); Handles.DrawLine(far[i], far[(i + 1) % 4]); Handles.DrawLine(near[i], far[i]); &#125; Handles.color = orgColor; &#125; &#125; static bool IsViewPortRectValidToRender(Rect normalizedViewPortRect) &#123; if (normalizedViewPortRect.width &lt;= 0f || normalizedViewPortRect.height &lt;= 0f) return false; if (normalizedViewPortRect.x &gt;= 1f || normalizedViewPortRect.xMax &lt;= 0f) return false; if (normalizedViewPortRect.y &gt;= 1f || normalizedViewPortRect.yMax &lt;= 0f) return false; return true; &#125; public virtual void OnSceneGUI() &#123; var c = (Camera)target; if (!IsViewPortRectValidToRender(c.rect)) return; SceneViewOverlay.Window(EditorGUIUtility.TrTextContent("Camera Preview"), OnOverlayGUI, (int)SceneViewOverlay.Ordering.Camera, target, SceneViewOverlay.WindowDisplayOption.OneWindowPerTarget); Color orgHandlesColor = Handles.color; Color slidersColor = kGizmoCamera; slidersColor.a *= 2f; Handles.color = slidersColor; // get the corners of the far clip plane in world space var far = new Vector3[4]; float frustumAspect; if (!GetFrustum(c, null, far, out frustumAspect)) return; Vector3 leftBottomFar = far[0]; Vector3 leftTopFar = far[1]; Vector3 rightTopFar = far[2]; Vector3 rightBottomFar = far[3]; // manage our own gui changed state, so we can use it for individual slider changes bool guiChanged = GUI.changed; // FOV handles Vector3 farMid = Vector3.Lerp(leftBottomFar, rightTopFar, 0.5f); // Top and bottom handles float halfHeight = -1.0f; Vector3 changedPosition = MidPointPositionSlider(leftTopFar, rightTopFar, c.transform.up); if (!GUI.changed) changedPosition = MidPointPositionSlider(leftBottomFar, rightBottomFar, -c.transform.up); if (GUI.changed) halfHeight = (changedPosition - farMid).magnitude; // Left and right handles GUI.changed = false; changedPosition = MidPointPositionSlider(rightBottomFar, rightTopFar, c.transform.right); if (!GUI.changed) changedPosition = MidPointPositionSlider(leftBottomFar, leftTopFar, -c.transform.right); if (GUI.changed) halfHeight = (changedPosition - farMid).magnitude / frustumAspect; // Update camera settings if changed if (halfHeight &gt;= 0.0f) &#123; Undo.RecordObject(c, "Adjust Camera"); if (c.orthographic) &#123; c.orthographicSize = halfHeight; &#125; else &#123; Vector3 pos = farMid + c.transform.up * halfHeight; c.fieldOfView = Vector3.Angle(c.transform.forward, (pos - c.transform.position)) * 2f; &#125; guiChanged = true; &#125; GUI.changed = guiChanged; Handles.color = orgHandlesColor; &#125; private static Vector3 MidPointPositionSlider(Vector3 position1, Vector3 position2, Vector3 direction) &#123; Vector3 midPoint = Vector3.Lerp(position1, position2, 0.5f); return Handles.Slider(midPoint, direction, HandleUtility.GetHandleSize(midPoint) * 0.03f, Handles.DotHandleCap, 0f); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>UnityCsReference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11]]></title>
    <url>%2F2018%2F07%2F09%2FC%2B%2B11%2F</url>
    <content type="text"><![CDATA[虚函数 对于一个class，产生一堆指向virtual functions的指针，虚函数表指针通常放在对象实例的最前面的位置。 每一个对象添加一个指针，指向相关的virtual table。这个指针被称作虚函数表指针。]]></content>
      <categories>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法]]></title>
    <url>%2F2018%2F07%2F09%2Farithmetic%2F</url>
    <content type="text"><![CDATA[背包问题]]></content>
      <tags>
        <tag>arithmetic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LoadingPerformance_Texture]]></title>
    <url>%2F2018%2F07%2F05%2FLoadingPerformance_Texture%2F</url>
    <content type="text"><![CDATA[资源加载资源加载是加载模块中最为耗时的部分，其CPU开销在Unity引擎中主要体现在Loading.UpdatePreloading和Loading.ReadObject两项中。 Loading.UpdatePreloading，这一项尽在调用类似LoadLevel(Async)的接口处出现，主要负责卸载当前场景的资源]]></content>
      <tags>
        <tag>uwa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[optimzation_memory_1]]></title>
    <url>%2F2018%2F07%2F05%2Foptimzation-memory-1%2F</url>
    <content type="text"><![CDATA[内存开销： 资源内存占用在一个较为复杂的大中型项目中，资源的内存占用往往占据了总体内存的70%以上。因此，资源使用是否恰当直接决定了项目的内存占用情况。一般来说，一款游戏项目的资源主要可分为如下几种：纹理（Texture）、网格（Mesh）、动画片段（AnimationClip）、音频片段（AudioClip）、材质（Material）、着色器（Shader）、字体资源（Font）以及文本资源（Text Asset）等等。其中，纹理、网格、动画片段和音频片段则是最容易造成较大内存开销的资源。 一、纹理纹理资源可以说是几乎所有游戏项目中占据最大内存开销的资源。一个6万面片的场景，网格资源最大才不过10MB，但一个2048x2048的纹理，可能直接就达到16MB。因此，项目中纹理资源的使用是否得当会极大地影响项目地内存占用。 纹理格式纹理格式是研发团队最需要关注的纹理属性。因为它不仅影响着纹理的内存占用，同时还决定了纹理的加载效率。在使用硬件支持的纹理格式时，你可能会遇到以下几个问题： 色阶问题 由于ETX、PVRTC等格式均为有损压缩，因此，当纹理色查范围跨度较大时，均不可避免地造成不同程度地“阶梯”状的色阶问题。因此，很多研发团队使用RGBA32/ARGB32格式来实现更好的效果。但是，这种做法将造成很大的内存占用。比如，同样一张1024x1024的纹理，如果不开启Mipmap，并且PVRTC格式，则其内存占用为512KB，而如果转换为RGBA32位，则很可能占用达到4MB。 ETC1不支持透明通道问题 在Andorid平台上，对于使用OpenGL ES 2.0的设备，其纹理格式仅能支持ETC1格式，该格式有个较为严重的问题，即不支持Alpha透明通道，使得透明贴图无法直接通过ETC1格式来进行储存。对此，我们建议研发团队将透明贴图尽可能拆分成两张，即一张RGB24位纹理记录原始纹理的颜色部分和一张Alpha8纹理记录原始纹理的透明通道部分。然后，将这两张贴图分别转化为ETC1格式的纹理，并通过特定的Shader来进行渲染，从而达到支持透明贴图的效果。这种方法极大程度伤毕竟RGBA透明贴图的渲染效果，同时降低纹理的内存占用。 纹理尺寸一般来说，纹理尺寸越大，则内存占用越大。所以，尽可能降低纹理尺寸，如果512x512的纹理对于显示效果已经够用，那么就不要使用1024x1024的纹理，因为后者的内存占用时前者的4倍。 Mipmap功能Mipmap旨在有效降低渲染带宽的压力，提升游戏的渲染效率。但是，开启Mipmap会将纹理内存提升1.33倍。对于具有较大纵深感的3D游戏来说，3D场景模型和角色我们一般是建议开启Mipmap功能的，而绝大多数UI均是渲染在屏幕最上层，开启Mipmap并不会提升渲染效率，反倒会增加无谓的内存占用。 Read &amp; Write一般情况下，纹理资源的”Read &amp; Write”功能在Unity引擎中默认是关闭的。开启该选项将会使纹理内存增大一倍。 二、网格Normal、Color和TangentMesh资源的数据中经常会含有大量的Color数据、Normal数据和Tangent数据。这些数据的存在将大幅度增加Mesh资源的文件提及和内存占用。其中，Color数据和Normal数据主要为3DMax、Maya等建模软件导出时设置所生成，而Tangent一般为导入引擎的生成。 更为麻烦的是，如果项目对Mesh进行Draw Call Batching操作的话，那么将很有可能进一步增大总体内存的占用。比如，100个Mesh进行拼合，其中99个Mesh均没有Color、Tangent等属性，剩下一个则包含有Color、Normal和Tangent属性，那么Mesh拼合后，CombinedMesh中将为每个Mesh来添加上此三个顶点属性，进而造成很大的内存开销。 引擎模块自身内存占用引擎自身中存在内存开销的部分纷繁复杂，可以说是由巨量“微小”内存所积累起来的，比如GameObject及其各种Component（量最大的Component应该算是Transform）了、ParticleSystem、MonoScript以及各种各样的模块Manager（SceneManager、CanvasManager、PersistentManager）等。 一般情况下，上面所指出的引擎各组成部分的内存开销均比较小，真正占据较大内存开销的这两处：WebStream和SerializedFile。其绝大部分的内存分配则是由AssetBundle加载资源所致。当使用new WWW或CreateFromMemory来加载AssetBundle时，Unity引擎会加载原始数据到内存中并对其进行解压，而WebStream的大小则是AssetBundle原始文件大小+解压后的数据大小+DecompressionBuffer(0.5MB)。同时，由于Unity5.3版本之前的AssetBundle文件为LZMA压缩，其压缩比类似于Zip(20%-50%)，所以对于1MB的原始AssetBundle文件，其加载后WebStream的大小则可能时5~6MB，因此，当项目中通过new WWW加载多个AssetBundle文件，且AssetBundle又无法即时释放时，WebStream的内存可能会很大。 对于SerilizedFile，则是当你使用LoadFromCacheOrDownload、CreateFromFile或new WWW本地AssetBundle文件时产生的序列化文件。 对于WebStream和SerializedFile，需要关注两点： 是否存在AssetBundle没有被清理干净的情况。可以通过Unity Profiler直接查看其具体的使用情况，并确定Take Sample时AssetBundle的存在是否合理； 对于占用WebStream较大的AssetBundle文件（如UI Atlas相关的AssetBundle文件等），建议使用LoadFromCacheOrDownLoad或CreateFromFile来替换，即将解压后的AssetBundle数据存储与本地Cache中进行使用。这种做法非常适合于内存特别吃紧的项目，即通过本地的磁盘控件来存储内存空间。 托管堆内存占用对于目前绝大多数基于Unity引擎开发的项目而言，其托管堆是由Mono分配和管理的。“托管”的本意是Mono可以自动地改变堆地大小来适应你所需要的内存，并且适当地调用垃圾回收（Garbage Collection操作来释放已经不需要地内存，从而降低开发人员再代码内存管理方面的门槛。 目前Unity所使用的Mono版本存在一个严重的问题，即：Mono的堆内存一旦分配就不会返还给系统。这意味着Mono的堆内存是只升不降的。举个粒子，项目运行时，再场景A中开辟了60MB的托管堆内存，而到下一个场景B时，只需要使用20MB的托管堆内存，那么Mono中将会存在40MB空闲的堆内存，且不会返还给系统。 高频率地New Class/Container/Array等。不要再Update、FixUpdate或较高调用频率地函数中开辟堆内存。 项目中较为合理地内存分配： 纹理资源：50MB 网格资源：20MB 动画片段：15MB 音频片段：15MB Mono堆内存：40MB 其它：10MB]]></content>
      <tags>
        <tag>uwa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[optimzation_memory_2]]></title>
    <url>%2F2018%2F07%2F05%2Foptimzation_memory_2%2F</url>
    <content type="text"><![CDATA[内存泄漏]]></content>
      <tags>
        <tag>uwa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[presentandsync]]></title>
    <url>%2F2018%2F07%2F05%2Fpresentandsync%2F</url>
    <content type="text"><![CDATA[WaitForTargetFPS该参数一般出现在CPU开销过低，且通过设定了目标帧率地情况下(Application.targetFrameRate)。当上一帧产生一个WaitForTargetFPS地空闲等待消耗时，以维持目标帧率。 解析：该项在Unity引擎地主循环中其实是最早执行地，即引擎实际上是根据上一帧地CPU耗时，在当前帧通过增补WaitForTargetFPS的方式来将运行FPS维持到目标值。比如，目标帧率为30帧/秒，上一帧耗时15ms，那么当前帧中WaitForTargetFPS将会是18（33-15）ms，但是这一帧中其他耗时为28ms，那么在Profiler中这一帧的总耗时就变成了46（18+28）ms。因此，由该值造成了Profiler开销较高的现象，其实是耗时的“假象”，在优化过程中，你对它可以“视而不见”。 Gfx.WaitForPresend &amp;&amp; Graphics.PresentAndSync这两个参数在Profiler中经常出现CPU占用较高的情况，且仅在发布版本中可以看到。究其原因，其实是CPU和GPU之间垂直同步（VSync）导致的，之所以会有两种参数，主要是与项目是否开启多线程渲染有关。当项目开启多线程渲染时，你看到的是Gfx.WaitForPresent；当项目未开启多线程渲染时，看到的则是Graphics.PresentAndSync。 Graphics.PresentAndSync是指主线程进行Present时的等待时间和等待垂直同步的时间。 Gfx.WaitForPresent其字面意思同样也是进行Present时需要等待的时间，但这里其实省略了很多的内容，其真实的意思应该是为了在渲染子线程（Rendering Thread）中进行Presend，当前主线程（MainThread）需要等待的时间。]]></content>
      <tags>
        <tag>uwa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity]]></title>
    <url>%2F2018%2F07%2F01%2FUnity3D_Game_Design%2F</url>
    <content type="text"><![CDATA[命名 模型命名 Max文件中角色模型命名为skin@sk_001武器模型命名为skin@wq_001 颜色贴图skin@st_001.png 高光贴图skin@st_001_ctr.png 导入导出能够从3DsMax导入Unity3D的资源 所有节点的位移、旋转、锁方、轴心和命名都将导入 网格模型包含顶点颜色、法线，一到两个UV通道 材质包含贴图以及漫反射颜色，以及单个网格的多维材质 动画（物体移动、旋转、缩放） 骨骼动画（角色动画） 角色模型制作规范模型 选人界面模型面数约4500-5000左右 游戏内主角模型面数2500-3000左右 Boss模型面数根据体型大小3000-5000左右 Npc模型面数900-1200造型简单面数没下限 武器模型面数250-500 造型简单面数没下限 模型在不是非常废面的情况下，转折的地方做出厚度，厚度适当夸张。 地面部分制作成双面或是封闭，小布条类模型做成双面模型 角色结构整体均衡 比如眼睛部分不需要细致刻画 贴图主角 512*512 pngBoss 512*512 pngNpc 256*256 png 武器体积较大的使用256*256 体积较小 128*128 png 尺寸设定制作模型前必须先确保模型尺寸，统一将显示单位与系统单位改为公尺。 注意正反面关系每个模型都包含正面和反面，一般来说引擎只会显示模型的正面，如要反面也一起显示需透过shader来实现，但增加反面显示时会降低性能，因此尽量让模型单面显示就好，而在制作模型时必须确保要显示的模型面是正面即可。 不要存在破面和迭面制作模型时注意顶点是否焊接好，未焊接的顶点可能会导致模型有破面的情形，另外模型面与面之间最好保持距离，不然会发生迭面的情况。 不要存在多余的顶点和T点删除一些没用的顶点，并且避免出现T点。 删除看不到的面制作模型时有些面可能在低下或是在模型里面，都是在场景进行中看不到的面，这些面可以删除，以减少模型面数提高效能。 物体的轴心每个物体都有一个坐标轴心，宜据物体属性设计好物体轴心位置，一般来说轴心都会放置在中心的位置，其他情况如门的轴心可能会在低下角落的位置。 使用简单几何体来制作复杂对象当遇到比较复杂的对象，且对象比较小，左乘模型反而增加了模型的面数，因此可以使用简单的平面模型结合透空贴图来实现复杂的造型，可以将图片存成PSD、PNG、TGA这种带有透明通道属性的贴图档。 重置模型（ResetXForm）制作模型时可能使用了缩放功能或镜像功能，这些指令会使得模型比例错乱以及出现负数轴向的情形，因此在模型制作完毕时最好进行ResetXForm指令，让模型回归最基本的状态。 制作虚拟碰撞体可以为模型制作简单的几何体来当作物体的碰撞体，可以依据物体的重要性与精确性来设计几何体外观。 材质贴图和UVUnity3D支持的Max材质Unity3D支持3dsmax的Standard(标准材质)与Muti/Sub-Object(多维/子物体材质)。 模型汇入Unity后没有贴图？当模型汇入Unity前，可以先创建一个Texture文件夹，并事先将贴图导入，这样模型汇入后就会自动读取到贴图。 模型塌陷制作模型时，建议将模型以一栋建筑进行塌陷，接着对模型进行UV拆解，这样可以将一个模型使用一张贴图来完成。 避免拉伸UV调整UV前先将材质球使用棋格 (checkter) 贴图来观看UV比例，调整UV时尽量让棋格维持正方形的形状。 贴图尺寸贴图必须是2的N词放（8、16、32、64、128、256），建议贴图不要超过1024*1024大小。 绘制UV出血绘制材质时绘制出血边缘，可避免出现明显接缝线。 透空贴图在Unity里的使用透空贴图毛边处理技巧透空贴图毛边处理技巧（进阶）材质与贴图命名烘培贴图教学3dsMax LightMap 烘培贴图3dsMax CompleteMap 烘培贴图Unity烘培贴图Unity3D地形制作地形编辑器基本功能介绍水系统介绍天空盒系统介绍第一人称导览3dsMax角色动画导入与基本控制单个角色动画导入多个角色动画导入角色基本控制第三人称角色控制角色阴影树木与粒子系统树木制作粒子系统-繁星粒子效果粒子系统-雪花粒子效果粒子系统-火焰粒子效果编辑界面介绍创建工程打开工程Project视图Hierarchy视图Inspector视图Scene视图视图介绍移动视图移动模型旋转模型缩放模型场景工具Sence视图控制条Game视图Game视图控制条工程的打包导出与导入游戏案例1Android和iOS版本发布Unity3D脚本概述Unity3D脚本概述Unity3D的基本语法访问其他组件访问其他游戏对象向量成员变量与全局变量实例化协同程序与中断创建游戏对象获取游戏对象添加组件与修改组件脚本组件克隆游戏对象时间1234567void OnGUI()&#123; GUILayout.Label("当前游戏时间：" + Time.time); GUILayout.Label("上一帧所消耗的时间：" + Time.deltaTime); GUILayout.Label("固定增量时间：" + Time.fixedTime); GUILayout.Label("上一帧所消耗的固定时间：" + Time.fixedDeltaTime);&#125; 随机数四元数Unity3D GUI界面设计（GUI&amp;NGUI&amp;UGUI）UGUI的网格重建、动静分离动静分离：也就是说同一个界面下的UI，可活动的元素放在一个Canvas下，不可活动的元素放在另一个Canvas下。虽然两个Canvas打断了合批，但是却减少了网格重建时间，总体上是有优化的。 究其原因，是因为在同一个Canvas下的某个元素发生变化时，同一Canvas下的所有元素都会进行网格重建(ReBatch)。井静态的元素在逻辑上是不需要重建的，因为他们都没变过，所以需要分开。 GUI常用控件GUI TextGUI Texture (LazyTexture)Label控件Button控件TextFieldToolBarSliderScrollView控件群组视图窗口NGUI Panel &amp; UGUI Canvas图集制作(TexturePacket)UITween动画顶点动画GUI Skin自定义风格组件Unity3D输入与控制键盘事件键盘按下事件键盘抬起事件键盘长按事件触摸事件触摸按下事件触摸抬起事件触摸长按事件鼠标事件鼠标按下事件鼠标抬起事件鼠标长按事件自定义事件输入管理器（InputHelper）自定义按键事件自定义按键轴实例练习角色模型与动画（Animation&amp;Animator）模型的载入设置角色动画播放3D动画动画裁切动画的帧Tween多媒体音频视频]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阴影映射的原理和实现]]></title>
    <url>%2F2018%2F06%2F30%2FShadow_Mapping%2F</url>
    <content type="text"><![CDATA[阴影贴图 (Shadwom mapping)像素与以纹理形式保存的光照深度缓冲区或者深度图像比较，通过这种方式计算像素是否处于光源照射范围之内，从而生成阴影。 原理阴影贴图是一种使用深度纹理来为渲染阴影提供解决方法的多通道计算。它的关键是，就是用投影光源代替最终视口来观察场景。通过移动视口到光源位置，可以观察到这个位置每个东西都是明亮的，因为从光的角度来看是没有阴影的。]]></content>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity3D优化专题]]></title>
    <url>%2F2018%2F06%2F26%2FUnity3D-Optimize%2F</url>
    <content type="text"><![CDATA[一 遮挡剔除OcclusionCulling遮挡剔除(Occlusion Culling)功能可在对象因被其他物体遮挡，当前在相机中无法看到时，禁用对象渲染。该功能不会在三维计算机图形中自动开启，因为在大部分情况下，离相机最远的对象最先渲染，离相机的对象覆盖先前的物体（该步骤称之为“重复渲染(overdraw)”）。遮挡剔除(Occlusion Culling)与视锥体剔除(Frustum Culling)不同。视锥体剔除(Frustum Culling)只禁用相机视野外的对象渲染，不禁用视野中被遮挡的任何物体的渲染。注意，使用遮挡剔除(Occlusion Culling)功能时，仍将受益于视锥体剔除(Frustum Culling)。当场景中包含大量模型时，势必会造成渲染效率的降低。如果使用遮挡剔除技术，可以使用那些被阻挡的物体不被渲染，从而达到提高渲染效率的目的。 遮挡剔除的基本原理是在场景中创建一个遮挡区域，该遮挡区域由单元格组成；每个单元格构成整个场景遮挡区域的一部分，这些单元格会把整个场景拆分为多个部分。当摄像机能够看到该单元格时，单元格中的物体会被渲染出来，而被其他单元格挡住的不被摄像机看到的物体不会被渲染。 下面，我们来做遮挡剔除的案例 二 层级消隐如果场景中存在大量的小物体，则可以使用层消隐优化场景。层消隐就是在比较远的距离将小物体剔除，减少绘制调用的次数。例如，在比较远的距离，大型建筑物依然可见，但是小型的石块和碎片隐藏掉。可以将小物件单独放入一个层，并且使用Camera.main.layerCullDistance函数设置层的消隐距离。调整摄像机位置进行测试即可。只有在摄像机距离这些物体小于10M的时候，地面上的这些物体才能显示出来。 1234567public class SeperateControl : MonoBehaviour &#123; void Start() &#123; float[] distance = new float[32]; distances[8] = 10; Camera.main.layerCullDistances = distances; // 如果main == null,则设置camera的tag为mainCamera &#125;&#125; 三 层级细节LOD层级细节LOD全称为LevelOfDetail,它是根据物体在游戏画面中锁占据的百分比来调用不同复杂度的模型的。简单理解就是当一个物体距离摄像机比较远的时候，使用复杂度低的模型，比较近的时候，使用复杂度高的模型。 在建模软件中，制作好各个层级的模型，并且根据复杂程度自高向低命名为：模型名称_LOD0,模型名称_LOD1,模型名称_LOD2，数字越低，复杂程度越高。 我们新建一个场景，构造最简单的LOD模型示例。 准备3个Unity基本游戏对象，添加必要的材质。 定义一个空对象，命名为_LOD,添加LODGroup组件 分别将以上三个基本对象拖拽到LODGroup的各个级别上 首先添加LOD0的对象，当然中间需要修改父节点，点击确定即可 在Scene视图中，拖动摄像机分别近距离与远距离观察模型的变化。 四 DrawCall讲解一个DrawCall，表示U3D使用这个材质/纹理，来进行一次渲染，那么这次渲染假设有3个对象，那么当3个对象都使用这一个材质/纹理的时候，就会产生一次DrawCall，可以理解为一次将纹理输送到屏幕上的过程，（实际上引擎大多会使用如双缓冲，缓存这类的手段来优化这个过程，但在这里我们只需要这样认识就可以了），假设3个对象使用不同的材质/纹理，那么无疑会产生3个DrawCall。 批处理动态物体需要在每个顶点上进行一定的开销，所以动态批处理仅支持小于900顶点的网格物体，如果你的着色器使用顶点位置，法线和UV值三种属性，那么你只能批处理300顶点一下的物体；请注意：属性数量的限制可能会在将来进行改变。 相同的物体采取相同的材质，修改其缩放比例，观察DrawCall的变化。 功能描述如下：Static Batching是将标明为Static的静态物件，如果在使用相同材质球的条件下，Unity会自动帮你把这两个物体合并成一个Batch，送往GPU来处理。 Static Batching可以让引擎降低任何尺寸网格的Draw Call，如下图所示： Profile 工具使用性能分析工具可以给我们提供游戏性能表现的详细信息。如果我们的游戏存在性能问题，如低帧率或者高内存占用，性能分析工具可以帮助我们法线问题的起因，并协助我们解决问题。 Profiler布局 在我们使用Profiler收集游戏数据之前，先打开它熟悉下界面布局。从菜单Window-&gt;Profiler打开。 在窗口左侧，可以看到一列profilers，每个profiler显示我们游戏的一个方面的信息，分别为cpu使用情况，gpu使用情况，渲染，内存使用情况，声音，物理和网络。 当开始录制时，窗口上部的每个profiler会随着时间显示数据。性能是随着时间变化的，所以随着时间变化的信息是比仅仅一帧的信息有用的多的。有些性能问题是持续性的，有些问题是仅仅在一帧中出现的，还有一些性能问题是随着时间逐渐显现的。]]></content>
      <tags>
        <tag>Unity3D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BRDF(双向反射分布函数)]]></title>
    <url>%2F2018%2F06%2F09%2FBRDF%2F</url>
    <content type="text"><![CDATA[在计算机图形学领域，着色（Shading）是指根据表面或者多边形相对光源和相机的角度和距离来计算它的颜色的过程。不同的用户可以使用不同的着色算法，CAD等追求相应速度的交互式图形领域可以使用简单快速的着色算法，卡通油画等艺术效果使用非真实感（Nonphotorealistic）着色算法，而追求真实感的CG电影或游戏则可以使用基于物理建模的着色算法。本文关注基于物理着色的BRDF模型，希望能将BRDF的来龙去脉将清楚，并分析Cook-TorranceBRDF公式的推倒过程。要模拟真实光照，我们先要弄清楚光照的现象。 光照现象光由光子组成，光子即具有粒子的特性，又表现出波的特性。从波的角度看，光是电磁波的一种，不同频率（波长）的光波能量不同，频率越高（波长越短），能量越高，频率越低（波长越长），能量越低，其中波长在380nm-780nm范围内的光波能被认类的视网膜感知到，这个范围的光波成为可见光，不同频率的可见光被人感知为不同的颜色，频率越高的光偏蓝，频率较低的光则偏红。 光学根据研究的尺度可以分为波动光学（Wave Optics）和几何光学（Geometric Optics），波动光学比几何光学复杂，而由于图形学领域光柱的尺度远大于可见光的波长（380nm - 780nm），也很少涉及光的偏振、干涉和衍射等波动光学才能解释的现象，所以我们一般用几何光学建立光照的模型。 光学平面边界上的散射 平面边界两边物质的折射率（Refractive Index）不同，当一束光线从一种物质照射到平面边界上时，其中一部分在平面边界被反射回这种物质，反射方向为入射方向关于平面法线的对称向量： $r_i = 2(n \cdot l)n - l$ 其中$r_i$是反射向量，l是光线入射向量，n是平面发现向量间的$\cdot$表示向量的点积，两个单位向量的点积等于它们夹角的余弦。 另一部分光穿过平面边界折射进入另一种物质，折射方向可由Snell法则（Snell’s Law）计算得出： ${sin\theta_i \over sin\theta_t}={v_i\over v_t}={\lambda_i\over \lambda_t}={n_t\over n_i}$ 其中下标i表示入射介质，下标t表示折射介质，$\theta$表示光线相对于边界法线的角度，v表示介质中的光速，$\lambda$表示介质中的波长，n表示介质的折射率。反射和折射的比例由菲涅尔方程(Fresnel Equations)给出，菲涅尔方程比较复杂，图形学里一般使用近似公式计算。]]></content>
      <tags>
        <tag>PBR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3D美术人员Technical Artist的学习之旅（1）]]></title>
    <url>%2F2018%2F06%2F03%2FTA-1%2F</url>
    <content type="text"><![CDATA[TA是美术和程序之间沟通的桥梁。美术同学需要一些更加方便，可视化更强的工具，例如拓扑的工具，各位都知道MAX里有一个石墨工具是可以用于拓扑的，但是操作石墨工具拓扑是一件很痛苦的事，这时候有一个插件工具能给解决这个问题，例如wrapit的拓扑插件。正因为有了这个插件工具，我们就不用把模型导入Topogun在再次进行二次操作，而编写这个插件就可以算作TA人员所要去做的一件事。]]></content>
      <tags>
        <tag>Artist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity ShaderLab]]></title>
    <url>%2F2018%2F05%2F19%2FUnity3D-ShaderLab%2F</url>
    <content type="text"><![CDATA[CG类型 Type Description float 32位浮点数据 half 16位浮点数据 int 32位整形数据 fixed 12位定点数 bool 布尔数据 sampler 纹理对象的句柄，分为sampler、sampler1D、sampler2D、sampler3D、samplerCUBE和samplerRECT。 float2x4 matrix // 表示2x4阶矩阵，包含8个float类型数据 使用技巧： 精度够用就好 颜色和单位向量，使用fixed 其他情况，尽量使用half（即范围在[-6万，） 内置数据类型：基于基础数据类型，如float3，表示float3类型的三维向量；同理，bool2表示布尔类型的二维向量。 向量最长不能超过四元，如float5 vector; //编译错误 Swizzle操作符：它可以将一个向量的成员取出组成一个新的向量。对于坐标或者角度等其它多维向量，Swizzle操作符(.)后接x、y、z、w分别表示原始向量的第一个、第二个、第三个和第四个元素；同样，对于颜色可以后接r、g、b和a来表示同样的索引。例如： float4(a,b,c,d).xwz 等价于 float4(a,d,c) float4(a,b,c,d).xxy 等价于 float4(a,a,b) Swizzle操作符只能对结构体和向量使用，不能对数组使用。]]></content>
      <categories>
        <category>Unity Shader</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何系统地进行性能优化？]]></title>
    <url>%2F2018%2F05%2F17%2FHow-to-systematically-optimize-performance%2F</url>
    <content type="text"><![CDATA[运行帧率低低配机器上运行帧率比较低是常见问题。a)首先是做分类，把通常的问题归类到几种瓶颈下来做讨论：GPU Bound、CPU Bound、Bandwidth Bound，还有Memory。这种分类方式基本是按照硬件资源的方式来进行的。b)GPU Bound是一种目前手游中比较常见的瓶颈，降低分辨率如果对帧率有非常明显的提升的话，非常大的可能就是GPU Bound。c)CPU Bound,降低分辨率的方式如果并不能提高帧率，那么可能是CPU Bound。CPU通常和Draw Call祥光，或者和复杂的游戏逻辑相关，通过Unity的Profiler工具可以比较明确看出是否是CPU Bound，以及这些计算时间都消耗在了哪里。TimeLine可以比较明确的看到瓶颈（5.3.8没有，暂时不研究）d)Bandwith Bound 在手游中也比较常见，一种比较简单的判断方式是使用NVIDIA Tegra Graphics Debugger这个工具（对于Tegra硬件更友好，但是比较难找。。。）中将所有贴图替换成2 * 2的大小，如果帧率有明显提升可能是Bandwidth瓶颈。当然也可以自己协代码所图来确认，比如使用Unity的Quality Setting里的Texture Quality。e)内存就用Unity地Profiler来看吧，不过这个对于帧率没什么影响。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3D数学：图形与游戏开发]]></title>
    <url>%2F2018%2F05%2F16%2F3d-math-base-graph-game-develop%2F</url>
    <content type="text"><![CDATA[惯性坐标系为了简化世界坐标系到物体坐标系的转换，人们引入了一种新的坐标系，称作惯性坐标系，意思是在世界坐标系到物体坐标系的“半途”。关系坐标系的原点和物体坐标系的原点重合，但惯性坐标系的轴平行于世界坐标系的轴。 4D齐次空间4D向量有4个分量，前3个是标准的x,y和z分量，第四个是w，有时称作齐次坐标。为了理解标准3D坐标是怎样扩展到4D坐标的，让我们先看一下2D中的齐次坐标，它的形式为(x,y,w)。想象在3D中w=1处的标准2D平面，实际的2D点(x,y)用齐次坐标表示(x,y,1)，对于哪些不在w=1平面的点，则将它们投影到w=1平面上。所以齐次坐标(x,y,w)映射的实际2D点为(x/w,y/w)。如图9.2所示。因此，给定一个2D点(x,y)，齐次空间中有无数多个点与之对应。所有点的形式都为(kx,ky,k),k≠0。这些点构成一条穿过齐次原点的直线。当w=0时，除法未定义，因此不存在实际的2D点。然而，可以将2D齐次点(x,y,0)解释为“位于无穷远的点”，它描述了一个方向而不是一个位置。在下节中会有关于该点的更多讨论。4D坐标的基本思想相同。实际的3D点能被认为是在4D中w=1“平面”上。4D点的形式为(x,y,z,w)，将4D点投影到这个“平面”上得到相应的实际3D点(x/w,y/w,z/w)。w=0时4D点表示“无限远点”，它描述了一个方向而不是一个位置。齐次坐标和通过除以w来投影时很有趣的，那我们为什么要使用4D坐标呢？有两个基本原因使得我们要使用4D向量和4X4矩阵。第一个原因实际上就是因为它是一种方便的记法，这也是下一节将要讨论的。 4X4平移矩阵3X3变换矩阵表示的是线性变换，不包含平移。因为矩阵乘法的性质，零向量总是变换成零向量，因此，任何能用矩阵乘法表达的变换都不包含平移。这很不幸，因为矩阵乘法和它的逆是一种非常方便的工具，不仅可以用来复用复杂的变换组合成简单的单一变换，还可以操纵嵌入式坐标系间的关系。如果能找到一种方法将3X3变换矩阵进行扩展，使它能处理平移，这将是 线性变换在数学上，如果满足下式，那么映射F(a)就是线性的：$F(a+b)=F(a)+F(b)$以及$F(ka)=kF(a)$如果映射F保持了基本运算：加法和数量乘，那么就可以称该映射为线性的。在这种情况下，将两个向量相加然后再进行变换得到的结果和先分别进行变换再讲变换后的向量相加得到的结果相同。同样，将一个向量数量乘在进行变换和先进行变换在数量乘的结果也是一样的。 仿射变换仿射变换是指线性变换后接着平移。因此，仿射变换的集合是线性变换的超集，任何线性变换都是仿射变换，但不是所有仿射变换都是线性变换。 可逆变换如果存在一个逆变换可以“撤销”原变换，那么该变换是可逆的。换句话说，如果存在可逆变换$F^-1$，使得$F^-1(F(a))=a$，对于任意$a$，映射$F(a)$是可逆的。 等角变换如果变换前后两向量夹角的大小和方向都不改变，该变换是等角的。只有平移，旋转和均匀缩放是等角变换。等角变换将会保持比例不变。镜像并不是等角变换，因为尽管两向量夹角的大小不变，但夹角的方向改变了。所有等角变换都是仿射和可逆的。 什么是欧拉角heading为绕y轴的旋转量，向右旋转为正。pitch为绕x轴的旋转量，注意是物体坐标系的x轴，不是原惯性坐标系的x轴。依然遵守左手法则，向下旋转为正。]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【基于物理的渲染（PBR）白皮书】（一）开篇：PBR核心知识体系总结与概览]]></title>
    <url>%2F2018%2F05%2F14%2FPBR-Guide-Vol1%2F</url>
    <content type="text"><![CDATA[光与物质光与物质：基于物理的渲染与着色理论光是一种复杂的现象，它同时展现出波与粒子两种特性。于是，为了描述光的表现特性，人们建立了各种模型。作为材质艺术家，我们感兴趣的是光线模型（Light Ray Model）因为它描述了光与物质的交互作用。对我们来说，理解光线如何与物质表面交互非常重要，因为我们的工作是创作描述物体表面的材质。我们创作出的纹理与材质再虚拟世界中与光交互，对光线表现特效理解的越多，创作出的材质就会更好。再这篇指南中，我们会讨论物理理论，而基于物理的渲染(physically-based rendering)(PBR)模型正是建立在其上的。我们从光线开始，逐步讲解PBR中的关键点。 光线光线模型阐明，光线在均匀透明介质（如空气）中的轨迹为直线。光线模型同时也阐明，当光传播遇到表面是，例如遇到不透明物体或穿过不同介质如从空气折射入水中，光的表现是可预测的。这样，当光从一个起点传播到某点最终转换为其他形式例如热时，我们可以将它的轨迹视觉化。击中一个表面的光线成为入射光，而它击中的角度称为入射角，如图01所示。一条光线射入两个不同介质间的平面交界面。先放出PBR知识体系的架构图： 系列文章前言基于物理的渲染（Physically Based Rendering，PBR）技术，自迪士尼SIGGRAPH 2012上提出了著名的“迪士尼原则的BRDF（Disney Principled BRDF）”之后，由于其高度的易用性以及方便的工作流，已经被电影和游戏业界广泛的使用。http://renderwonk.com/publications/s2010-shading-course/https://blog.selfshadow.com/publications/s2012-shading-course/https://blog.selfshadow.com/publications/s2013-shading-course/https://blog.selfshadow.com/publications/s2014-shading-course/https://blog.selfshadow.com/publications/s2015-shading-course/https://blog.selfshadow.com/publications/s2016-shading-course/https://blog.selfshadow.com/publications/s2017-shading-course/《Physically Based Rendering:From Theory to Implementation,Third Edition》这本书专注离线渲染，实时渲染只能用到里面很少的一部分。http://www.pbr-book.org/3ed-2018/contents.html《Real-Time Rendering 4th》中PBR的相关章节《Physically Based Shader Development for Unity》，主要是PBR在Unity引擎中的使用，而且是以Surface Shader的方式，准入门级，比较浅。 PBR知识体系概览这篇文章接下来的部分，是这个系列文件PBR知识体系的精华浓缩版。涉及八个部分的内容： 核心PBR理论 渲染方程与BxDF 迪士尼原则的BxDF（Disney Principled BxDF） 漫反射BRDF模型（Diffuse BRDF） 镜面反射BRDF模型（Specular BRDF） 基于物理的环境光照（Physically Based Environment Lighting） 离线渲染相关（Offline Rendering Related） 进阶渲染主题（Advanced Rendering Topics） PBR核心理论与渲染原理PBR核心知识体系的第一部分自然是PBR的核心理论以及相关的渲染原理。 基于物理的渲染（Physically Based Rendering，PBR）是指使用基于物理原理和微平面理论建模的着色/光照模型，以及使用从现实中测量的表面参数来准确表示真实世界材质的渲染理念。以下是对PBR基础理念的概括： 微平面理论（Microfacet Theory）。微平面理论是将物体表面建模成无数微观尺度上有随机朝向的理想镜面反射的小平面（microfacet）的理论。在实际的PBR工作流中，这种物体表面的不规则性用粗糙度贴图或者高光贴图来表示。 能量守恒（Energy Conservation）。出射光线的能量永远不能超过入射光线的能量。随着粗糙度的上升镜面反射区域的面积会增加，作为平衡，镜面反射区域的平均亮度则会下降。 菲涅尔反射（Fresnel Reflectance）。光线以不同角度入射会有不同的反射率。相同的入射角度，不同的物质也会有不同的反射率。万物皆有菲涅尔反射。F0是即0度角入射的菲涅尔反射。大多数非金属的F0范围是0.02~0.04，大多数金属的F0范围是0.7~1.0。 线性空间（Liner Space）。光照计算必须在线性空间完成，shader中输入的gamma空间的贴图比如漫反射贴图需要被转成线性空间，在具体操作时需要根据不同引擎和渲染器的不同做不同的操作。而描述物体属性的贴图如粗糙度，高光贴图，金属贴图等必须保证是线性空间。 色调映射（Tone Mapping）。也称色调复制（tone reproduction），是将宽范围的照明级别拟合到屏幕有限色域内的过程。因为基于HDR渲染出来的亮度值会超过显示器能够现实最大亮度，所以需要使用色调映射，将光照结果从HDR转换微显示器能够正常显示的LDR。 物质的光学特性（Substance Optical Properties）。现实世界中有不同类型的物质可分为三大类：绝缘体（Insulators），半导体（semi-conductors）和导体（conductors）。在渲染和游戏领域，我们一般只对其中的两个感兴趣：导体（金属）和绝缘体（电解质，非金属）。其中非金属具有单色/灰色镜面反射颜色。而金属具有彩色的镜面反射颜色。即非金属的F0是一个float。而金属的F0是一个float3，如下图。 光与非光学平坦表面的交互原理光在与非光学平坦表面（Non-Optically-Flat Surfaces）的交互时，非光学平坦表面表现得像一个微小的光学平面表面的大集合。表面上的每个点都会以略微不同的方向对入射光反射，而最终的表面外观是许多具有不同表面取向的点的聚合结果。在微观尺度上，表面越粗糙，反射越模糊，因为表面取向与整个宏观表面取向的偏离更强。图片顶部所示的表面，表面相对光滑；表面取向仅略有变化，从而产生更清晰的反射。图片底部所示的表面较粗糙；表面上的不同点具有广泛变化的方向取向，导致反射光方向的高度变化，并因此导致模糊的反射。注意，两个表面在肉眼可见尺度下看起来是光滑的，粗糙度差异仅在微观尺度上。出于着色的目的，我们通常会去用统计方法处理这种微观几何现象，并将表面视为在每个点处在多个方向上反射（和折射）光。从表面反射的光的行为很好理解，那么，从表面折射的光会发生什么变化？这取决于对象本身的特性： 对于金属，折射会立刻被吸收-能量被自由电子立即吸收。 对于非金属（也成为电介质或绝缘体），一旦光在其内部折射，就表现为常规的参与介质，表现出吸收和散射两种行为。 漫反射和次表面散射本质相同另外，漫反射和次表面散射其实是相同的物理现象，本质都是折射光的次表面散射的结果。唯一的区别是相对于观察尺度的散射距离。散射距离相较于像素来说微不足道，次表面散射便可以近似为漫反射。也就是说，光的折射现象，建模为漫反射还是次表面散射，取决于观察的尺度，如下图。在左上角，像素（带有红色边框的绿色圆形）大于光想离开表面之前所经过的距离。在这种情况下，可以假设出射光从入口点（右上）射出，可以当作漫反射，用局部着色模型处理。在底部，像素小于散射距离；如果需要更真实的着色效果，则不能忽略这些距离的存在，需当作次表面散射现象进行处理。 一、PBR的范畴（Scope of PBR）寒霜（Frostbite）引擎在SIGGRAPH 2014的分享《Moving Frostbite to PBR》中提出，基于物理的渲染的范畴，由三部分组成： 基于物理的材质（Material） 基于物理的光照（Lighting） 基于物理适配的摄像机（Camera） 完整的这三者，才是真正完整的基于物理的渲染系统。而很多同学一提到PBR，就说PBR就是镜面反射采用微平面Cook-Torrance模型，其实是不太严谨的。二、渲染方程与BxDFPBR核心知识体系的第二部分是渲染方程与BxDF。渲染方程作为渲染领域中的重要理论，将BxDF代入渲染方程是求解渲染问题的一般方法。 2.1渲染方程与反射方程渲染方程（The Rendering Equation）作为渲染领域中的重要理论，其描述了光能在场景中的流动，是渲染中不可感知方面的最抽象的正式表示。根据光学的物理学原理，渲染方程在理论上给出了一个完美的结果，而各种各样的渲染技术，知识这个理想结果的一个近似。 渲染方程的物理基础是能量守恒定律。在一个特定的位置和方向，出射光$L_o$是自发光$L_e$与反射光线之和，反射光线本身是各个方向的入射光Li之和诚意表面反射率及入射角。 这个方程金国交叉点将出射光线与入射光线联系在一起，它代表了场景中全部的光线传输。所有更加完善的算法都可以看作是这个方程的特殊形式的解。 某一点p的渲染方程，可以表示为：$Lo=L_e + $$\int\Omega $&lt;/font&gt;${f_r\cdot L_i \cdot (w_i\cdot n)\cdot dw_i}$其中： $L_o$是p点的出射光亮度。 $L_e$是p点的发出的光亮度。 $f_r$是p点入射方向到出射方向光的反射比例，即BxDF，一般为BRDF。 $L_i$是p点入射光亮度。 $(w_i\cdot n)$是入射角带来的入射光衰减。 $\int_\Omega $$…dw_i$是入射方向半球积分（可以理解为无穷小的累加和）。 而在实时渲染中，我们常用的反射方程（The Reflctance Equation），则是渲染方程的简化的版本，或者说是一个特例：$Lo=L_e + $$\int\Omega $&lt;/font&gt;${f_r\cdot L_i \cdot (w_i\cdot n)\cdot dw_i}$同样，其中： $L_o$是p点的出射光亮度。 $f_r$是p点入射方向到出射方向光的反射比例，即BxDF，一般为BRDF。 $L_i$是p点入射光亮度。 $(w_i\cdot n)$是入射角带来的入射光衰减。 $\int_\Omega $$…dw_i$是入射方向半球积分（可以理解为无穷小的累加和）。 2.2 BxDFBxDF一般而言是对BRDF、BTDF、BSDF、BSSRDF等几种双向反射分布函数的一个统一的表示。其中，BSDF可以看作BRDF和BTDF更一般的形式，而且BSDF=BRDF+BTDF。而BSSRDF和BRDF的不同之处在于，BSSRDF可以指定不同的光线入射位置和出射位置。在上述这些BxDF中，BRDF最为简单，也最为常用。因为游戏和电影中的大多数物体都是不透明的，用BRDF就完全足够。而BSDF、BTDF、BSSRDF往往更多用于半透明材质和次表面散射材质。我们时常讨论的PBR中的BxDF，一般都为BRDF，对于进阶的一些材质的渲染，才会讨论BSDF等其它三种BxDF。另外，BxDF即上文所示渲染方程以及反射方程中的$f_r$项。 2.3 BRDF的分类 三、迪士尼原则的BxDF（Disney Principled BxDF）PBR核心知识体系的第三部分是迪士尼原则的BxDF。迪士尼动画工作室在SIGGRAPH 2012上著名的talk《Physically-based shading at Disney》中提出了迪士尼原则的BRDF（Disney Principled BRDF）,奠定了后续游戏行业和电影行业PBR的方向和标准。了解Disney Principled BxDF，是深入理解PBR的重要一环。基于物理的渲染，其实早在20世纪就已经在图形学业界有了一些套路怒，2010年在SIGGRAPH上就已经有公开讨论的Course《SIGGRAPH 2010 Course:Physically-Based Shading Models in File and Game Production》，而直到2012~2013年，才正式进入大宗的视野，渐渐被电影和游戏业界广泛使用。 迪士尼动画工作室则是这次PBR革命的重要推动者。迪士尼的Brent Burley与SIGGRAPH 2012上进行了著名的talk《Physically-based shading at Disney》，提出了迪士尼原则的BRDF（Disney Principled BRDF），由于其高度的通用性，将材质复杂的物理属性，用非常直观的少量变量表达了出来（如金属度metallic和粗糙度roughness），在电影业界和游戏业界引起了不小的轰动。从此，基于物理的渲染正式进入大众的视野。 在2012年受到Diney的启发后，以下是主流游戏引擎从传统渲染转移到基于物理的渲染时间节点： [SIGGRAPH 2013]UE4 : [Real shading in unreal engine 4] [SIGGRAPH 2014] Frostbite （寒霜）:[Moving Frostbite to PBR] [GDC 2014] Unity : [Physically Based Shading in Unity] 3.1 迪士尼原则的BRDF（Disney Principled BRDF）3.1.1 Disney Principled BRDF核心理念在2012年迪士尼原则的BRDF被提出之前，基于物理的渲染都需要大量复杂而不直观的参数，此时PBR的优势，并没有那么明显。 在2012年迪士尼提出，他们的着色模型是艺术导向（Art Directable）的，而不一定要是完全物理正确（physically correct）的，并且对为平面BRDF的各项都进行了严谨的调查，并提出了清晰明确而简单的解决方案。 迪士尼的理念是开发一种“原则性”的易用模型，而不是严格的物理模型。正因为这种艺术导向的易用性，能让美术同学非常直观的使用少量参数，以及非常标准化的工作流，就能快速实现涉及大量不同材质的真实感的渲染工作。而这对于传统的着色模型来说，是不可能完成的任务。 迪士尼原则的BRDF（Disney Principled BRDF）核心理念如下： 应使用直观的参数，而不是物理类的晦涩参数。 参数应尽可能少。 参数在其合理范围内应该为0到1。 允许参数在有意义时超出正常的合理范围。 所有参数组合应尽可能健壮和合理。 以上五条原则，很好地保证了迪士尼原则的BRDF的易用性。 3.1.2 Disney Principled BRDF参数以上理念为基础，迪士尼动画工作室对每个参数的添加进行了把关，最终得到了颜色参数（baseColor）和下面描述的是个标量参数： baseColor（基础色）：表面颜色，通常由纹理贴图提供。 subsurface（次表面）：使用次表面近似控制漫反射形状。 metallic（金属度）：金属（0=电介质，1=金属）。这是两种不同模型之间的线性混合。金属模型没有漫反射成分，并且还具有等于基础色着色入射镜面反射。 specular（镜面反射强度）：入射镜面反射两。用于取代折射率。 specularTint（镜面反射颜色）：对美术控制的让步，用于对基础色（base color）的入射镜面反射进行颜色控制。掠射镜面反射仍然时非彩色的。 roughness（粗糙度）：表面粗糙度，控制漫反射和镜面反射。 anisotropic（各向异性强度）：各向异性强度。用于控制镜面反射高光的纵横比。（0=各向同性，1=最大各向异性） sheen（光泽度）：一种额外的掠射分量（grazing component），主要用于布料。 sheenTine（光泽颜色）：对sheen（光泽度）的颜色控制。 clearcoat（清漆强度）：有特殊用途的第二个镜面波瓣（specular lobe）。 clearcoatGloss（清漆光泽度）：控制透明涂层光泽度，0=“缎面（satin）”外观，1=“光泽（gloss）”外观。 每个参数的效果的渲染示例如下图所示。 3.2 迪士尼原则的BSDF（Disney Principled BSDF）随后的2015年，迪士尼动画工作室在Disney Principled BRDF的基础上进行了修订，提出了Disney Principled BSDF [Extenting the Disney BRDF to a BSDF with Integrated Subsurface Scattering,2015] 以下是开源三维动画软件Blender实现的Disney Principled BSDF的图示： 四、漫反射BRDF模型（Diffuse BRDF）为了求解渲染方程，需要分别求解Diffuse BRDF和Specular BRDF。所以PBR核心知识体系的第四部分是Diffuse BRDF。Diffuse BRDF可以分为传统型和基于物理型两大类。其中，传统型主要是总所周知的Lambert。而基于物理型，从1994年的Oren Nayar开始，这里一直统计到今年（2019年）。其中较新的有GDC 2017上提出的适用于GGX+Smith的基于物理的漫反射模型（PBR diffuse for GGX+Smith），也包含了最近在SIGGRAPH2018上提出的，来自《使命召唤：二战》的多散射漫反射BRDF（MultiScattrering Diffuse BRDF）： Oren Nayar[1994] Simplified Oren-Nayar[2012] Disney Diffuse[2012] Renormalized Disney Diffuse[2014] Gotanda Diffuse[2014] PBR diffuse for GGX+Smith[2017] MultiScattrering Diffuse BRDF[2018] 五、镜面反射BRDF模型（Specular BRDF）PBR核心知识提醒的第五部分是Specular BRDF。这也是基于物理的渲染领域中最活跃，最主要的部分。上图中加粗部分为目前业界较为主流的模型。 游戏业界目前最主流的基于物理的镜面反射BRDF模型是基于微平面理论（microfacet theory）的Microfacet Cook-Torrance BRDF。 而微平面理论（microfacet theory）源自将微观几何（microgeometry）建模为微平面（microfacets）的集合思想，一般用于描述来自非光学平坦（non-optically flat）表面的表面反射。 微平面理论的基本假设是微观几何（microgeometry）的存在，微观几何的尺度小于观察尺度（例如着色分辨率），但大于可见光波长的尺度（因此应用几何光学如衍射一样的波效应等可以忽略）。且微平面理论在2013年和以前时仅用于推导单反射（single-bounce）表面反射的表达式；而随着领域的深入，最近几年也出现了使用microfacet理论对多次反弹表面的一些探讨。 由于假设微观几何尺度明显大于可见光波长，因此可以将每个表面点视为光学平坦的。如上文所述，光学平坦表面将光线分成两个方向：反射和折射。 每个表面点将来自给定进入方向的光反射到单个出射方向，该方向取决于微观几何法线（microgeometry normal）m的方向。在计算BRDF项时，指定光方向I和视图方向v。这意味着所有表面点，只有那些恰好正确朝向可以将I反射到v的那些小平面可能有助于BRDF值（其他方向有正有负，积分之后，相互抵消）。 在下图中，我们可以看到这些“正确朝向”的表面点的表面法线m正好位于I和v之间的中间位置。I和v之间的矢量成为半矢量（half-vector）或半角矢量（half-angle vector）；我们将其表示为h。 并非所有的m = h的表面点都会积极地对反射做出共享；一个被I方向（阴影shadowing），v方向（掩蔽masking）或两者的其他表面区域阻挡。Microfacet理论假设所有被遮蔽的光（shadowed light）都从镜面反射项中消失；实际上，由于多次表面反射，其中一些最终将是可见的，但这在目前常见的微平面理论中一般并未去考虑，各种类型的光表面相互作用如下图所示。上图在左侧，我们看到一些表面点从I的方向被遮挡，因为它们被遮挡并且不接受光（因此它们不能反射任何）。在中间，我们看到从视图方向v看不到一些表面点，因此当然不会看到从它们反射的任何光。在这两种情况下，这些表面点对BRDF没有共享。实际上，虽然阴影区域没有接受从I接受任何直射光，但它们确实接受（并因此反射）从其他表面区域反射的光（如右图所示）。microfacet理论忽略了这些互相反射。 5.1 从物理现象到BRDF利用这些假设（局部光学平坦表面，没有相互反射），可以很容易推导出一个被成为Microfacet Cook-Torrnace BRDF的一般形式的Specular BRDF项。此Specular BRDF具有以下形式： $f(l,v)={D(h)F(v,h)G(l,v,h)\over 4(n\cdot l)(n \cdot v)}$ 其中： D(h):法线分布函数（Normal Distribution Function），描述微面元发现分布的概率，即正确朝向的发现的浓度。即具有正确朝向，能够将来自I的光反射到v的表面点的相对于表面面积的浓度。 F(I,h):菲涅尔方程（Fresnel Equation），描述不同的表面角下表面所反射的光线所占的比率。 G(l,v,h):几何函数（Geometry Function），描述微平面自成阴影的属性，即m=h的未被遮蔽的表面点的百分比。 分母4(n\cdot l)(n \cdot v):校正因子（correctionfactor），作为微观几何的局部空间和整个宏观表面的局部空间之间变换的微平面量的校正。 关于Cook-Torrance BRDF，需要强调的两点注意事项： 对于分母中的点击，仅仅避免负值时不够的，也必须避免零值。通常通过在常规的clamp或绝对值操作之后添加非常小的正值来完成。 Microfacet Cook-Torrance BRDF是实践中使用最广泛的模型，实际上也是人们可以想到的最简单的微平面模型。它仅对几何光学系统中的单层为表面上的单个散射进行建模，没有考虑多次散射，分层材质，以及衍射。Microfacet模型，实际上还有很长的路要走。 下面对Microfacet Cook-Torrance BRDF中的D、F、G项分别进行简单说明。 5.2 Specular D法线分布函数（Normal Distribution Function, NDF）D的常见模型可以总结如下： Beckmann[1963] Blinn-Phong[1977] GGX[2007]/Trowbridge-Reitz[1975] Generalized-Trowbridge-Reitz(GTR)[2012] Anisotropic Beckmann[2012] Anisotropic GGX[20115] 其中，业界较为主流的法线分布函数是GGX（Trowbridge-Reitz），因为具有更好的高光长尾： $D_{GGX} = {\alpha \over (\pi(n \cdot m)^2(\alpha^2 - 1) + 1)^2}$ 另外，需要强调一点。Normal Distribution Function正确的翻译是法线分布函数，而不是正太分布函数。google翻译等翻译软件会将Normal Distribution Function翻译成正态分布函数，而不少中文资料就跟着翻译成正态分布函数，这是错误的。 其实，一些参考文献会使用术语“法线分布（distribution of normals）”来避免与高斯正太分布(Gaussian normal distribution)混淆。 5.3 Specular F对于菲涅尔（Fresnel）项，业界方案一般都采用Schlick的Fresnel近似，因为计算成本低廉，而且精度足够： $F_{Schlick}(v,h)=F_0 + (1 - F_0)(1 - (v \cdot h))^5$ 菲涅尔项的常见模型可以总结如下： Cook-Torrance[1982] Schlick[1994] Gotanta[2014] 5.4 Specular G几何项G的常见模型可以总结如下： Smith[1967] Cook-Torrance[1982] Neumann[1999] Kelemen[2001] Implicit[2013] 另外，Eric Heitz在[Heitz14]中展示了Smith几何阴影函数是正确且更准确的G项，并将其扩展为Smith联合遮蔽函数(Smith Joint Masking-Shadowing Function)，该函数具有四种形式： 分离遮蔽阴影型（Separable Masking and Shadowing） 高度相关遮蔽阴影型（Height-Correlated Masking and Shadowing） 方向相关遮蔽阴影型（Direction-Correlated Masking and Shadowing） 高度-方向相关遮蔽阴影型（Height-Direction-Correlated Masking and Shadowing） 目前较为常用的是最为简单的形式，分离遮蔽阴影（Separable Masking and Shadowing Function）。 该形式将几何项G分为两个独立的部分：光线方向（light）和视线方向（view），并对两者用相同的分布函数描述。根据这种思想，结合法线分布函数（NDF）与Smith几何阴影函数，于是有了以下新的Smith几何项： Smith-GGX Smith-Beckmann Smith-Schlick Schlick-Beckmann Schlick-GGx 其中UE4的方案是上面列举中的”Schlick-GGX”，即基于Schlick近似，将K映射为$k = {\alpha \over 2}$，去匹配GGX Smith方程： $k = {\alpha \over 2}$$\alpha = roughness^2$$G_1(v)={(n\cdot v)\over {(n\cdot v)(1-k)+k}}$$G(l,v,h)=G_1(l)G_1(v)$ 六、基于物理的环境光照（Physically Based Environment Lighting）有了直接光部分，我们也需要环境光。所以PBR核心知识体系的第六部分是基于物理的环境光照，一般大家也直接默认环境光照的技术方案是基于图像的光照（Image Based Lighting, IBL)。这也是真正让基于物理的渲染画质提升的主要贡献者。漫反射环境光照部分一般采用传统IBL中辉度环境映射（Irradiance Environment Mapping）技术，并不是基于物理的特有方案，这里暂不讨论。 而基于物理的镜面反射（Specular）环境光照，业界中一般会采用基于图像的光照（IBL）的方案。要将基于物理的BRDF模型与基于图像的光照（IBL）一起使用，需要求解光照亮度积分（Radiance Integral），而求解光亮度积分通常会使用重要性采样（Importance Sample）。 重要性采样（Importance Sample）即通过现有的一些已知条件（分布函数），想办法集中于被积函数分布可能性较高的区域（重要的区域）进行采样，进而可高效和准确的计算。 6.1 分解求和近似（Split Sum Approximation）基于重要性采样的思路，将蒙特卡洛积分公式代入渲染方程可得： $$ 6.3.1 流派1：2D LUTUE4在[Real Shading in Unreal Engine 4,2013]中提出，第二个求和项，使用Schlick近似后，$F0$可以从积分中分出来：$\int\Omega{Li(l)f(l,v)cos\theta_l\cdot dl} = F_0\int\Omega{f(l,v)\over F(v,h)}(1-(1-v\cdot h)^5)cos\thetaldl+\int\Omega{f(l,v)\over F(v,h)}(1-v\cdot h)^5cos\theta_ldl$上式留下了两个输入(Roughness和$cos\theta$v)和两个输出(缩放和向$F_0$的偏差(a scale and bias to $F_0$))，即把上述方程看成是$F_0 \cdot Scale + Offset$的形式。我们预先计算此函数的结果并将其存储在2D查找纹理(LUT,look-up texture)中。这张红绿色的贴图，输入roughtness、$cos\theta$，输出环境BRDF镜面反射的强度。是关于roughness、$cos\theta$与环境BRDF镜面反射强度的固有映射关系。可以离线预计算。具体的取出方式为： ${1\over N}\sum{k=1}^N {f(l_k,v)cos\theta{l_k}\over p(l_k,v)}=LUT.r * F_0 + LUT.g$即UE4是通过把Fresnel公式的F0提出来，组成F0*Scale+Offset的方式，再将Scale和Offset的索引存到一张2D LUT上。靠roughness和NdotV进行查找。 6.3.2 流派2：解析拟合COD: Black Ops 2的做法，是通过数学工具Mathematica(http://www.wolfram.com/mathematica/)中的数值积分拟合出曲线，即将UE4离线计算的这张2D LUT用如下函数进行了拟合：1234float3 EnvironmentBRDF(float g, float NoV, float3 rf0)&#123; float4 t = float4(1/0.96, 0.475, (0.0275 - 0.25))&#125; 七、离线渲染相关（Offline Rendering Related）虽然我们目前主要关注的是实时渲染（实时光栅图形学相关，暂时不关注实时光线追踪）领域，但很多时候，实时渲染也需要涉及到预计算，尤其是IBL相关的预计算，所以或多或少会用到离线渲染相关的知识。所以PBR核心知识体系的第七部分是离线渲染相关的主题。以下是与实时渲染结合相对紧密的离线渲染的核心主题以及概括总结（主要是统计学与概览相关）： 重要性采样（Importance Sample）：蒙特卡洛积分的一种采样策略。思路是基于分布函数，尽量对被积函数分布可能性较高的区域进行采样。 多重要性采样（Muti Importance Sampling，MIS）：估算某一积分时，基于多个分布函数获取采样，并期望至少某一分布与被积函数形状适配。即根据各种技术对采样进行加权计算，进而消除近似于它的概览。即偶然中包含着某种必然。 蒙特卡洛方法（Monte Carlo Methods）：一种以概率统计理论为指导的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。 低偏差序列（Low-discrepancy sequence）：一种确定生成的超均匀分布列，也成为随机列、次随机列，常见低偏差序列有Hammersley，Halton等。 拟蒙特卡罗方法（Quasi-Monte Carlo Method）：使用低差异来进行数值积分和研究其它一些数值问题的方法。 八、进阶渲染主题（Advanced Rendering Topics）前面的核心PBR主题都讨论完以后，会有更多进阶的内容浮出水面，它们共同组成了PBR核心知识体系的第八部分。以下是一个列举： 进阶着色模型 布料BRDF(Cloth BRDF) 清漆着色模型(Clear Coat Model) 次表面散射BRDF模型(Subsurface Scattering BRDF Model) 进阶材质功能 全能材质(Uber Shader) 分层材质(Layered Materials) 分层全能材质(Layered Uber Shader) 混合材质(Blending Material) 过滤材质(Filtering Materials) 进阶理论 物理光学(Physics of Light) 波动光学(Wave Optics) 基于物理的摄像机(Physical Based Camera) 基于物理的光源(Physical Based Light) 白炉测试(White Furnace Test) 进阶BxDF BSDF BTDF BSSRDF 进阶材质渲染 皮肤渲染(Skin Rendering) 布料渲染(Cloth Rendering) 半透明表面渲染(Translucent Surfaces Rendering) 头发渲染(Hair Rendering) 毛发渲染(Fur Rendering) 车漆渲染(Car Paint Rendering) 水体渲染(Water Rendering) 湿润表面渲染(Wet Surface Rendering) 天空与大气渲染(Sky and Atmosphere Rendering) 薄表面材质渲染(Thin Surface Rendering) 体积渲染(Volumetric Rendering)]]></content>
      <tags>
        <tag>计算机图形学</tag>
        <tag>游戏引擎</tag>
        <tag>游戏开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Direct3D 11]]></title>
    <url>%2F2018%2F05%2F14%2Fd3d11%2F</url>
    <content type="text"><![CDATA[点积(dot product)计算结果是标量值；也叫标量积(scalar product)。等于两个向量对应分量的乘积之和。 $\mathbf{u \cdot v} = u_xv_x+u_yv_y+u_zv_z$ 4.1 准备工作4.1.4 交换链和页面翻转为了避免在动画中出现闪烁，最好的做法是在一个离屏（off-screen）纹理中执行所有的动画帧绘制工作，这个离屏纹理成为后台缓存区(back buffer)。当我们在后台缓冲区中完成给定帧的绘制工作后，便可以将后台缓冲区作为一个作为一个完整的帧显示在屏幕上；使用这种方法，用户不会感觉到帧的绘制过程，只会看到完整的帧。从理论上讲，将一帧显示到屏幕上所消耗的时间小于屏幕的垂直刷新时间。硬件会自动维护两个内置的纹理缓冲区来实现这一功能，这两个缓冲区分别成为前台缓冲区(front buffer)和后台缓冲区。前台缓冲区存储了当前显示在屏幕上的图像数据，而动画的下一帧会在后台缓冲区中执行绘制。当后台缓冲区的绘制工作完成之后，前后两个缓冲区的做哟个会发生翻转；后台缓冲区会变为前台huan’ch 4.1.5 深度缓冲区深度缓冲区(depth buffer)是一个不包含图像数据的纹理对象。在一定程度上，深度信息可以被认为是一种特殊的像素。常见的深度值范围在0.0到1.0之间，其中0.0表示离观察者最近的物体，1.0表示离观察者最远的物体。深度缓冲区中的每个元素与后台缓冲区中的每个像素一一对那个（即，后台缓冲区的第ij个元素对应于深度缓冲区第ij个元素）。所以，当后台缓冲区的分辨率为1280x1024时，在深度缓冲区中有1280x1024个深度元素。 4.1.6 纹理资源视图纹理可以被绑定到渲染管线（rendering pipeline）的不同阶段(stage);例如，比较常见的情况是将纹理作为渲染目标（即，Direct3D渲染到纹理）或着色器资源（即，在着色器中对纹理进行采样）。当创建用于这两种目的的纹理资源时，应使用绑定标记值： D3D11_BIND_RENDER_TARGET|D3D10_BIND_SHADER_RESOURCE指定纹理所要绑定的两个管线阶段。其实，资源不能被直接绑定到一个管线阶段；我们只能把与资源关联的资源试图绑定到不同的管线阶段。无论以哪种方式使用纹理，Direct3D始终要求我们在初始化时为纹理创建相关的资源视图(resource view)。这样有助于提供运行效率，正如SDK文档指出的那样：“运行时环境与驱动程序可以在视图创建执行相应的验证和映射，减少绑定时的类型检查”。所以，当把纹理作为一个渲染目标和着色器资源时，我们要为它创建两种试图：渲染目标试图 (ID3D11RenderTargetView)和着色器资源视图 (ID3D11ShaderResourceView)。资源视图主要有两个功能：（1）告诉Direct3D如何使用资源（即，指定资源所要绑定的管线阶段）； 4.1.7 多重采样因为计算机显示器上的像素分辨率有限，所以当我们绘制一条任意直线时，该直线很难精确地显示在屏幕上。当无法提高显示器的分辨率，缩小像素尺寸，也可以有效地缓解这一问题，使阶梯效应明显降低。当无法提高显示器分辨率或分辨率不够高时，我们可以使用抗锯齿 (antialiasing)技术。其中的一种技术叫做超级采样（supersampling），它把后台缓冲和深度缓冲的大小提高到屏幕分辨率的4倍。 4.1.8 Direct3D中的多重采样4.2 对Direct3D进行初始化 ID3D11Device接口用于检测显示适配器功能和分配资源。 ID3D11DeviceContext接口用于设置管线状态、将资源绑定到图形管线和生成渲染命令。 4.2.2 检测4X多重采样质量支持创建了设备后，我们就可以检查4X多重采样质量等级了。所有支持Direct3D 11的设备都支持所有渲染目标格式的4X MSAA（支持的质量等级可能并不相同）。123UINT m4xMsaaQuality;HR(md3dDevice-&gt;CheckMultisampleQualityLevels(DXGI_FORMAT_R8G8B8AB_UNORM, 4, &amp;m4xMassQuality));assert(m4xMsaaQuality&gt;0); 因为4X MSAA总是被支持的，所以返回的质量等级总是大于0。 4.2.3 描述交换链下一步是创建交换链，首先需要填充一个DXGI_SWAP_CHAIN_DESC结构体来描述我们将要创建的交换链的特性。该结构体的定义如下：12345678910typedef struct DXGI_SWAP_CHAIN_DESC&#123; DXGI_MODE_DESC BufferDesc; DXGI_SAMPLE_DESC SampleDesc; DXGI_USAGE BufferUsage; UINT BufferCount; HWND OutputWindow; BOOL Windowed; DXGI_SWAP_EFFECT SwapEffect; UINT Flags;&#125;DXGI_SWAP_CHAIN_DESC; DXGI_MODE_DESC类型是另一个结构体，其定义如下：12345678typedef struct DXGI_MODE_DESC&#123; UINT Width; // 后台缓冲区宽度 UINT Height; // 后台缓冲区高度 DXGI_RATIONAL RefreshRate; // 显示刷新率 DXGI_MODE_SCANLINE_ORDER ScanlineOrdering; // display scanline mode DXGI_MODE_SCALING Scaling; // display scaling mode &#125; 注意：在下面的数据成员描述中，我们只覆盖了一些常用的标记值和选项，它们对于初学者来说非常重要。对于其他标志值和选项的描述，请参阅SDK文档。 BufferDesc:该结构体描述了我们所要创建的后台缓冲区的属性。我们主要关注的属性有：宽度、高度和像素骼时；其他属性的详情请参阅SDK文档。 SampleDesc:]]></content>
      <tags>
        <tag>Direct3D 11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shader模板缓冲和模板测试]]></title>
    <url>%2F2018%2F04%2F26%2FUnity-Stencil-Buffer-Stencil-Test%2F</url>
    <content type="text"><![CDATA[在图形学种一个像素会有如下缓存： 颜色缓存color buffer/pixel buffer : 存储该点即将显示地颜色，RGBA值 深度缓存depth buffer/z buffer:存储该点地深度，z 模板缓存stencil buffer： 通常用作限制渲染区域。更高级用法需结合深度缓冲，例如某像素地模板缓冲值会随着其是否通过深度缓冲测试而改变。 累计缓存Accumulation Buffer:与颜色缓存类似，同样储存一个RGBA值。累计缓存是为合成多幅图像而设计地，累计缓存提供了一种在保持好地颜色分辨率下实现在场景中”多重曝光(multiple exposures”地方法。使用累计缓存可以产生许多图像效果来提高图像的真实性，其中包括：反走样，运动模糊，软阴影，深度域（景深）和卷积。要产生这些效果，必须将图像渲染多次，对场景位置（或所选的物体）进行微小的、渐增的改变，然后累计结果。 stencil与颜色缓冲区和深度缓存区类似，模板缓存区可以为屏幕上的每个像素点保存一个无符号整数值（通常是个八位整数）。这个值的具体意义视程序的具体应用而定。在渲染的过程中，可以用这个值与一个预先设定的参考值相比较，根据比较的结果来决定是否更新相应的像素点的颜色值。这个比较的过程成为模板测试Stencil Test。模板测试发生在透明度测试(alpha test)之后。如果模板测试通过，则相应的像素点更新，否则不更新。图形渲染管线中，基于单个像素的测试操作的顺序如下图]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Lerp]]></title>
    <url>%2F2018%2F04%2F26%2FUnity-Lerp%2F</url>
    <content type="text"><![CDATA[有时，我们在做游戏时会发现有些跟随动作不够圆滑或者需要一个缓冲的效果，这时，一般会考虑到插值。（比如摄像机跟随主角） 插值是数学上的一个概念，公式： from + (to - from) * t;from是起始地位置，to是目标位置，按照数字t在from到to之间插值。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CG-Input-Output-And-Semantic-Bind]]></title>
    <url>%2F2018%2F04%2F21%2FCG-Input-Output-And-Semantic-Bind%2F</url>
    <content type="text"><![CDATA[先复习一下GPU的工作流程，第三章从CPU运行原理和数据流程的角度阐述了顶点着色器程序和片段着色程序的输入输出，即，应用程序(宿主程序)将图元信息(顶点位置、法向量、纹理坐标等)传递给顶点着色程序；顶点着色程序基于图元信息进行坐标空间变换，运算得到的数据传递到片段着色程序中；片段着色程序还可以接受从应用程序中传递的纹理信息，将这些信息综合起来计算每个片段的颜色值，最后将这些颜色值输送到帧缓冲区(或颜色缓冲区)中。这一章中，我们将讲解Cg语言通过何种机制确定数据类型和传递形式。三个问题：1、从应用程序传递到GPU的数据，分为图元信息数据(在GPU处理的基本数据如顶点位置信息等)和其他的离散数据(在GPU运行流程中不会发生变化，如材质对光的反射、折射信息)，这两种输入数据如何区分？2、从应用程序传递到GPU中的图元信息如何区分类型，即，顶点程序怎么知道一个数据是位置数据，而不是法线量数据？3、顶点着色程序与片段着色程序之间的数据传递如何进行？cg关键字不但用于指定输入图元的数据含义(是位置信息，还是法向量信息),本质也则对应着这些图元数据存放的硬件资源(寄存器或者纹理)，称之为语义词(Semantics),通常也根据其用法称之为绑定语义词(binging semantics)。 除语义词外，Cg中还提供了三个关键字，int、out、inout，用于表示函数的输入参数的传递方式，称为输入/输出关键字，这组关键字可以和语义词合用表达硬件上不同的存储位置，即同一个语义词，使用in关键字修饰和out关键词修饰，表示的图形硬件上不同的寄存器。 Cg语言还提供两个修饰符：uniform,用于指定变量的数据初始化方式；const关键字的含义与C/C++中相同，表示被修饰变量为常量变量。 uniformCg语言将输入输出数据流分为两类： Varying inputs,即数据流输入图元信息的各种组成要素。从应用程序输入到GPU的数据除了顶点位置数据，还有顶点的法向量数据，纹理坐标数据等。 Uniform inputs,表示一些与三维渲染有关的离散信息数据，这些数据通常由应用程序传入，并通常不会随着图元信息的变化而变化，如材质对光的反射信息、运动矩阵等。Uniform修饰一个参数，表示该参数的值由外部应用程序初始化并传入。使用Uniform修饰的变量，除了数据来源不同外，与其他变量是完全一样的。需要注意的一点是：uniform修辞的变量是从外部传入的，所以在Cg程序(顶点程序和片段程序)中通常所有uniform参数修辞函数形参，不容许声明一个uniform修辞的局部变量！ Cg语言中参数传递方式同样分为”值传递”和”引用传递”，但指针机制并不被GPU硬件支持，所以Cg语言采用不同的语法修辞符来区别”值传递”和”引用传递”.这些修辞符分别为： in :修辞一个形参只是用于输入，进入函数体时被初始化，且该形参值的改变不会影响实参值，这是典型的值传递方式。 out :修辞一个形参只是用于输出的，进入函数体时并没有被初始化，这种类型的形参一般是一个函数的运行结果； inout:修辞一个形参即用于输入也用于输出，这是典型的引用传递。例如： void myFunction(float x); //等价于in float x，这种用法和C/C++完全一致语义词(Semantic)与语义绑定(Binding semantics) 语义词，表示输入图元的数据含义(是位置信息，还是法向量信息)，也表明这些图元数据存放的硬件资源(寄存器或者纹理缓存区)。顶点着色程序和片段着色程序中Varying inputs类型的输入，必须和一个语义词相绑定，这称之为绑定语义(binding semantics)。 记住这一点：语义，是两个处理阶段(顶点程序、片段程序)之间的输入/输出数据和寄存器之间的桥梁，同时语义通常也表示数据的含义，如POSITION一般表示参数存放的数据是顶点位置。 语义，只对两个处理阶段的输入/输出数据有意义，也就是说，语义只有在入口函数中才有效，在内部函数(一个阶段的内部处理函数，和下一个阶段没有数据传递关系)无效，被忽略。 顶点着色程序必须声明一个输出变量，并绑定POSITION语义词，该变量中的数据将被用于且至被用于光栅化！ 为了保持顶点程序输出语义和片段程序输入语义的一致性，通常使用相同的struct类型数据作为两者之间的传递，这是一种非常方便的写法，推荐使用。 注意：当使用struct结构中成员变量绑定语义时，需要主要到顶点着色程序中使用的POSITION语义词，是不会被片段程序所使用的。 都要记住vertex program中的绑定语义(POSITION除外)的输出形参中的数据会传递到fragment program中绑定相同语义的输入形参中。 片段着色器的输出语义词较少，通常是COLOR。这是因为片段着色程序运行完毕后，就基本到了GPU流水线的末端了。片段程序必须声明一个out向量(三元或四元),绑定语义词COLOR，这个值将被用作该片段的最终颜色值。 语义绑定方法绑定语义放在函数的参数列表的参数声明后面中： [const][int|out|inout]&lt;type&gt;&lt;identifier&gt;[:&lt;binding-semantic&gt;][=&lt;initializer&gt;] 绑定语义可以放在结构体(struct)的成员变量后面： 1234struct &lt;struct-tag&gt;&#123; &lt;type&gt;&lt;identifier&gt; [:&lt;binding-semantic&gt;];&#125;; 绑定语义词可以放在函数声明的后面，其形式为：1234&lt;type&gt; &lt;identifier&gt;(&lt;parameter-list&gt;)[:&lt;binding-semantic&gt;]&#123; &lt;body&gt;&#125; 最后一种语义绑定的方法是，将绑定语义词放在全局非静态变量的声明后面。其形式为： &lt;type&gt; &lt;identifer&gt;[:&lt;binding-semantic&gt;][=&lt;initializer&gt;];]]></content>
      <tags>
        <tag>CG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Mesh]]></title>
    <url>%2F2018%2F04%2F21%2FUnity-Mesh%2F</url>
    <content type="text"><![CDATA[Mesh是Unity内的一个组件，成为网格组件。 Mesh网格 MeshFilter网格过滤器 Mesh Renderer 网格渲染器 Mesh: 是指模型的网格，建模就是建网格。Mesh的主要属性内容包括顶点坐标，法线，纹理坐标，三角形绘制序列等其他有用属性和功能。因此建网格，就是画三角形；画三角形就是定位三个点。Mesh Filter: 内包含一个Mesh组件，可以根据MeshFilter获得网格的组件，也可以为MeshFilter设置Mesh内容。Mesh Renderer: 是用于把网格渲染出来的组件。MeshFilter的作用就是把Mesh扔给MeshRender将模型或者是几何体绘制显示出来。 它们之间的关系大概就是GameObject挂MeshFilter组件，该组件有Mesh属性，该属性存顶点坐标，法线等属性，然后用Mesh Renderer(SkinMeshRenderer)才能将此网格渲染出来。 Mesh属性 顶点坐标(vertex) 顶点坐标数组存放Mesh的每个顶点空间坐标，假设某mesh有n个顶点，则vertex的size为n 法线(normal) 法线数组存放mesh每个顶点的法线，大小与顶点坐标对应，normal[i]对应vector[i]的法线 纹理坐标(uv) 它定义了图片上每个点的位置的信息，这些点与3D模型是互相联系的，以决定表面纹理贴图的位置，UV就是将图像上每个点精确对应到模型物体的表面uv[i]对应vectex[i] 三角形序列(triangle) 每个mesh都由若干个三角形组成，而三角形的三个点就是顶点坐标里的点，三角形的数组的size - 三角形个数 * 3 例如：某mesh有四个顶点0,1,2,3v0( 1, 1, 0)v1(-1, 1, 0)V2( 1,-1, 0)V3(-1,-1, 0)那么它们可以组成这样的一个网格tri[0] = v0,v3,v1, tri[1] = v0, v2, v3 注意：三角形的顶点顺序必须是顺时针，顺时针表示正面，逆时针表示背面，而Unity3D在渲染默认只渲染正面，背面是看不见的。(双面渲染一般用于头发等材质的处理)那么该三角形可以表示: tri = new int[2 * 3]{0,3,1, 0, 2, 3}; 如何要获取第N个三角形对应的三个顶点坐标，则:V1 = tri[N 3+0],v2 = tri[N 3 + 1], v3 = tri[N * 3 + 2] 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748using UnityEngine;using System.Collections;//注意Unity是左手坐标系！！！，Unity默认是不渲染背面的public class CreateMesh : MonoBehaviour &#123; private MeshFilter filter; private Mesh mesh; void Start () &#123; filter = GetComponent&lt;MeshFilter&gt;(); mesh = new Mesh(); filter.mesh = mesh; InitMesh(); &#125; void InitMesh() &#123; mesh.name = "MyMesh"; Vector3[] vertics = new Vector3[8]&#123; new Vector3(1,1,0), new Vector3(-1, 1, 0), new Vector3(1,-1,0), new Vector3(-1,-1,0), new Vector3(1,1,1), new Vector3(-1, 1, 1), new Vector3(1,-1,1), new Vector3(-1,-1,1) &#125;; mesh.vertices = vertics; int[] triangles = new int[12 * 3]&#123; 0, 3, 1, 0, 2, 3, 4, 7, 5, 4, 6, 7, 0, 1, 5, 0, 5, 4, 2, 3, 7, 2, 7, 6, 0, 4, 6, 0, 6, 2, 1, 3, 7, 1, 7, 5, &#125;; mesh.triangles = triangles; /*Vector2[] uv = new Vector2[4]&#123; new Vector2(1,1), new Vector2(0,1), new Vector2(1,0), new Vector2(0,0) &#125;; mesh.uv = uv;*/ &#125;&#125; 效果如下(一定要加Mesh Renderer因为这玩意是负责渲染的,Unity这货材质缺失就是显示粉色的) 网格已经生成了，接下来就是给网格贴图了，uv属性会直接控制贴显示贴图的哪一部分，以及如何显示贴图uv中的每一项和vertices的每一项都是一一对应的，unity在贴图的时候，会把uv中的每一个点和vertices中对应的索引的顶点一一关联起来，这样可以实现贴图任意形状实现最终效果 shared在源对象上修改属性，非shared每次修改属性会从新生成一个对象。在编辑器下非运行期如果使用shared会修改本地文件，如果使用非shared会提示内存泄漏。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cocos2d]]></title>
    <url>%2F2018%2F04%2F20%2Fcocos2d%2F</url>
    <content type="text"></content>
      <tags>
        <tag>Cocos2D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寻仙手游客户端分析]]></title>
    <url>%2F2018%2F04%2F20%2Fxxsy-client-framework%2F</url>
    <content type="text"><![CDATA[寻仙手游客户端是采用Unity5.3.8+uLua开发的一款MMORPG手游。 流程顺序应用程序启动Handheld.PlayFullScreenMovie通过该方法播放视频文件进入更新模块SDK初始化安卓通过AndroidJavaClass访问Java实例 资源模块UI模块更新模块网络模块这里是在多线程中做的，使用的是NetworkStream这个。 Lua模块Lua 注册1234567891011121314151617181920212223242526272829303132[MonoInvokeCallbackAttribute(typeof(LuaCSFunction))]static int call(System.IntPtr L)&#123; int upidx = LuaDLL.lua_upvalueindex(1); int fnidx = (int)LuaDLL.lua_touserdata(L, upidx); if (fnidx &lt;= || fnidx &gt; m_count) &#123; LuaDLL.luaL_error(L, "SafeCallApi : bad function index " + fnidx); return 0; &#125; var info = m_infos[fnidx - 1]; try &#123; if (L != LuaMgr.m_L) &#123; using (new GuardL &#123; L = LuaMgr.m_L&#125;) &#123; LuaMgr.m_L = L; int v = info.function(); return v; &#125; &#125; int r = info.function(); return r; &#125; catch (System.Exception err) &#123; LuaDLL.lua_pushstring(L, "SafeCallApi : exception \n" + err.ToString()); &#125; LuaDll.lua_error(L); return 0;&#125; 技能模块角色模块动画模块状态模块CD模块状态模块场景模块子物体模块同屏系统每个场景里一般都有很多对象，对其中一个对象而言，它一般只关注自己周围一定范围内的其它对象。同屏系统的主要工作就是将对象周围一定范围内的其它对象精确且高效的统计，为客户端的表现以及其它系统提供服务。 我们采取的思想是每个对象维护了一个同屏信息，同屏信息主要包括同屏对象列表和同屏玩家列表。 导致同屏信息表改变的原因主要有三个：新对象进入场景，对象位置改变，对象离开场景。针对以上三种原因我们采取了两种实现机制：定时更新机制，立刻更新机制。立刻更新机制： 主要针对对象离开场景的情况。 实现步骤主要是根据离开对象记录的同屏信息，再相关联对象和自己的同屏信息内相互去掉。定时更新机制： 主要针对对象进入场景和对象位置改变两个原因。 针对对象进入场景原因实现主要是对象进入场景时，设置新对象标记。然后通过定时更新实现同屏信息变化。 针对对象位置改变原因实现步骤主要是对象位置改变，设置位置变更标记。然后通过定时更新实现同屏信息变化。 定时更新机制是每个tick对场景内所有本tick进行过位置变化或者新进入的对象进行同屏信息更新。更新的主要逻辑是再同屏信息内的对象若离开同屏则进行清除和未在同屏信息内的玩家若满足进入同屏则加入。 由于定时更新使用频繁且实现复杂，因此采取了搞笑的实现方法来实现这个功能。由于定时更新需要检测哪些对象进入同屏，如果整个检测整个场景内的对象，比较费，由此提出了单元格概念(CellSpace)，就是把场景划分N * N的格子，每个各自作为一个单元格，单元格内维护对象列表。然后再根据玩家的同屏距离，首先获得所在的单元戈，再判断对应单元格的对象是否进入对象同屏，减少判断数量。 游戏专用子系统武器、道具、游戏专用渲染地形渲染、水体模拟及渲染玩家机制状态机及动画、相对摄像机的操控（HID）、碰撞流行、移动游戏摄像机固定设想、脚本/动画摄像机、跟踪玩家摄像机、调试用飞行摄像机人工智能目标及决策、动作（引擎接口）、视线追踪及感知、路径搜寻（A* ）前端平视显示器（HUD）、全动视频（FMV）、游戏内置电影（IGC）、游戏内置GUI、游戏内置菜单、包裹/吸引模式视觉效果光照贴图及动态阴影、高动态光照、PRT光照此表面散射、粒子及贴花系统、后处理效果、环境贴图场景图/剔除优化空间部分（BSP树）、遮挡及潜在可见集、纹理及表面管理、调试绘图（直线等）、图形设备接口性能剖析及调试录影及回放、内存及性能统计、游戏内菜单或控制台游戏性基础高层次的游戏流程系统/FSM脚本系统静态世界元素、动态游戏对象模型、实时基于代理人模拟、时间/信息系统、世界载入/串流骨骼动画动画状态树及蹭、反向动力学（IK）层阶式物体依附、游戏专用的后期处理、线性插值、动画播放、子骨骼播放、动画解压、骨骼网格渲染、布娃娃物理在线多人安排比赛及游戏管理、对象管辖权策略、游戏状态复制音频DSP/效果、三维音频模型、音频播放/管理低阶渲染器材质及着色器、静态及动态光源、摄像机、文本及字体、几何图元提交、视区及虚拟屏幕、纹理及表面管理、调试绘图（直线等）、图形设备接口碰撞及物理力及约束、光线/形状投影（查询）、刚体、Phantom、形状/可碰撞体、物理/碰撞世界人体学接口设备（HID）游戏专用接口、物理设备I/O资源（游戏资产）三维模型资源、纹理资源、材质资源、字体资源、骨骼资源、碰撞资源、物理参数、游戏世界/地图、其他核心系统模块启动及终止、断言、单元测试、内存分配、数学库、字符串及散列字符串标识符、调试用打印及日志、本地化服务、影片播放器、语法分析器（CSV、XML等）、性能剖析/统计采集、引擎配置（INI文件等）、随机数生成器、曲线及曲圆库、RITI/反射/序列化、对象句柄/唯一标识符、异步文件I/O平台独立层平台检测、原子数据类型、集合及迭代器、文件系统、网络传播层（UDP/TCP）、高分辨率时钟、线程库、图形包裹类、物理/碰撞包裹类第三方软件开发包DirectX\OpenGL、Boost、STL/STLPort]]></content>
      <tags>
        <tag>Unity</tag>
        <tag>MMORPG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.Net .Net Framework mono]]></title>
    <url>%2F2018%2F04%2F18%2FNet-Net-Framework-mono%2F</url>
    <content type="text"><![CDATA[.net从一个抽象上来说其实是一个理念，使多种语言编写的程序能够通过一个通用的Runtime运行在不同的操作系统及硬件平台上。比如.net framework是在windows上实现的.net platform,mono是一个跨平台的.net platform一个.net platform想到达到.net的目标，就需要一些组件，比如CLR(Common Language Runtime),比如FCL基础类库，比如各种语言编译器，编译器编译出来的东西想要在CLR中运行，那也需要遵循一定的标准，这就是CLI和CIL，CIL规定了编译输出的规则，而CLI规定了编译器输入语言的规则，只有符合这种标准的语言才能编译成CIL语言运行在CLR中。好了现在有CIL和CLR，可以用符合CLI的语言比如C#编写程序了，然后将其编译成CIL，最后在CLR中运行Unity能跨平台的原因就是实现了各个平台的”即时编译器”(C#代码-&gt;中间语言-&gt;各个平台的原生代码)]]></content>
  </entry>
  <entry>
    <title><![CDATA[减少装箱(Boxing)和拆箱(UnBoxing)操作]]></title>
    <url>%2F2018%2F04%2F17%2FC-0%2F</url>
    <content type="text"><![CDATA[.Net的类型分值类型和引用类型，这两个类型的本质区别，值类型数据是分配在栈中，而引用类型数据分配在堆上，那么如果要把一个值类型数据放到堆上，就需要装箱操作；反之，把一个放在堆上的值类型数据取出来，则需要拆箱操作。减少装箱和拆箱操作的好处 对于堆的操作效率比较低 堆上分配的内存资源，需要GC来回收，从而降低程序效率 格式化操作有较多的装箱拆箱操作，比如String.Format, Console.WriteLine之类的语句， Console.WriteLine(&quot;Number list:{0}, {1}, {2}&quot;, 1.ToString(), t.2ToString(), 3.ToString()) 由于1.ToString()的结果是String类型，属于引用类型，因此不涉及装箱拆箱操作；]]></content>
      <tags>
        <tag>C#</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity ECS Readme]]></title>
    <url>%2F2018%2F04%2F17%2FUnity-ECS-README%2F</url>
    <content type="text"><![CDATA[Entitas - The Entity Component System Framework for C# and UnityEntitas is a super fast Entity Component System Framework (ECS) specifically made for C# and Unity. Internal caching and blazing fast component access makes it second to none. Several design decisions have been made to work optimal in a garbage collected environment and to go easy on the garbage collector. Entitas comes with an optional code generator which radically reduces the amount of code you have to write and makes your code read like well written prose. » Download» Documentation» Ask a question» Wiki and example projects» #madeWithEntitas Video Tutorials &amp; Unity Unite Talks Entitas ECS Unity Tutorial Entitas ECS Unity Tutorial Entity system architecture with Unity ECS architecture with Unity by example Setup &amp; Basics Git &amp; Unit Tests » Open the slides on SlideShare: Unite Europe 2015 » Open the slides on SlideShare: Unite Europe 2016 First glimpseThe optional code generator lets you write code that is super fast, safe and literally screams its intent. 123456789public static GameEntity CreateRedGem(this GameContext context, Vector3 position) &#123; var entity = context.CreateEntity(); entity.isGameBoardElement = true; entity.isMovable = true; entity.AddPosition(position); entity.AddAsset("RedGem"); entity.isInteractive = true; return entity;&#125; 123456var entities = context.GetEntities(Matcher&lt;GameEntity&gt;.AllOf(GameMatcher.Position, GameMatcher.Velocity));foreach(var e in entities) &#123; var pos = e.position; var vel = e.velocity; e.ReplacePosition(pos.value + vel.value);&#125; OverviewEntitas is fast, light and gets rid of unnecessary complexity. There are less than a handful classes you have to know to rocket start your game or application: Entity Context Group Entity Collector Read more… Code GeneratorThe Code Generator generates classes and methods for you, so you can focus on getting the job done. It radically reduces the amount of code you have to write and improves readability by a huge magnitude. It makes your code less error-prone while ensuring best performance. I strongly recommend using it! Read more… Unity integrationThe optional Unity module integrates Entitas nicely into Unity and provides powerful editor extensions to inspect and debug contexts, groups, entities, components and systems. Read more… Entitas deep diveRead the wiki or checkout the example projects to see Entitas in action. These example projects illustrate how systems, groups, collectors and entities all play together seamlessly. Download EntitasEach release is published with zip files containing all source files you need. Show releases Thanks toBig shout out to @mzaks, @cloudjubei and @devboy for endless hours of discussion and helping making Entitas awesome! Maintainer(s) @sschmid | @s_schmid | @entitas_csharp Different language?Entitas is available in C# Swift C++ Objective-C Java Python Scala Go F# TypeScript Kotlin Haskell Erlang Clojure]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity ECS]]></title>
    <url>%2F2018%2F04%2F16%2FUnity-Coroutine%2F</url>
    <content type="text"><![CDATA[CoroutinesWaitForENdOffFrame 帧末尾执行yield return null 表示暂缓一帧，在下一帧接着往下处理，于yield return 0 或 yield return 1一样的功能yield return new WaitForSeconds协程的真正用途是分布做一个比较耗时的事情，比如游戏里面的加载资源 Unity面对的问题 面向对象的编程方式（曾经的圣典，已经跟不上时代，OOP最大的问题是数据和逻辑混在一起，而现在我们要数据驱动模型） 由Mono编译的非最优机器码 GC机制 单线程开发 工作流程 创建一个GameObject对象； 在对象上添加组件：Renderer，Collider，Rigidbody physics； 创建MonoBehaviour脚本并将其添加到对象中，以便在运行时控制和更改这些组件的状态属性； 以上3个步骤执行，我们成为Unity的执行流程，作为Unity开发者来说，这个是最基本的流程。但是这种做法有它自己的缺点和性能问题。比如数据和逻辑是紧密耦合的，这意味着代码重用的频率比较低，因为逻辑与特定数据相关联，无法单独分离出来。例如下图所示的GameObject和Components实例中，GameObject依赖于Transform、Renderer、Rigidbody和Collder引用，这些脚本中的引用对象分散在堆内存中。 游戏对象、其行为及其组件之间的内存引用： Unity GameObject场景可以让游戏在非常短的时间内完成原型构建并运行，这个也是Unity的特色可以让开发者快速入手，但它对于性能来说不太理想。我们在深层次的探讨这个问题，每个引用类型都包含可能不需要访问的许多额外数据，这些未使用的成员也占用了处理器缓存中的宝贵空间。比如我们继承的Mono就是一个典型的案例，如果只需要现有组件的极少功能接口函数或者变量，则可以将其余部分视为浪费空间，如下面的“浪费空间”图所示： 在上图中，粗体表示实际用于移动操作的成员，其余的就是浪费空间，若要移动GameObject，脚本需要从Transform组件访问位置和旋转数据成员。当硬件从内存中获取数据时，缓存航中会填充许多可能无用的数据，如果只是为所有应该移动的GameObjects设置一个只有位置和旋转成员的阵列，这将能够在很短的时间内执行，如何去掉无用的数据？ECS就是味解决此问题而设计的。 ECS实体组件系统Unity的新实体组件系统可帮助消除低效的对象引用，我们考虑只包含它所需数据的实体，而不考虑自带集合的GameObjects。在下面的实体组件系统中，请注意Bullet实体没有附件Transform或Rigidbody组件，Bullet实体只是显示运行更新所需的原始数据，借助这个新系统，您可以将逻辑与各个对象类型完全分离。 这个系统具有很大的优势：它不仅可以提供缓存效率，缩短访问时间；它还支持在需要使用这种数据对齐方式的现代CPU中采用先进技术（自动矢量化/SIMD）这为游戏提供了所需的默认性能。如下图所示： 上图请注意缓冲行存储中的碎片和继承Mono系统生成的空间浪费，数据对比如下所示： 上图是将与单个移动操作相关的内存空间与实现系统目标的两个操作进行对比的结果。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Manual]]></title>
    <url>%2F2018%2F04%2F16%2FUnity-Manual%2F</url>
    <content type="text"><![CDATA[public static float Mathf.Round(float f) 四舍五入 DisallowMultipleComponent 禁止一个脚本被加载多次 YieldInstruction 中断指令所有yield指令的基类参考WaitForSeconds, WaitForFixedUpdate, Coroutine and MonoBehaviour,StartCoroutine WaitForSeconds 等待几秒Namespace: UnityEngineInherits from: YieldInstruction 在给定的秒数内，暂停协同程序的执行。WaitForSeconds只能用在协同程序中的yield声明。 RequireComponent当你添加了一个用了RequireComponent组件的脚本，需要的组件将会自动被添加到GameObject上。这个可以有效避免组装错误。在新建类的前面加 [RequireComponent(typeof(LineRenderer))] AssetDatabase.ImportAssetstatic function ImportAsset(path : string, options : ImportAssetOptions = ImportAssetOptions.Default):void 导入指定路径的资源所有路径都是相对于工程目录文件，例如”Assets/MyTexture/hello.png” AssetImporter.GetAtPathstatic function GetAtPath(path: string):AssetImporter 通过指定路径来导入资源 TextureWrapMode在进行纹理贴图时，图像会出现在物体表面(u,v)位置上，而这些值在[0.0,1.0]范围内。但是，如果超出这个范围，会发生什么情况呢，这由纹理的映射函数来决定.常见有下面几种： 重复(REPEAT):图像在表面上重复出现。在算法上，忽略纹理坐标的整数部分，并将纹理图的拷贝粘贴在物体表面上。对于大多数复制纹理的使用，在纹理顶部的纹理单元应于底部的纹理单元相匹配，在纹理左侧的纹理单元也应于右侧的纹理单元相匹配。 截取(CLAMP): 将大于1.0的数值设置为1.0，将小于0.0的数值设置为0.0，即将超出[0.0,1.0]范围的数值截取到[0.0,1.0]范围内，这样会导致纹理边缘的重复。 镜像重复(MIRRORED_REPEAT_ARB) 边界截取(CLAMP_TO_BORDER_ARB) 边缘截取(CLAMP_TO_EDGE) CameraClearFlag12345678public enum CameraClearFlags&#123; Skybox = 1, // 这是默认设置，在屏幕上空的部分显示当前相机的天空盒。如果当前相机没有设置天空盒，它会默认使用Edit-&gt;Render Settings里)中选择天空盒。然后它将退回使用背景颜色，另外天空盒组件可以添加到相机上。 SolidColor = 2, // 屏幕上的任何空的部分显示当前相机的背景颜色 Color = 2, Depth = 3, // 该深度的东西永远都不会被裁剪 Nothing = 4, // 什么事情都不做&#125; ProjectornearClipPlane 近裁剪面的距离 farClipPlane 远裁剪面的距离 fieldOfView 该投影的视野，以度为单位 aspectRatio 投影的宽高比 orthographic 投射是正交还是透视 orthographicSize 在正交模式下投射的一半尺寸 ignoreLayers 哪个物体层被这个投射器忽略 material 要投射到每个物体的材质 MeshMesh.RecalculateBounds在修改完顶点后你应该用这个函数以确保包围体是恰当的。赋值三角形将自动重新计算包围体。 Mesh.RecalculateNormals重新计算网格的法线在修改完定点后，通常会更新发现来反映新的变化。发现是根据共享的顶点计算出来的。导入到网格有时不共享所有顶点。例如：一个顶点在一个纹理坐标的接缝处将会被分为两个顶点。因此这个RecalculateNormals函数将会在纹理坐标接缝处创建一个不光滑的法线。RecalculateNormals不会自动产生切线，因此bumpmap着色器在调用RecalculateNormals之后不会工作。然而你可以提取你自己的切线。 惯性坐标系因为在进行物体到世界坐标系的转换时候，即需要平移同时也需要进行旋转，为了简化这种变化，在其中假如惯性坐标系，其中惯性坐标系的原点与本地坐标系的原点重合其轴和世界坐标系平英。那么本地坐标系到惯性坐标系只需要旋转操作（之前也得缩放）再到世界坐标系只需要进行平移。 构建AssetBundles在AssetBundle工作流的文档中，我们有一个代码示例，它将三个参数传递给BuildPipeline.BuildAssetBundles函数。让我们更深入实际的了解。Assets/AssetBundles:这是AssetBundles输出的目录。您可以将其更改为您想要的任何输出目录，只需确保在尝试构建之前文件夹实际存在。 BuildAssetBundleOptionsBuildAssetBundleOptions您可以指定几种具有各种效果的不同。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity优化]]></title>
    <url>%2F2018%2F04%2F12%2FUnity-Optimize%2F</url>
    <content type="text"><![CDATA[更新不透明贴图的压缩格式为ETC 4bit，因为android市场的手机中的GPU有多种，每家的GPU支持不同的压缩格式，但他们都兼容ETC格式。 对于透明贴图，我们只能选择RGBA 16bit 或者RGBA 32bit。 减少FPS，在ProjectSetting-&gt; Quality中的VSync Count 参数会影响你的FPS，EveryVBlank相当于FPS=60，EverySecondVBlank = 30；这两种情况都不符合游戏的FPS的话，我们需要手动调整FPS，首先关闭垂直同步这个功能，然后在代码的Awake方法里手动设置FPS（Application.targetFrameRate = 45;）降低FPS的好处：1）省电，减少手机发热的情况；2）能都稳定游戏FPS，减少出现卡顿的情况。 当我们设置了FPS后，再调整下Fixed timestep这个参数，这个参数在ProjectSetting-&gt;Time中，目的是减少物理计算的次数，来提高游戏性能。 尽量少使用Update LateUpdate FixedUpdate，这样也可以提升性能和节省电量。多使用事件（不是SendMessage，使用自己写的，或者C#中的事件委托）。 待机时，调整游戏的FPS为1，节省电量。 图集大小最好不要高于1024，否则游戏安装之后、低端机直接崩溃、原因是手机系统版本低于2.2、超过1000的图集无法读取、导致。2.2 以上没有遇见这个情况。注意手机的RAM 与 ROM、小于 512M的手机、直接放弃机型适配。 VSCount 垂直同步Unity3D中新建一个空场景的时候，帧速率（FPS总是很低），大概在60~70之间。在Unity3D中当运行场景打开Profiler的时候，我们会看到VSync 这一项占了很大的比重。这个是什么呢，这个就是垂直同步。我们可以关闭VSync来提高帧速率，选择edit-&gt;project settings-&gt;Quality。在右侧面板中可以找到VSync Count,把它选成Don’t Sync。这就关闭了VSync(垂直同步)，现在在运行场景看看，帧速率是不是提高很多。现在来说说什么是垂直同步，要知道什么是垂直同步，必须要先明白显示器的工作原理，显示器上的所有图像都是一线一线的扫描上去的，无论是隔行扫描还是逐行扫描，显示器都有两种同步参数——水平同步和垂直同步。 什么叫水平同步？什么叫垂直同步？垂直和水平是CRT中两个基本的同步信号，水平同步信号决定了CRT画出一条横越屏幕线的时间，垂直同步信号决定了CRT从屏幕顶部画到底部，再返回原始位置的时间，而恰恰是垂直同步代表着CRT显示器的刷新率水平。 为什么关闭垂直同步信号会影响游戏中的FPS数值？如果我们选择等待垂直同步信号（也就是我们平时所说的垂直同步打开），那么在游戏中或许强劲的显卡迅速的绘制完一屏的图像，但是没有垂直同步信号的到达，显卡无法绘制下一屏，只有等85单位的信号到达，才可以绘制。这样FPS自然要受到操作系统刷新率运行值的制约。 而如果我们选择不等待垂直同步信号（也就是我们平时所说的关闭垂直同步），那么游戏中作完一屏画面，显卡和显示器无需等待垂直同步信号就可以开始下一屏图像的绘制，自然可以完全发挥显卡的实力。但是不要忘记，正是因为垂直同步的存在，才能使得游戏进程和显示器刷新率同步，使得画面更加平滑和稳定。取消了垂直同步信号，固然可以换来更快的速度，但是在图像的连续性上势必打折扣。这也正是很多朋友抱怨关闭垂直后发现画面不连续的理论原因。 合并材质球Unity3D中每导入一次模型就多一个材质球，可我的这些模型都是共用一张贴图的就想共用一个材质球，所以每次都要删除再附上，很麻烦。怎么才能合并这些材质球？采用TexturePacking吧 遍历gameobject，取出material，并根据shader来将material分类； 调用Unity自带的PackTextures函数来合并每个shader分类中的material所对应的textures（PackTextures函数有缺陷，不过可以将就用）； 根据合并的大的texture来更新原有模型的texture、material已经uv坐标值。 需要注意的是：需要合并的纹理应该是物体在场景中距离相近的，如果物体在场景中的距离较远，则不建议合并纹理，因为这样做很有可能非但起不到优化的作用，反而降低了运行效率。 mesh合并分为2种方式合并 自带的合并必须勾选静态。 所有被勾选了“Static”的GameObject，其中的Mesh Filter中的mesh都会被合并到 “Combined Mesha (root: scene)” 中 也可以用脚本来合并mesh 。 12345678910111213141516171819202122using UnityEngine;using System.Collections; public class MyClass : MonoBehaviour&#123; void Start () &#123; MeshFilter [] meshFilters = GetComponentsInChildren&lt;MeshFilter&gt; (); CombineInstance[] combine = new CombineInstance[meshFilters.Length]; for(int i = 0; i &lt; meshFilters.Length; i++) &#123; combine[i].mesh = meshFilters[i].sharedMesh; combine[i].transform = meshFilters[i].transform.localToWorldMatrix; meshFilters[i].gameObject.active = false; &#125; transform.GetComponent&lt;MeshFilter&gt;().mesh = new Mesh (); transform.GetComponent&lt;MeshFilter&gt;().mesh.CombineMeshes (combine); transform.gameObject.active = true; &#125;&#125; 先在 Unity 中建立空物件 ( Empty ) 再创建2个 Cube 方块，并放入空物件底下 (可以改成你自己的模型) 把 MyClass 代码丟进空物件上 。 (可选) 建立一个 Material 材质，并且丢进空物件上 执行 角色Material数量2-3个，骨骼数量小于30个，面片数量300-1500，一般角色应该没有IK结点这是因为角色的动作大多数都是事先设定好的，并不需要经过IK操作来进行实时计算（Rogdoll除外），所以在模型导入时，不要将IK结点一起导入。 静态实体不要附加Animation Component在静态实体上附加Animation部件虽然对结果没有影响，但却会增加一定的CPU开销来调用这一组件，所以尽量去掉该组件。网格顶点数小于500；UV值范围尽量不要超过（0, 1）区间；尽量保证UV值不越界，这对于将来的纹理拼合优化很有帮助。 地形地形的分辨率大小长宽均尽量小于257。这是因为地形太大，会造成大量顶点数据，给你的内存带宽造成一定的影响，在目前的ios设备中，内存带宽是非常有限的，需要尽量节省。同时，如果用Unity自带的地形，一定也要使用Occlusion Culling，因为Unity的刷地形工具虽然方便，但却是framekiller，刷过之后，你会发现drawcall增加的非常多。混合纹理数量不要超过4。地形的混合操作是很耗时的，应该尽量避免。能合并的纹理尽量合并。 纹理 纹理格式建议png或tga。不用转成ios硬件支持的PVRTC格式，因为Unity在发布时会帮你自动转的。 纹理尺寸长宽小于1024。同时应该尽可能地小，够用就好，以保证纹理对内存带宽的影响达到最小。 支持Mipmap（UI不需要转，不然会增大内存）建议生成Mipmap。虽然这种做法会增加一些应用程序的大小，但在游戏运行时，系统会根据需求应用Mipmap来渲染，从而减少内存带宽。 检查Alpha值如果纹理的alpha通道均为1，则用RGB的24位纹理来代替RGBA的32位纹理。（据说Unity内部会进行自动检测） 光源光源“Important”个数建议1个，一般为方向光。“Important”个数应该越小越少。个数越多，drawcall越多。Pixel Light数目1-2个。 粒子特效屏幕上的最大粒子数建议小于200个粒子。每个粒子发射器发射的最大粒子数建议不超过50个。粒子大小如果可以的话，粒子的size应该尽可能地小。因为Unity的粒子系统的shader无论是alpha test还是alpha blending都是一笔不小的开销。同时，对于非常小的粒子，建议粒子纹理去掉alpha通道。尽量不要开启粒子的碰撞功能。非常耗时。 音频游戏中播放时间较长的音乐（如背景音乐）使用.ogg或.mp3的压缩格式。较短音乐（如枪声）使用.wav和.aif的未压缩音频格式。 相机裁剪平面将远平面设置成合适的距离。远平面过大会将一些不必要的物体加入渲染，降低效率。根据不同的物体设置不同的远裁剪平面Unity提供了可以根据不同的layer来设置不同的view distance，所以我们可以实现将物体进行分层，大物体层设置的可视距离大些，而小物体层可以设置地小些，另外，一些开销比较大的实体（如粒子系统）可以设置得更小些等等。 碰撞尽量不用MeshCollider如果可以的话，尽量不用MeshCollider，以节省不必要的开销。如果不能避免的话，尽量用减少Mesh的面片数，或用较少面片的代理体来代替。 其他Drawcall尽可能地减少Drawcall的数量。IOS设备上建议不超过100。减少的方法主要有如下几种：Frustum Culling，Occlusion Culling，Texture Packing。Frustum Culling是Unity内建的，我们需要做的就是寻求一个合适的远裁剪平面；Occlusion Culling，遮挡剔除，Unity内嵌了Umbra，一个非常好OC库。但Occlusion Culling也并不是放之四海而皆准的，有时候进行OC反而比不进行还要慢，建议在OC之前先确定自己的场景是否适合利用OC来优化；Texture Packing，或者叫Texture Atlasing，是将同种shader的纹理进行拼合，根据Unity的static batching的特性来减少draw call。建议使用，但也有弊端，那就是一定要将场景中距离相近的实体纹理进行拼合，否则，拼合后很可能会增加每帧渲染所需的纹理大小，加大内存带宽的负担。这也就是为什么会出现“DrawCall降了，渲染速度也变慢了”的原因。 非运动物体尽量打上Static标签Unity在运行时会对static物体进行自动优化处理，所以应该尽可能将非运行实体勾上static标签。 场景中尽可能地使用prefab尽可能地使用prefab的实例化物体，以降低内存带宽的负担。检查实体的PrefabType，尽量将其变成PrefabInstance，而不是ModelPrefabInstance。 移动平台相对于PC机，具有体积小，计算弱，带宽少的特点。 因此做手机游戏的开发，优化的方向，与力度对比PC游戏都有所区别。 必须要做到优化流程，合理利用资源。目前在手机上面，还不能够像PC游戏那样追求高质量渲染效果，为了让手机不那么容易发烫，还要控制cpu，gpu，不能让他们全速运算。 材质方面：纹理方面，建议使用压缩纹理， Android上面使用ETC1，苹果上面使用PVRTC。UV坐标控制在0到1之间，人物模型面数控制在1500内，骨骼控制在30个以内。场景中使用一个主光（不能再多了）。尽量减少alphaTest和alphaBlend材质的使用。在手机上，这是很杀效率的。骨骼动画方面：在动画方面可以考虑不使用插值，固定的帧率的动画。 如果要做插值，考虑使用四元数（表示旋转）和向量（表示位移）来做插值。 四元数做插值速度比矩阵来的快，Slerp提供了平滑插值。 优化的常规技巧剖析你的游戏。不要花费时间来优化那些晦涩的代码或者缩减图形文件的大小，除非这是你游戏的瓶颈。第一次剖析你的游戏将会使你发现你游戏的瓶颈。Apple’s Shark是一个很好的用来剖析基于OpenGL的程序的工具。再次剖析你的游戏。优化之后不要忘记再剖析一次你的游戏，这样可以检查你所做的优化是否达到了预期的效果。当然，这样做也可能会使你发现更多的瓶颈。流程第一、性能第二。花费时间来使你游戏的创建尽可能地流畅。尽可能快地修正游戏中的错误将会使你后期更容易优化你的游戏。在Scene View中测试场景。这样做将会使你清楚了解这个场景中的物体或者附加在物体上的脚本是否降低了游戏性能。如果Scene View反应迟钝，那么有可能是图形方面的原因，如果Scene View反应不迟钝，那么瓶颈可能出在脚本或者物理系统上。禁用指定游戏物体。在play模式下，尝试禁用并启用游戏物体来排查出游戏慢的原因。 网格如果可能的话，把相邻的物体（网格）合并为一个只有一个材质的物体（网格）。比如，你的游戏中包含一个桌子，上面有一堆东西，你完全可以在3D程序中将它们合并在一起（这可能也需要你将这些物体的纹理合并为一个大的纹理集）。减少需要渲染的物体的数量可以极大地提高游戏性能。 不要有不必要的网格。如果你的游戏场景中有一个人物，那么他应该是一个网格。如果你有一个船，那么它也应该只是一个网格。每一个网格只用一种材质。使用极少的面数的网格（比如500个多边形以下）。最好把你人物的三角面数量控制在1500-2000个之间。这个数量可以说是游戏质量和性能之间一个均衡值。如果你的模型有四边形，那么在导入模型的时候，引擎将会把每个四边形变为两个三角形。 光照像素光。像素光可以让你的游戏看起来效果很牛逼，但是不要使用过多的像素光。在你的游戏中可以使用质量管理器来调节像素光的数量来取得一个性能和质量的均衡点. 性能占用顺序：聚光灯&gt;点光源&gt;平行光。一个好的点亮场景的方法就是先得到你想要的效果，然后看看哪些光更重要；在保持光效的前提下看看哪些光可以去掉。 点光源和聚光灯只影响它们范围内的网格。如果一个网格处于点光源或者聚光灯的照射范围之外，并且光源的attenuate开关是打开的，那么这个网格将不会被光源所影响，这样就可以节省性能开销。这样做理论上来讲可以使用很多小的点光源而且依然能有一个好的性能，因为这些光源只影响一小部分物体。一个网格在有8个以上光源影响的时候，只响应前8个最亮的光源。 贴图在外观不变的前提下，贴图大小越小越好。如果你的显卡的显存不够大的话，你游戏中的贴图将会被转存到系统内存中，在显卡调用它们的时候再传到显卡中。对于比较新的电脑来说，内存和显卡之间有足够的带宽来达到一个很好的性能；如果你很无耻地用了巨多的大图片的话，在低显存的电脑上运行你的游戏的时候，你的游戏必然会挂掉。倒是没有必要在图形编辑软件中调整贴图的大小。你可以在unity导入贴图的时候进行调整。 不要使用低质量的图片。在小播放界面的游戏中使用低质量的jpeg图片或者低色彩的png图片亦或是gif图片没什么问题。在发布游戏的时候，引擎会自动压缩这些图片，多重压缩和解压将会降低图片的质量，所以最好保持贴图文件的分辨率为原始分辨率。这样就会减少多重压缩和解压所导致的图片失真现象。 Shaders多重效果的shader就比看起来样式很单一的shader要更耗费资源。同样在一个拥有贴图和光反射的物体上，使用VertexLit Diffuse shader无疑是最省资源的。 在美术制作场景的过程中，会使用到大量的粒子系统。比如场景中的火把。在我们的一个地下城场景中，美术们放置了大量的火把。整个场景中的各个地方，有100来个火把。 unity中，在摄像机范围外的粒子系统虽然不会被绘制。但是update是一直持续的。这也就意味着，这100多个火把，不论是否可见都在更新。 这个设计应该是很不合理的，在我看过的其他引擎中，都会有一个开关，来控制不可见的粒子系统是否需要update。有的粒子系统在不可见的时候需要更新,比如爆炸。有的不需要更新，比如火堆火把。 为了避免不必要的update开销，尤其是最后游戏是要发布到页游平台（web player只能使用一个cpu的核）。于是写了一个脚本，控制不可见的粒子系统就不更新。 该脚本主要是用到了2个MonoBehaviour的函数。OnBecameInvisible() 当变为不可见 和 OnBecameVisible() 当变成可见。 要这2个函数起作用的前提是，该GameObject绑定了MeshRender组件。所以，我们要在粒子系统的GameObject放置在一个GameObject 下，且给该GameObject绑定一个MeshRender 与 MeshFilter。MeshFilter中的mesh可以随便找个cube。 在Start（） 的时候，把最GameObject的scale设置为很小，以保证该cube不被看见。其实遍历所有的child，把active设置为false。 在OnBecameVisible 中 遍历所有child，把active设置为true。在OnBecameInvisible中 遍历所有child，把active设置为false。 Unity 性能优化 Draw Call Unity（或者说基本所有图形引擎）生成一帧画面的处理过程大致可以这样简化描述：引擎首先经过简单的可见性测试，确定摄像机可以看到的物体，然后把这些物体的顶点（包括本地位置、法线、UV等），索引（顶点如何组成三角形），变换（就是物体的位置、旋转、缩放、以及摄像机位置等），相关光源，纹理，渲染方式（由材质/Shader决定）等数据准备好，然后通知图形API——或者就简单地看作是通知GPU——开始绘制，GPU基于这些数据，经过一系列运算，在屏幕上画出成千上万的三角形，最终构成一幅图像。 在Unity中，每次引擎准备数据并通知GPU的过程称为一次Draw Call。这一过程是逐个物体进行的，对于每个物体，不只GPU的渲染，引擎重新设置材质Shader也是一项非常耗时的操作。因此每帧的Draw Call次数是一项非常重要的性能指标，对于iOS来说应尽量控制在20次以内，这个值可以在编辑器的Statistic窗口看到。 Unity内置了Draw Call Batching技术，从名字就可以看出，它的主要目标就是在一次Draw Call中批量处理多个物体。只要物体的变换和材质相同，GPU就可以按完全相同的方式进行处理，即可以把它们放在一个Draw Call中。Draw Call Batching技术的核心就是在可见性测试之后，检查所有要绘制的物体的材质，把相同材质的分为一组（一个Batch），然后把它们组合成一个物体（统一变换），这样就可以在一个Draw Call中处理多个物体了（实际上是组合后的一个物体）。 但Draw Call Batching存在一个缺陷，就是它需要把一个Batch中的所有物体组合到一起，相当于创建了一个与这些物体加起来一样大的物体，与此同时就需要分配相应大小的内存。这不仅会消耗更多内存，还需要消耗CPU时间。特别是对于移动的物体，每一帧都得重新进行组合，这就需要进行一些权衡，否则得不偿失。但对于静止不动的物体来说，只需要进行一次组合，之后就可以一直使用，效率要高得多。 Unity提供了Dynamic Batching和Static Batching两种方式。Dynamic Batching是完全自动进行的，不需要也无法进行任何干预，对于顶点数在300以内的可移动物体，只要使用相同的材质，就会组成Batch。Static Batching则需要把静止的物体标记为Static，然后无论大小，都会组成Batch。如前文所说，Static Batching显然比Dynamic Batching要高效得多 要有效利用Draw Call Batching，首先是尽量减少场景中使用的材质数量，即尽量共享材质，对于仅纹理不同的材质可以把纹理组合到一张更大的纹理中（称为Texture Atlasing）。然后是把不会移动的物体标记为Static。此外还可以通过CombineChildren脚本（Standard Assets/Scripts/Unity Scripts/CombineChildren）手动把物体组合在一起，但这个脚本会影响可见性测试，因为组合在一起的物体始终会被看作一个物体，从而会增加GPU要处理的几何体数量，因此要小心使用。 对于复杂的静态场景，还可以考虑自行设计遮挡剔除算法，减少可见的物体数量同时也可以减少Draw Call。 总之，理解Draw Call和Draw Call Batching原理，根据场景特点设计相应的方案来尽量减少Draw Call次数才是王道，其它方面亦然。 Draw Call Batching （绘制调用批处理） To draw an object on the screen, the engine has to issue a draw call to the graphics API (OpenGL ES in the case of iOS). Every single draw call requires a significant amount of work on the part of the graphics API, causing significant performance overhead on the CPU side.在屏幕上渲染物体，引擎需要发出一个绘制调用来访问图形API（iOS系统中为OpenGL ES）。每个绘制调用需要进行大量的工作来访问图形API，从而导致了CPU方面显著的性能开销。 Unity combines a number of objects at runtime and draws them together with a single draw call. This operation is called “batching”. The more objects Unity can batch together, the better rendering performance you will get.Unity在运行时可以将一些物体进行合并，从而用一个绘制调用来渲染他们。这一操作，我们称之为“批处理”。一般来说，Unity批处理的物体越多，你就会得到越好的渲染性能。 Built-in batching support in Unity has significant benefit over simply combining geometry in the modeling tool (or using theCombineChildren script from the Standard Assets package). Batching in Unity happensafter visibility determination step. The engine does culling on each object individually, and the amount of rendered geometry is going to be the same as without batching. Combining geometry in the modeling tool, on the other hand, prevents effecient culling and results in much higher amount of geometry being rendered.Unity中内建的批处理机制所达到的效果要明显强于使用几何建模工具（或使用Standard Assets包中的CombineChildren脚本）的批处理效果。这是因为，Unity引擎的批处理操作是在物体的可视裁剪操作之后进行的。Unity先对每个物体进行裁剪，然后再进行批处理，这样可以使渲染的几何总量在批处理前后保持不变。但是，使用几何建模工具来拼合物体，会妨碍引擎对其进行有效的裁剪操作，从而导致引擎需要渲染更多的几何面片。 Materials材质Only objects sharing the same material can be batched together. Therefore, if you want to achieve good batching, you need to share as many materials among different objects as possible.只有拥有相同材质的物体才可以进行批处理。因此，如果你想要得到良好的批处理效果，你需要在程序中尽可能地复用材质和物体。 If you have two identical materials which differ only in textures, you can combine those textures into a single big texture - a process often calledtexture atlasing. Once textures are in the same atlas, you can use single material instead.如果你的两个材质仅仅是纹理不同，那么你可以通过纹理拼合操作来将这两张纹理拼合成一张大的纹理。一旦纹理拼合在一起，你就可以使用这个单一材质来替代之前的两个材质了。 If you need to access shared material properties from the scripts, then it is important to note that modifyingRenderer.material will create a copy of the material. Instead, you should useRenderer.sharedMaterial to keep material shared.如果你需要通过脚本来访问复用材质属性，那么值得注意的是改变Renderer.material将会造成一份材质的拷贝。因此，你应该使用Renderer.sharedMaterial来保证材质的共享状态。 Dynamic Batching动态批处理Unity can automatically batch moving objects into the same draw call if they share the same material.如果动态物体共用着相同的材质，那么Unity会自动对这些物体进行批处理。 Dynamic batching is done automatically and does not require any additional effort on your side.动态批处理操作是自动完成的，并不需要你进行额外的操作。 Tips:提醒：1、Batching dynamic objects has certain overheadper vertex, so batching is applied only to meshes containing less than900 vertex attributes in total.批处理动态物体需要在每个顶点上进行一定的开销，所以动态批处理仅支持小于900顶点的网格物体。 2、If your shader is using Vertex Position, Normal and single UV, then you can batch up to 300 verts and if your shader is using Vertex Position, Normal, UV0, UV1 and Tangent, then only 180 verts.Please note: attribute count limit might be changed in future如果你的着色器使用顶点位置，法线和UV值三种属性，那么你只能批处理300顶点以下的物体；如果你的着色器需要使用顶点位置，法线，UV0，UV1和切向量，那你只能批处理180顶点以下的物体。请注意：属性数量的限制可能会在将来进行改变。 4、Don’t use scale. Objects with scale (1,1,1) and (2,2,2) won’t batch.不要使用缩放尺度（scale）。分别拥有缩放尺度(1,1,1)和(2,2,2)的两个物体将不会进行批处理。 5、Uniformly scaled objects won’t be batched with non-uniformly scaled ones.统一缩放尺度的物体不会与非统一缩放尺度的物体进行批处理。Objects with scale (1,1,1) and (1,2,1) won’t be batched. On the other hand (1,2,1) and (1,3,1) will be.使用缩放尺度(1,1,1)和 (1,2,1)的两个物体将不会进行批处理，但是使用缩放尺度(1,2,1)和(1,3,1)的两个物体将可以进行批处理。 6、Using different material instances will cause batching to fail.使用不同材质的实例化物体（instance）将会导致批处理失败。 7、Objects with lightmaps have additional (hidden) material parameter: offset/scale in lightmap, so lightmapped objects won’t be batched (unless they point to same portions of lightmap)拥有lightmap的物体含有额外（隐藏）的材质属性，比如：lightmap的偏移和缩放系数等。所以，拥有lightmap的物体将不会进行批处理（除非他们指向lightmap的同一部分）。 8、Multi-pass shaders will break batching. E.g. Almost all unity shaders supports several lights in forward rendering, effectively doing additional pass for them多通道的shader会妨碍批处理操作。比如，几乎unity中所有的着色器在前向渲染中都支持多个光源，并为它们有效地开辟多个通道。 9、Using instances of a prefab automatically are using the same mesh and material.预设体的实例会自动地使用相同的网格模型和材质。 Static Batching静态批处理 Static batching, on the other hand, allows the engine to reduce draw calls for geometry of any size (provided it does not move and shares the same material). Static batching is significantly more efficient than dynamic batching. You should choose static batching as it will require less CPU power.相对而言，静态批处理操作允许引擎对任意大小的几何物体进行批处理操作来降低绘制调用（只要这些物体不移动，并且拥有相同的材质）。因此，静态批处理比动态批处理更加有效，你应该尽量低使用它，因为它需要更少的CPU开销。 In order to take advantage of static batching, you need explicitly specify that certain objects are static and willnot move, rotate or scale in the game. To do so, you can mark objects as static using the Static checkbox in the Inspector:为了更好地使用静态批处理，你需要明确指出哪些物体是静止的，并且在游戏中永远不会移动、旋转和缩放。想完成这一步，你只需要在检测器（Inspector）中将Static复选框打勾即可；Using static batching will require additional memory for storing the combined geometry. If several objects shared the same geometry before static batching, then a copy of geometry will be created for each object, either in the Editor or at runtime. This might not always be a good idea - sometimes you will have to sacrifice rendering performance by avoiding static batching for some objects to keep a smaller memory footprint. For example, marking trees as static in a dense forest level can have serious memory impact.使用静态批处理操作需要额外的内存开销来储存合并后的几何数据。在静态批处理之前，如果一些物体共用了同样的几何数据，那么引擎会在编辑以及运行状态对每个物体创建一个几何数据的备份。这并不总是一个好的想法，因为有时候，你将不得不牺牲一点渲染性能来防止一些物体的静态批处理，从而保持较少的内存开销。比如，将浓密森里中树设为Static，会导致严重的内存开销。 Static batching is only available in Unity iOS Advanced.静态批处理目前只支持Unity iOS Advanced。 前两天，MadFinger，就是当今iOS与Android上画质最牛逼闪闪的游戏之一——ShadowGun的开发商，令人惊异地放出了一个ShadowGun的样例关卡以及若干可免费使用的Shader，国外同行们的分享精神真的是令人赞叹不已。原文在这里，以下是我的一些摘录和笔记。 首先是一些优化常识。针对图形方面的优化主要包括三角形数量，纹理所占内存，以及Shader，前两项基本没什么好讲的，针对设备机能的限制制定相应的指标即可，所以Shader就成为了图形性能优化的关键。 Alpha blending 在Unity官方文档中讲，由于硬件原因，在iOS设备上使用alpha-test会造成很大的性能开销，应尽量使用alpha-blend代替。这里提到，在同屏使用alpha-blend的面数，尤其是这些面所占屏幕面积的大小，对性能也会造成很大影响。原因是使用alpha-blend的面会造成overdraw的增加，这尤其对低性能设备的影响很大。不过没有购买Pro版，没有Occlusion Culling功能的话，就不必顾虑这一问题了，反正overdraw是必然的。 复杂的Per-pixel shader Per-pixel shader即Fragment shader，顾名思义是要对每个渲染到屏幕上的像素做处理的shader，如果per-pixel shader比较复杂且需要处理的像素很多时，也就是使用该shader的面占屏幕面积很大时，对性能的影响甚至要超过alpha blending。因此复杂的per-pixel shader只适用于小物体。 下面是对几个Shader的逐一讲解： Environment specular maps(Shader Virtual Gloss Per Vertex Additive)Specular map通常都是利用贴图的alpha通道来定义物体表面的光滑程度（反光度），这个shader的特点是per-vertex计算反光度的，有着相当不错的效果的同时比per-pixel的shader性能要高得多。这个shader很适用于关卡环境等占很大区域的模型。 经过优化的动态角色光照和阴影(Light probes和BRDF Shader)传统的Lightmaps无法支持动态物体，对此Unity提供了Light probes技术，预先把动态物体的光照信息保存在代理对象(即Light probes)中，运行时动态物体从距离最近的Probe中获取光照信息。 Unity本身还提供了一个效果非常棒的专为移动设备优化过的角色Shader，支持Diffuse、Specular和Normal maps，并通过一个特殊的脚本生成贴图用于模仿BRDF光照效果。最终产生的效果堪比次时代大作中的角色光影效果。 雾和体积光(Shader Blinking Godrays)目前在移动设备上要开启真正的雾效基本不可行，ShadowGun的方案是通过简单的网格＋透明贴图(称为雾面)来模拟雾效。在玩家靠近时，雾面逐渐变淡，同时fog plane的顶点也会移开(即使完全透明的alpha面也会消耗很多渲染时间)。 使用这个Shader的网格需要经过处理： 顶点的alpha值用于决定顶点是否可以移动(在例子中0为不可动，1为可动)。顶点法线决定移动的方向然后Shader通过计算与观察者的距离来控制雾面的淡入/淡出。这个Shader还可以用来做体积光和其它一些alpha效果。 飞机坠毁的浓烟效果(Shader Scroll 2 Layers Sine Alpha-blended)通过粒子产生浓烟的代价太高，所以ShadowGun中使用了网格＋贴图动画来制作这个效果。通过混合两层贴图并让它们交错移动来产生动画效果。其中顶点alpha值用于让网格的边缘看起来比较柔和，同时使用顶点颜色来模拟从火焰到烟雾的过渡效果。 带动态效果的天空盒(Shader Scroll 2 Layers Multiplicative)通过两张贴图的混合和移动产生云的动态效果。 旗帜和衣服的飘动效果(Shader Lightmap + Wind)同样利用顶点alpha值决定哪些顶点可以移动，然后shader的参数用于调整摆动的方向和速度。 一、程序方面 1. 务必删除脚本中为空或不需要的默认方法； 2. 只在一个脚本中使用OnGUI方法；（最好不要加） 3. 避免在OnGUI中对变量、方法进行更新、赋值，输出变量建议在Update内； 4. 同一脚本中频繁使用的变量建议声明其为全局变量，脚本之间频繁调用的变量或方法建议声明为全局静态变量或方法； 5. 不要去频繁获取组件，将其声明为全局变量； 6. 数组、集合类元素优先使用Array，其次是List； 7. 脚本在不使用时脚本禁用之，需要时再启用； 8. 可以使用Ray来代替OnMouseXXX类方法； 9. 需要隐藏/显示或实例化来回切换的对象，尽量不要使用SetActiveRecursively或active，而使用将对象远远移出相机范围和移回原位的做法； 10. 尽量少用模运算和除法运算，比如a/5f，一定要写成a * 0.2f。 11. 对于不经常调用或更改的变量或方法建议使用Coroutines &amp; Yield； 12. 尽量直接声明脚本变量，而不使用GetComponent来获取脚本；iPhone 13. 尽量使用整数数字，因为iPhone的浮点数计算能力很差； 14. 不要使用原生的GUI方法； 15. 不要实例化（Instantiate）对象，事先建好对象池，并使用Translate“生成”对象；二、模型方面 1. 合并使用同贴图的材质球，合并使用相同材质球的Mesh； 2. 角色的贴图和材质球只要一个，若必须多个则将模型离分离为多个部分； 2. 骨骼系统不要使用太多； 3. 当使用多角色时，将动画单独分离出来； 4. 使用层距离来控制模型的显示距离； 5. 阴影其实包含两方面阴暗和影子，建议使用实时影子时把阴暗效果烘焙出来，不要使用灯光来调节光线阴暗。 6. 少用像素灯和使用像素灯的Shader； 7. 如果硬阴影可以解决问题就不要用软阴影，并且使用不影响效果的低分辨率阴影； 08、实时阴影很耗性能，尽量减小产生阴影的距离； 09、允许的话在大场景中使用线性雾，这样可以使远距离对象或阴影不易察觉，因此可以通过减小相机和阴影距离来提高性能； 10、使用圆滑组来尽量减少模型的面数； 11、项目中如果没有灯光或对象在移动那么就不要使用实时灯光； 12、水面、镜子等实时反射/折射的效果单独放在Water图层中，并且根据其实时反射/折射的范围来调整； 13、碰撞对效率的影响很小，但碰撞还是建议使用Box、Sphere碰撞体； 14、建材质球时尽量考虑使用Substance； 15、尽量将所有的实时反射/折射（如水面、镜子、地板等等）都集合成一个面； 16、假反射/折射没有必要使用过大分辨率，一般6464就可以，不建议超过256256； 17、需要更改的材质球，建议实例化一个，而不是使用公共的材质球； 18、将不须射线或碰撞事件的对象置于IgnoreRaycast图层； 19、将水面或类似效果置于Water图层 20、将透明通道的对象置于TransparentFX图层； 21、养成良好的标签（Tags）、层次（Hieratchy）和图层（Layer）的条理化习惯，将不同的对象置于不同的标签或图层，三者有效的结合将很方便的按名称、类别和属性来查找； 22、通过Stats和Profile查看对效率影响最大的方面或对象，或者使用禁用部分模型的方式查看问题到底在哪儿； 23、使用遮挡剔除（Occlusion Culling）处理大场景，一种较原生的类LOD技术，并且能够“分割”作为整体的一个模型。 三、其它 场景中如果没有使用灯光和像素灯，就不要使用法线贴图，因为法线效果只有在有光源（Direct Light/Point Light/Angle Light/Pixel Light）的情况下才有效果。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C# 线程同步]]></title>
    <url>%2F2018%2F04%2F12%2FC-Thread-Sync%2F</url>
    <content type="text"><![CDATA[线程同步的方式线程同步有：临界区、互斥区、事件、信号量四种方式 临界区(Critical Section)：临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。 互斥量(Mutex)：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享 信号量(Semaphore)：它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目 事件(Event)：通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作 lock 关键字lock 关键字将语句块标记为临界区，方法是获取给定对象的互斥锁，执行语句，然后释放该锁。lock 确保当一个线程位于代码的临界区时，另一个线程不进入临界区。如果其他线程试图进入锁定的代码，则它将一直等待（即被阻止），直到该对象被释放。 同步事件和等待句柄使用锁或监视器对于防止同时执行区分线程的代码块很有用，但是这些构造不允许一个线程向另一个线程传达事件。这需要“同步事件”，它是有两个状态（终止和非终止）的对象，可以用来激活和挂起线程。让线程等待非终止的同步事件可以将线程挂起，将事件状态更改为终止可以将线程激活。如果线程试图等待已经终止的事件，则线程将继续执行，而不会延迟。 同步事件有两种：AutoResetEvent 和 ManualResetEvent。它们之间唯一的不同在于，无论何时，只要 AutoResetEvent 激活线程，它的状态将自动从终止变为非终止。相反，ManualResetEvent 允许它的终止状态激活任意多个线程，只有当它的 Reset 方法被调用时才还原到非终止状态。 等待句柄，可以通过调用一种等待方法，如WaitOne、WaitAny 或 WaitAll，让线程等待事件。System.Threading.WaitHandle.WaitOne使线程一直等待，直到单个事件变为终止状态；System.Threading.WaitHandle.WaitAny 阻止线程，直到一个或多个指示的事件变为终止状态；System.Threading.WaitHandle.WaitAll 阻止线程，直到所有指示的事件都变为终止状态。当调用事件的 Set 方法时，事件将变为终止状态。 AutoResetEvent 允许线程通过发信号互相通信。 通常，当线程需要独占访问资源时使用该类。线程通过调用 AutoResetEvent 上的 WaitOne 来等待信号。 如果 AutoResetEvent 为非终止状态，则线程会被阻止，并等待当前控制资源的线程通过调用 Set 来通知资源可用。调用 Set 向 AutoResetEvent 发信号以释放等待线程。 AutoResetEvent 将保持终止状态，直到一个正在等待的线程被释放，然后自动返回非终止状态。 如果没有任何线程在等待，则状态将无限期地保持为终止状态。如果当 AutoResetEvent 为终止状态时线程调用 WaitOne，则线程不会被阻止。 AutoResetEvent 将立即释放线程并返回到非终止状态。可以通过将一个布尔值传递给构造函数来控制 AutoResetEvent 的初始状态：如果初始状态为终止状态，则为 true；否则为 false。AutoResetEvent 也可以同 staticWaitAll 和 WaitAny 方法一起使用。 WaitHandle.WaitOne()阻止当前线程，直到当前的 WaitHandle 收到信号为止 EventWaitHandle.Set()将事件状态设置为有信号，从而允许一个或多个等待线程继续执行。]]></content>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[托管代码和非托管代码]]></title>
    <url>%2F2018%2F04%2F11%2Fmanaged-code-unmanaged-code%2F</url>
    <content type="text"><![CDATA[托管代码是-Microsoft的中间语言(IL)，他主要作用是在.Net FRAMEWORK的公共语言运行库(CLR)执行代码前去编译源代码，也就是说托管代码充当着翻译的作用，源代码在运行时分为两个阶段： 源代码编译为托管代码，(所以源代码可以有很多种，如VB,C#,J#) 托管代码编译为Microsoft的平台专用语言 编译器把代码编译成中间语言(IL),而不是能在你的电脑上运行的机器码。中间语言被封装在一个叫程序集(Assembly)的文件中，程序集中包含了描述你所创建的类，方法和属性(例如安全需求)的所有元数据。你可以拷贝这个程序集到另一台服务器上部署它。 托管代码在公共语言运行库(CLR)中运行。这个运行库给你的运行代码提供各种各样的服务，通常来说，他会加载和验证程序集，以此来保证中间语言的正确性 托管代码是一种中间语言，运行在CLR上；非托管代码被编译为机器码，运行在机器上 托管代码独立于平台和语言，能更好的实现不同语言平台之间的兼容；非托管代码依赖于平台和语言。 托管代码可享受CLR提供的服务（如安全检测，垃圾回收），不需要自己完成这些操作非托管代码需要自己提供安全检测、垃圾回收等操作。]]></content>
      <tags>
        <tag>C#</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity加载和内存管理]]></title>
    <url>%2F2018%2F04%2F11%2FAssetBundle%2F</url>
    <content type="text"><![CDATA[Unity有两种动态加载机制：Resources.Load和AssetBundle，二者本质并无区别。Resources.Load就是从一个缺省打进程程序包的AssetBundle(Resourece)里加载资源，而一般AssetBundle文件需要你自己创建，运行时加载。 AssetBundle加载基础通过AssetBunlde加载资源，分为两步，第一步是获取AssetBundle对象，第二步是通过该对象加载需要的资源。而第一步又分为两种方式，下文中将结合常用的API进行详细地描述。 第一步，获取AssetBundle对象常用地API方式一，先获取WWW对象，再通过WWW.assetBundle获取AssetBundle对象：public WWW(string uri); 加载Bundle文件并获取WWW对象，完成后会在内存中创建较大地WebStream(解压后的内容，通常为原Bundle文件的4~5倍大小，纹理资源比例可能更大),因此后续的AssetBundle.Load可以直接在内存中进行。 public static WWW LoadFromCacheOrDownload(string uri, int version, unit crc = 0); 加载Bundle文件并获取WWW对象，同时将解压形式的Bundle内容存入磁盘中作为缓存（如果该Bundle已在缓存中，则省去这一步），完成后只会在内存中创建较小的SerializedFile，而后续的AssetBundle.Load需要通过IO从磁盘中的缓存获取。 public AssetBundle assetBundle; 通过之前两个接口获取WWW对象后，即可通过WWW.assetBundle获取AssetBundle对象。 方式二，直接获取AssetBundle:public static AssetBundle LoadFromFile(string path); public static AssetBundle LoadFromFileAsync(string path); 通过未压缩的Bundle文件，同步创建AssetBundle对象，这是最快的方式。创建完成后只会在内存中创建较小的SerializedFile，而后续的AssetBundle.Load需要通过IO从磁盘中获取。如果AssetBundle是未压缩，或者是数据块形式（LZ4算法压缩）的，LoadFromFile将从磁盘中直接加载它。如果AssetBundle是高度压缩(LZMA算法压缩)的，再将它加载进入内存前，会首先将它解压。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667void LoadAssetBundles(string baseDir)&#123; if (assetBundleInfos != null) &#123; for (int i = 0; i &lt; assetBundleInfos.Length; i++) &#123; var bInfo = assetBundleInfos[i]; if (bInfo.assetBundle != null) &#123; bInfo.assetBundle.Unload(false); &#125; &#125; assetBundleInfos = null; &#125; var abInfos = new List&lt;AssetBundleInfo&gt;(50); var files = Directory.GetFiles(m_dir_update, &quot;*.bytes&quot;); for (int i = 0; i &lt; files.Length; i++) &#123; string f = files[i]; string n = Path.GetFileName(f); if (!CheckABName(abInfos, n)) contine; abInfos.Add(new AssetBundleInfo&#123;name = n, uri = f&#125;); &#125; if (baseDir != null) &#123; files = Directory.GetFiles(baseDir, &quot;*.bytes&quot;); for (int i = 0; i &lt; files.Length; i++) &#123; string f = files[i]; string n = Path.GetFileName(f); if (!CheckABName(abInfos, n)) continue; abInfos.Add(new AssetBundleInfo&#123;name = n, uri = f&#125;); &#125; &#125; files = LoadConfigLines(&quot;res_idx&quot;); for (int i = 0; i &lt; files.Length; i++) &#123; string n = files[i].Trim(); if (!CheckABName(abInfos, n)) continue; string f = streamAssetsPath + n; abInfos.Add(new AssetBundleInfo&#123;name = n, uri = f&#125;); &#125; if (abInfos.Count == 0) return; string prefix = &quot;assets/res/&quot;; int cprefix = prefix.Length; for (int i = 0; i &lt; abInfos.Count;) &#123; var abInfo = abInfos[i]; var ab = AssetBundle.LoadFromFile(abInfo.uri); if (ab == null) &#123; abInfos.RemoveAt(i); sbError.Append(&quot;\nfail ab : &quot;); sbError.Append(abInfo) &#125; &#125;&#125; public static AssetBundle LoadFromMemory(byte[] binary) 通过Bundle的二进制数据，异步创建AssetBundle对象，完成后会在内存中创建较大的WebStream。调用时，Bundle的解压是异步进行的，因此对于未压缩的Bundle文件，该接口于LoadFromMemoryAsync是等价的。 public static AssetBundle LoadFromMemoryAsync 该接口是 CreateFromMemory 的同步版本，这个方法的参数是包含了AssetBundle数据的字节数组。如果需要的话，你还可以传入一个CRC(循环冗余校验码)参数。如果AssetBundle使用了LZMA算法压缩，那么AssetBundle在加载的时候会被解压。如果AssetBundle使用了LZ4算法压缩，它将直接以压缩形式被加载。 12345678IEnumerator LoadFromMemoryAsync(string path)&#123; AssetBundleCreateRequest createRequest = AssetBundle.LoadFromMemoryAsync(File.ReadAllBytes(path)); yield return createRequest; AssetBundle bundle = createRequest.assetBundle; var prefab = bundle.LoadAsset&lt;GameObject&gt;(&quot;MyObject&quot;); Instantiate(prefab);&#125; 第二步，从AssetBundle加载资源的常用APIpublic Object Load(string name, Type type); 通过给定的名字和资源类型，加载资源。加载时会自动加载其依赖的资源，即Load一个Prefab时，会自动Load其引用的Texture资源。 public Object[] LoadAll(Type type); public AssetBundleRequest LoadAllAssetsAsync(); 一次性加载Bundle中给定资源类型的所有资源 public AssetBundleRequest LoadAsync(string name, Type type) AssetBundle的压缩类型Unity3D引擎为我们提供了三种压缩策略来处理AssetBundle的压缩，即： LZMA格式 LZ4格式 不压缩 LZ4是块压缩(chunk-based)，LZMA是流压缩(stream-based)。流压缩(LZMA)在处理整个数据块时使用同一个字典，它提供了最大可能的压缩率但只支持顺序读取。块压缩(LZ4)指的是原始数据被分成大小相同的子块并单端压缩。如果你想要实时解压/随机读取开销小，则应该使用这种。 LZMA压缩方式的优点在于使用同一个字典压缩率较高，但只能顺序读取意味着加载任意一个资源时，都需要将整个AssetBundle解压，造成卡顿和额外内存占用。LZ4基于快压缩率较低（测试LZMA换LZ4：86.9M-&gt;108M），但只需解压需要块即可，不会有大的卡顿和额外内存占用。 LZMA(stream-based)在默认情况下，打包生成的AssetBundle都会被压缩。在U3D中，AssetBundle的标准压缩格式便是LZMA（LZMA是一种序列化流文件），因此在默认情况下，打出的AssetBundle包处于LZMA格式的压缩状态。 LZ4(chunk-based)Unity 5.3之后的版本增加了LZ4格式压缩，是一种块压缩方式，由于LZ4的压缩比一般，因此经过压缩之后的AssetBundle包体的体积较大（该算法基于chunk）。但是，使用LZ4格式的好处在于解压缩的时间相对要短。 使用LZ4格式压缩，需要打包设置 BuildPipeline.BuildAssetBundles(Application.streamingAssetPath, BuildAssetBundleOptions.ChunkBasedCompression); 不压缩当然，我们也可以不对AssetBundle进行压缩。没有经过压缩的胞体系最大，但是访问速度最快。 若要使用不压缩的策略，只需要在打包的时候开启 BuildPipeline.BuildAsetBundles(Application.streamingAssetPath, BuildAssetBundleOptions.UncompressedAssetBundle); 五 AssetBundle原理分析5.2 AssetBundle及Assets的卸载在AssetBundle的下载和加载过程中，以及Assets加载和实例化过程中，AssetBundle以及加载的Assets都会占用内存。 AssetBundle的卸载采用Assetbundle.Unload(bool)接口。 Assets的卸载有两种方式: AssetBundle.Unload(true); // 这会强制卸载掉所有从AssetBundle加载的Assets。 Resource.UnloadUnusedAssets()和Resources.UnloadAsset。这会卸载掉所有没有用到的Assets。需要注意的是，该接口作用于整个系统，而不仅仅是当前的AssetBundle，而且不会卸载从当前AssetBundle文件中加载并仍在使用的Assets。 对于实例化出来的对象，可以使用GameObject.Destroy活GameObject.DestroyImmediate。注意的是：官方说法是这样的，如果使用GameObject.Destroy接口，Unity会将真正的删除操作延后到一个合适的时机统一进行处理，但会在渲染之前。 对于WWW对象，可以使用www=null或www.dispose。这两者是由区别的，www=null不会立即释放内存，而是系统自动回收机制启动时回收。www.dispose则会立即调用系统的回收机制来释放内存。当WWW对象被释放后，其对于Web Stream数据的引用计数也会相应减1。 对于Web Stream数据，它所占用的内存会在其引用计数为0时，被系统自动回收。例如：当上图中的AssetBundle对象和WWW对象被释放后，Web Stream数据所占内存也会被系统自动回收。 AssetBundle依赖加载如果一个或者多个UnityEngine.Objects引用了其他AssetBundle中的UnityEngine.Object，那么AssetBundle之间就产生了依赖关系了。如果UnityEngine.ObjectA所引用的UnityEngine.ObjectB不是其他的AssetBundle中的，那么依赖就不会产生。如果产生依赖，被依赖对象(UnityEngine.ObjectB)将被拷贝进你创建的AssetBundle(指包含UnityEngine.ObjectA的AssetBundle) 更近一步，如果有多个对象(UnityEngine.ObjectA1、UnityEngine.ObjectA2、UnityEngine.ObjectA3…)引用了同一个被依赖对象(UnityEngine.ObjectB)，那么被依赖对象将被拷贝多份，打包进各个对象各自的AssetBundle。 如果一个AssetBundle存在依赖性，那么要注意的是，那些包含了被依赖对象的AssetBundles，需要在你想要实例化的对象的加载之前加载。Unity不会自动帮你加载这些依赖。]]></content>
      <tags>
        <tag>Unity3D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity3D中自带事件函数的执行顺序]]></title>
    <url>%2F2018%2F04%2F11%2FUnity-Note%2F</url>
    <content type="text"><![CDATA[在Unity3D继承自MonoBehavior的脚本中，有几个Unity3D自带的事件函数按照预定的顺序作为脚本执行。其执行顺序如下： 编辑器（Editor） Reset：Reset函数被调用来初始化脚本属性当脚本第一次被附到对象上，并且在Reset命令被使用时也会调用。Reset是在用户点击Inspector面板上Reset按钮或者首次添加该组件时被调用。Reset最常用于在检视面板中给定一个默认值。 第一次场景加载（First Scene Load）这些函数会在一个场景开始（场景中每个物体只调用一次）时被调用。 Awake：这个函数总是在任何Start()函数之前一个预设被实例化之后调用，如果一个GameObject是非激活的(inactive)，在启动期间Awake函数是不会被调用的直到它是活动的(active)。 OnEnable：只有在对象激活(active)状态下才会被调用，这个函数只有在object被启动(enable)后才调用。这会发生在一个MonoBehavior实例被创建，例如当一个关卡被加载或者一个带有脚本组件的GameObject被实例化。 注意：当一个场景被添加到场景中，所有脚本上的Awake()和OnEnable()函数将会被调用在Start()、Update()等它们中任何函数被调用之前。自然的，当一个物体在游戏过程中被实例化时这不能被强制执行。 第一帧更新之前（Before the first frame update） Start：只有在脚本被启用了Start()函数将会在Update()函数第一帧之前被调用。对于那些被添加到场景中的物体，所有脚本上的Start()函数将会在它们中任何的Update()函数之前被调用，当一个物体在游戏过程中被实例化时这不能被强制执行。 在帧之间（In between frames） OnApplicationPause：这个函数将会被调用在暂停被检测有效的在正常的帧更新之间的一帧的结束时。在OnApplicationPause被调用后将会有额外的一帧用来允许游戏显示图像表示在暂停状态下。 更新顺序（Update Order）当你在跟踪游戏逻辑和状态，动画，相机位置等的时候，有几个不同的事件函数你可以使用。常见的模式是在Update()函数中执行大多数人物，但是也有其它的函数你可以使用。 FixedUpdate：常被用作逻辑Tick函数，FixedUpdate函数经常会比Update函数更频繁的被调用。它一帧会被调用多次，如果帧率低它可能不会在帧之间被调用，就算帧率是高的。所有的图形计算和更新在FixedUpdate之后会立即执行。当在FixedUpdate里执行移动计算，你并不需要Time.deltaTime乘以你的值，这是因为FixedUpdate是按真实时间，独立于帧被调用的。 Update：Update每一帧都会被调用，对于帧更新它是主要的负荷函数。 LateUpdate：LateUpdate会在Update结束之后每一帧被调用，任何计算在Update里执行结束当LateUpdate开始时。LateUpdate常被为第三人称视角相机跟随。 渲染（Rendering） OnPreCull：在相机剔除场景前被调用。剔除是取决于哪些物体对于摄像机是可见的，OnPreCull尽在剔除起作用之前被调用。 OnBecameVisible/OnBecameInvisible：当一个物体对任意摄像机变得可见/不可见时被调用。 OnPreRender：在摄像机开始渲染场景之前被调用。 OnRenderObject：在指定场景渲染完成之后调用，你可以使用GL类或者Graphics.DrawMeshNow来绘制自定义几何体在这里。 OnPostRender：在摄像机完成渲染之后调用。 OnRenderImage(Pro Only)：在场景渲染完成之后允许屏幕图像后期处理调用。 OnGUI：为了响应GUI事件，每帧会被调用多次（一般最低两次）。布局Layout和Repaint事件会首先处理，接下来是通过Layout和键盘/鼠标事件对应的每个输入事件。 OnDrawGizmos：用于可视化的绘制一些小玩意在场景视图中。 协同程序（Corotines）正常的协同程序更新是在Update函数饭回之后运行。一个协同程序是可以暂停执行(yield)直到给出的依从指令（YieldInstruction）完成，携程的不同运用。 yield：在所有的Update函数都已经被调用的下一帧该协程将持续执行。 yield WaitForSeconds：一段指定的时间延迟之后继续执行，在所有的Update函数完成调用的那一帧之后。 yield WaitForFixedUpdate：所有脚本上的FixedUpdate函数已经执行调用之后持续。 yield WWW：在WWW下载完成之后持续。 yield StartCoroutine：协同程序链，将会等到MuFunc函数协程执行完成首先。 销毁（When the Object is Destroyed） OnDestroy：这个函数会在一个对象销毁前一帧调用，会在所有帧更新一个对象存在的最后一帧之后执行，对象也许会响应Object.Destroy或一个场景关闭时被销毁。 退出游戏（When Quitting）这些函数会在你场景中所有的激活的物体上调用： OnApplicationQuit：这个函数在应用退出之前的所有游戏物体上调用，在编辑器（Editor）模式中会在用户停止PlayMode时调用，在网页播放器（web Player）中会在网页视图关闭时调用。 OnDisable：当行为变为非启用(disable)或非激活（inactive）时调用。 脚本的生命周期流程图 在Update中使用Time.deltaTime，获取到的是这一帧的时间，如果游戏卡，帧率低，那这个值就大。如果游戏流畅，帧率高，这个值就小，Time.deltaTime=1.0f/帧率 MonoBehaviour.Update 更新渲染帧当MonoBehaviour启用时，其Update在每一帧被调用。 MonoBehaviour.FixedUpdate 固定更新逻辑帧当MonoBehaviour启用时，其 FixedUpdate在每一帧被调用。处理Rigidbody时，需要用FixedUpdate代替Update。例如：给刚体加一个作用力时，你必须应用作用力在FixedUpdate里的固定帧，而不是Update中的帧(两者帧长不同)。 MonoBehaviour.LateUpdate 晚于更新渲染帧末尾当Behaviour启用时，其LateUpdate在每一帧被调用。LateUpdate是在所有Update函数调用后被调用。这可用于调整脚本执行顺序。例如:当物体在Update里移动时，跟随物体的相机可以在LateUpdate里实现。 Update和FixedUpdate的区别Update跟当前平台的帧数有关，而FixedUpdate是CPU tick 的时间，所以处理物理逻辑的时候要把代码放在FixedUpdate而不是Update。Update是在每次渲染新的一帧的时候才会调用，也就是说，这个函数的更新频率和设备的性能有关以及被渲染的物体（可以认为是三角形的数量）。在性能好的机器上可能fps 30，差的可能小些。这会导致同一个游戏在不同的机器上效果不一致，有的快有的慢。因为Update的执行间隔不一样了。而FixedUpdate，是在固定的时间间隔执行，不受游戏帧率的影响。有点像Tick。所以处理Rigidbody的时候最好用FixedUpdate。 FixedUpdate的时间间隔可以在项目设置中更改，Edit-&gt;ProjectSetting-&gt;time 找到Fixedtimestep。就可以修改了。 Update和LateUpdate的区别LateUpdate是在所有Update函数调用后被调用。这可用于调整脚本执行顺序。例如：当物体在Update里移动时，跟随物体的相机可以在LateUpdate里实现。LateUpdate是晚于所有Update执行的。例如：游戏中有2个脚步，脚步1含有Update和LateUpdate，脚步2含有Update，那么当游戏执行时，每一帧都是把2个脚步中的Update执行完后才执行LateUpdate 。虽然是在同一帧中执行的，但是Update（渲染帧）会先执行，LateUpdate（渲染帧末尾）会晚执行。现在假设有2个不同的脚本同时在Update中控制一个物体，那么当其中一个脚本改变物体方位、旋转或者其他参数时，另一个脚步也在改变这些东西，那么这个物体的方位、旋转就会出现一定的反复。如果还有个物体在Update中跟随这个物体移动、旋转的话，那跟随的物体就会出现抖动。 如果是在LateUpdate中跟随的话就会只跟随所有Update执行完后的最后位置、旋转，这样就防止了抖动。 影响渲染顺序因素地总结 Camrea Depth 相机组件上设置的相机深度，深度越大越靠后渲染。 Sorting Layer 在Tags &amp; Layers设置中可见。 Order In Layer 相当于Sorting Layer的子排序，用这个值做比较时只有都在同一层时才有效。 RenderQueue Shader中对Tags设置的”Queue” Camera Depth永远最高。Camera Depth小的一定先进渲染管线。当Sorting Layer和Order in Layer相同时RenderQueue小的先进渲染管线。 当Sorting Layer和Order In Layer不相同时！当两个材质使用了不同的RenderQueue,且这两个RenderQueue都在[0~2500]或[2501~5000]时，SortingLayer和OrderInLayer的排序生效。当两个材质使用了不同的RenderQueue,且这两个RenderQueue分别再[0~2500]或[2501~5000]时，则一定会按照RenderQueue绘制，无视SortingLayer,OrderInLayer的排序。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[约束]]></title>
    <url>%2F2018%2F04%2F11%2Fconstraint%2F</url>
    <content type="text"><![CDATA[T:struct 类型参数必须是值类型。可以指定除Nullable以外的任何值类型。 T:class 类型参数必须是引用类型，包括任何类、接口、委托或数组类型。 T:new() 类型参数必须具有无参数的公共构造函数。当与其他约束一起使用时，new()约束必须最后指定。 T:&lt;接口名称&gt; 类型参数必须是指定的接口或实现指定的接口。可以指定多个接口约束。约束接口也可以是泛型的。 T:U 为T提供的类型参数必须是为U提供的参数或派生自为U提供的参数。这称为螺类型约束。 public class MyGenericClass&lt;T&gt; where T:IComparable {} class MyClassy&lt;T, U&gt; where T : class where U : struct {} public class MyGenericClass&lt;T&gt; where T: IComparable, new() { T item = new T(); } 12345678910interface MyI &#123;&#125;class Dictionary&lt;TKey, TVal&gt;where TKey: IComparable, IEnumerablewhere TVal: MyI&#123; public void Add(Tkey key, TVal val) &#123; &#125;&#125; public bool MyMethod&lt;T&gt; (T t) where T: IMyInterface {} 1234567class List&lt;T&gt;&#123; void Add&lt;U&gt;(List&lt;U&gt; items) where U: T &#123; &#125;&#125; default 之所以会用到default关键字，是因为需要在不知道类型参数为值类型还是引用类型的情况下，为对象实例赋初值。 ```class TestDefault{ public T foo() { return default(T); }}]]></content>
      <tags>
        <tag>C#</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23种设计模式]]></title>
    <url>%2F2018%2F04%2F11%2F23-Design-Patterns%2F</url>
    <content type="text"><![CDATA[设计模式分为三大类：创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。结构性模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介模式、解释器模式。其实还有两类：并发型模式和线程池模式。 设计模式六大原则：总原则-开闭原则对扩展开放，对修改封闭。在程序需要进行扩展的时候，不能去修改原有的代码，而是扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，外面需要使用接口和抽象类等，后面的具体设计中我们会提到这点。 1、单一职责原则不要存在多余一个导致类变更的原因，也就是说每个类应该实现单一的职责，否则就应该把类拆分。 2.里氏替换原则(Liskov Substitution Principle)任何积累可以出现的地方，子类一定可以出现 6.合成复用原则(Composite Reuse Principle)尽量首先使用合成/聚合的方式，而不是使用继承。 单线程单例模式12345678910111213141516171819public sealed class Singleton // 密封防止继承&#123; private static Singleton uniqueInstance; // 唯一的实例 // 私有构造函数外部无法创建实例 private Singleton() &#123; &#125; // 全局唯一访问点 public static Singleton GetInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125;&#125; 单线程单例模式的几个要点： Singleton模式的实例构造器可以设置为protected以允许子类派生。 Singleton模式一般不要ICloneable接口，因为这可能会导致多个对象实例，与Singleton模式的初衷违背。 Singleton模式一般不要支持序列化，因为这也有可能导致多个对象实例，同样与Singleton模式的初衷违背。 Singleton模式只考虑到了对象创建的工作，没有考虑到对象效果的工作。全局静态的放到托管堆中还可以接受？ 不能应对多线程环境，在多线程环境下，使用Singleton模式仍然有可能得到Singleton类的多个实例对象。 工厂设计模式简单工厂设计模式123456789101112131415161718192021222324252627282930313233343536373839404142434445public enum FruitKind&#123; Apple, Pear,&#125;public interface Fruit&#123; void WhatIm();&#125;public class Apple : Fruit&#123; public void WhatIm() &#123; Console.WriteLine(&quot;I am Apple&quot;); &#125;&#125;public class Pear : Fruit&#123; public void WhatIm() &#123; Console.WriteLine(&quot;I am pear&quot;); &#125;&#125;public class FruitFactory&#123; public static Fruit CreateFruit(FruitKind type) &#123; switch(type) &#123; case FruitKind.Apple: return new Apple(); case FruitKind.Pear: return new Pear(); &#125; return null; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; Fruit a = FruitFactory.CreateFruit(FruitKind.Pear); a.WhatIm(); &#125;&#125; 不太喜欢损失性能和不容易看到内部的逻辑，所以上述不太喜欢。上述存在一个问题，产品内部随便折腾没啥问题，但是做一个新的产品就蛋疼了。 工厂方法设计模式 抽象产品类 具体产品类 抽象工厂类 具体工厂类12345678910111213141516171819202122232425262728293031323334public enum FruitKind&#123; Apple, Pear,&#125;public interface Fruit&#123; void WhatIm();&#125;public class Apple : Fruit&#123; public void WhatIm() &#123; Console.WriteLine(&quot;I am Apple&quot;); &#125;&#125;public class Pear : Fruit&#123; public void WhatIm() &#123; Console.WriteLine(&quot;I am pear&quot;); &#125;&#125;public interface FruitFactory&#123; Fruit CreateFruit();&#125;public class PearFactory : FruitFactory&#123; public Fruit CreateFruit() &#123; return new Apple(); &#125;&#125; 上述代码解耦了，]]></content>
      <tags>
        <tag>C#</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试]]></title>
    <url>%2F2018%2F04%2F11%2FInterface%2F</url>
    <content type="text"><![CDATA[接口(Interface)是一种规划，为你定义了一系列的规则和任务，但不去实现它类和结构体可以继承多个接口抽象类表示该类中可能已经有一些的具体定义生成的库在这里： Temp\StagingArea\libs\armeabi-v7a\libil2cpp.so 符号表在这里，需要把扩展名弄成.so，才能被bugly的符号工具转换。 Temp\StagingArea\libs\armeabi-v7a\libil2cpp.so.debug C++代码生成到这里，最好保存这个目录，以便对应看调用栈： Temp\StagingArea\Il2Cpp\il2cppOutput ArrayList会把所有插入其中的数据都当成了object类型来处理。弊端：1、不是类型安全的；2、存在装箱拆箱操作12345678910Add() //向数组中添加一个元素Remove() //删除数组中的一个元素RemoveAt(int i);////不是骨骼动画,可以用animator,///骨骼动画 animator只能用一个,Reverse()//反转数组的元素Sort()//从小到大排序数组的元素Clone()//复制一个数组//List//可通过索引访问 在决定使用List还是使用ArrayList 类(两者具有类似的功能)时,记住List类在大多数情况下执行的更好并且是类型安全的,如果对List类型T使用值类型,则需要考虑实现和装箱问题如果对类型T实用值类型,则编译器将特别针对该值类型生成List类的实现,这意味着不必对再提醒一下，模板容器里不要使用枚举。比如Dictionary之类的，枚举会boxing，产生无用的GC就用int替代吧 请描述游戏动画有哪几种，以及其原理。答:主要有关节动画,单一网络模型动画(关键帧动画),骨骼动画.关节动画把角色分为若干独立部分,一个部分对应一个网络模型,部分的动画连接成一个整体的动画,角色比较灵活Quake2中实用了这种动画.单一网络模型动画由一个完整的网络模型构成,在动画序列的关键帧里记录各个顶点的原位置及其改变量,然后插值运算实现动画效果,角色动画较真实.骨骼动画,广泛应用的动画方式,集成了以上两个方式的优点,骨骼按角色特点组成一定的层次结构,由关节相连,可做相对运动,皮肤作为单一网络蒙在骨骼之外,决定角色的外观,皮肤网络每一个顶点都会收到骨骼的影响,从而实现完美的动画. alpha blend 工作原理alpha blend用于做半透明效果.Color=(源颜色 源系数)OP(目标颜色 目标系数);其中OP(混合方式)有加,减,反减,取最小,取最大 OpenGL Alpha混合假设一种不透明的东西的颜色是A，另一种透明的东西颜色是B，那么透过B看A，看上去的颜色C就是B和A的混合颜色，可以用以下公式来模拟，设B物体的透明度为alpha（取值为0-1，0为完全透明，1为完全不透明） R(C)=alpha*R(B)+(1-alpha)R(A) G(C)=alpha*G(B)+(1-alpha)G(A) B(C)=alpha*B(B)+(1-alpha)G(A) 写光照计算中的diffuse的计算公式答:漫反射光(diffuse)计算公式为:ldiffuse = DintensityDcolorN.L;(Dintensity)表示漫反射强度,Dcolor表示漫反射光颜色,N为该点的法向量,L为光源向量其他,3D渲染中,物体表面的光照计算公式为:I = 环境关(lambient) + 漫反射光(ldiffuse) + 镜面高光(lspecular);其中,环境光(ambient)计算公式为: lambient = Aintensity*Acolor;(Aintensity)表示环境光强度,Acolor表示环境光颜色 镜面高光(specular)计算公式为:lspecular = SintensityScolor(R.V)n;(Sintensity)表示镜面光照强度,Scolor表示镜面光颜色,R为光的反射向量,V为观察者向量 MipMap是什么？作用？答:在三维计算机图形的贴图渲染中有一个常用的技术成为Mipmapping,为了加快渲染速度和减少图像锯齿,贴图被处理成由一系列被预先计算和优化过的图片组成的文件,这样的贴图被称为mipmap 用u3d实现2d游戏，有几种方式？答：一种用UI实现(GUI,NGUI…)，一种是采用3d实体对象（plane），绘制在3d对象上，调节摄像机，采用平行投影模式或则固定视角。 u3d中碰撞器和触发器的区别？答：触发器只是碰撞器身上的一个属性，碰撞器是触发器的载体。 物体发生碰撞的必要条件答：需要检测碰撞的物体身上存在刚体组件（或被检测物体），也要碰撞器collider CharacterController和Rigidbody的区别 物体发生碰撞时，有几个阶段，分别对应的函数答：排除触发，有3种，OnCollisionEnter(),OnCollisionStay(); OnCollisionExit() u3d中，几种施加力的方式，描述出来。答：a)爆炸力（AddExplosionForce(force : float, forcePos : Vector3，radius : float, upwards : float, mode : ForceMode)），应用一个力到刚体来模拟爆炸效果,就是在爆炸力中心坐标position,搜索在radius范围内的刚体，对其释放力作用，超出radius范围的刚体不受力作用，爆炸力将随着刚体的距离线性减弱。b)力AddForce(force : Vector3, mode : ForceMode),主要施力给一个刚，使其移动。c)位置力AddForceAtPosition(force : Vector3, position : Vector3, mode : ForceMode), 在position施加一个力，施力的主体将会受到一个力和力矩。d)相对力AddRelativeForce(force : Vector3, mode : ForceMode),类似于AddForce； 什么叫做链条关节答:Hinge Joint ,他可以模拟两个物体见 物体自旋转使用的函数叫什么答：transform.Rotate(eulerAngles : Vector3, relativeTo : Space = Space.self); 物体绕某点旋转使用函数叫什么答：transform.RotateAround(point : Vector3, axis : Vector3, angles : float) u3d提供了一个用于保存读取数据的类，（playerPrefs），请列出保存读取整形数据的函数答：PlayerPrefs.GetInt(key : string, defaultValue : int = 0); unity3d提供了几种光源，分别是什么答：平行光,点光源，聚光灯，环境光 unity3d从唤醒到销毁有一段生命周期，请列出系统自己调用的几个重要方法。答：void Awake(),void Start(), void Update(), void FixedUpdate(),void LateUpdate(), void OnGUI() ，void Reset(), OnDisable(), void OnDestroy() 物理更新一般在哪个系统函数里？答：void FixedUpdate() 移动相机动作在哪个函数里，为什么在这个函数里。答：void LateUpdate(),因为这个函数是在Update执行完毕才执行的，不然的话就有可能出现摄像机里面什么都看到的情况。 当游戏中需要频繁创建一个物体对象时，我们需要怎么做来节省内存。Unity里有两种动态加载机制:一个是Resources.Load,另外一个通过AssetBundle,其实两者区别不大,Resources.Load就是从一个缺省打进程序包里的AssetBundle里加载资源,而一般AssetBundle文件需要你自己创建,运行时动态加载AssetBundle运行时加载AssetBundle.Unload(flase)是释放AssetBundle文件 一个场景放置多个camera并同时处于活动状态，会发生什么23.简述prefab的用处和环境24.如何销毁一个UnityEngine.Object以及其子类25.为什么u3d会出现组件上数据丢失的情况26.u3d下如何安全的在不同工程迁移asset数据DrawCall优化一 Mesh Renderer二 Skinned Mesh Renderer三 合并要求对比四 总结五 场景制作建议DrawCall优化合并,即DrawCall Batching.通过减少Draw call数和对显卡性能的消耗来提高性能一 Mesh Renderer分为Dynamic Batching 和 Static BatchingDynamic Batching不需要任何操作,只要共享材质(即使是不同的Mesh模型也可以)Unity中的内存种类实际上Unity游戏使用的内存一共有三种:程序代码,托管堆(Managed Heap)以及本机堆(Native Heap)程序代码包括了所有的Unity引擎,使用的库,以及你所写的所有的游戏代码,在编译后,得到的运行文件将会被加载到设备中执行,并占用一定内存.这部分内存实际上是没有办法去”管理的” 法线贴图一: 法线贴图的原理光照效果很大程度上是由垂直于物体表面的法线决定的,因为法线影响反射光的方向,均匀垂直的法线是镜面贴图但是有时候我们会给一个平面使用砖墙贴图,砖墙应该是凹凸不平的,而如果让砖墙使用该平面的法线的话,画面就很假,而如果按真实砖墙去做模型的话,即做高精度模型,一方面制作麻烦,另一方面运行时对性能的损耗很大.法线贴图就是来解决这个问题的.法线贴图就是把法线信息存储在一张图里.使用发现贴图时,通常顶点数和三角形面数只有高精度模型的十分之一不到.二: 法线贴图的实现将材质贴图对应的法线绘制在一张贴图上,将贴图对应点的单位法线向量信息float3(x,y,z)存储在途中对应的颜色里压缩法线贴图的好处:压缩后的法线贴图,大小只有原来的1/4左右,故可以使用更大或者更多的贴图来提升画面品质.Unity3D的法线贴图Unity3D使用的压缩法线贴图是DXT5nm格式的,有A和G两个通道,对于法线(x,y,z) A对应x,G对应y对压缩法线贴图的采样依然是如下函数 float4 packedNormal = tex2D(_NormalMap, IN.uv_MainTex); packedNormal.w对应A通道,既法线的xpackedNormal.y对应G通道,既法线的yUnity3D热更新全书-加载(一)从AssetBundle说起我们试全面分析一下Unity3D提供的资源加载机制 Resourecs//内嵌资源,使用方法Resources.Load,可以加载任意种类的资源,不能动态修改 StreamingAssets//随包资源,使用方法IO或WWW.Load,WWW.Load可以加载任意种类资源,IO仅限bytes和text WWW从网络下载并加载 WWW从网络加载AssetBundle一和二显然不具有热更新的效果,这里就不做讨论3 4都是从网络加载的,他们有什么区别呢首先说3,这是没有缓冲的,我们显然不想让用户重复的浪费流量,不可取然后是4,assetbundle提供了一个版本号来做缓冲对比,可以比较好的起到更新的目标assetbundle原来就是Unity3D为我们准备的方案,难怪每本书都会大篇介绍AssetBundle,后文简称AB每本书都告诉你,AB很强大,AB帮你解决了跨平台问题,帮你解决了依赖关系.首先AB的确很好很强大,他能收纳Unity自己的所有资源种类,贴图,材质,shader预设然后可以每平台支持,这就是第一个陷进,注意是每平台都支持,不是多平台支持每个平台都要单独导出,而每个平台到底差了些什么呢?nothing而最大的质量差异,源自贴图有些平台贴图不压缩,有些平台贴图要压缩,而且根据不通的平台特性,套用不通的压缩算法,先压过再存到包里这就是AB帮你干的最主要的事情听起来很贴心呢,等等,你是不是忘了一个特定的命题,这个命题叫做UI压缩的图片会有质量损失,UI贴图我们通常是不压缩的然后UI还会触及到AB的另一个问题以NGUI为例,NGUI的资源关系比较复杂,有贴图-&gt;图集-&gt;布局不同的布局经常交叉应用贴图如果用AB想把每个界面分开打包,给用户最小的资源更新量,这个任务可以用来灾难来形容最终热更新推送给用户的东西是以文件为单位的,而AB在小粒度文件并且之间有较为复杂的应用关系这种需求的下的使用是一场灾难AB对每个平台的差异编译不是可选的,而是强制的,假如你有web,ios,android,三个平台,无论如何你都要导出三次没了AssetBundle,我们怎么办把碎片文件下载回来,并且组装对于UI这个情景,是完全可行的,把布局和图集保存为文本形式,把文本和贴图下载回来,然后组装对于其他场景片段,在有动画和贴图需要压缩的情况下,AB依然是唯一的选择unity没有提供在运行时压缩压缩贴图的手段,动画也不容易存储,只能运行时压缩DXT,只有pc和wp8支持对于各种各样的资源加载回特别凌乱么,不会其实本质上可以统一成bytes的处理texture可以从bytes加载字符串可以从bytes加载AB可以从bytes加载自定义二进制存储,本身就是bytesUnity3D热更新全书-加载(二)如何在不用AssetBundle的前提下动态加载预设Unity3D的主要构成大家都知道,首先是场景图,场景图上的节点构成一棵树每个节点对应一个GameObject对象然后每个GameObject有若干个组件有一些组件会与资源产生关系,比如MeshRenderer会关联材质,材质回关联shader和贴图场景图的一部分回保存为一个预设,prefab有时候我们会需要预设去复用,而预设的加载似乎只能通过AB去打包,其实不然,这里我们有一个开源的库就可以解决这个问题为什么不使用AB,可以见上一篇,加载(一),不使用AB一份资源全平台同意,也没有痛苦的打包时间,资源依赖也很容易处置 物理更新一般在FixedUpdate里,每固定帧绘制时执行一次,和update不同的是FixedUpdate是渲染帧执行,如果你的渲染效率低下的时候FixedUpdate调用次数就会跟着下降,FixedUpdate比较适用于物理引擎的计算,因为是跟每帧渲染有关,Update就比较适合做控制.移动相机动作在LateUpdate函数,当所有Update结束才调用,比较适合用于命令脚本的执行,当游戏中需要频繁创建一个物体对象时,做一个pool,游戏开始时预先实例化足够的数量,用的时候取,不用的时候回收. 什么是渲染管道?渲染管道中有很多步骤,都要将几何体从一个坐标系中变换到另一个坐标系中.本地坐标-&gt;视图坐标-&gt;背面裁剪-&gt;光照-&gt;裁剪-&gt;投影-&gt;视图变换-&gt;光栅化优化内存: 自带压缩类库 将暂时不用的以后还需要实用的物体隐藏起来而不是直接Destroy掉 释放AssetBundle占用的资源 降低模型的片面数,降低模型的骨骼数量,降低贴图的大小 使用光照贴图,使用多层次细节(LOD),使用着色器(Shader),使用预设(Prefab)资源加载: Resources.Load(); AssetBundlelocalPosition:自身位置,相对于父级的变换位置,Position:在世界坐标transform的位置静态构造函数不允许访问修饰符,也不接受任何参数碰撞器(Collider)有碰撞效果,IsTrigger=false,可以调用OnCollisionEnter/Stay/Exit函数触发器(Trigger)没有碰撞效果,IsTrigger=true,可以调用OnTriggerEnter/Stay/Exit函数 物体发生碰撞的必要条件?必须带有collider碰撞起和rigibody刚体属性或者人物控制器其实人物控制器就包含了前两者,另外一个也要带有Collider,Collider分类:网格碰撞器,盒子碰撞器,胶囊碰撞器,球型碰撞器,地形碰撞器 CharacterController和Rigidbody的区别?Rigidbody具有完全真是物理的特性,而CharacterController可以说是受限的Rigidbody,具有一定的物理效果但不是完全真实的.4.物体发生碰撞时,几种施加力的方式,描述出来?rigidbody.AddForce/AddForceAtPosition,都是rigidbody的成员函数 物体发生碰撞时,有几个阶段,分别对应的函数三个阶段,OnCollsionEnter/Stay/Exit函数 Unity3d提供了几种光源,分别是什么共4中,DirectrionaLight,PointLight,SpotLight,AreaLight(用于烘培) 使用Unity3d实现2d游戏,有几种方式?(1).使用本身GUI(2).把相机的Projection(投影)值调位Orthographic(正交投影),不考虑z轴;(3).使用2d插件,如:2DTollKit9.下列代码在运行中回产生几个临时对象?string a = new string(“abc”);a = (a.ToUpper() + “123”).SubString(0, 2);答:其实在C#第一行是会出错的(Java中倒是可行),应该这样初始化string b = new string(new char[]{‘a’, ‘b’, ‘c’}} 请简述关键字Sealed用在类声明和函数声明时的作用答:类声明时可防止其他类继承此类,在方法中声明则可防止派生类重写此方法 简述四元数的作用,四元数对欧拉角的优点?答:四元数用于表示旋转相对于欧拉角的优点:(1).能进行增量旋转(2).避免方向锁(3)给定方位的表达方式有两种,互为负(欧拉角有无数种表达方式)12.如何安全的在不用工程间安全的迁移asset数据,三种方法答(1).将Assets目录和Library目录一起迁移(2)导出包(3)用unity自带的assert server功能13.当一个细小的高速物体碰撞另一个较大的物体时,会出现什么情况?如何避免?穿透(碰撞检测失败)14.MipMap是什么?作用?在三维计算机图形的贴图渲染中有一个常用的技术被成为Mipmapping,为了加快渲染速度和减少图像锯齿,贴图被处理成为 反射实现原理：在运行时根据程序集和其中的类型得到元数据12345678910using System.Reflection;Assembly.Load("程序集");//加载一个程序集，返回类型是一个Assemblyforeach(Type type in assembly.GetType())&#123; stromh t = type.name;&#125;Type type = assembly.GetType("程序集.类名"); //获取当前类的类型var activator = System.Activator.CreateInstance(type); // 创建此类型实例MethodInfo mInfo = type.GetMethod("方法名");//获取当前方法mInfo.Invok(null, 方法参数);]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unity-nature-review]]></title>
    <url>%2F2018%2F04%2F10%2Funity-nature-review%2F</url>
    <content type="text"><![CDATA[是否有多维子材质：多维子材质材质测试，三个子材质，50个物体，使用多维子材质12帧，330个dc，343面。拆开之后20帧，154dc，134面。多维子材质Unity无法动态合并。叠加模式贴图，可以不用Alpha通道特效粒子贴图是否合并是否有些粒子能使用序列帧，不过和视角有关，去掉alpha贴图合并。动画boneweight,没有特殊需要的情况下受两个骨骼影响就够了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[大端模式与小端模式]]></title>
    <url>%2F2018%2F04%2F02%2FUnix%2F</url>
    <content type="text"><![CDATA[字节序 Little-Endian 低位字节放在内存的低地址端，高位字节放在内存的高地址端。 Big-Endian 高位字节放在内存的高地址端，低位字节放在内存的低地址端。 Network byte order TPC/IP各层协议将字节序定义为Big-Endian，因此TCP/IP协议中使用的字节序通常称之为网络字节序。 高/低地址端首先要知道C程序中内存的空间布局情况：在《C专家编程》和《Unix环境高级编程》中关于内存空间布局情况的说明，大致如下图： ——————————————— 最高内存地址 0xffffffff栈底栈栈顶NULL（空洞）堆未初始化的数据正文段（代码段——————————————— 最高内存地址 0x00000000 在内存分布中，栈是向下增长的，而堆是向上增长的。 加入在栈分配unisgned char buf[4]，他在栈上分布如下栈底（高地址）buf[3]buf[2]buf[1]buf[0]栈顶（低地址） 高/低位字节在十进制中靠左边的是高位，靠右边的地址，在其它进制也是如此 unisgned int value = 0x12345678; Big-Endian:低地址存放高位栈底（高地址）buf[3] (0x78)buf[2] (0x56)buf[1] (0x34)buf[0] (0x12)栈顶（低地址） Litter-Endian:高地址存高位栈顶（高地址）buf[0] (0x78)buf[1] (0x56)buf[2] (0x34)buf[3] (0x12)栈底（低地址） 主机序（Host Order）就是遵循Little-Endian规则。所以当两台主机之间通过TCP/IP协议进行通信的时候就需要调用相应的函数进行主机序（Little-Endian）和网络（Big-Endian）的转换。 Big-Endian和Little-Endian优缺点Big-Endian 优点： 靠首先提取高位字节，总是可以在偏移位置为0的字节来确定这个数字是正数还是负数。 数值打印是按顺序存放的 Litter-Endian 优点： 数学计算，精度处理。]]></content>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua参考手册上半部分]]></title>
    <url>%2F2018%2F04%2F02%2FLua-5-1-refer-manual%2F</url>
    <content type="text"><![CDATA[Lua 是一个扩展式程序设计语言，它被设计成支持通用的过程式编程，并有相关数据描述的设施。 Lua 也能对面向对象编程，函数式编程，数据驱动式编程提供很好的支持。 它可以作为一个强大、轻量的脚本语言，供任何需要的程序使用。 Lua 以一个用 clean C 写成的库形式提供。（所谓 Clean C ，指的 ANSI C 和 C++ 中共通的一个子集）作为一个扩展式语言，Lua 没有 “main” 程序的概念：它只能 嵌入 一个宿主程序中工作，这个宿主程序被称作 embedding program 或简称为 host 。 宿主程序可以通过调用函数执行一小段 Lua 代码，可以读写 Lua 变量，可以注入 C 函数让 Lua 代码调用。 这些扩展的 C 函数，可以大大的扩展了 Lua 可以处理事务的领域，这样就可以订制出各种语言， 而它们共享一个统一的句法格式的框架。 Lua 的官方发布版就包含了一个叫做 lua 的简单的宿主程序，它用 Lua 库提供了一个保证独立的 Lua 解释器。Lua 是一个自由软件，它的使用许可决定了对它的使用过程一般没有任何保证。 这份手册中描述的东西的实现，可以在 Lua 的官方网站 www.lua.org 找到，跟其它的许多参考手册一样，这份文档有些地方比较枯燥。 关于 Lua 的设计想法的探讨，可以看看 Lua 网站上提供的技术论文。 有关用 Lua 编程的细节介绍，可以读一下 Roberto 的书，Programming in Lua (Second Edition) 。 这一节从词法、语法、句法上描述 Lua 。 换句话说，这一节描述了哪些 token （符记）是有效的，它们如何被组合起来，这些组合方式有什么含义。关于语言的构成概念将用常见的扩展 BNF 表达式写出。也就是这个样子： {a} 意思是 0 或多个 a ， [a] 意思是一个可选的 a 。 非最终的符号会保留原来的样子，关键字则看起来像这样 kword ， 其它最终的符号则写成 `=´ 。 完整的 Lua 语法可以在本手册最后找到。 Lua 中用到的 名字（也称作 标识符）可以是任何非数字开头的字母、数字、下划线组成的字符串。 这符合几乎所有编程语言中关于名字的定义。 （字母的定义依赖于当前环境：系统环境中定义的字母表中的字母都可以被用于标识符。） 标识符用来命名变量，或作为表的域名。 下面的关键字是保留的，不能用作名字： and break do else elseif end false for function if in local nil not or repeat return then true until while Lua 是一个大小写敏感的语言： and 是一个保留字，但是 And 和 AND 则是两个不同的合法的名字。 一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。 下面这些是其它的 token ： + - * / % ^ # == ~= &lt;= &gt;= &lt; &gt; = ( ) { } [ ] ; : , . .. ... 字符串既可以用一对单引号引起，也可以是双引号，里面还可以包含类似 C 的转义符： ‘\a’ （响铃）， ‘\b’ （退格）， ‘\f’ （表单）， ‘\n’ （换行）， ‘\r’ （回车）， ‘\t’ （横向制表）， ‘\v’ （纵向制表）， ‘\‘ （反斜杠）， ‘\”‘ （双引号）， 以及 ‘\’’ （单引号)。 而且，如果在一个反斜杠后跟了一个真正的换行符，其结果就是在字符串中产生一个换行符。 我们还可以用反斜杠加数字的形式 \ddd 来描述一个字符。这里， ddd 是一串最多三位的十进制数字。（注意，如果需要在这种描述方法后接一个是数字的字符， 那么反斜杠后必须写满三个数字。）Lua 中的字符串可以包含任何 8 位的值。包括用 ‘\0’ 表示的零。只有在你需要把不同的引号、换行、反斜杠、或是零结束符这些字符置入字符串时， 你才必须使用转义符。别的任何字符都可以直接写在文本里。（一些控制符可以会影响文件系统造成某些问题， 但是不会引起 Lua 的任何问题。）字符串还可以用一种长括号括起来的方式定义。 我们把两个正的方括号间插入 n 个等号定义为第 n 级正长括号。 就是说，0 级正的长括号写作 [[ ， 一级正的长括号写作 [=[ ，如此等等。 反的长扩展也作类似定义； 举个例子，4 级反的长括号写作 ]====] 。 一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束。 整个词法分析过程将不受分行限制，不处理任何转意符，并且忽略掉任何不同级别的长括号。 这种方式描述的字符串可以包含任何东西，当然特定级别的反长括号除外。另一个约定是，当正的长括号后面立即跟了一个换行符， 这个换行符就不包含在这个字符串内。 举个例子，假设一个系统使用 ASCII 码 （这时，’a’ 编码为 97 ，换行符编码为 10 ，’1’ 编码为 49 ）， 下面五种方式描述了完全相同的字符串： a = &#39;alo\n123&quot;&#39; a = &quot;alo\n123\&quot;&quot; a = &#39;\97lo\10\04923&quot;&#39; a = [[alo 123&quot;]] a = [==[ alo 123&quot;]==] 数字常量可以分两部分写，十进制底数部分和十进制的指数部分。指数部分是可选的。 Lua 也支持十六进制整数常量，只需要在前面加上前缀 0x 。 下面是一些合法的数字常量的例子： 3 3.0 3.1416 314.16e-2 0.31416E1 0xff 0x56 注释可以在除字符串内的任何地方是以两横 (—) 开始。 如果跟在两横后面的不是一个长括号，这就是一个短注释，它的作用范围直到行末； 否则就是一个长注释，其作用范围直到遇到反的长括号。 长注释通常被用来临时屏蔽代码块。Lua 是一种 动态类型语言。 这意味着变量没有类型，只有值才有类型。 语言中不存在类型定义。而所有的值本身携带它们自己的类型信息。Lua 中的所有值都是一致 (first-class) 的。 这意味着所有的值都可以被放在变量里，当作参数传递到另一个函数中，并被函数作为结果返回。Lua 中有八种基本类型： nil, boolean, number, string, function, userdata, thread, and table. Nil 类型只有一种值 nil ，它的主要用途用于标表识和别的任何值的差异； 通常，当需要描述一个无意义的值时会用到它。 Boolean 类型只有两种值：false 和 true。 nil 和 false 都能导致条件为假；而另外所有的值都被当作真。 Number 表示实数（双精度浮点数）。 （编译一个其它内部数字类型的 Lua 解释器是件很容易的事；比如把内部数字类型改作 单精度浮点数或长整型。参见文件 luaconf.h 。） String 表示一串字符的数组。 Lua 是 8-bit clean 的： 字符串可以包含任何 8 位字符， 包括零结束符 (‘\0’) （参见 §2.1）。Lua 可以调用（和处理）用 Lua 写的函数以及用 C 写的函数userdata 类型用来将任意 C 数据保存在 Lua 变量中。 这个类型相当于一块原生的内存，除了赋值和相同性判断，Lua 没有为之预定义任何操作。 然而，通过使用 metatable （元表） ，程序员可以为 userdata 自定义一组操作。 userdata 不能在 Lua 中创建出来，也不能在 Lua 中修改。这样的操作只能通过 C API。 这一点保证了宿主程序完全掌管其中的数据。thread 类型用来区别独立的执行线程，它被用来实现 coroutine （协同例程）。 不要把 Lua 线程跟操作系统的线程搞混。 Lua 可以在所有的系统上提供对 coroutine 的支持，即使系统并不支持线程。table 类型实现了一个关联数组。也就是说， 数组可以用任何东西（除了nil）做索引，而不限于数字。 table 可以以不同类型的值构成；它可以包含所有的类型的值（除 nil 外）。 table 是 lua 中唯一的一种数据结构；它可以用来描述原始的数组、符号表、集合、 记录、图、树、等等。 用于表述记录时，lua 使用域名作为索引。 语言本身采用一种语法糖，支持以 a.name 的形式表示 a[“name”]。 有很多形式用于在 lua 中创建一个 table （参见 §2.5.7）。跟索引一样， table 每个域中的值也可以是任何类型（除 nil外）。 特别的，因为函数本身也是值，所以 table 的域中也可以放函数。 这样 table 中就可以有一些 methods 了 。table， function ，thread ，和 (full) userdata 这些类型的值是所谓的对象： 变量本身并不会真正的存放它们的值，而只是放了一个对对象的引用。 赋值，参数传递，函数返回，都是对这些对象的引用进行操作； 这些操作不会做暗地里做任何性质的拷贝。库函数 type 可以返回一个描述给定值的类型的字符串。Lua 提供运行时字符串到数字的自动转换。 任何对字符串的数学运算操作都会尝试用一般的转换规则把这个字符串转换成一个数字。 相反，无论何时，一个数字需要作为字符串来使用时，数字都会以合理的格式转换为字符串。 需要完全控制数字怎样转换为字符串，可以使用字符串库中的 format 函数 （参见 string.format）。写上变量的地方意味着当以其保存的值来替代之。 Lua 中有三类变量：全局变量，局部变量，还有 table 的域。一个单一的名字可以表示一个全局变量，也可以表示一个局部变量 （或者是一个函数的参数，这是一种特殊形式的局部变量）： var ::= Name Name 就是所定义的标识符。任何变量都被假定为全局变量，除非显式的以 local 修饰定义。 局部变量有其作用范围： 局部变量可以被定义在它作用范围中的函数自由使用。在变量的首次赋值之前，变量的值均为 nil。方括号被用来对 table 作索引： var ::= prefixexp `[´ exp `]´ 对全局变量以及 table 域之访问的含义可以通过 metatable 来改变。 以取一个变量下标指向的量 t[i] 等价于调用 gettable_event(t,i)。 （参见 §2.8 ，有一份完整的关于 gettable_event 函数的说明。 这个函数并没有在 lua 中定义出来，也不能在 lua 中调用。 这里我们把它列出来只是方便说明。） var.Name 这种语法只是一个语法糖，用来表示 var[“Name”]： var ::= prefixexp `.´ Name 所有的全局变量都是放在一个特定 lua table 的诸个域中，这个特定的 table 叫作 environment （环境）table 或者简称为 环境 （参见 §2.9）。 每个函数都有对一个环境的引用， 所以一个函数中可见的所有全局变量都放在这个函数所引用的环境表（environment table）中。 当一个函数被创建出来，它会从创建它的函数中继承其环境，你可以调用 getfenv 取得其环境。 如果想改变环境，可以调用 setfenv。 （对于 C 函数，你只能通过 debug 库来改变其环境； 参见 §5.9）。 对一个全局变量 x 的访问 等价于 _env.x，而这又可以等价于 gettable_event(_env, &quot;x&quot;) 这里，_env 是当前运行的函数的环境。 （函数 gettable_event 的完整说明参见 §2.8。 这个函数并没有在 lua 中定义出来，也不能调用。 当然，_env 这个变量也同样没有在 Lua 中定义出来。 我们在这里使用它们，仅仅只是方便解释而已。） 2.4 - 语句段（Statement）Lua 支持惯例形式的语句段，它和 Pascal 或是 C 很相象。 这个集合包括赋值，控制结构，函数调用，还有变量声明。 2.4.1 - Chunk（语句组）Lua 的一个执行单元被称作 chunk。 一个 chunk 就是一串语句段，它们会被循序的执行。 每个语句段可以以一个分号结束： chunk ::= {stat [`;´]} 这儿不允许有空的语句段，所以 ‘;;’ 是非法的。 lua 把一个 chunk 当作一个拥有不定参数的匿名函数 （参见 §2.5.9）处理。 正是这样，chunk 内可以定义局部变量，接收参数，并且返回值。 chunk 可以被保存在一个文件中，也可以保存在宿主程序的一个字符串中。 当一个 chunk 被执行，首先它会被预编译成虚拟机中的指令序列， 然后被虚拟机解释运行这些指令。 chunk 也可以被预编译成二进制形式；细节参考程序 luac。 用源码形式提供的程序和被编译过的二进制形式的程序是可以相互替换的； Lua 会自动识别文件类型并做正确的处理。 语句块是一列语句段；从语法上来说，一个语句块跟一个 chunk 相同： block ::= chunk 一个语句块可以被显式的写成一个单独的语句段： stat ::= do block end 显式的语句块对于控制变量的作用范围很有用。 有时候，显式的语句块被用来在另一个语句块中插入 return 或是 break （参见 §2.4.4）。 Lua 允许多重赋值。 因此，赋值的语法定义是等号左边放一系列变量， 而等号右边放一系列的表达式。 两边的元素都用逗号间开： stat ::= varlist1 `=´ explist1 varlist1 ::= var {`,´ var} explist1 ::= exp {`,´ exp} 在作赋值操作之前， 那一系列的右值会被对齐到左边变量需要的个数。 如果右值比需要的更多的话，多余的值就被扔掉。 如果右值的数量不够需求， 将会按所需扩展若干个 nil。 如果表达式列表以一个函数调用结束， 这个函数所返回的所有值都会在对齐操作之前被置入右值序列中。 （除非这个函数调用被用括号括了起来；参见 §2.5）。 赋值段首先会做运算完所有的表达式，然后仅仅做赋值操作。 因此，下面这段代码 i = 3 i, a[i] = i+1, 20 会把 a[3] 设置为 20，而不会影响到 a[4] 。 这是因为 a[i] 中的 i 在被赋值为 4 之前就被拿出来了（那时是 3 ）。 简单说 ，这样一行 x, y = y, x 可以用来交换 x 和 y 中的值。 对全局变量以及 table 中的域的赋值操作的含义可以通过 metatable 来改变。 对变量下标指向的赋值，即 t[i] = val 等价于 settable_event(t,i,val)。 （关于函数 settable_event 的详细说明，参见 §2.8。 这个函数并没有在 Lua 中定义出来，也不可以被调用。 这里我们列出来，仅仅出于方便解释的目的） 对于全局变量的赋值 x = val 等价于 _env.x = val，这个又可以等价于 settable_event(_env, &quot;x&quot;, val) 这里，_env 指的是正在运行中的函数的环境。 （变量 _env 并没有在 Lua 中定义出来。 我们仅仅出于解释的目的在这里写出来。） if、 while、以及 repeat 这些控制结构符合通常的意义，而且也有类似的语法： stat ::= while exp do block end stat ::= repeat block until exp stat ::= if exp then block {elseif exp then block} [else block] end Lua 也有一个 for 语句，它有两种形式。控制结构中的条件表达式可以返回任何值。 false 和 nil 两者都被认为是假条件。 所有不同于 nil 和 false 的其它值都被认为是真 （特别需要注意的是，数字 0 和空字符串也被认为是真）。在 repeat–until 循环中， 内部语句块的结束点不是在 until 这个关键字处， 它还包括了其后的条件表达式。 因此，条件表达式中可以使用循环内部语句块中的定义的局部变量。return 被用于从函数或是 chunk（其实它就是一个函数）中 返回值。 函数和 chunk 可以返回不只一个值， 所以 return 的语法为 stat ::= return [explist1] break 被用来结束 while、 repeat、或 for 循环， 它将忽略掉循环中下面的语句段的运行： stat ::= break break 跳出最内层的循环。return 和 break 只能被写在一个语句块的最后一句。 如果你真的需要从语句块的中间 return 或是 break ， 你可以使用显式的声名一个内部语句块。 一般写作 do return end 或是 do break end， 可以这样写是因为现在 return 或 break 都成了一个语句块的最后一句了。 for 有两种形式：一种是数字形式，另一种是一般形式。 数字形式的 for 循环，通过一个数学运算不断的运行内部的代码块。 下面是它的语法： stat ::= for Name `=´ exp `,´ exp [`,´ exp] do block end block 将把 name 作循环变量。从第一个 exp 开始起，直到第二个 exp 的值为止，其步长为 第三个 exp 。 更确切的说，一个 for 循环看起来是这个样子 for v = e1, e2, e3 do block end 这等价于代码： do local var, limit, step = tonumber(e1), tonumber(e2), tonumber(e3) if not (var and limit and step) then error() end while (step &gt; 0 and var &lt;= limit) or (step &lt;= 0 and var &gt;= limit) do local v = var block var = var + step end end 注意下面这几点： 所有三个控制表达式都只被运算一次，表达式的计算在循环开始之前。 这些表达式的结果必须是数字。var 、limit 、以及 step 都是一些不可见的变量。 这里给它们起的名字都仅仅用于解释方便。如果第三个表达式（步长）没有给出，会把步长设为 1 。你可以用 break 来退出 for 循环。循环变量 v 是一个循环内部的局部变量； 当 for 循环结束后，你就不能在使用它。 如果你需要这个值，在退出循环前把它赋给另一个变量。一般形式的 for 通过一个叫作迭代器（iterators）的函数工作。 每次迭代，迭代器函数都会被调用以产生一个新的值， 当这个值为 nil 时，循环停止。 一般形式的 for 循环的语法如下： stat ::= for namelist in explist1 do block end namelist ::= Name {`,´ Name} for 语句好似这样 for var_1, ···, var_n in explist do block end 它等价于这样一段代码： do local f, s, var = explist while true do local var_1, ···, var_n = f(s, var) var = var_1 if var == nil then break end block end end 注意以下几点： explist 只会被计算一次。 它返回三个值， 一个迭代器函数，一个状态，一个迭代器的初始值。f、 s、 以及 var 都是不可见的变量。 这里给它们起的名字都只是为了解说方便。你可以使用 break 来跳出 for 循环。循环变量 var_i 对于循环来说是一个局部变量； 你不可以在 for 循环结束后继续使用。 如果你需要保留这些值，那么就在循环结束前赋值到别的变量里去。2.4.6 - 把函数调用作为语句段为了允许使用可能的副作用， 函数调用可以被作为一个语句段执行： stat ::= functioncall 在这种情况下，所有的返回值都被舍弃。 函数调用在 §2.5.8 中解释。 2.4.7 - 局部变量声名局部变量可以在语句块中任何地方声名。 声名可以包含一个初始化赋值操作： stat ::= local namelist [`=´ explist1] 如果有的话，初始化赋值操作的行为等同于赋值操作（参见 §2.4.3）。 否则，所有的变量将被初始化为 nil。 一个 chunk 同时也是一个语句块（参见 §2.4.1）， 所以局部变量可以放在 chunk 中那些显式注明的语句块之外。 这些局部变量的作用范围从声明起一直延伸到 chunk 末尾。 局部变量的可见规则在 §2.6 中解释。 2.5 - 表达式Lua 中有这些基本表达式： exp ::= prefixexp exp ::= nil | false | true exp ::= Number exp ::= String exp ::= function exp ::= tableconstructor exp ::= `...´ exp ::= exp binop exp exp ::= unop exp prefixexp ::= var | functioncall | `(´ exp `)´ 数字和字符串在 §2.1 中解释； 变量在 §2.3 中解释； 函数定义在 §2.5.9 中解释； 函数调用在 §2.5.8 中解释； table 的构造在 §2.5.7 中解释； 可变参数的表达式写作三个点 (‘…’) ，它只能被用在有可变参数的函数中； 这些在 §2.5.9 中解释。 二元操作符包含有数学运算操作符（参见 §2.5.1）， 比较操作符（参见 §2.5.2），逻辑操作符（参见 §2.5.3）， 以及连接操作符（参见 §2.5.4）。 一元操作符包括负号（参见see §2.5.1）， 取反 not（参见 §2.5.3）， 和取长度操作符（参见 §2.5.5）。 函数调用和可变参数表达式都可以放在多重返回值中。 如果表达式作为一个独立语句段出现（参见 §2.4.6） （这只能是一个函数调用）， 它们的返回列表将被对齐到零个元素，也就是忽略所有返回值。 如果表达式用于表达式列表的最后（或者是唯一）的元素， 就不会有任何的对齐操作（除非函数调用用括号括起来）。 在任何其它的情况下，Lua 将把表达式结果看成单一元素， 忽略除第一个之外的任何值。 这里有一些例子： f() -- 调整到 0 个结果 g(f(), x) -- f() 被调整到一个结果 g(x, f()) -- g 被传入 x 加上所有 f() 的返回值 a,b,c = f(), x -- f() 被调整到一个结果 （ c 在这里被赋为 nil ） a,b = ... -- a 被赋值为可变参数中的第一个， -- b 被赋值为第二个 （如果可变参数中并没有对应的值， -- 这里 a 和 b 都有可能被赋为 nil） a,b,c = x, f() -- f() 被调整为两个结果 a,b,c = f() -- f() 被调整为三个结果 return f() -- 返回 f() 返回的所有结果 return ... -- 返回所有从可变参数中接收来的值 return x,y,f() -- 返回 x, y, 以及所有 f() 的返回值 {f()} -- 用 f() 的所有返回值创建一个列表 {...} -- 用可变参数中的所有值创建一个列表 {f(), nil} -- f() 被调整为一个结果 被括号括起来的表达式永远被当作一个值。所以， (f(x,y,z)) 即使 f 返回多个值，这个表达式永远是一个单一值。 （(f(x,y,z)) 的值是 f 返回的第一个值。如果 f 不返回值的话，那么它的值就是 nil 。） 2.5.1 - 数学运算操作符Lua 支持常见的数学运算操作符： 二元操作 + （加法）， - （减法），* （乘法）， / （除法）， % （取模），以及 ^ （幂）； 和一元操作 - （取负）。 如果对数字操作，或是可以转换为数字的字符串（参见 §2.2.1）， 所有这些操作都依赖它通常的含义。 幂操作可以对任何幂值都正常工作。比如， x^(-0.5) 将计算出 x 平方根的倒数。 取模操作被定义为 a % b == a - math.floor(a/b)*b 这就是说，其结果是商相对负无穷圆整后的余数。（译注：负数对正数取模的结果为正数） 2.5.2 - 比较操作符Lua 中的比较操作符有 == ~= &lt; &gt; &lt;= &gt;= 这些操作的结果不是 false 就是 true。 等于操作 (==) 首先比较操作数的类型。 如果类型不同，结果就是 false。 否则，继续比较值。 数字和字符串都用常规的方式比较。 对象 （table ，userdata ，thread ，以及函数）以引用的形式比较： 两个对象只有在它们指向同一个东西时才认为相等。 每次你创建一个新对象（一个 table 或是 userdata ，thread 函数）， 它们都各不相同，即不同于上次创建的东西。 你可以改变 Lua 比较 table 和 userdata 的方式，这需要使用 “eq” 这个原方法 （参见 §2.8）。 §2.2.1 中提及的转换规则并不作用于比较操作。 所以， “0”==0 等于 false， 而且 t[0] 和 t[“0”] 描述的是 table 中不同的域。 操作符 ~= 完全等价于 (==) 操作的反值。 大小比较操作以以下方式进行。 如果参数都是数字，那么就直接做数字比较。 否则，如果参数都是字符串，就用字符串比较的方式进行。 再则，Lua 就试着调用 “lt” 或是 “le” 元方法 （参见 §2.8）。 2.5.3 - 逻辑操作符Lua 中的逻辑操作符有 and, or, 以及 not。 和控制结构（参见 §2.4.4）一样， 所有的逻辑操作符把 false 和 nil 都作为假， 而其它的一切都当作真。 取反操作 not 总是返回 false 或 true 中的一个。 与操作符 and 在第一个参数为 false 或 nil 时 返回这第一个参数； 否则，and 返回第二个参数。 或操作符 or 在第一个参数不为 nil 也不为 false 时， 返回这第一个参数，否则返回第二个参数。 and 和 or 都遵循短路规则； 也就是说，第二个操作数只在需要的时候去求值。 这里有一些例子： 10 or 20 --&gt; 10 10 or error() --&gt; 10 nil or &quot;a&quot; --&gt; &quot;a&quot; nil and 10 --&gt; nil false and error() --&gt; false false and nil --&gt; false false or nil --&gt; nil 10 and 20 --&gt; 20 （在这本手册中， —&gt; 指前面表达式的结果。） 2.5.4 - 连接符Lua 中字符串的连接操作符写作两个点 (‘..’)。 如果两个操作数都是字符串或都是数字，连接操作将以 §2.2.1 中提到的规则把其转换为字符串。 否则，会取调用元方法 “concat” （参见 §2.8）。 2.5.5 - 取长度操作符取长度操作符写作一元操作 #。 字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）。 table t 的长度被定义成一个整数下标 n 。 它满足 t[n] 不是 nil 而 t[n+1] 为 nil； 此外，如果 t[1] 为 nil ，n 就可能是零。 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候， 它的长度就精确的为 n，即最后一个值的下标。 如果数组有一个“空洞” （就是说，nil 值被夹在非空值之间）， 那么 #t 可能是指向任何一个是 nil 值的前一个位置的下标 （就是说，任何一个 nil 值都有可能被当成数组的结束）。 2.5.6 - 优先级Lua 中操作符的优先级写在下表中，从低到高优先级排序： or and &lt; &gt; &lt;= &gt;= ~= == .. + - * / % not # - (unary) ^ 通常，你可以用括号来改变运算次序。 连接操作符 (‘..’) 和幂操作 (‘^’) 是从右至左的。 其它所有的操作都是从左至右。 2.5.7 - Table 构造table 构造子是一个构造 table 的表达式。 每次构造子被执行，都会构造出一个新的 table 。 构造子可以被用来构造一个空的 table， 也可以用来构造一个 table 并初始化其中的一些域。 一般的构造子的语法如下 tableconstructor ::= `{´ [fieldlist] `}´ fieldlist ::= field {fieldsep field} [fieldsep] field ::= `[´ exp `]´ `=´ exp | Name `=´ exp | exp fieldsep ::= `,´ | `;´ 每个形如 [exp1] = exp2 的域向 table 中增加新的一项， 其键值为 exp1 而值为 exp2。 形如 name = exp 的域等价于 [“name”] = exp。 最后，形如 exp 的域等价于 [i] = exp ， 这里的 i 是一个从 1 开始不断增长的数字。 这这个格式中的其它域不会破坏其记数。 举个例子： a = { [f(1)] = g; &quot;x&quot;, &quot;y&quot;; x = 1, f(x), [30] = 23; 45 } 等价于 do local t = {} t[f(1)] = g t[1] = &quot;x&quot; -- 1st exp t[2] = &quot;y&quot; -- 2nd exp t.x = 1 -- t[&quot;x&quot;] = 1 t[3] = f(x) -- 3rd exp t[30] = 23 t[4] = 45 -- 4th exp a = t end 如果表单中最后一个域的形式是 exp ， 而且其表达式是一个函数调用或者是一个可变参数， 那么这个表达式所有的返回值将连续的进入列表 （参见 §2.5.8）。 为了避免这一点，你可以用括号把函数调用（或是可变参数）括起来 （参见 §2.5）。 初始化域表可以在最后多一个分割符， 这样设计可以方便由机器生成代码。 2.5.8 - 函数调用Lua 中的函数调用的语法如下： functioncall ::= prefixexp args 函数调用时，第一步，prefixexp 和 args 先被求值。 如果 prefixexp 的值的类型是 function， 那么这个函数就被用给出的参数调用。 否则 prefixexp 的元方法 “call” 就被调用， 第一个参数就是 prefixexp 的值，跟下来的是原来的调用参数 （参见 §2.8）。 这样的形式 functioncall ::= prefixexp `:´ Name args 可以用来调用 “方法”。 这是 Lua 支持的一种语法糖。像 v:name(args) 这个样子，被解释成 v.name(v,args)， 这里 v 只会被求值一次。 参数的语法如下： args ::= `(´ [explist1] `)´ args ::= tableconstructor args ::= String 所有参数的表达式求值都在函数调用之前。 这样的调用形式 f{fields} 是一种语法糖用于表示 f({fields})； 这里指参数列表是一个单一的新创建出来的列表。 而这样的形式 f’string’ （或是 f”string” 亦或是 f[[string]]） 也是一种语法糖，用于表示 f(‘string’)； 这里指参数列表是一个单独的字符串。 因为表达式语法在 Lua 中比较自由， 所以你不能在函数调用的 ‘(‘ 前换行。 这个限制可以避免语言中的一些歧义。 比如你这样写 a = f (g).x(a) Lua 将把它当作一个单一语句段， a = f(g).x(a) 。 因此，如果你真的想作为成两个语句段，你必须在它们之间写上一个分号。 如果你真的想调用 f， 你必须从 (g) 前移去换行。 这样一种调用形式：return functioncall 将触发一个尾调用。 Lua 实现了适当的尾部调用（或是适当的尾递归）： 在尾调用中， 被调用的函数重用调用它的函数的堆栈项。 因此，对于程序执行的嵌套尾调用的层数是没有限制的。 然而，尾调用将删除调用它的函数的任何调试信息。 注意，尾调用只发生在特定的语法下， 这时， return 只有单一函数调用作为参数； 这种语法使得调用函数的结果可以精确返回。 因此，下面这些例子都不是尾调用： return (f(x)) -- 返回值被调整为一个 return 2 * f(x) return x, f(x) -- 最加若干返回值 f(x); return -- 无返回值 return x or f(x) -- 返回值被调整为一个 2.5.9 - 函数定义函数定义的语法如下： function ::= function funcbody funcbody ::= `(´ [parlist1] `)´ block end 另外定义了一些语法糖简化函数定义的写法： stat ::= function funcname funcbody stat ::= local function Name funcbody funcname ::= Name {`.´ Name} [`:´ Name] 这样的写法： function f () body end 被转换成 f = function () body end 这样的写法： function t.a.b.c.f () body end 被转换成 t.a.b.c.f = function () body end 这样的写法： local function f () body end 被转换成 local f; f = function () body end 注意，并不是转换成 local f = function () body end （这个差别只在函数体内需要引用 f 时才有。） 一个函数定义是一个可执行的表达式， 执行结果是一个类型为 function 的值。 当 Lua 预编译一个 chunk 的时候， chunk 作为一个函数，整个函数体也就被预编译了。 那么，无论何时 Lua 执行了函数定义， 这个函数本身就被实例化了（或者说是关闭了）。 这个函数的实例（或者说是 closure（闭包）） 是表达式的最终值。 相同函数的不同实例有可能引用不同的外部局部变量， 也可能拥有不同的环境表。 形参（函数定义需要的参数）是一些由实参（实际传入参数）的值初始化的局部变量： parlist1 ::= namelist [`,´ `...´] | `...´ 当一个函数被调用， 如果函数没有被定义为接收不定长参数，即在形参列表的末尾注明三个点 (‘…’)， 那么实参列表就会被调整到形参列表的长度， 变长参数函数不会调整实参列表； 取而代之的是，它将把所有额外的参数放在一起通过变长参数表达式传递给函数， 其写法依旧是三个点。 这个表达式的值是一串实参值的列表，看起来就跟一个可以返回多个结果的函数一样。 如果一个变长参数表达式放在另一个表达式中使用，或是放在另一串表达式的中间， 那么它的返回值就会被调整为单个值。 若这个表达式放在了一系列表达式的最后一个，就不会做调整了（除非用括号给括了起来）。 我们先做如下定义，然后再来看一个例子： function f(a, b) end function g(a, b, ...) end function r() return 1,2,3 end 下面看看实参到形参数以及可变长参数的映射关系： CALL PARAMETERS f(3) a=3, b=nil f(3, 4) a=3, b=4 f(3, 4, 5) a=3, b=4 f(r(), 10) a=1, b=10 f(r()) a=1, b=2 g(3) a=3, b=nil, ... --&gt; (nothing) g(3, 4) a=3, b=4, ... --&gt; (nothing) g(3, 4, 5, 8) a=3, b=4, ... --&gt; 5 8 g(5, r()) a=5, b=1, ... --&gt; 2 3 结果由 return 来返回（参见 §2.4.4）。 如果执行到函数末尾依旧没有遇到任何 return 语句， 函数就不会返回任何结果。 冒号语法可以用来定义方法， 就是说，函数可以有一个隐式的形参 self。 因此，如下写法： function t.a.b.c:f (params) body end 是这样一种写法的语法糖： t.a.b.c.f = function (self, params) body end 2.6 - 可视规则Lua 是一个有词法作用范围的语言。 变量的作用范围开始于声明它们之后的第一个语句段， 结束于包含这个声明的最内层语句块的结束点。 看下面这些例子： x = 10 -- 全局变量 do -- 新的语句块 local x = x -- 新的一个 &#39;x&#39;, 它的值现在是 10 print(x) --&gt; 10 x = x+1 do -- 另一个语句块 local x = x+1 -- 又一个 &#39;x&#39; print(x) --&gt; 12 end print(x) --&gt; 11 end print(x) --&gt; 10 （取到的是全局的那一个） 注意这里，类似 local x = x 这样的声明， 新的 x 正在被声明，但是还没有进入它的作用范围， 所以第二个 x 指向的是外面一层的变量。 因为有这样一个词法作用范围的规则， 所以可以在函数内部自由的定义局部变量并使用它们。 当一个局部变量被更内层的函数中使用的时候， 它被内层函数称作 upvalue（上值），或是 外部局部变量。 注意，每次执行到一个 local 语句都会定义出一个新的局部变量。 看看这样一个例子： a = {} local x = 20 for i=1,10 do local y = 0 a[i] = function () y=y+1; return x+y end end 这个循环创建了十个 closure（这指十个匿名函数的实例）。 这些 closure 中的每一个都使用了不同的 y 变量， 而它们又共享了同一份 x。 errorerror(message[, level]) Level = 1[默认]：为调用error位置(文件+行号) Level = 2：指出哪个调用error的函数的函数 Level = 0：不添加错误位置信息因为 Lua 是一个嵌入式的扩展语言， 所有的 Lua 动作都是从宿主程序的 C 代码调用 Lua 库 （参见 lua_pcall）中的一个函数开始的。 在 Lua 编译或运行的任何时候发生了错误，控制权都会交还给 C ， 而 C 可以来做一些恰当的措施（比如打印出一条错误信息）。Lua 代码可以显式的调用 error 函数来产生一条错误。 如果你需要在 Lua 中捕获发生的错误， 你可以使用 pcall 函数。 MetatableLua 中的每个值都可以用一个 metatable。 这个 metatable 就是一个原始的 Lua table ， 它用来定义原始值在特定操作下的行为。 你可以通过在 metatable 中的特定域设一些值来改变拥有这个 metatable 的值 的指定操作之行为。 举例来说，当一个非数字的值作加法操作的时候， Lua 会检查它的 metatable 中 “_add” 域中的是否有一个函数。 如果有这么一个函数的话，Lua 调用这个函数来执行一次加法。我们叫 metatable 中的键名为 事件 (event) ，把其中的值叫作 元方法 (metamethod)。 在上个例子中，事件是 “add” 而元方法就是那个执行加法操作的函数。你可以通过 getmetatable 函数来查询到任何一个值的 metatable。你可以通过 setmetatable 函数来替换掉 table 的 metatable 。 你不能从 Lua 中改变其它任何类型的值的 metatable （使用 debug 库例外）； 要这样做的话必须使用 C API 。每个 table 和 userdata 拥有独立的 metatable （当然多个 table 和 userdata 可以共享一个相同的表作它们的 metatable）； 其它所有类型的值，每种类型都分别共享唯一的一个 metatable。 因此，所有的数字一起只有一个 metatable ，所有的字符串也是，等等。一个 metatable 可以控制一个对象做数学运算操作、比较操作、连接操作、取长度操作、取下标操作时的行为， metatable 中还可以定义一个函数，让 userdata 作垃圾收集时调用它。 对于这些操作，Lua 都将其关联上一个被称作事件的指定健。 当 Lua 需要对一个值发起这些操作中的一个时， 它会去检查值中 metatable 中是否有对应事件。 如果有的话，键名对应的值（元方法）将控制 Lua 怎样做这个操作。metatable 可以控制的操作已在下面列出来。 每个操作都用相应的名字区分。 每个操作的键名都是用操作名字加上两个下划线 ‘_‘ 前缀的字符串； 举例来说，”add” 操作的键名就是字符串 “__add”。 这些操作的语义用一个 Lua 函数来描述解释器如何执行更为恰当。这里展示的用 Lua 写的代码仅作解说用； 实际的行为已经硬编码在解释器中，其执行效率要远高于这些模拟代码。 这些用于描述的的代码中用到的函数 （ rawget ， tonumber ，等等。） 都可以在 §5.1 中找到。 特别注意，我们使用这样一个表达式来从给定对象中提取元方法 metatable(obj)[event] 这个应该被解读作 rawget(getmetatable(obj) or {}, event) 这就是说，访问一个元方法不再会触发任何的元方法， 而且访问一个没有 metatable 的对象也不会失败（而只是简单返回 nil）。 “add”: + 操作。下面这个 getbinhandler 函数定义了 Lua 怎样选择一个处理器来作二元操作。 首先，Lua 尝试第一个操作数。 如果这个东西的类型没有定义这个操作的处理器，然后 Lua 会尝试第二个操作数。 function getbinhandler (op1, op2, event) return metatable(op1)[event] or metatable(op2)[event] end 通过这个函数， op1 + op2 的行为就是 function add_event (op1, op2) local o1, o2 = tonumber(op1), tonumber(op2) if o1 and o2 then -- 两个操作数都是数字？ return o1 + o2 -- 这里的 &#39;+&#39; 是原生的 &#39;add&#39; else -- 至少一个操作数不是数字时 local h = getbinhandler(op1, op2, &quot;__add&quot;) if h then -- 以两个操作数来调用处理器 return h(op1, op2) else -- 没有处理器：缺省行为 error(···) end end end &quot;sub&quot;: - 操作。 其行为类似于 &quot;add&quot; 操作。 &quot;mul&quot;: * 操作。 其行为类似于 &quot;add&quot; 操作。 &quot;div&quot;: / 操作。 其行为类似于 &quot;add&quot; 操作。 &quot;mod&quot;: % 操作。 其行为类似于 &quot;add&quot; 操作， 它的原生操作是这样的 o1 - floor(o1/o2)*o2 &quot;pow&quot;: ^ （幂）操作。 其行为类似于 &quot;add&quot; 操作， 它的原生操作是调用 pow 函数（通过 C math 库）。 &quot;unm&quot;: 一元 - 操作。 function unm_event (op) local o = tonumber(op) if o then -- 操作数是数字？ return -o -- 这里的 &#39;-&#39; 是一个原生的 &#39;unm&#39; else -- 操作数不是数字。 -- 尝试从操作数中得到处理器 local h = metatable(op).__unm if h then -- 以操作数为参数调用处理器 return h(op) else -- 没有处理器：缺省行为 error(···) end end end &quot;concat&quot;: .. （连接）操作， function concat_event (op1, op2) if (type(op1) == &quot;string&quot; or type(op1) == &quot;number&quot;) and (type(op2) == &quot;string&quot; or type(op2) == &quot;number&quot;) then return op1 .. op2 -- 原生字符串连接 else local h = getbinhandler(op1, op2, &quot;__concat&quot;) if h then return h(op1, op2) else error(···) end end end &quot;len&quot;: # 操作。 function len_event (op) if type(op) == &quot;string&quot; then return strlen(op) -- 原生的取字符串长度 elseif type(op) == &quot;table&quot; then return #op -- 原生的取 table 长度 else local h = metatable(op).__len if h then -- 调用操作数的处理器 return h(op) else -- 没有处理器：缺省行为 error(···) end end end 关于 table 的长度参见 §2.5.5 。 “eq”: == 操作。 函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作。 元方法仅仅在参于比较的两个对象类型相同且有对应操作相同的元方法时才起效。 function getcomphandler (op1, op2, event) if type(op1) ~= type(op2) then return nil end local mm1 = metatable(op1)[event] local mm2 = metatable(op2)[event] if mm1 == mm2 then return mm1 else return nil end end“eq” 事件按如下方式定义： function eq_event (op1, op2) if type(op1) ~= type(op2) then -- 不同的类型？ return false -- 不同的对象 end if op1 == op2 then -- 原生的相等比较结果？ return true -- 对象相等 end -- 尝试使用元方法 local h = getcomphandler(op1, op2, &quot;__eq&quot;) if h then return h(op1, op2) else return false end end a ~= b 等价于 not (a == b) 。 &quot;lt&quot;: &lt; 操作。 function lt_event (op1, op2) if type(op1) == &quot;number&quot; and type(op2) == &quot;number&quot; then return op1 &lt; op2 -- 数字比较 elseif type(op1) == &quot;string&quot; and type(op2) == &quot;string&quot; then return op1 &lt; op2 -- 字符串按逐字符比较 else local h = getcomphandler(op1, op2, &quot;__lt&quot;) if h then return h(op1, op2) else error(···); end end end a &gt; b 等价于 b &lt; a. &quot;le&quot;: &lt;= 操作。 function le_event (op1, op2) if type(op1) == &quot;number&quot; and type(op2) == &quot;number&quot; then return op1 &lt;= op2 -- 数字比较 elseif type(op1) == &quot;string&quot; and type(op2) == &quot;string&quot; then return op1 &lt;= op2 -- 字符串按逐字符比较 else local h = getcomphandler(op1, op2, &quot;__le&quot;) if h then return h(op1, op2) else h = getcomphandler(op1, op2, &quot;__lt&quot;) if h then return not h(op2, op1) else error(···); end end end end a &gt;= b 等价于 b &lt;= a 。 注意，如果元方法 “le” 没有提供，Lua 就尝试 “lt” ， 它假定 a &lt;= b 等价于 not (b &lt; a) 。 “index”: 取下标操作用于访问 table[key] 。12345678910111213141516171819function gettable_event (table, key) local h if type(table) == "table" then local v = rawget(table, key) if v ~= nil then return v end h = metatable(table).__index if h == nil then return nil end else h = metatable(table).__index if h == nil then error(···); end end if type(h) == "function" then return h(table, key) -- 调用处理器 else return h[key] -- 或是重复上述操作 endend newindex赋值给指定下标 table[key] = value 12345678910111213141516171819202122232425function settable_event (table, key, value) local h if type(table) == "table" then local v = rawget(table, key) if v ~= nil then rawset(table, key, value) return end h = metatable(table).__newindex if h == nil then rawset(table, key, value) return end else h = metatable(table).__newindex if h == nil then error(···) end end if type(h) == "function" then return h(table, key,value) -- 调用处理器 else h[key] = value -- 或是重复上述操作 endend “call”: 当 Lua 调用一个值时调用。123456789101112function function_event (func, ...) if type(func) == &quot;function&quot; then return func(...) -- 原生的调用 else local h = metatable(func).__call if h then return h(func, ...) else error(···) end endend 2.9 - 环境类型为 thread ，function ，以及 userdata 的对象，除了 metatable 外还可以用另外一个与之关联的被称作 它们的环境的一个表， 像 metatable 一样，环境也是一个常规的 table ，多个对象可以共享 同一个环境。userdata 的环境在 Lua 中没有意义。 这个东西只是为了在程序员想把一个表关联到一个 userdata 上时提供便利。关联在线程上的环境被称作全局环境。 全局环境被用作它其中的线程以及线程创建的非嵌套函数 （通过 loadfile ， loadstring 或是 load ）的缺省环境。 而且它可以被 C 代码直接访问（参见 §3.3）。关联在 C 函数上的环境可以直接被 C 代码访问（参见 §3.3）。 它们会作为这个 C 函数中创建的其它函数的缺省环境。关联在 Lua 函数上的环境用来接管在函数内对全局变量（参见 §2.3）的所有访问。 它们也会作为这个函数内创建的其它函数的缺省环境。你可以通过调用 setfenv 来改变一个 Lua 函数 或是正在运行中的线程的环境。 而想操控其它对象（userdata、C 函数、其它线程）的环境的话，就必须使用 C API 。 2.10 - 垃圾收集Lua 提供了一个自动的内存管理。 这就是说你不需要关心创建新对象的分配内存操作，也不需要在这些对象不再需要时的主动释放内存。 Lua 通过运行一个垃圾收集器来自动管理内存，以此一遍又一遍的回收死掉的对象 （这是指 Lua 中不再访问的到的对象）占用的内存。 Lua 中所有对象都被自动管理，包括： table, userdata、 函数、线程、和字符串。Lua 实现了一个增量标记清除的收集器。 它用两个数字来控制垃圾收集周期： garbage-collector pause 和 garbage-collector step multiplier 。garbage-collector pause 控制了收集器在开始一个新的收集周期之前要等待多久。 随着数字的增大就导致收集器工作工作的不那么主动。 小于 1 的值意味着收集器在新的周期开始时不再等待。 当值为 2 的时候意味着在总使用内存数量达到原来的两倍时再开启新的周期。step multiplier 控制了收集器相对内存分配的速度。 更大的数字将导致收集器工作的更主动的同时，也使每步收集的尺寸增加。 小于 1 的值会使收集器工作的非常慢，可能导致收集器永远都结束不了当前周期。 缺省值为 2 ，这意味着收集器将以内存分配器的两倍速运行。你可以通过在 C 中调用 lua_gc 或是在 Lua 中调用 collectgarbage 来改变这些数字。 两者都接受百分比数值（因此传入参数 100 意味着实际值 1 ）。 通过这些函数，你也可以直接控制收集器（例如，停止或是重启）。 2.10.1 - 垃圾收集的元方法使用 C API ， 你可以给 userdata （参见 §2.8）设置一个垃圾收集的元方法。 这个元方法也被称为结束子。 结束子允许你用额外的资源管理器和 Lua 的内存管理器协同工作 （比如关闭文件、网络连接、或是数据库连接，也可以说释放你自己的内存）。一个 userdata 可被回收，若它的 metatable 中有 __gc 这个域 ， 垃圾收集器就不立即收回它。 取而代之的是，Lua 把它们放到一个列表中。 最收集结束后，Lua 针对列表中的每个 userdata 执行了下面这个函数的等价操作： function gc_event (udata) local h = metatable(udata).__gc if h then h(udata) end end 在每个垃圾收集周期的结尾，每个在当前周期被收集起来的 userdata 的结束子会以 它们构造时的逆序依次调用。 也就是说，收集列表中，最后一个在程序中被创建的 userdata 的 结束子会被第一个调用。 2.10.2 - Weak Table（弱表）weak table 是一个这样的 table，它其中的元素都被弱引用。 弱引用将被垃圾收集器忽略掉， 换句话说， 如果对一个对象的引用只有弱引用， 垃圾收集器将回收这个对象。 weak table 的键和值都可以是 weak 的。 如果一个 table 只有键是 weak 的，那么将运行收集器回收它们的键， 但是会阻止回收器回收对应的值。 而一个 table 的键和值都是 weak 时，就即允许收集器回收键又允许收回值。 任何情况下，如果键和值中任一个被回收了，整个键值对就会从 table 中拿掉。 table 的 weak 特性可以通过在它的 metatable 中设置 mode 域来改变。 如果 mode 域中是一个包含有字符 ‘k’ 的字符串时， table 的键就是 weak 的。 如果 __mode 域中是一个包含有字符 ‘v’ 的字符串时， table 的值就是 weak 的。 在你把一个 table 当作一个 metatable 使用之后， 就不能再修改 __mode 域的值。 否则，受这个 metatable 控制的 table 的 weak 行为就成了未定义的。 2.11 - Coroutine （协同例程）Lua 支持 coroutine ，这个东西也被称为协同式多线程 (collaborative multithreading) 。 Lua 为每个 coroutine 提供一个独立的运行线路。 然而和多线程系统中的线程不同，coroutine 只在显式的调用了 yield 函数时才会挂起。 创建一个 coroutine 需要调用一次 coroutine.create 。 它只接收单个参数，这个参数是 coroutine 的主函数。 create 函数仅仅创建一个新的 coroutine 然后返回它的控制器 （一个类型为 thread 的对象）； 它并不会启动 coroutine 的运行。 当你第一次调用 coroutine.resume 时， 所需传入的第一个参数就是 coroutine.create 的返回值。 这时，coroutine 从主函数的第一行开始运行。 接下来传入 coroutine.resume 的参数将被传进 coroutine 的主函数。 在 coroutine 开始运行后，它讲运行到自身终止或是遇到一个 yields 。 coroutine 可以通过两种方式来终止运行： 一种是正常退出，指它的主函数返回（最后一条指令被运行后，无论有没有显式的返回指令）; 另一种是非正常退出，它发生在未保护的错误发生的时候。 第一种情况中， coroutine.resume 返回 true ， 接下来会跟着 coroutine 主函数的一系列返回值。 第二种发生错误的情况下， coroutine.resume 返回 false ， 紧接着是一条错误信息。 coroutine 中切换出去，可以调用 coroutine.yield。 当 coroutine 切出，与之配合的 coroutine.resume 就立即返回， 甚至在 yield 发生在内层的函数调用中也可以（就是说， 这不限于发生在主函数中，也可以是主函数直接或间接调用的某个函数里）。 在 yield 的情况下，coroutine.resume 也是返回 true， 紧跟着那些被传入 coroutine.yield 的参数。 等到下次你在继续同样的 coroutine ，将从调用 yield 的断点处运行下去。 断点处 yield 的返回值将是 coroutine.resume 传入的参数。 类似 coroutine.create ， coroutine.wrap 这个函数也将创建一个 coroutine ， 但是它并不返回 coroutine 本身，而是返回一个函数取而代之。一旦你调用这个返回函数，就会切入 coroutine 运行。 所有传入这个函数的参数等同于传入 coroutine.resume 的参数。 coroutine.wrap 会返回所有应该由除第一个（错误代码的那个布尔量） 之外的由 coroutine.resume 返回的值。 和 coroutine.resume 不同， coroutine.wrap 不捕获任何错误； 所有的错误都应该由调用者自己传递。 看下面这段代码展示的一个例子： function foo (a) print(&quot;foo&quot;, a) return coroutine.yield(2*a) end co = coroutine.create(function (a,b) print(&quot;co-body&quot;, a, b) local r = foo(a+1) print(&quot;co-body&quot;, r) local r, s = coroutine.yield(a+b, a-b) print(&quot;co-body&quot;, r, s) return b, &quot;end&quot; end) print(&quot;main&quot;, coroutine.resume(co, 1, 10)) print(&quot;main&quot;, coroutine.resume(co, &quot;r&quot;)) print(&quot;main&quot;, coroutine.resume(co, &quot;x&quot;, &quot;y&quot;)) print(&quot;main&quot;, coroutine.resume(co, &quot;x&quot;, &quot;y&quot;)) 当你运行它，将得到如下输出结果： co-body 1 10 foo 2 main true 4 co-body r main true 11 -9 co-body x y main true 10 end main false cannot resume dead coroutine 3 - 程序接口（API）这个部分描述了 Lua 的 C API ， 也就是宿主程序跟 Lua 通讯用的一组 C 函数。 所有的 API 函数按相关的类型以及常量都声明在头文件 lua.h 中。 虽然我们说的是“函数”，但一部分简单的 API 是以宏的形式提供的。 所有的这些宏都只使用它们的参数一次 （除了第一个参数，也就是 lua 状态机）， 因此你不需担心这些宏的展开会引起一些副作用。 在所有的 C 库中，Lua API 函数都不去检查参数的有效性和坚固性。 然而，你可以在编译 Lua 时加上打开一个宏开关来 开启 luaconf.h 文件中的宏 luai_apicheck 以改变这个行为。 堆栈Lua 使用一个虚拟栈来和 C 传递值。 栈上的的每个元素都是一个 Lua 值 （nil，数字，字符串，等等）。 无论何时 Lua 调用 C，被调用的函数都得到一个新的栈， 这个栈独立于 C 函数本身的堆栈，也独立于以前的栈。 （译注：在 C 函数里，用 Lua API 不能访问到 Lua 状态机中本次调用之外的堆栈中的数据） 它里面包含了 Lua 传递给 C 函数的所有参数， 而 C 函数则把要返回的结果也放入堆栈以返回给调用者 （参见 lua_CFunction）。 方便起见，所有针对栈的 API 查询操作都不严格遵循栈的操作规则。 而是可以用一个索引来指向栈上的任何元素： 正的索引指的是栈上的绝对位置（从一开始）； 负的索引则指从栈顶开始的偏移量。 更详细的说明一下，如果堆栈有 n 个元素， 那么索引 1 表示第一个元素（也就是最先被压入堆栈的元素） 而索引 n 则指最后一个元素； 索引 -1 也是指最后一个元素（即栈顶的元素）， 索引 -n 是指第一个元素。 如果索引在 1 到栈顶之间（也就是，1 ≤ abs(index) ≤ top） 我们就说这是个有效的索引。 堆栈尺寸当你使用 Lua API 时，就有责任保证其坚固性。 特别需要注意的是，你有责任控制不要堆栈溢出。你可以使用 lua_checkstack 这个函数来扩大可用堆栈的尺寸。无论何时 Lua 调用 C ， 它都只保证 LUA_MINSTACK 这么多的堆栈空间可以使用。 LUA_MINSTACK 一般被定义为 20 ，因此，只要你不是不断的把数据压栈，通常你不用关心堆栈大小。所有的查询函数都可以接收一个索引，只要这个索引是任何栈提供的空间中的值。 栈能提供的最大空间是通过 lua_checkstack 来设置的。 这些索引被称作可接受的索引，通常我们把它定义为： (index &lt; 0 &amp;&amp; abs(index) &lt;= top) || (index &gt; 0 &amp;&amp; index &lt;= stackspace) 注意，0 永远都不是一个可接受的索引。（译注：下文中凡提到的索引，没有特别注明的话，都指可接受的索引。） LUA_GLOBALSINDEX除了特别声明外，任何一个函数都可以接受另一种有效的索引，它们被称作“伪索引”。 这个可以帮助 C 代码访问一些并不在栈上的 Lua 值。 伪索引被用来访问线程的环境，函数的环境，注册表，还有 C 函数的 upvalue。线程的环境（也就是全局变量放的地方）通常在伪索引 LUA_GLOBALSINDEX 处。 正在运行的 C 函数的环境则放在伪索引 LUA_ENVIRONINDEX 之处。可以用常规的 table 操作来访问和改变全局变量的值，只需要指定环境表的位置。 举例而言，要访问全局变量的值，这样做： lua_getfield(L, LUA_GLOBALSINDEX, varname); C Closure当C函数被创建出来，我们有可能会把一些值关联在一起， 也就是创建一个Cclosure； 这些被关联起来的值被叫做upvalue ，它们可以在函数被调用的时候访问的到。（参见lua_pushcclosure）。无论何时去调用C函数，函数的upvalue都被放在指定的伪索引处。我们可以用lua_upvalueindex这个宏来生成这些伪索引。第一个关联到函数的值放在lua_upvalueindex(1)位置处，依次类推。任何情况下都可以用lua_upvalueindex(n)产生一个upvalue的索引，即使n大于实际的upvalue数量也可以。它都可以产生一个可接受但不一定有效的索引。 LUA_REGISTRYINDEXLua提供了一个注册表，这是一个预定义出来的表，可以用来保存任何C代码想保存的Lua值。这个表可以用伪索引LUA_REGISTRYINDEX来定位。 任何C库都可以在这张表里保存数据，为了防止冲突，你需要特别小心的选择键名。 一般的用法是，你可以用一个包含你的库名的字符串做为键名，或者可以取你自己C代码中的一个地址，以 light userdata 的形式做键。注册表里的整数健被用于补充库中实现的引用系统的工作，一般说来不要把它们用于别的用途。 C 中的错误处理在内部实现中，Lua 使用了 C 的 longjmp 机制来处理错误。 （如果你使用 C++ 的话，也可以选择换用异常；参见 luaconf.h 文件。） 当 Lua 碰到任何错误（比如内存分配错误、类型错误、语法错误、还有一些运行时错误） 它都会产生一个错误出去； 也就是调用一个 long jump 。 在保护环境下，Lua 使用 setjmp 来设置一个恢复点； 任何发生的错误都会激活最近的一个恢复点。几乎所有的 API 函数都可能产生错误，例如内存分配错误。 但下面的一些函数运行在保护环境中（也就是说它们创建了一个保护环境再在其中运行）， 因此它们不会产生错误出来： lua_newstate, lua_close, lua_load, lua_pcall, and lua_cpcall。 在 C 函数里，你也可以通过调用 lua_error 产生一个错误。 lua_Alloctypedef void * (*lua_Alloc) (void *ud, void *ptr, size_t osize, size_t nsize); Lua 状态机中使用的内存分配器函数的类型。 内存分配函数必须提供一个功能类似于 realloc 但又不完全相同的函数。 它的参数有 ud ，一个由 lua_newstate 传给它的指针； ptr ，一个指向已分配出来或是将被重新分配或是要释放的内存块指针； osize ，内存块原来的尺寸； nsize ，新内存块的尺寸。 如果且只有 osize 是零时，ptr 为 NULL 。 当 nsize 是零，分配器必须返回 NULL； 如果 osize 不是零，分配器应当释放掉 ptr 指向的内存块。 当 nsize 不是零，若分配器不能满足请求时，分配器返回 NULL 。 当 nsize 不是零而 osize 是零时，分配器应该和 malloc 有相同的行为。 当 nsize 和 osize 都不是零时，分配器则应和 realloc 保持一样的行为。 Lua 假设分配器在 osize &gt;= nsize 时永远不会失败。 这里有一个简单的分配器函数的实现。 这个实现被放在补充库中，由 luaL_newstate 提供。 static void *l_alloc (void *ud, void *ptr, size_t osize, size_t nsize) { (void)ud; (void)osize; /* not used */ if (nsize == 0) { free(ptr); return NULL; } else return realloc(ptr, nsize); } 这段代码假设 free(NULL) 啥也不影响，而且 realloc(NULL, size) 等价于 malloc(size)。 这两点是 ANSI C 保证的行为。 lua_atpaniclua_CFunction lua_atpanic (lua_State *L, lua_CFunction panicf); 设置一个新的 panic （恐慌） 函数，并返回前一个。如果在保护环境之外发生了任何错误， Lua 就会调用一个 panic 函数，接着调用 exit(EXIT_FAILURE)， 这样就开始退出宿主程序。 你的 panic 函数可以永远不返回（例如作一次长跳转）来避免程序退出。panic 函数可以从栈顶取到出错信息。 lua_callvoid lua_call(lua_State *L, int nargs, int nresults); 调用一个函数。要调用一个函数请遵循以下协议：首先，要调用的函数应该被压入堆栈；接着，把需要传递给这个函数的参数按正序压栈；这是指第一个参数首先压栈。 最后调用一下lua_call；nargs是你压入堆栈的参数个数。当函数调用完毕后，所有的参数以及函数本身都会出栈。而函数的返回值这时则被压入堆栈。返回值的个数将被调整为nresults个， 除非 nresults 被设置成 LUA_MULTRET。 在这种情况下，所有的返回值都被压入堆栈中。 Lua 会保证返回值都放入栈空间中。 函数返回值将按正序压栈（第一个返回值首先压栈）， 因此在调用结束后，最后一个返回值将被放在栈顶。被调用函数内发生的错误将（通过 longjmp）一直上抛。下面的例子中，这行 Lua 代码等价于在宿主程序用 C 代码做一些工作： a = f(&quot;how&quot;, t.x, 14) 这里是 C 里的代码： lua_getfield(L, LUA_GLOBALSINDEX, &quot;f&quot;); /* 将调用的函数 */ lua_pushstring(L, &quot;how&quot;); /* 第一个参数 */ lua_getfield(L, LUA_GLOBALSINDEX, &quot;t&quot;); /* table 的索引 */ lua_getfield(L, -1, &quot;x&quot;); /* 压入 t.x 的值（第 2 个参数）*/ lua_remove(L, -2); /* 从堆栈中移去 &#39;t&#39; */ lua_pushinteger(L, 14); /* 第 3 个参数 */ lua_call(L, 3, 1); /* 调用 &#39;f&#39;，传入 3 个参数，并索取 1 个返回值 */ lua_setfield(L, LUA_GLOBALSINDEX, &quot;a&quot;); /* 设置全局变量 &#39;a&#39; */ 注意上面这段代码是“平衡”的： 到了最后，堆栈恢复成原由的配置。 lua_CFunctiontypedef int (*lua_CFunction) (lua_State *L); C 函数的类型。为了正确的和 Lua 通讯，C 函数必须使用下列 定义了参数以及返回值传递方法的协议： C 函数通过 Lua 中的堆栈来接受参数，参数以正序入栈（第一个参数首先入栈）。 因此，当函数开始的时候， lua_gettop(L) 可以返回函数收到的参数个数。 第一个参数（如果有的话）在索引 1 的地方，而最后一个参数在索引 lua_gettop(L) 处。 当需要向 Lua 返回值的时候，C 函数只需要把它们以正序压到堆栈上（第一个返回值最先压入）， 然后返回这些返回值的个数。 在这些返回值之下的，堆栈上的东西都会被 Lua 丢掉。 和 Lua 函数一样，从 Lua 中调用 C 函数也可以有很多返回值。 下面这个例子中的函数将接收若干数字参数，并返回它们的平均数与和： static int foo (lua_State *L) { int n = lua_gettop(L); /* 参数的个数 */ lua_Number sum = 0; int i; for (i = 1; i &lt;= n; i++) { if (!lua_isnumber(L, i)) { lua_pushstring(L, &quot;incorrect argument&quot;); lua_error(L); } sum += lua_tonumber(L, i); } lua_pushnumber(L, sum/n); /* 第一个返回值 */ lua_pushnumber(L, sum); /* 第二个返回值 */ return 2; /* 返回值的个数 */ } lua_checkstackint lua_checkstack (lua_State *L, int extra); 确保堆栈上至少有 extra 个空位。 如果不能把堆栈扩展到相应的尺寸，函数返回 false 。 这个函数永远不会缩小堆栈； 如果堆栈已经比需要的大了，那么就放在那里不会产生变化。 lua_closevoid lua_close (lua_State *L); 销毁指定 Lua 状态机中的所有对象（如果有垃圾收集相关的元方法的话，会调用它们），并且释放状态机中使用的所有动态内存。 在一些平台上，你可以不必调用这个函数， 因为当宿主程序结束的时候，所有的资源就自然被释放掉了。 另一方面，长期运行的程序，比如一个后台程序或是一个 web 服务器， 当不再需要它们的时候就应该释放掉相关状态机。这样可以避免状态机扩张的过大。 lua_concatvoid lua_concat (lua_State *L, int n); 连接栈顶的 n 个值， 然后将这些值出栈，并把结果放在栈顶。如果 n 为 1 ，结果就是一个字符串放在栈上（即，函数什么都不做）； 如果 n 为 0 ，结果是一个空串。 连接依照 Lua 中创建语义完成（参见 §2.5.4 ）。 lua_cpcallint lua_cpcall (lua_State *L, lua_CFunction func, void *ud); 以保护模式调用 C 函数 func 。 func 只有能从堆栈上拿到一个参数，就是包含有 ud 的 light userdata。 当有错误时， lua_cpcall 返回和 lua_pcall 相同的错误代码， 并在栈顶留下错误对象； 否则它返回零，并不会修改堆栈。 所有从 func 内返回的值都会被扔掉。 lua_createtablevoid lua_createtable (lua_State *L, int narr, int nrec); 创建一个新的空 table 压入堆栈。 这个新 table 将被预分配 narr 个元素的数组空间 以及 nrec 个元素的非数组空间。 当你明确知道表中需要多少个元素时，预分配就非常有用。 如果你不知道，可以使用函数 lua_newtable。 lua_dumpint lua_dump (lua_State *L, lua_Writer writer, void *data); 把函数 dump 成二进制 chunk 。 函数接收栈顶的 Lua 函数做参数，然后生成它的二进制 chunk 。 若被 dump 出来的东西被再次加载，加载的结果就相当于原来的函数。 当它在产生 chunk 的时候，lua_dump 通过调用函数 writer （参见 lua_Writer） 来写入数据，后面的 data 参数会被传入 writer 。最后一次由写入器 (writer) 返回值将作为这个函数的返回值返回； 0 表示没有错误。 这个函数不会把 Lua 返回弹出堆栈。 lua_equalint lua_equal (lua_State *L, int index1, int index2); 如果依照 Lua 中 == 操作符语义，索引 index1 和 index2 中的值相同的话，返回 1 。 否则返回 0 。 如果任何一个索引无效也会返回 0。 lua_errorint lua_error (lua_State *L); 产生一个 Lua 错误。 错误信息（实际上可以是任何类型的 Lua 值）必须被置入栈顶。 这个函数会做一次长跳转，因此它不会再返回。 （参见 luaL_error）。 lua_gcint lua_gc (lua_State *L, int what, int data); 控制垃圾收集器。这个函数根据其参数 what 发起几种不同的任务： LUA_GCSTOP: 停止垃圾收集器。LUA_GCRESTART: 重启垃圾收集器。LUA_GCCOLLECT: 发起一次完整的垃圾收集循环。LUA_GCCOUNT: 返回 Lua 使用的内存总量（以 K 字节为单位）。LUA_GCCOUNTB: 返回当前内存使用量除以 1024 的余数。LUA_GCSTEP: 发起一步增量垃圾收集。 步数由 data 控制（越大的值意味着越多步）， 而其具体含义（具体数字表示了多少）并未标准化。 如果你想控制这个步数，必须实验性的测试 data 的值。 如果这一步结束了一个垃圾收集周期，返回返回 1 。LUA_GCSETPAUSE: 把 data/100 设置为 garbage-collector pause 的新值（参见 §2.10）。 函数返回以前的值。LUA_GCSETSTEPMUL: 把 arg/100 设置成 step multiplier （参见 §2.10）。 函数返回以前的值。 lua_getallocflua_Alloc lua_getallocf (lua_State *L, void **ud); 返回给定状态机的内存分配器函数。 如果 ud 不是 NULL ，Lua 把调用 lua_newstate 时传入的那个指针放入 *ud 。 lua_getfenvvoid lua_getfenv (lua_State *L, int index); 把索引处值的环境表压入堆栈。 lua_getfieldvoid lua_getfield(lua_State *L, int index, const char *k); 把 t[k] 值压入堆栈， 这里的 t 是指有效索引 index 指向的值。 在 Lua 中，这个函数可能触发对应 “index” 事件的元方法。 lua_getglobalvoid lua_getglobal(lua_State *L, const char *name); 把全局变量name里的值压入堆栈。 这个是用一个宏定义出来的： #define lua_getglobal(L,s) lua_getfield(L, LUA_GLOBALSINDEX, s) lua_getmetatableint lua_getmetatable (lua_State *L, int index); 把给定索引指向的值的元表压入堆栈。 如果索引无效，或是这个值没有元表， 函数将返回 0 并且不会向栈上压任何东西。 lua_gettablevoid lua_gettable (lua_State *L, int index); 把t[k] 值压入堆栈， 这里的t是指有效索引 index 指向的值， 而 k 则是栈顶放的值。这个函数会弹出堆栈上的 key （把结果放在栈上相同位置）。 在 Lua 中，这个函数可能触发对应 “index” 事件的元方法。 lua_gettopint lua_gettop(lua_State *L); 返回栈顶元素的索引。 因为索引是从 1 开始编号的， 所以这个结果等于堆栈上的元素个数（因此返回 0 表示堆栈为空）。 lua_insertvoid lua_insert (lua_State *L, int index); 把栈顶元素插入指定的有效索引处， 并依次移动这个索引之上的元素。 不要用伪索引来调用这个函数，因为伪索引不是真正指向堆栈上的位置。 lua_Integertypedef ptrdiff_t lua_Integer; 这个类型被用于 Lua API 接收整数值。缺省时这个被定义为 ptrdiff_t ， 这个东西通常是机器能处理的最大整数类型。 lua_isbooleanint lua_isboolean (lua_State *L, int index); 当给定索引的值类型为 boolean 时，返回 1 ，否则返回 0 。 lua_iscfunctionint lua_iscfunction (lua_State *L, int index); 当给定索引的值是一个 C 函数时，返回 1 ，否则返回 0 。 lua_isfunctionint lua_isfunction (lua_State *L, int index); 当给定索引的值是一个函数（ C 或 Lua 函数均可）时，返回 1 ，否则返回 0 。 lua_islightuserdataint lua_islightuserdata (lua_State *L, int index); 当给定索引的值是一个 light userdata 时，返回 1 ，否则返回 0 。 lua_isnilint lua_isnil (lua_State *L, int index); 当给定索引的值是 nil 时，返回 1 ，否则返回 0 。 lua_isnumberint lua_isnumber (lua_State *L, int index); 当给定索引的值是一个数字，或是一个可转换为数字的字符串时，返回 1 ，否则返回 0 。 lua_isstringint lua_isstring (lua_State *L, int index); 当给定索引的值是一个字符串或是一个数字（数字总能转换成字符串）时，返回 1 ，否则返回 0 。 lua_istableint lua_istable (lua_State *L, int index); 当给定索引的值是一个 table 时，返回 1 ，否则返回 0 。 lua_isthreadint lua_isthread (lua_State *L, int index); 当给定索引的值是一个 thread 时，返回 1 ，否则返回 0 。 lua_isuserdataint lua_isuserdata (lua_State *L, int index); 当给定索引的值是一个 userdata （无论是完整的 userdata 还是 light userdata ）时，返回 1 ，否则返回 0 。 lua_lessthanint lua_lessthan (lua_State *L, int index1, int index2); 如果索引 index1 处的值小于 索引 index2 处的值时，返回 1 ； 否则返回 0 。 其语义遵循 Lua 中的 &lt; 操作符（就是说，有可能调用元方法）。 如果任何一个索引无效，也会返回 0 。 lua_loadint lua_load (lua_State *L, lua_Reader reader, void *data, const char *chunkname); 加载一个 Lua chunk 。 如果没有错误， lua_load 把一个编译好的 chunk 作为一个 Lua 函数压入堆栈。 否则，压入出错信息。 lua_load 的返回值可以是： 0: 没有错误；LUA_ERRSYNTAX: 在预编译时碰到语法错误；LUA_ERRMEM: 内存分配错误。这个函数仅仅加栽 chunk ；而不会去运行它。 lua_load 会自动检测 chunk 是文本的还是二进制的， 然后做对应的加载操作（参见程序 luac）。lua_load 函数使用一个用户提供的 reader 函数来 读取 chunk （参见 lua_Reader）。 data 参数会被传入读取器函数。chunkname 这个参数可以赋予 chunk 一个名字， 这个名字被用于出错信息和调试信息。 lua_newstatelua_State *lua_newstate (lua_Alloc f, void *ud); 创建的一个新的独立的状态机。 如果创建不了（因为内存问题）返回 NULL 。 参数 f 是一个分配器函数； Lua 将通过这个函数做状态机内所有的内存分配操作。 第二个参数 ud ，这个指针将在每次调用分配器时被直接传入。 lua_newtablevoid lua_newtable (lua_State *L); 创建一个空table，并将之压入堆栈。它等价于lua_createtable(L, 0, 0)。 lua_pushglobaltable[-0, +1, –] void lua_pushglobaltable (lua_State *L); Pushes the global environment onto the stack. lua_newthreadlua_State *lua_newthread (lua_State *L); 创建一个新线程，并将其压入堆栈， 并返回维护这个线程的 lua_State 指针。 这个函数返回的新状态机共享原有状态机中的所有对象（比如一些 table）， 但是它有独立的执行堆栈。没有显式的函数可以用来关闭或销毁掉一个线程。 线程跟其它 Lua 对象一样是垃圾收集的条目之一。 lua_newuserdatavoid *lua_newuserdata (lua_State *L, size_t size); 这个函数分配分配一块指定大小的内存块， 把内存块地址作为一个完整的 userdata 压入堆栈，并返回这个地址。userdata 代表 Lua 中的 C 值。 完整的 userdata 代表一块内存。 它是一个对象（就像 table 那样的对象）： 你必须创建它，它有着自己的元表，而且它在被回收时，可以被监测到。 一个完整的 userdata 只和它自己相等（在等于的原生作用下）。当 Lua 通过 gc 元方法回收一个完整的 userdata 时， Lua 调用这个元方法并把 userdata 标记为已终止。 等到这个 userdata 再次被收集的时候，Lua 会释放掉相关的内存。 lua_nextint lua_next (lua_State *L, int index); 从栈上弹出一个 key（键）， 然后把索引指定的表中 key-value（健值）对压入堆栈 （指定 key 后面的下一 (next) 对）。 如果表中以无更多元素， 那么 lua_next 将返回 0 （什么也不压入堆栈）。典型的遍历方法是这样的： /* table 放在索引 &#39;t&#39; 处 */ lua_pushnil(L); /* 第一个 key */ while (lua_next(L, t) != 0) { /* 用一下 &#39;key&#39; （在索引 -2 处） 和 &#39;value&#39; （在索引 -1 处） */ printf(&quot;%s - %s\n&quot;, lua_typename(L, lua_type(L, -2)), lua_typename(L, lua_type(L, -1))); /* 移除 &#39;value&#39; ；保留 &#39;key&#39; 做下一次迭代 */ lua_pop(L, 1); } 在遍历一张表的时候， 不要直接对 key 调用 lua_tolstring ， 除非你知道这个 key 一定是一个字符串。 调用 lua_tolstring 有可能改变给定索引位置的值； 这会对下一次调用 lua_next 造成影响。 lua_Numbertypedef double lua_Number; Lua 中数字的类型。 确省是 double ，但是你可以在 luaconf.h 中修改它。通过修改配置文件你可以改变 Lua 让它操作其它数字类型（例如：float 或是 long ）。 lua_objlen &amp; luaS_rawlensize_t lua_objlen (lua_State *L, int index); -- 5.1 size_t lua_rawlen (lua_State *L, int index); -- 5.3 返回指定的索引处的值的长度。 对于 string ，那就是字符串的长度； 对于 table ，是取长度操作符 (‘#’) 的结果； 对于 userdata ，就是为其分配的内存块的尺寸； 对于其它值，为 0 。 lua_pcalllua_pcall (lua_State *L, int nargs, int nresults, int errfunc); 以保护模式调用一个函数。nargs 和 nresults 的含义与 lua_call 中的相同。 如果在调用过程中没有发生错误， lua_pcall 的行为和 lua_call 完全一致。 但是，如果有错误发生的话， lua_pcall 会捕获它， 然后把单一的值（错误信息）压入堆栈，然后返回错误码。 同 lua_call 一样， lua_pcall 总是把函数本身和它的参数从栈上移除。如果 errfunc 是 0 ， 返回在栈顶的错误信息就和原始错误信息完全一致。 否则，errfunc 就被当成是错误处理函数在栈上的索引。 （在当前的实现里，这个索引不能是伪索引。） 在发生运行时错误时， 这个函数会被调用而参数就是错误信息。 错误处理函数的返回值将被 lua_pcall 作为出错信息返回在堆栈上。典型的用法中，错误处理函数被用来在出错信息上加上更多的调试信息，比如栈跟踪信息 (stack traceback) 。 这些信息在 lua_pcall 返回后，因为栈已经展开 (unwound) ， 所以收集不到了。lua_pcall 函数在调用成功时返回 0 ， 否则返回以下（定义在 lua.h 中的）错误代码中的一个： LUA_ERRRUN: 运行时错误。LUA_ERRMEM: 内存分配错误。 对于这种错，Lua 调用不了错误处理函数。LUA_ERRERR: 在运行错误处理函数时发生的错误。 lua_popvoid lua_pop (lua_State *L, int n); 从堆栈中弹出 n 个元素。 lua_pushbooleanvoid lua_pushboolean (lua_State *L, int b); 把 b 作为一个 boolean 值压入堆栈。 lua_pushcclosurevoid lua_pushcclosure (lua_State *L, lua_CFunction fn, int n); 把一个新的C closure压入堆栈。当创建了一个C函数后，你可以给它关联一些值，这样就是在创建一个C closure；接下来无论函数何时被调用，这些值都可以被这个函数访问到。为了将一些值关联到一个C函数上，首先这些值需要先被压入堆栈（如果有多个值，第一个先压）。接下来调用lua_pushcclosure来创建出closure并把这个C函数压到堆栈上。参数n告之函数有多少个值需要关联到函数上。lua_pushcclosure也会把这些值从栈上弹出。 lua_pushcfunctionvoid lua_pushcfunction (lua_State *L, lua_CFunction f); 将一个 C 函数压入堆栈。 这个函数接收一个 C 函数指针，并将一个类型为 function 的 Lua 值 压入堆栈。当这个栈顶的值被调用时，将触发对应的 C 函数。注册到 Lua 中的任何函数都必须遵循正确的协议来接收参数和返回值 （参见 lua_CFunction）。 lua_pushcfunction 是作为一个宏定义出现的： #define lua_pushcfunction(L,f) lua_pushcclosure(L,f,0) lua_pushfstringconst char *lua_pushfstring (lua_State *L, const char *fmt, ...); 把一个格式化过的字符串压入堆栈，然后返回这个字符串的指针。 它和 C 函数 sprintf 比较像，不过有一些重要的区别：摸你需要为结果分配空间： 其结果是一个 Lua 字符串，由 Lua 来关心其内存分配 （同时通过垃圾收集来释放内存）。这个转换非常的受限。 不支持 flag ，宽度，或是指定精度。 它只支持下面这些： ‘%%’ （插入一个 ‘%’）， ‘%s’ （插入一个带零终止符的字符串，没有长度限制）， ‘%f’ （插入一个 lua_Number）， ‘%p’ （插入一个指针或是一个十六进制数）， ‘%d’ （插入一个 int)， ‘%c’ （把一个 int 作为一个字符插入）。 lua_pushintegervoid lua_pushinteger (lua_State *L, lua_Integer n); 把 n 作为一个数字压栈。 lua_pushlightuserdatavoid lua_pushlightuserdata (lua_State *L, void *p); 把一个 light userdata 压栈。userdata 在 Lua 中表示一个 C 值。 light userdata 表示一个指针。 它是一个像数字一样的值： 你不需要专门创建它，它也没有独立的 metatable ， 而且也不会被收集（因为从来不需要创建）。 只要表示的 C 地址相同，两个 light userdata 就相等。 lua_pushlstringvoid lua_pushlstring (lua_State *L, const char *s, size_t len); 把指针 s 指向的长度为 len 的字符串压栈。 Lua 对这个字符串做一次内存拷贝（或是复用一个拷贝）， 因此 s 处的内存在函数返回后，可以释放掉或是重用于其它用途。 字符串内可以保存有零字符。 lua_pushnilvoid lua_pushnil (lua_State *L); 把一个 nil 压栈。 lua_pushnumbervoid lua_pushnumber (lua_State *L, lua_Number n); 把一个数字 n 压栈。 lua_pushstringvoid lua_pushstring (lua_State *L, const char *s); 把指针s指向的以零结尾的字符串压栈。 Lua 这个字符串做一次内存拷贝（或是复用一个拷贝）， 因此 s 处的内存在函数返回后，可以释放掉或是重用于其它用途。 字符串中不能包含有零字符；第一个碰到的零字符会认为是字符串的结束。 lua_pushthreadint lua_pushthread (lua_State *L); 把 L 中提供的线程压栈。 如果这个线程是当前状态机的主线程的话，返回 1 。 lua_pushvaluevoid lua_pushvalue(lua_State *L, int index); 把堆栈上给定有效处索引处的元素作一个拷贝压栈。 lua_pushvfstringconst char *lua_pushvfstring (lua_State *L, const char *fmt, va_list argp); 等价于 lua_pushfstring， 不过是用 va_list 接收参数，而不是用可变数量的实际参数。 lua_rawequalint lua_rawequal (lua_State *L, int index1, int index2); 如果两个索引 index1 和 index2 处的值简单地相等 （不调用元方法）则返回 1 。 否则返回 0 。 如果任何一个索引无效也返回 0 。 lua_rawgetvoid lua_rawget (lua_State *L, int index); 类似于 lua_gettable，但是作一次直接访问（不触发元方法）。 lua_rawgetivoid lua_rawgeti (lua_State *L, int index, int n); 把 t[n] 的值压栈， 这里的 t 是指给定索引 index 处的一个值。这是一个直接访问；就是说，它不会触发元方法。 lua_rawsetvoid lua_rawset (lua_State *L, int index); 类似于 lua_settable ，但是是作一个直接赋值（不触发元方法）。 lua_rawsetivoid lua_rawseti (lua_State *L, int index, int n); 等价于t[n] = v，这里的 t 是指给定索引index 处的一个值， 而 v 是栈顶的值。函数将把这个值弹出栈。 赋值操作是直接的；就是说，不会触发元方法。]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSharp]]></title>
    <url>%2F2018%2F04%2F02%2FCSharp%2F</url>
    <content type="text"><![CDATA[internal、sealedinternal：本应用程序使用，其它进程无法使用 sealed（密封）：由它修饰的类、方法、属性将不能被继承或是重写。sealed 必须和override一起使用sealed修饰符表示密封用于类时，表示该类不能被继承，不能和abstract同时使用，不能被实例化。密封类不能用作基类、也不能继承，而抽象类总是希望被继承的。 fixedfixed 语句可防止垃圾回收器重新定位可移动的变量。 fixed 语句仅允许存在于不安全的上下文中。 Fixed 还可用于创建固定大小的缓冲区。 fixed 语句将为托管变量设置一个指针，并在该语句的执行过程中“单边锁定”该变量。 如果没有 fixed，指向可移动的托管变量的指针将几乎没有什么用处，因为垃圾回收可能会不可预见地重新定位变量。 C# 编译器只允许将指针分配给 fixed 语句中的托管变量。 不支持持多继承，C#类始终继承一个基类（如果未在声明中指定一个基类，则继承自System.Object) 如果对类没有定义显示构造函数，则编译器将提供默认的构造函数，以初始化这些类的成员字段。但是，如果显式添加了构造函数，就可以有效控制整个构造过程。派生类通过使用:base()语法可以显式调用基类的构造函数 override 具有override关键字修饰符的方法是对基类中同名方法的新实现，基类中的同名方法必须声明为virtual或abstract类型。给基类中的方法添加virtual关键字表示可以重写它的实现。new static 和 virtual关键字不能与override访问修饰符同时使用。 virtual 支持多态，不能与static override同时使用 abstract 一个抽象类包含抽象方法和非抽象方法，抽象方法只存放函数原型，不涉及主体代码，override关键字可在派生类中抽象方法，经override声明重写的方法称为重写基类方法，其签名必须与override方法的签名相同。只是不能被实例化，除此以外具有类的其他特性，重要的是抽象类可以包含抽象方法，这是普通类所不能的。抽象方法只能声明于抽象方法中，且不包含任何实现，派生类必须覆盖它们。 interface 包含未实现的方法声明，派生类必须实现未实现的方法，抽象类是抽象方法，接口则是所有成员，接口包含属性，索引器事件 索引器索引器允许类或者结构的实例按照于数组相同的方法进行索引取值，索引器与属性类似，不同的是索引器的访问时带参的 索引器的索引值(Index)类型不受限制 索引器允许重载 索引器不是一个变量 索引器和属性的不同点 属性以名称来标识，索引器以函数形式标识 索引器可以被重载，属性不可以 索引器不能声明为static，属性可以 interface、abstract abstract interface 能否实例化 不能 不能 抽象类和接口的区别： 类是对对象的抽象，可以把抽象类理解为把类当作对象，抽象成的类叫抽象类，而接口只是一个行为的规范或规定， 接口基本上不具备类型的任何具体特点，它仅仅承诺了能够调用的方法 抽象类比较细，而接口比较简单 抽象类和接口的使用 如果预计要创建组件的多个版本，则创建抽象类。抽象类提供简单的方法来控制组件版本。 抽象类主要用于关系密切的对象；而接口适合为不相关的类提供通用功能 Marshal提供了一个方法集合，这些方法用于分配非托管内存、复制非托管内存块、将托管类型转换为非托管类型，此外还提供了在于非托管代码交互时使用的其他方法 命名空间：System.Runtime.InteropServices程序集：mscorlib AllocHGlobal(int32); // 通过使用指定的字节数，从进程的非托管内存中分配内存SizeOf(Type)返回非托管类型的大小(以字节为单位) this12345678910111213public static class PGExt&#123; public static T PG_GetComponent(this List&lt;Component&gt; components) where T : Component &#123; int c = components.Count; for (int i = 0; i &lt; c; ++i) &#123; var p = components[i] as T; if ((object)p != null) return p; &#125; return null; &#125;&#125; 为什么这里会有一个this关键字，做什么用？其实这就是扩展方法！这个扩展方法在静态类中声明，定义一个静态方法，其中第一个参数定义可它的扩展类型，PG_GetComponent方法扩展了List类，因为它的第一个参数定义了List类型，为了区分扩展方法和一般的静态方法，扩展方法还需要给第一个参数使用this关键字。 现在就可以使用带List类型的PG_GetComponent方法了： var mf = cacheComponents.PG_GetComponent&lt;MeshFilter&gt;(); volatilevolatile关键字指示一个字段可以由多个同时执行的线程修改。声明volatile的字段不受编译器优化的限制。这样可以确保该字段在任何时间呈现的都是最新的值。volatile修饰符通常用于由多个线程访问但不使用lock语句对访问进行序列化的字段。volatile关键字可应用于以下类型的字段： 引用类型 指针类型（在不安全的上下文中）。请注意，虽然指针本身可以是可变的，但是它指向的对象不能是可变的。换句话说，无法声明“指向可变对象的指针”。 类型，如sbyte、byte、short、ushort、int、uint、。 引用类型的泛型类型参数。 IntPtr和UIntPtr 事件和委托1234567891011121314151617181920212223242526272829public delegate void Print();class Test&#123; public event Print print; // 去掉event就是一个委托 public void Start() &#123; if (print == null) return; print(); &#125;&#125;class Program&#123; static void Print1() &#123; Console.WriteLine("Hello"); &#125; static void Print2() &#123; Console.WriteLine("World"); &#125; static void Main(string[] args) &#123; var obj = new Test(); obj.print += Print1; // 事件无法使用= obj.print += Print2; // 委托会清掉之前的关联 obj.Start(); &#125;&#125; 事件实际上是一个特殊的委托实例，不用事件也没有关系。实际上事件只是削弱了委托的功能，event在编辑器角度保护了程序的安全，因为你只能用+=、-=来注册事件了，而不能使用=为事件关联方法。（在委托中还可以使用=来绑定方法，不过=是一种破坏性代码，不管之前是否已经绑定方法，他都会将其清除） extern:指示方法在外部实现 堆栈和堆 Heap &amp; Stack首先堆栈和堆（托管堆）都在进程的虚拟内存中。（在32位处理器上每个进程的虚拟内存为4GB）栈是内存中完全用于存储局部变量或成员（值类型数据）的高效区域，但其大小有限制。托管堆占内存比栈大得多，当访问速度较慢。托管堆只用于分配内存。在创建值类型数据时，在栈上分配内存；当创建引用型类型数据时，在托管堆上分配并返回对象的引用。注意这个对象的引用，像其他局部变量一样也是保存在栈中，该引用指向的值则位于托管堆中。如果创建一个包含值类型的引用类型，比如数组，其元素的值也是存放在托管堆中的某个地方，由使用该实体的变量引用；而值类型存储在使用它们的地方，有几处在使用，就有几个副本存在。对于引用类型，如果在声明变量的时候没有使用new运算符，运行时不会给它分配托管堆的内存空间，而是在栈上给它分配一个包含null的值的引用。对于值类型，运行时会给它分配栈上的空间，并且调用构造函数来初始化对象的状态。 堆栈stack堆栈中存储值类型堆栈实际上是向下填充，即由高内存地址指向低内存地址填充。堆栈的工作方式是先分配内存的变量后后释放（先进后出原则）。堆栈的变量是从下向上释放，这样就保证了堆栈中先进后出的规则不与变量的生命周期起冲突堆栈的性能非常高，但是对于所有的变量来说不太灵活，而且变量的生命周期必须嵌套。通常我们希望使用一种方法分配内存来存储数据，并且方法退出后很长一段时间内数据仍然可以使用。此时就要用到堆（托管堆） 堆（托管堆）heap堆（托管堆）存储引用类型。引用类型共有四种：类类型、接口类型、数组类型和委托类型。所有引用类型变量所引用的对象，其内存都是托管堆中分配的。严格地说，我们常说的“对象变量”其实是类类型的引用变量。但在实际中人们经常将引用类型的变量简称为“对象变量”，用它来指代所有四种类型的引用变量。此堆非彼堆，.NET中的堆由垃圾收集器自动管理。与堆栈不同，堆是从下往上分配，所以自动的空间都在已用空间的上面。比如创建一个对象： Customer cus; cus = new Customer(); 声明一个Customer的引用cus，在堆栈上给这个引用分配存储空间。这仅仅只是一个引用，不是实际的Customer对象！cus占4个字节的空间，包含了存储Customer的引用地址。接着分配堆上的内存以存储Customer对象的实例，假定Customer对象的实例是32字节，为了在堆上找到一个存储Customer对象的存储位置。.NET运行库在堆中搜索第一个从未使用的，32字节的连续块存储Customer对象的实例。然后把分配给Customer对象实例的地址赋给cus变量。 从这个例子中可以看出，建立对象引用的过程比建立值变量的过程复杂，且不能避免性能的降低！实际上就是.NET运行库中保存堆的状态信息，在堆中添加新数据时，堆栈中的引用变量也要更新。性能上损失很多。有种机制在分配变量内存的时候，不会受到堆栈的限制：把一个引用变量的值赋给一个相同类型的变量，那么这两个变量就引用同一个堆中对象。当一个应用变量出作用域时，它会从堆栈中删除。但引用对象的数据仍然保留在堆中，一直到程序结束或者该数据不被任何变量应用时，垃圾收集器会删除它。 装箱转化123456789101112using System;class Boxing&#123; public static void Main() &#123; int i = 110; object obj = i; Console.WriteLine(&quot;i=&#123;0&#125;,obj = &#123;1&#125;&quot;,i,obj); obj = 330; Console.WriteLine(&quot;i = &#123;0&#125;,obj=&#123;1&#125;&quot;,i,obj); &#125;&#125; 定义整数类型变量的时候，这个变量占用的内存是内存占中分配的，第二句是装箱操作将变量110存放到了内存堆中，而定义object对象类型的变量Obj则在内存栈中，并指向int类型的数值110，而该数值是赋给变量i的数值副本。内存格局通常分为四个区全局数据区：存放全局变量，静态数据，常量代码区：存放所有的程序代码栈区：存放为运行而分配的局部变量，参数，返回数据，返回地址等。 值类型变量和引用类型变量的内存分配模型也不一样。为了理解清楚这个问题，首先先区分两种不同类型的内存区域：线程堆栈（Thread Stack）和托管堆（Managed Heap）。每个正在运行的程序都对应着一个进程（process），在一个进程内部，可以有一个或多个线程（thread），每个线程都拥有一块“自留地”，称为“线程堆栈”，大小为1M，用于保存自身的一些数据，比如函数中定义的局部变量、函数调用的传参值，这部分内存区域的分配与回收不需要人为干涉。 所有值类型的变量都是在线程堆栈中分配的。另一块内存区域成为“堆（heap）”，在.NET托管环境下，堆由CLR进行管理，所以又称为“托管堆（managed heap）”。 用new关键字创建的类的对象时，分配给对象的内存单元就位于托管堆中。在程序中我们可以随意地使用new 关键字创建多个对象，因此，托管堆中的内存资源是可以动态申请并使用的，当然使用完了必须归还。 对象变量的相互赋值不会导致对象自身被复制，其结果是两个对象变量指向同一对象。另外，由于对象变量是一个局部变量，因为，对象变量本身是位于线程堆栈中的。严格区分对象变量和对象变量所引用的对象，是面向对象编程的关键之一。 托管堆.NET框架包含一个托管堆，所有的.NET语言在分配引用类型对象时都要使用它。像值类型这样的轻量级对象始终分配在栈中，但是所有的类实例和数组都被生成在一个内存池中，这个内存池就是托管堆。 垃圾收集器算法： 将所有的托管内存标记为垃圾 寻找正被使用的内存块，并将他们标记为有效 释放所有没有被使用的内存块 整理堆以减少碎片 托管堆优化看上去很简单，但是垃圾收集器实际采用的步骤和堆管理系统的其它部分并非微不足道，其中尝尝涉及为提高性能而作的优化设计。举例来说，垃圾收集遍历整个内存池具有很高的开销。然而，研究表明大部分的托管堆上分配的对象只有很短的生存期，因此堆被分为三个段，称作generations。新分配的对象被放在generation 0中。这个generation是最先被回收的-在这个generation中最有可能找到不再使用的内存，由于它的尺寸很小（小到足以放进处理器的L2 cache中），因此在它里面的回收将是最快和最高效的。托管堆的另外一种优化操作与locality of reference规则有关。该规则表明，一起分配的对象经常被一起使用。如果对象们在堆中位置很紧凑的话，高速缓存的性能将会得到提高。由于托管堆的天性，对象们总是被分配在连续的地址上，托管堆总是保持紧凑，结果使得对象们始终彼此靠近，永远不会分得很远。这一点与标准提供的非托管代码形成了鲜明的对比，在标准堆中，堆很容易变成碎片，而且一起分配的对象经常分得很远。还有一种优化是与大对象有关的。通常，大对象具有很长的生存期。当一个大对象在.NET托管堆中产生时，它被分配在堆的一个特殊部分中，这部分堆永远不会被整理。因此移动大对象所带来的开销超过了整理这部分堆所能提高的性能。 关于外部资源（External Resources）的问题垃圾收集器能够有效地管理从托管堆中释放的资源，但是资源回收操作只有在内存紧张而触发一个回收动作时才执行。那么，累时怎样来管理像数据库连接或者窗口句柄这样有限的资源的呢？等待，直到垃圾回收被触发之后在清理数据库连接或者文件句柄并不是一个好方法，这会严重降低系统的性能。所有拥有外部资源的类，在这些资源已经不再用到的时候，都应当执行Close或者Dispose方法。需要清理外部资源的类还应当实现一个终止操作（finalizer）。在C#中，创建终止操作的首选方式是在析构函数中实现，而在Framework层，终止操作的实现则是通过重载System.Object.Finalize方法。以下两种实现终止操作的方法是等效的：123456789~OverdueBookLocator()&#123; Dispose(false);&#125;public void Finalize()&#123; base.Finalize(); Dispose(false);&#125; 在C#中，同时在Finalize方法和析构函数实现终止操作将会导致错误的产生。除非你有足够的理由，否则你不应该创建析构函数或者Finalize方法。终止操作会降低系统的性能，并且增加执行期的内存开销。同时，由于终止操作被执行的方式，你并不能保证何时一个终止操作被执行。 内存分配和垃圾回收的细节对GC有了一个总体印象之后，让我们来讨论关于托管堆中的分配与回收工作的细节。托管堆看起来与我们已经熟悉的C++编程中的传统的堆一点都不像。在传统的堆中，数据结构习惯于使用大块的空闲内存。在其中查找特定大小的内存块是一件很耗时的工作，尤其是当内存中充满碎片的时候。与此不同，在托管堆中，内存被组成连续的数组，指针总是巡着已经被使用的内存和未被使用的内存之间的边界移动。当内存被分配的时候，指针只是简单地递增—由此而来的一个好处是，分配操作的效率得到了很大的提升。当对象被分配的时候，它们一开始被generation 0中。当generation 0的大小快要达到它的上限的时候，一个只在generation 0中执行的回收操作被触发。由于generation 0的大小很小，因此这将是一个非常快的GC过程。这个GC过程的结果是将generation 0彻底的刷新了一遍。不再使用的对象被释放，正在使用的对象被整理并移入generation 1中。当generation 1的大小随着generation 0中移入的对象数量的增加而接近它的上限的时候，一个回收动作被触发在generation 0和generation 1中执行GC过程。如同在generation 0中一样，不再使用的对象被释放，正在被使用的对象被整理并移入下一个generation中。大部分GC过程的主要目标是generation 0，因为在generation 0中最优可能存在大量的已不再使用的临时对象。对generation 2的回收过程具有很高的开销，并且此过程只有在generation 0和generation 1的GC过程不能释放足够的内存时才会被触发。如果对generation 2的GC过程仍然不能释放足够的内存，那么系统就会抛出OutOfMemoryException异常。带有终止操作的对象的垃圾收集过程要稍微复杂一些。当一个带有终止操作的对象被标记为垃圾时，它并不会被立即释放。相反，它会被放置一个终止队列（finalizetion queue）中，此队列为这个对象建立一个引用，来避免这个对象被回收。后台线程为队列中的每个对象执行它们各自的终止操作，并且将已经执行过终止操作的对象从终止队列中删除。只有那些已经执行过终止操作的对象才会在下一次垃圾回收过程中被内存中删除。这样做的一个后果是，等待被终止的对象有可能在它被清除之前，被移入更高一级的generation中，从而增加它被清除的延迟时间。需要执行终止操作的对象应当事先IDisposable接口，以便程序通过此接口快速执行终止动作。IDisposable接口包含一个Dispose方法。这个方法被用来释放外部资源并抑制终止操作。123456789101112131415161718public class OverdueBookLocator:IDisposable&#123; ~OverdueBookLocator() &#123; InternalDispose(false); &#125; public void Dispose() &#123; InternalDispose(true); &#125; protected void InternalDispose(bool disposing) &#123; if (disposing) &#123; GC.SuppressFinalize(this); &#125; &#125;&#125; 栈和托管堆通用类型系统（CTS）区分两种基本类型：值类型和引用类型。它们之间的根本区别在于它们在内存中的存储方式。.NET使用两种不同的物理内存来存储数据栈和托管堆值类型总是内存中占用一个预定义的字节数（例如，int类型占4个字节，而string类型占用的字节数会根据字符串的长度而不同）。当声明一个值类型变量时，会在栈中分配适当大小的内存（除了引用类型的值类型成员外，如类的int字段）。内存中的这个空间用来存储变量所包含的值。.NET维护一个栈指针，它包含栈中下一个可用的内存空间的地址。当一个变量离开作用域时，栈指针指向下移动被释放变量所占用的字节数。所以它仍指向下一个可用地址。引用变量也利用栈，但这时候栈包含的只是对另一个内存位置的引用，而不是实际值。这个位置是托管堆中的一个地址，和栈一样，他也维护一个指针，包含堆中下一个可用的内存地址。但是，堆不是先入后出的，因为对对象的引用可在我们的程序中传递（例如，作为参数传递给方法调用）。堆中的对象不会在程序的一个预定点离开作用域。为了在不适用在堆中分配的内存时将它释放。.NET定期执行垃圾回收器，垃圾垃圾递归检查应用程序中所有对象的引用。引用不再有效的对象使用的内存无法从程序中访问，该内存就可以回收。 类型层次结构CTS定义了一种类型层级结构，该结构不仅仅描述了不同预定义类型，还指出了用户定义类型的层次结构的位置。 枚举可以定义除Char以外的所有整数类型，默认类型是int123456enum Color : byte&#123; Red, Green, Blue,&#125;; readonly与constreadonly是运行时常量，程序运行时进行赋值，赋值完之后无法更改，也被称为只读变量。const表示编译时常量，程序编译时将对常量值进行解析，并将所有常量值引用替换为相应值。 using 语句提供可确保正确使用IDisposable对象的方便语法。 示例1234using (Font font1 = new Font("Arial", 10.0f))&#123; byte charset = font1.GdiCharSet;&#125; 备注File和Font是访问非托管资源（本例中为文件句柄和设备上下文）的托管类型的示例。有许多其他类别的非托管资源和封装这些资源的类库类型。所有此类型都必须实现IDisposable接口。IDisposable对象的生存期限于单个方法时，应在using语句中声明并实例化它。using语句按照正确的方式调用对象上的Dispose方法，并（在按照前面所示方式使用它时）会导致在调用Dispose时对象自身处于范围之外。在using块中，对象是只读的并且无法进行修改或重新分配。 using语句可确保调用Dispose，即使using块中发生异常也是如此。通过将对象放入try块中，然后调用finally块中的Dispose，可以实现相同的结果；实际上，这就是编译器转换using语句的方式。前面的代码示例在编译时将扩展到以下代码（请注意，使用额外的大括号为对象创建有限范围）；123456789101112&#123; Font font1 = new Font("Arial", 10.0f); try &#123; byte charset = font1.GdiCharSet; &#125; finally &#123; if (font1 != null) ((IDsiposable)font1).Dispose(); &#125;&#125; 可在using语句中声明一个类型的多个实例，如下面的示例中所示：1234using (Font font3 = new Font("Arial", 10.0f), font4 = new Font("Arial", 10.0f))&#123; // Use font3 and font4.&#125; 可以在实例化资源对象，然后将变量传递到using语句，但这不是最佳做法。在这种情况下，控件退出using块以后，对象保留在作用域中，但是可能没有访问其未托管资源的劝降。换句话说，它不再是完全初始化的。如果尝试在using块外部使用该对象，则可能导致引发异常。因此，通常最好在using语句中实例化该对象并将其范围限制在using块中。12345678Font font2 = new Font("Arial", 10.0f);using (font2) // not recommended&#123; // use font2&#125;// font2 is still in scope// but the method call throws an exceptionfloat f = font2.GetHeight(); HashTable HashSet和Dictionary的区别HashTable哈希表(HashTable)表示键/值对的集合.在.NET Framework中,HashTable是System.Collections命名空间提供的一个容器,用于处理和表现类似key-value的键值对,其中key通常可用来快速查找,同时key是区分大小写;value用于存储对应于key的值.hashtable中key-value键值对均为object类型,所以hashtable可以支持任何类型的keyvalue键值对,任何非null对象都可以用作键值对.在哈希表添加一个key/键值对:HashTableObject.Add(key,);在哈希表中去除某个key/键值对:HashTableObject.Remove(key);从哈希表中移除所有元素:HashtableObject.Clear();判断哈希表是否包含特定键key:HashtableObject.Contains(key); HashSetHashSet类主要是设计用来做高性能集运算的,例如对两个集合求交集,并集,差集等.集合中包含一组不重复出现且无特性顺序的元素,HashSet拒绝接受重复的对象.HashSet的一些特性如下: HashSet中的值不能重复且没有顺序 HashSet的容量会按需自动添加 DictionaryDictionary表示键值的集合.Dictionary&lt;string,string&gt;是一个泛型他本身有集合的功能有时候可以把它堪称数组它的结构是这样的:Dictionary&lt;[key],[value]&gt;它的特点是存入对象是需要与[key]值一一对应的存入该泛型通过某一个一定的[key]去找对应的值 HashTable和Dictionary的区别 HashTable不支持泛型,而Dictionary支持泛型 HashTable的元素属于Object类型,所以在存储或检索值类型时通常发生装箱和拆箱的操作,所以你可能需要进行类型转换的操作,而且对于int,float这些值类型还需要进行装箱等操作,非常耗时. 单线程程序中推荐使用Dictionary,有泛型优势,且读取速度较快,容量利用更充分.多线程程序中推荐使用Hashtable,默认的hashtable允许单线程写入,多线程读取,对hashtable进一步调用synchronized()方法可以获得完全线程安全的类型,而Dictionary非线程安全,必须人为使用lock语句进行保护,效率搭建. 在通过代码测试的时候发现key是整数型Dictionary的效率比hashtable快,如果key是字符串型,Dictionary的效率没有hashtable快.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static int count = 1000000;static void IntMethod()&#123; Dictionary&lt;int, int&gt; dictionary = new Dictionary&lt;int, int&gt;(); Hashtable hashtable = new Hashtable(); for (int i = 0; i &lt; count; i++) &#123; dictionary.Add(i,i); hashtable.Add(i,i); &#125; Stopwatch stopwatch = Stopwatch.StartNew(); for (int i = 0; i &lt; count; i++) &#123; int value = dictionary[i]; &#125; stopwatch.Stop(); UnityEngine.Debug.Log(stopwatch.ElapsedMilliseconds); stopwatch = Stopwatch.StartNew(); for (int i = 0; i &lt; count; i++) &#123; object value = hashtable[i]; &#125; stopwatch.Stop(); UnityEngine.Debug.Log(stopwatch.ElapsedMilliseconds);&#125;static void StringMethod()&#123; Dictionary&lt;string,string&gt; dictionary = new Dictionary&lt;string, string&gt;(); Hashtable hashtable = new Hashtable(); for (int i = 0; i &lt; count; i++) &#123; dictionary.Add(i.ToString(),"aaa"); hashtable.Add(i.ToString(), "bbb"); &#125; Stopwatch stopwatch = Stopwatch.StartNew(); for (int i = 0; i &lt; count; i++) &#123; string vale = dictionary[i.ToString()]; &#125; stopwatch.Stop(); UnityEngine.Debug.Log(stopwatch.ElapsedMilliseconds); stopwatch = Stopwatch.StartNew(); for (int i = 0; i &lt; count; i++) &#123; object value = hashtable[i.ToString()]; &#125; stopwatch.Stop(); UnityEngine.Debug.Log(stopwatch.ElapsedMilliseconds);&#125;]]></content>
      <categories>
        <category>CSharp</category>
      </categories>
      <tags>
        <tag>CSharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xxsy-sence-merge-render]]></title>
    <url>%2F2018%2F04%2F02%2Fxxsy-sence-merge-render%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[PJ04]]></title>
    <url>%2F2018%2F04%2F02%2Fxxsy-skill%2F</url>
    <content type="text"><![CDATA[normal_logic Index Type Data1 Data2 Data3 Data4 Data5 1 随机移动 2 固定线路 3 跟随逻辑 4 恐惧逻辑 5 飞行逻辑 6 7 8 怪物闲聊 talk_list.id 起始延迟时间 间隔时间 9 宠物跟随 20 怪物边聊边走 refresh_table 物体id 刷新方式 cha_list.id 0手动1刷一次2死亡复合3条件 talk_list 事件类型 事件id 4，驾云/瞬移 trans_cmn.id]]></content>
      <tags>
        <tag>Pj04</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL]]></title>
    <url>%2F2018%2F04%2F01%2Fopengl%2F</url>
    <content type="text"><![CDATA[基本概念与读者以前听说的可能不同，OpenGL（对其它3D应用程序接口来说也是如此）3D图形编程并不都是关于着色器的。不管是使用C、C++、C#、JavaScript等编程语言的哪一种，客户端都必须完成相当多的工作，来管理这些着色器，以及向它们馈送（feed）几何图形、变换矩阵和其他各种数据。本书的第一部分是真正的数据——3D图形编程教程，从基本原则开始讲述，当然这些都是基于实时3D图形渲染的行业标准OpenGL的。着色器编程非常令人兴奋，但是作者并不打算将本书写成一本着色器编程数据。实际上，如果没有如何管理场景，设置视点、模型和变换矩阵，以及载入纹理等知识，那么即使懂得如何编写优秀的着色器也难有所成……我想读者一定明白我的意思。为了帮助读者上手，本书提供了一个小型的“存储着色器”库，它们能够完成大多数常规任务。读者甚至可能会发现，对于简单3D渲染来说，这些着色器已经能够满足所有需要了。但是，随着知识的增长，读者可能并不会满足于此。在进入第二部分之前，还未读者准备GLSL“快速开始”，因此读者无需等到完成掌握OpenGL应用程序接口就能开始创造性了。 3D图形技术和术语本书的每一章都包含一个或多个实例程序用来演示这一章锁讨论的编程技术。尽管本章有意避免了关于编程细节的讨论，但扔提供了一个示例程序向读者演示最低程度上需要熟悉的技术和术语，以帮助读者充分利用本书。本章的示例程序叫做BLOCK，读者可以从随书提供的示例程序集中的“Chapter 1”文件夹中找到它。将数学和图形数据转换到3D空间图像的操作叫做渲染（Rendering）。当这个术语作为动词使用时，指的是计算机创建三维图像时所经历的过程。它也作为名词使用，指的仅仅是最终的图像作品。 光栅化（Rasterization）实际绘制或填充每个定点之间的像素形成线段就叫做光栅化（Rasterization）。我们可以通过隐藏表面消除（Hidden Surface Removal）来进一步澄清3D设计意图。视口：把绘图坐标映射到窗口坐标裁剪区域的高度和宽度很少正好与窗口的宽度和高度（以像素为单位）相匹配。因此，坐标系统必须从逻辑笛卡尔坐标映射到物理屏幕像素坐标。这个映射是通过一种叫做视口（ViewPort）的设置来指定的。视口就是窗口内部用于绘制裁剪区域的客户区域。视口简单地把裁剪区域映射到窗口的一个区域。通常，视口被定义为整个窗口，但这并非严格必须的。例如，我们可能只希望在窗口的下半部分进行绘图。在用GPA抓帧的时候会发现，如果更改屏幕分辨率，就是只绘制到了视口或者窗口的一部分。与此形成对照的是，图1.20所示显示了一个与裁剪区域相匹配的视口。我们所看到的的这个窗口仍然是300*200像素。但是，现在可视区域将占据窗口的左下部分。我们可以使用视口来缩小或放大窗口中的图像，也可以通过把视口设置为大于窗口的用户区域，从而只显示裁剪区域的一部分。顶点——空间中的一个位置 核心模式和立即渲染模式早期的OpenGL使用立即渲染模式（Immediate mode，也就是固定渲染管线），立即渲染模式容易使用和理解，但是效率太低。因此从OpenGL3.2开始，规范文档开始废弃立即渲染模式，推出核心模式(Core-profile)，这个模式完全移除了旧的特性。 状态机OpenGL自身是一个巨大的状态机(State Machine)：一系列的变脸描述OpenGL此刻应当如何运行。绘制3D图形是一项复杂的任务。在接下来的章节，我们讨论许多OpenGL函数。对于一个特定的几何图形，有许多因素可能会影响它的绘制。对象是不是与背景混合？要不要进行正面或背面剔除？当前限制的是什么纹理？这样的问题数不胜数。 我们把这类变量的集合成为管线的状态。状态机是一个抽象的模型，表示一组状态变量的集合。每个状态变量可以有各种不同的值，或者只能可以打开或关闭等。当我们在OpenGL中进行绘图时，如果每次都要指定所有这些变量显示有点不切实际。反之，OpenGL使用了一种状态模型（或称状态机）来追踪所有的OpenGL状态变量。当一个状态值被设置之后，它就一直保持这个状态，直到其他函数对它进行修改为止。许多状态只能简单的打开或关闭。例如，深度测试（参见第3章）就是要么打开、要么关闭。打开深度测试的几何绘图将会被检查以确保在进行渲染之前总会在任何位于它后面的对象前方。在深度测试关闭后进行的几何图形绘制（例如2D覆盖）则会在不进行深度比较的情况下进行绘制。 为了打开这些类型的状态变量，可以使用下面这个OpenGL函数。void glEnable(GLenum capability);我们可以使用下面这个对应的函数，把这些变量的状态设置为关闭。void glDisable(GLenum capability);以深度测试为例，可以使用下面这个函数调用深度测试。glEnable(GL_DEPTH_TEST);也可以使用下面这个函数调用关闭深度测试。glDisable(GL_DEPTH_TEST);如果希望对一个状态变量进行测试，以判断它是否已被打开，OpenGL还提供了一种方便的机制。Glboolean glIsEnabled(GLenum capability);但是，并不是所有的状态变量都只是简单地打开或关闭。许多OpenGL函数专门用于设置变量的值，此后这些变量一直保持被设置时的值，直到再次被修改。我们在任何时候都可以查询这些变量的值。OpenGL提供了一组查询函数，可以查询布尔型、整型、单精度浮点型和双精度浮点型变量的值。这4个函数的原型如下所示： 颜色缓冲区颜色缓冲区（COLOR_BUFFER）就是帧缓冲区（FRAME_BUFFER），你需要渲染的场景最终每一个像素都要写入该缓冲区，然后由它渲染到屏幕上显示。 深度缓冲区深度缓冲区（DEPTH_BUFFER）与帧缓冲区对应，用于记录上面每个像素的深度值，通过深度缓冲区，我们就可以进行深度测试，从而确定像素的遮挡关系，保证渲染正确。 模版缓冲区模版缓冲区（STENCIL_BUFFER）与深度缓冲大小相同，通过设置模版缓冲每个像素的值，我们可以指定在渲染的时候只渲染某些像素，从而可以达到一些特殊的效果。 Texture Wrapping通常，纹理坐标的范围在(0,0)到(1,1)之间，但是假如我们制定的坐标在这之外呢？OpenGL会如何做出反应？默认情况下，OpenGL会重复绘制纹理图，不过，OpenGL也提供了更多的选择方案： GL_REPEAT：默认方案，重复纹理图片 GL_MIRRORED_REPEAT：类似于默认方法，不过每次重复的时候进行镜像重复。 GL_CLAMP_TP_EDGE：将坐标限制在0到1之间。超出的坐标会重复绘制边缘的像素，变成一种扩展边缘的图案。 GL_CLAMP_TO_BORDER：超出的坐标将会被绘制成用户指定的边界颜色 Mip贴图Mip贴图是一种功能强大的纹理技巧，它不仅可以提高渲染性能，而且可以改善场景的显示质量。它使用标准纹理贴图处理两个常见的问题，从而实现上述目标。第一个问题是一种称为闪烁（Scintillation，即锯齿假影）的效果。当屏幕上被渲染物体的表面与它所应用的纹理图像相比显得非常小时，就会出现这种效果。闪烁可以被看成是某种类型的闪光，当纹理 图像的采样区域的移动幅度与它在屏幕上的大小相比显得不成比例时，就会发生这种现象。当照相机或物体处于运动状态时，我们很容易看到闪烁的负面效果。 第二个问题更多地和性能有关，但它的原因和闪烁相同。也就是说，问题的根源在与它必须加载大量的纹理内存并对它们进行过滤处理，但屏幕上实际显示的只是很少的一部分片段。纹理越大，这个问题造成的性能影响也就越为明显。 Mip贴图纹理由一系列图像组成，每个图像大小在每个轴的方向上都缩小一半，或者说是原来图像像素总数的四分之一。图5.11所示显示了这些场景。MipMap并不一样是正方形的，但每个图像的大小都依次减半，知道最后一个图像的大小是1 x 1的纹理单元位置。当其中一个纬度的大小到达1时，接下来的减半处理就只发生在其他纬度上了。使用一组正方形（即各个纬度的大小相等）的MipMap所要求的的内存比不使用MipMap要多出三分之一。MipMap是通过glTexImage函数加载的。现在轮到level参数发挥它的作用了，因为它指定了图像数据用于哪个Mip层。第一层是0，接着是1、2，然后依次类推。如果MipMap未被使用，那么就只有第0层会被加载。在默认情况下，为了使用MipMap，所有的Mip层都必须加载。但是我们可以用GL_TEXTURE_BASE_LEVEL和GL_TEXTURE_MAX_LEVEL纹理参数特别设置需要使用的基层和最大层。例如，如果想指定只加载从第0层至第4层，可以像下面这样调用glTexParameteri函数两次。12glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_BASE_LEVEL,0);glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAX_LEVEL,4); 尽管GL_TEXTURE_BASE_LEVEL和GL_TEXTURE_MAX_LEVEL控制哪些Mip层被加载，但我们仍然可以使用GL_TEXTURE_MIN_LOD和GL_TEXTURE_MAX_LOD参数限制已加载的Mip层的使用范围。 MipMap过滤MipMap在两个基本的纹理过滤模式GL_NEAREST和GL_LINEAR尚添加了一个新的变化，这是通过向Mip贴图过滤提供了4中不同变化实现的。表5.5列出了这些变化。表5.5 经过MipMap的纹理过滤 常量 描述 GL_NEAREST 在Mip基层上执行最邻近过滤 GL_LINER 在Mip基层上执行线性过滤 GL_NEAREST_MIPMAP_NEAREST 选择最邻近Mip层，并执行最邻近过滤 GL_NEAREST_MIPMAP_LINER 在Mip层之间执行线性插补，并执行最邻近过滤 GL_LINEAR_MIPMAP_LINEAR 在Mip层之间执行线性插补，并执行线性过滤，又称三线性Mip贴图 仅仅使用glTexImage函数加载Mip层并不能启用Mip贴图功能。如果纹理过滤设置为GL_LINER或GL_NEAREST，那么就只有纹理贴图基层会被使用，其他所有加载的Mip层都将被忽略。我们必须制定其中一个Mip贴图过滤器，这样才能使用所有已加载的Mip层。这个常量具有GL_FILTER_MIPMAP_SELECTOR的形式，其中FILTER制定了被选择的Mip层将要使用的纹理过滤器，SELECTOR则制定了如何选择Mip层。例如，GL_NEAREST选择最接近匹配的Mip层。应该选择哪种过滤器取决于具体的应用以及希望实现的性能要求。例如，GL_NEAREST_MIPMAP_NEAREST具有非常好的性能，并且闪烁现象也非常弱，但最邻近过滤在视觉效果上尝尝难以令人满意。GL_LINEAR_MIPMAP_NEAREST常常用于对游戏进行加载，因为它适用了更高质量的线性过滤器。但是，它需要在不同大小的可用Mip层之间进行快速选择（最邻近过滤）。 各向异性过滤各向异性纹理过滤（Anisotropic texture filtering）并不是OpenGL核心规范的一部分，但它是一种得到广泛支持的扩展，可以极大地提高纹理过滤操作的质量。我们在本章前面内容中讲述了纹理贴图，并学习了两种最基本的纹理过滤：最邻近过滤（GL_NEAREST）和线性过滤（GL_LINEAR）。当一个纹理贴图被过滤时，OpenGL使用纹理坐标来判断一个特定的几何片段将落在纹理贴图的什么地方。然后，紧邻这个位置的纹理单元使用GL_NEAREST或GL_LINEAR过滤操作进行采样。 常量 描述 GL_RGB 按照红、绿、蓝顺序排列的颜色 GL_RGBA 按照红、绿、Alpha顺序排列的颜色]]></content>
      <tags>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法]]></title>
    <url>%2F2018%2F03%2F29%2FRed-Black-Tree%2F</url>
    <content type="text"><![CDATA[红黑树红黑树是一种自平衡二叉查找树。 性质1.节点是红色或黑色。2.根节点是黑色3.每个叶节点（NIL或空节点）是黑色4.每个红色节点的两个子节点都是黑色的（也就是说不存在两个连续的红色节点）；5.从任意一个节点到其叶子节点都包含相同数目的黑色节点； AVL树性质1.本身首先是一棵二叉搜索树2.带有平衡条件：每个节点的左右子树的高度之差的绝对值（平衡因子）最多为1. 节点数STL和Linux都使用红黑树作为平衡树的实现1.如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的两级O(logN)，而RB-Tree最多只需要3次旋转，只需要O(1)的复杂度。2.其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。3.map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计行能是高于AVL的。 二叉查找树定义1.若左子树不空，则左子树所有节点的值均小于或等于它的根节点的值；2.若右子树不空，则右子树所有节点的值均大于或等于它的根节点的值；3.左、右子树也分别为二叉排序树； 查找步骤：若根节点的关键字值等于查找的关键字，成功。否则，若小于根节点的关键字值，递归查左子树。P(n)=O(logn) 非递归遍历前序非递归遍历123456789101112131415161718192021222324252627282930void preorder_traversal_iteratively(TreeNode* root)&#123; if (root == 0) &#123; return; &#125; stack&lt;TreeNode*&gt; s; s.push(root); cout &lt;&lt; root-&gt;val &lt;&lt; ' '; TreeNode* last_pop = root; while (!s.empty()) &#123; TreeNode* top = s.top(); if (top-&gt;left != 0 &amp;&amp; top-&gt;left != last_pop &amp;&amp; top-&gt;right != last_pop) &#123; s.push(top-&gt;left); cout &gt;&gt; top-&gt;left-&gt;val &lt;&lt; ' '; &#125; else if (top-&gt;right != 0 &amp;&amp; top-&gt;right != last_pop &amp;&amp; (top-&gt;left == 0 || top-&gt;left == last_pop)) &#123; s.push(top-&gt;right); cout &gt;&gt; top-&gt;right-&gt;val &lt;&lt; ' '; &#125; else &#123; s.pop(); last_pop = top; &#125; &#125;&#125; Hash(散列函数)给定M，存在函数f(key)，对任意给定给定的关键字key，代入函数厚若能得到包含该关键字的记录在表中的地址，则称表M为哈希(Hash)表，函数(key)为哈希(Hash)函数。如果key不相同，但是f(k1)=f(k2),这种现象成为碰撞(Collision) 哈希函数1.直接寻址发：取关键字或关键字的某个线性函数值为散列地址。即H(key)=key或H(key) = a * key + b,其中a和b为常熟（这种散列函数叫做自身函数）。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Objective-C]]></title>
    <url>%2F2018%2F03%2F24%2FObjective-C%2F</url>
    <content type="text"><![CDATA[Objective-C: C的超集Objective-C是C语言的严格超集—任何C语言不经修改可以直接通过Objective-C编译器 Objective-C代码文件的扩展名.h 头文件.m 源代码文件，包含Objective-C和C代码.mm 源代码文件，包含Objective-C、C、C++代码，仅在你的Objective-C代码中确实需要使用C++类或者特性的时候采用这种扩展名 当你需要在源代码中包含头文件的时候，你可以使用标准的#include编译选项，但是Objective-C提供了更好的方法。#import选项和#include选项完全相同，只是它可以确保相同的文件只会被包含一次。Objective-C的例子和文档都倾向于使用#import。 语法C++调用方法 obj.method(argument); Objective-C调用方法 [obj method: argument]; 类声明总是由@interface编译选项开始，由@end选项结束。 123456789101112@interface MyObject: NSObject&#123; int memberVar1; // 实体变量 id &#125;+(return_type) class_method; //类方法-(return_type) instance_method1; //实例方法-(void)fbSendInviteByID: (NSDictionary*)info&#123;&#125;@end 方法前面+/-号代表函数的类型：加号(+)代表类方法(class method),不需要实例就可以调用，与C++的静态函数(static member function)相似。减号(-)即是一般的实例方法(instance method)1-(void)setColorToRed: (float)red Green: () pragma mark]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unity热更新方案-ILRuntime]]></title>
    <url>%2F2018%2F03%2F23%2FUnity-ILRuntime%2F</url>
    <content type="text"><![CDATA[ILRuntime的优势同市面上的其他热更方案相比，ILRuntime主要有以下优点： 无缝访问C#工程的线程代码，无需额外抽象脚本API 直接使用VS2015进行开发，ILRuntime的解释编译引擎支持.Net 4.6编译的DLL 执行效率是L#的10-20倍 选择性的CLR绑定使跨域调用更快速，绑定后跨域调用的性能能达到slua的2倍左右(从脚本调用GameObject之类的接口) 支持跨域集成 完整的泛型支持 拥有Vs2015调试插件，可以实现真机源码级调试(WIP) https://github.com/Ourpalm/ILRuntimehttps://ourpalm.github.io/ILRuntime/public/v1/guide/tutorial.html 如果你希望在Unity中使用ILRuntime,推荐的方式是直接使用ILRuntime源代码，这样ILRuntime可以根据你的发布设置自动进行优化。 你需要将下列源代码目录复制到Unity工程的Assets目录： Mono.Cecil.20 Mono.Cecil.Pdb ILRuntime 需要注意的是，需要删除这些目录里面的bin、obj、Properties子目录，以及.csproj文件。此外由于ILRuntime使用了unsafe代码来优化执行效率，所以你需要在Unity中开启unsafe模式： 在Assets目录里建立一个名为smcs.rsp的文本文件 在smcs.rsp文件中假如-unsafe 如果你使用的是Unity5.4及以前的版本，并且使用的编译设置是.Net 2.0而不是.Net 2.0 Subset的话，你需要将上述说明中的smcs.rsp文件名改为gmcs.rsp。如果你使用的是Unity5.5以上的版本，你需要将上述说明的smcs.rsp文件名改为mcs.rsp 从Visual Studio开始如果你希望在VisiualStudio的C#项目中使用ILRuntime，你只需要引用编译好的ILRuntime.dll,Mono.Cecil.20.dll以及Mono.Cecil.Pdb即可。 使用之前ILRuntime项目提供了一个测试用例工程ILRuntimeTest,用来验证ILRuntime的正常运行，在运行测试用例前，需要手动生成一下TestCases里面的工程，生成DLL文件。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Skinned Mesh原理解析]]></title>
    <url>%2F2018%2F03%2F23%2FUnity-Skinned-Mesh%2F</url>
    <content type="text"><![CDATA[一、3D模型动画基本原理和分类3D模型动画的基本原理是让模型中各定点的位置随时间变化。主要种类由Morph动画，关节动画和骨骼蒙皮动画(Skinned Mesh)。从动画数据的角度来说，三者一般都采用关键帧技术，即只给出关键帧的数据，其他帧的数据使用插值得到。但由于这三种技术的不同，关键帧的数据是不一样的。 Morph(渐变，变形)动画是直接指定动画每一帧的顶点位置，其动画关键中存储的是Mesh所有顶点在关键帧对应时刻的位置。 关节动画的模型不是一个整体的Mesh，而是分成很多部分(Mesh),通过一个父子层级结构将这些分散的Mesh组织在一起，父Mesh带动其子Mesh运动，各mesh中的顶点坐标定义在自己的坐标系中，这样各个Mesh是作为一个整体参与运动的。动画帧中设置各子Mesh相对于Mesh的变化（主要是旋转，当然也可以包括移动和缩放），通过子到父，一级级的变化累加（当然从技术上，如果是矩阵操作是累乘）得到该Mesh在整个动画模型所在的坐标空间中的变换（从本文的视角来说就是世界坐标系了，下同），从而确定每个Mesh在世界坐标系中的位置和方向，然后以Mesh为单位渲染即可。关节动画的问题是，各部分Mesh中的顶点时固定在其Mesh坐标系中的，这样在两个mesh结合处就可能产生裂缝。 第三类就是骨骼蒙皮动画即Skinned Mesh了，骨骼蒙皮动画的出现解决了关节动画的裂缝问题，而且效果非常酷，骨骼动画的基本原理可概括为：在骨骼控制下，通过顶点混合动态计算蒙皮网格的顶点，而骨骼的运动相对于其父骨骼，并由动画关键帧数据驱动。一个骨骼动画通常包括骨骼层次结构数据，网格(Mesh)数据，网格蒙皮数据(skin info)和骨骼的动画(关键帧)数据。 二、Skinned Mesh 原理和结构分析Skinned Mesh中文一般乘坐骨骼蒙皮动画，这种动画包含骨骼(Bone)和蒙皮(Skinned Mesh)两个部分，Bone的层次结构和关节动画类似，Mesh则和关节动画不同：关节动画中时使用多个分散的Mesh,而Skinned Mesh中的Mesh是一个整体，也就是说只有一个mesh,实际上如果没有骨骼让Mesh运动变形，Mesh就和静态模型一样了，Skinned Mesh技术的精华在于蒙皮，所谓的皮并不是模型的贴图，而是mesh本身，蒙皮是将mesh中的顶点附着（绑定）在骨骼之上，而且每个顶点可以被多个骨骼所控制，这样的关节处的顶点由于同时收到了父子骨骼的拉扯而改变位置就消除了裂缝。 1.理解骨骼和骨骼层次结构(Bone Hierarchy)首先要明确一个观念：骨骼决定了模型整体在世界坐标系中的位置和朝向。先看看静态模型吧，静态模型没有骨骼，我们在世界坐标系中放置静态模型时，只要指定模型自身坐标系在世界坐标系中的位置和朝向。在骨骼动画中，不是把Mesh直接放到世界坐标系中，Mesh只是作为Skin使用的，是依附骨骼的，真正决定模型在世界坐标系中的位置和朝向的是骨骼。在渲染静态模型时，由于模型的顶点都是定义在模型坐标系中的，所以各顶点只要经过模型坐标系到世界坐标系的变换就可以进行渲染。而对于骨骼动画，设置模型的位置和朝向，实际实在设置根骨骼的位置和朝向，然后根据骨骼层级结构中父子骨骼之间的变换关系计算出各个骨骼的位置和朝向，然后根据骨骼堆Mesh中顶点的绑定计算出顶点在世界坐标系中的坐标，从而堆顶点进行渲染，要记住，在骨骼动画中，骨骼才是模型主题，Mesh不过是一层皮，一件衣服。如何理解骨骼？请看第二个管娘：骨骼可理解为一个坐标空间。在一些文章中往往会提到关节和骨骼，那么关节是什么？骨骼有事什么？下图是一个手臂的骨骼层次的实例。骨骼只是一个形象的说法，实际上骨骼可理解为一个坐标空间，关节可理解为骨骼坐标空间的远点。关节的位置由它在父骨骼坐标空间中描述，上图中由三块骨骼，分别是手臂，前臂和两个手指。Clavicle(骨锁)是一个关节，它是上臂的原点，同样肘关节(elbow joint)是前臂的原点，腕关节(wrist)是手指骨骼的远点。关节既决定了骨骼空间的位置，旋转和缩放分量决定了骨骼空间的旋转和缩放。我们来看前臂这个骨骼，其原点位置位于上臂上某处的，对于上臂来说，它知道自己的坐标空间某处(即肘关节所在的位置)有一个子空间，那就是前臂，至于前臂里面是啥就不考虑了。当前臂绕肘关节旋转时，实际是前臂坐标空间在旋转，从而其中包含的子空间也在绕肘关节旋转，这个例子中是finger骨骼。和实际生物骨骼不同的是，我们这里的骨骼并没有实质的骨头，所以前臂旋转时，他自己没啥可转的，改变的只是坐标空间的朝向。你可以说上图蓝线在转，但实际蓝线并不存在，蓝线只是画上去表示骨骼之间关系的，真正转的是骨骼空间，我们能看到在转的是wrist joint,也就是两个finger骨骼的坐标空间，因为他们是子空间，会跟随父空间运动，就好比跟着地球转一样。 骨骼就是坐标空间，骨骼层次就是嵌套的坐标空间。关节只是描述骨骼的位置即骨骼自己的坐标空间原点再其父空间中的位置，绕关节旋转是指骨骼坐标空间(包括所有子空间)自身的旋转。但还有两个可能的疑问，一是骨骼的长度，由于骨骼是坐标空间没有所谓的长度和宽度限制，我们看到的长度一方面是蒙皮后的结果，而另一方面子骨骼的原点(也就是关节)的位置往往决定了视觉上父骨骼的长度，比如这里upper arm线段的长度实际是由elbow joint的位置决定的。第二个问题，实际上我们的例子中手指没有子骨骼，所以那个端点并不存在，那是为了方便演示画上去的。实际问题中总有最下层的骨骼，他们不能决定其他骨骼了，他们的作用只剩下控制Mesh顶点了。对了，那么手指的长度如何确定？我们看到的长度应该是手指部分的顶点和蒙皮决定的，也就是由Mesh中属于手指的那些点离腕关节的距离决定。 经过一段长篇大论，我们终于弄清楚骨骼和骨骼层次结构了，但是为什么要将骨骼组织成层次结构呢？答案是为了做动画方便，设想如果只有一块骨骼，那么让他动起来太简单了，动画每一帧直接指定他的位置即可，如果是n块呢？通过组成一个层次结构，就可以通过父骨骼控制子骨骼的运动，牵一发而动全身，改变某骨骼时并不需要设置其子骨骼的位置，子骨骼的位置会通过计算自动得到，上问已经说过，父子骨骼之间的关系可以理解为，子骨骼位于父骨骼的坐标系中，我们知道物体在坐标系中可以平移变换，以及自身的旋转和缩放。子骨骼在父骨骼的坐标系中也可以做这些变换来改变自己在其父骨骼坐标系中的位置和朝向等，那么如何表示呢？由于4x4矩阵可以同时表示上述三种变换，所以一般描述骨骼在其父骨骼坐标系时使用一个举证，也就是DirectX SkinnedMesh中的FramrTrnsformMatrix。实际上这不是唯一的方法，但应该是公认的方法因为矩阵不光可以同时表示多种变换还可以方便的通过连乘进行变换的组合，这在层次结构中非常方便。在本文的例子-最简单的skinned mesh示例中，我只演示了评议变换，所以只用一个3d坐标就可以表示子骨骼在父骨骼的位置。下面是Bone Class最初的定义：12345class Bone&#123; public: float m_x, m_y, m_z;//这个坐标是定义在父骨骼坐标系中&#125; 同时增加了一组坐标，存放计算好的世界坐标系。将各个骨骼相关于相对于父骨骼摆放好，就形成了一个骨骼层次结构的初始坐标，所谓初始是指定义骨骼层次时，后来动画改变了骨骼的相对位置，准确的说一般是改变了骨骼自身的旋转而位置保持不变。 假设我们通过某种方法建立了骨骼层次结构，那么每一块骨骼的位置都依赖于其父骨骼的位置，而跟骨骼没有父，他的位置就是整个骨骼体系在世界坐标系中的位置。可以认为root的父就是世界坐标系。但是初始位置时，跟骨骼一般不是世界原点的，比如使用3d max character studio创建的biped骨架时，一般两脚之间时世界原点，而根骨骼-骨盆位于原点上方(+z轴上)。这有什么关系呢，其实也没什么大不了的，只是我们在指定骨骼动画模型整体坐标时，比如设定坐标(0,0,0),则根骨骼-骨盆被置于世界原点，假如xy平面时地面，那么人下个身子到地面下了。我们想让两脚之间算作人的原点，这样设定(0,0,0)的坐标时人就站在地面上了，所以可以在两脚之间设定一个额外的根骨骼放到世界原点上，或者这个骨骼并不需要真实存在，只是在你的骨骼模型结构中保存骨盆骨骼到世界原点的变换矩阵。在微软X文件中，一般有一个Scene_Root节点，这算一个额外的骨骼吧，他的变换矩阵为单位阵，表示他初始位于世界原点，而真正骨骼的跟Bip01,作为Scene_root的子骨骼，其变换矩阵表示相对于root的位置。说这么多其实我只是像解释下，为什么要存在Scenen_Root这种额外的骨骼，以及加深理解骨骼定位骨骼动画模型整体的世界坐标的作用。 有了骨骼类，现在让我们看一下建立骨骼层次的代码，在bone class中增加一个构造函数和两个成员函数： 1234567891011121314151617class Bone&#123;public: Bone(float x, float y, float z): m_pSibling(NULL),m_pFirstChild(NULL),m_pFather(NULL), m_x(x),m_y(y),m_z(z)&#123;&#125; void SetFirstChild(Bone *pChild) &#123; m_pFirstChild = pChild; m_pFirstChild-&gt;m_pFather = this; &#125; void SetSibling(Bone *pSibling) &#123; m_pSibling = pSibling; m_pSibling-&gt;m_pFather = m_pFather; &#125;&#125; 注意我增加了一个成员变量，Bone* m_pFather,这是指向父骨骼的指针，在这个例子中计算骨骼动画时本不需要这个指针，但我为了画一条从父骨骼关节到子骨骼关节的连线，增加了它，因为每个骨骼只有第一子骨骼的指针，绘制父骨骼时从父到子画线就只能画一条，所以记录每个骨骼的父，在胡子hi子骨骼时画这根线。 有了这个函数，就可以创建骨骼层次了，例如：1234567891011121314Bone * g_boneRoot;Bone * g_bone1, *g_bone32, *g_bone22;void buildBones()&#123; g_boneRoot = new Bone(0,0,0); g_bone1 = new Bone(0.1,0,0); g_bone21 = new Bone(0,0,0.1,0); g_bone22 = new Bone(0.1, 0.0,0); g_boneRoot-&gt;SetFirstChild(g_bone1); gbone1-&gt;SetFirstChild(g_bone21); g_bone21-&gt;SetSibling(g_bone22);&#125; 接下来是骨骼层次中最核心的部分，更新骨骼！由于动画的作用，某个骨骼的变化(TransformMatrix)变了，这时就要根据新的变化来计算，所以这个过程一般乘坐UpdateBoneMatrix。因为骨骼的变化都是相对父的，要变换顶点必须使用世界变换矩阵，所以这个过程根据更新了某些骨骼的骨骼变换矩阵(TransformMatrix)计算出所有骨骼的世界变换矩阵(CombinedMatrix)。在本文的例子中，骨骼只能平移，甚至我们没有用矩阵，所以当有骨骼变动时要做的只是直接计算骨骼的世界坐标，因此函数命名为ComputeWorldPos,相当于UpdateBoneMatrix后再用顶点相乘CombinedMatrix。123456789101112131415class Bone&#123; //give father's world pos, compute the bone's world pos void ComputeWorldPos(float fatherWX, float fatherWY, float WZ) &#123; m_wx = fatherWX + m_x; m_wy = fatherWY + m_y; m_wz = fatherWZ + m_z; if (m_pSibling != NULL) m_pSibling-&gt;ComputeWorldPos(fatherWX, fatherWY, fatherWZ); if (m_pFirstChild != NULL) m_pFirstChild-&gt;ComputreWorldPos(m_wx, m_wy, m_wz); &#125;&#125; 其中的递归调用使用了微软例子的思想。 有了上述函数，当某骨骼运动时就可以让其子骨骼跟随运动了，但是怎么让骨骼运动呢？这就是动画问题了，我不打算在这个简单的例子中使用关键帧动画，而只是通过程序每帧改变某些骨骼的位置，DEMO中的animateBones就是做这个的，你可以在里面改变不同的骨骼看看效果。在本文下面会对骨骼的关键帧动画做简单的讨论。 2.蒙皮信息和蒙皮过程2-1 Skin info的定义上文曾讨论过，Skinned Mesh中Mesh时作为皮肤使用，蒙在骨骼之上的。为了让普通的Mesh具有蒙皮的功能，必须添加蒙皮信息，即Skin info。我们知道mesh是由顶点构成的，建模时顶点是定义在模型自身坐标系的，即相对于Mesh原点的，而骨骼动画中决定模型顶点最终世界坐标的是骨骼，所以要让骨骼决定顶点的世界坐标，这就要将顶点和骨骼联系起来，Skin info正是起了这个作用。下面是DEMO中顶点类的定义的代码片段： 1234567891011#define MAX_BONE_PER_VERTEX 4class Vertex&#123; float m_x, m_y, m_z;//local pos in mesh space float m_wX, m_wY, m_wZ; // blended vertex pos, in world space // skin info int m_boneNum; Bone * m_bones[MAX_BONE_PER_VERTEX]; float m_boneWeights[MAX_BONE_PER_VERTEX];&#125; 顶点的Skin info包含影响该顶点的骨骼数目，只想这些骨骼的指针，这些骨骼作用于该顶点的权重(Skin weight)。由于只是一个简单的例子，这儿没有考虑优化，所以用静态数组存放骨骼指针和权重，且实际引擎中Skin info的定义方式不一定是这样的，但基本原理一致。 MAX_BONE_PER_VERTEX在这儿用来设置可同时影响顶点的最大骨骼数，实际上由于这个DEMO是手工进行Vertex Blending并且没有硬件加速，以及为了确保速度，一般会定义最大骨骼数。另外在本Demo中，Skin info是手工设定的，而实际项目中，一般是在建模软件中生成这些信息并导出。 Skin info 的作用是使用各个骨骼的变换矩阵对顶点进行变换并乘以权重，这样某块骨骼只能对该顶点产生部分影响。各骨骼权重之和应该为1. Skin info是针对顶点的，然后在使用Skin info前我们必须要使用Bone Offset Matrix对顶点进行变换，下面具体讨论Bone offset Matrix。（写下这句话的时候我感觉不妥，因为实际是先将所有的矩阵相乘最后在用作顶点，这儿是按照理论上的顺序进行讲述吧，请不要与实际情况混肴，其实他们也并不矛盾。而且在我们的DEMO中由于没有使用矩阵，所以变换的顺序和理论顺序是一致的） 2-2 Bone Offset Matrix的含义和计算方法上文已经说过：“骨骼动画中决定模型顶点最终世界坐标的是骨骼，所以要让骨骼决定顶点的世界坐标”，现在让我们看下顶点受一块骨骼的作用的坐标变换过程： mesh vertex(defined in mesh space)——&gt;Bone space——&gt;world从这个过程中可以看出，需要首先将模型顶点从模型空间变换到某块骨骼自身的骨骼空间，然后才能利用骨骼的世界变换计算顶点的世界坐标。Bone Offset Matrix的作用正是将模型从顶点空间变换到骨骼空间。那么Bone Offset Matrix如何得到呢？下面具体分析： Mesh space是建模时使用的空间，mesh中顶点的位置相对于这个空间的原点定义。比如在3dmax中建模时(视xy平面为地面，+z朝上)，可将模型两脚之间的中点作为Mesh空间的原点，并将其放置在世界原点，这样左脚上某一顶点坐标是(10,10,2),右脚上堆成的一点坐标是(-10,10,2)，头顶的坐标是(0,0,170)。由于此时Mesh空间和世界空间重合，上述坐标即在Mesh空间也是世界空间，换句话说，此时实际是以世界空间作为Mesh空间了。在骨骼动画中，在世界中放置的是骨骼而不是Mesh，所以这个区别并不重要。在3d max中添加骨骼的时候，也是将骨骼放入世界空间中，并调整骨骼的相对位置是得和mesh相吻合（即设置骨骼的TransformMatrix),得到股价的初始姿势以及相应的Transform Matrix(按惯例模型做成两臂侧平举直立，骨骼也要适合这个姿态)。由于骨骼的Transform Matrix(作用是将顶点从骨骼空间变换到上层空间)是基于其父骨骼空间的，只有根骨骼的Transform是基于世界空间的，所以要通过自下而上一层层Tranform变换(如果使用行向量右乘矩阵，这个Transform的累计过程就是C=MboneMfatherMgrandpar..Mroot),得到该骨骼在世界空间上的变换矩阵-Combined Transform Matrix,即通过这个矩阵可将该顶点从骨骼空间变换到世界空间。那么这个矩阵的逆矩阵就可以将世界空间中的顶点变换到某块骨骼的骨骼空间。由于Mesh实际上就是定义在世界空间了，所以这个逆矩阵就是Offset Matrix。即OffsetMatrix就是骨骼在初始位置（没有经过任何动画改变）时将bone变换到世界空间的矩阵(CombinedTransformMatrix)的逆矩阵，有一些资料称之为InverseMatrix。在几何流水线中，是通过变换矩阵将顶点变换到上层空间，最终得到世界坐标，逆矩阵则作相反的事，所以Inverse这种提法也符合惯例。那么Offset这种提法从字面上怎么理解呢？Offset即骨骼相对世界原点的偏移，世界原点加上这个偏移就变成骨骼空间的原点，同样定义在世界空间中的点经过这个偏移矩阵的作用也被变换成骨骼空间了。从另一角度理解，在动画中模型中顶点的位置是根据骨骼位置动态计算的，也就是说顶点跟着骨骼动，但首先必须确定顶点和骨骼之间的相对位置（即顶点在该骨骼坐标系中的位置），一个骨骼可能对应很多顶点，如果要保存这个相对位置每个顶点对于每块受控制的骨骼都要保存，这样就要保存太多的矩阵了。。所以只保存mesh空间到骨骼空间的变换（即OffsetMatrix),然后通过这个变换计算每个顶点在该骨骼空间中的坐标，所以OffsetMatrix也反应了mesh和每块骨骼的相对位置，只是这个位置是间接的通过和世界坐标空间的关系表达的，在初始位置将骨骼按照模型的形状摆好的关键之处。 以上的分析是通过mesh space和world space重合得到Offset Matrix的计算方法。那么如果他们不重合呢？那就要先计算顶点从mesh space变换到world space的变换矩阵，并乘上（还是右乘为例）Combined Matrix的Inverse Matrix从而得到Offset Matrix。但是这不是找麻烦吗，因为Mesh的原点在哪里并不重要，为啥不让他们重合呢？ 还有一个问题是，既然Offset Matrix可以计算出来，为啥还要在骨骼动画文件中同时提供TransformMatrix和OffsetMatrix呢？实际上文件中确实可以不提供OffsetMatrix,而只在载入时计算，但TransformMatrix不可缺少，动画关键帧数据一般只存储骨骼的旋转和跟骨骼的位置，骨骼见的相对位置还是要靠TransformMatrix提供。在微软的X文件结构中提供了OffsetMatrix,原因是什么呢？我不知道。我猜想一个可能的原因是为了兼容性和灵活性，比如mesh并没有定义在世界坐标系，而是作为一个object放置在3d max中，在导出骨骼动画时不能简单的认为mesh的顶点坐标时相对于世界远点的，还要把这个object的位置考虑进去，于是导出插件要计算OffsetMatrix并保存在x文件中以避免兼容性问题。 关于OffsetMatrix和TransformMatrix含有评议，旋转和缩放的讨论： 首先，OffsetMatrix取决于骨骼的初始位置(即TransformMatrix),由于骨骼动画中我们使用的动画中的位置，初始位置时什么样并不重要，所以可以在初始位置中包含平移，而旋转和缩放在动画中设置(一般也仅仅使用旋转，这也是为啥动画通常中可以用一个四元数表示骨骼的关键帧)。在这种情况下，OffsetMatrix只包含平移即可。因此一些引擎的Bone中不存放Transform矩阵，而只存放骨骼在父骨骼空间的坐标，然后旋转只在动画帧中设置，最基本的骨骼动画即可实现。但也可在Transform和Offset Matrix中包括旋转和缩放，这样可以提供创建动画时的容错性。 在本文的DEMO中，我们也没有使用矩阵保存Bone Offset，而只用了一个坐标保存偏移位置。 123456789101112131415161718192021222324class BoneOffset&#123;public: float m_offx, m_offy, m_offz;;//在Bone class中，有一个方法用来计算Bone Offsetclass Bone&#123;public: BoneOffset m_boneOffset; //called after ComputeWorldPos() when bone loaded but not animated void ComputeBoneOffset() &#123; m_boneOffset.m_offx = -m_wx; m_boneOffset.m_offy = -m_wy; m_boneOffset.m_offz = -m_wz; if (m_pSibling != NULL) m_pSibing-&gt;ComputeBoneOffset(); if (m_pFirstChild != NULL) m_pFirstChild-&gt;ComputeBoneOffset(); &#125;&#125;; 在ComputeBoneOffset()中，使用计算好的骨骼的世界坐标来计算bone offset,这儿的计算只是取一个负数，在实际引擎中，如果bone offset是一个矩阵，这儿就应该是求逆矩阵，其实由于旋转矩阵是正交的，只要求出旋转矩阵的转置矩阵。注意由于我们计算Bone offset时是使用计算好的世界坐标，所以在这之前必须在初始位置时对根骨骼调用ComputeWorldPos()以计算出各个骨骼在初始位置时的世界坐标。 2-3 最终：顶点混合(vertex blending)现在我们有了Skin info,有了Bone Offset。现在开始做顶点混合，这是骨骼动画的精髓所在，正是这个技术消除了关节处的裂缝。顶点混合后得到了顶点新的世界坐标，对所有的顶点执行vertex blending后，从Mesh的角度看，Mesh deform(变形)了，变成动画需要的形状了。 首先，让我们看看使用单块骨骼对顶点进行作用的过程以下是DEMO中的相关代码：12345678910111213141516class Vertex&#123;public: void ComputerWorldPosByBone(Bone *pBone, float &amp;outx, float &amp;outY, float &amp;outZ) &#123; //step1: transform vertex from mesh space to bone space outX = m_x + pBone-&gt;m_boneOffset.m_offx; outY = m_y + pBone-&gt;m_boneOffset.m_offy; outZ = m_z + pBone-&gt;m_boneOffset.m_offz; //step2: transform vertex bone space to world space outX += pBone-&gt;m_wx; outY += pBone-&gt;m_wy; outZ += pBone-&gt;m_wz; &#125;&#125;; 这个函数使用一块骨骼对顶点进行变换，将顶点Mesh坐标系变换到世界坐标系，这儿使用了骨骼的Bone Offset Matrix和Combined Transform Matrix 对于多块骨骼，对每块骨骼执行这个过程并将结果根据权重混合(即vertex blending)就得到顶点最终的世界坐标。进行vertex blending的代码如下：1234567891011121314151617181920212223class Vertex&#123; void BlendVertex() &#123; //do the vertex blending,get the vertex's pos in world space m_wX = 0; m_wY = 0; m_wZ = 0; for (int i = 0; i &lt; m_boneNum; ++i) &#123; float tx, ty, tz; ComputeWorldPosByBone(m_bones[i], tx, ty, tz); tx *= m_boneWeights[i]; ty *= m_boneWeights[i]; tz *= m_boneWeights[i]; m_wX += tx; m_wY += ty; m_wZ += tz; &#125; &#125;&#125; 这些函数我都放在Vertex类中了，因为只是一个简单DEMO所以没有特别考虑类结构问题，在BlendVertex()中，遍历影响该顶点的所有骨骼，用每块骨骼计算出顶点的世界坐标，然后使用Skin Weight对这些坐标进行加权平均。tx,ty,tz是某块骨骼作用后顶点的世界坐标乘以权重后的值，这些值相加后就是最终的世界坐标了。 现在让我们用一个工时回顾以下Vertex blending的整个过程(使用矩阵变换) 1234Vworld = Vmesh * BoneOffsetMatrix1 * CombindMatrix1 * Weight1+ Vmesh* BoneOffsetMatrix2 * CombineMatrix2*Wright2+ ...+ Vmesh * BoneOffsetMatrixn * CombindMatrixN * WeightN 4 总结从结构上看，SkinnedMesh包括：动画数据，骨骼数据，包括Skin info的Mesh数据，以及Bone Offset Matrix。 从过程上看，载入阶段：载入并建立骨骼层次结构，计算或载入Bone Offset Matrix,载入Mesh数据和Skin info(具体的实现不同的引擎可能都不一样)。运行阶段：根据时间从动画数据中获取骨骼当前时刻的Transfrom Matrix，调用UpdateBoneMatrix计算出各骨骼的CombineMatrix,对于每个顶点根据Skin info进行Vertex Blending计算出顶点的世界坐标，最终进行模型的渲染。 三、关于本文的例子这个例子做了尽可能的简化，只包含一个cpp文件，使用OpenGL和GLUT作为渲染器和框架，仅有400多行代码。例子中手工创建了一个骨骼层次和Mesh，手工设置Skin info并自动计算BoneOffset,使用程序控制骨骼平移演示了骨骼层次的运动和骨骼影响下Mesh顶点的运动，例子中甚至没有使用矩阵。本例子仅作理解骨骼动画只用。截图中绿色网格是模型原始形状，蓝色是骨骼，红色是动画时模型形状，DEMO中左数第二个骨骼做上下运动，最下方的骨骼做x方向平移。DEMO没有使用旋转，而实际的骨骼动画中往往没有平移只有旋转的，因为胳膊只能转不能边长，但原理一致。(这个公式使用的是行向量左乘矩阵)由于BoneOffsetMatrix和Combined Matrix都是矩阵，可以先相乘这样就减少了很多计算了，在实际游戏中可以VS进行硬件加速计算。代码的执行过程为，初始化时：12345678910111213141516171819202122buildBones();//创建骨骼层次buildMesh();//创建mesh,设置skin info，计算bone offset ``` 每帧运行时：```C++//draw original meshg_mesh-&gt;DrawStaticMesh(0,0,0);//move bonesanimateBones();//update all bone's pos in bone treeg_boneRoot-&gt;ComputeWorldPos(0,0,0);//update vertex pos by bones,using vertex blendingg_mesh-&gt;UpdateVertices();//draw deformed meshg_mesh-&gt;Draw();//draw boneg_boneRoot-&gt;Draw(); 为保证文本的完整性，下面贴出所有代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382// A simplest Skinned Mesh demo#include &lt;GL/glut.h&gt;#define NULL 0class BoneOffset&#123;public : //BoneOffset transform a vertex from mesh space to bone space. //In other words, it is the offset from mesh space to a bone's space. //For each bone, there is a BoneOffest. //If we add the offset to the vertex's pos (in mesh space), we get the vertex's pos in bone space //For example: if a vertex's pos in mesh space is (100,0,0), the bone offset is (-20,0,0), so the vertex's pos in bone space is (80,0,0) //Actually, BoneOffset is the invert transform of that we place a bone in mesh space, that is (-20,0,0) means the bone is at (20,0,0) in mesh space float m_offx , m_offy , m_offz ;&#125;;//----------------------------------------------------------------class Bone&#123;public : Bone () &#123;&#125; Bone ( float x , float y , float z ):m_pSibling (NULL ),m_pFirstChild (NULL ),m_pFather (NULL ),m_x (x ),m_y (y ),m_z (z )&#123;&#125; ~Bone () &#123;&#125; Bone * m_pSibling ; Bone * m_pFirstChild ; Bone * m_pFather ; //only for draw bone void SetFirstChild (Bone * pChild ) &#123; m_pFirstChild = pChild ; m_pFirstChild -&gt;m_pFather = this ; &#125; void SetSibling (Bone * pSibling ) &#123; m_pSibling = pSibling ; m_pSibling -&gt;m_pFather = m_pFather ; &#125; float m_x , m_y , m_z ; //pos in its parent's space float m_wx , m_wy , m_wz ; //pos in world space //give father's world pos, compute the bone's world pos void ComputeWorldPos ( float fatherWX , float fatherWY , float fatherWZ ) &#123; m_wx = fatherWX +m_x ; m_wy = fatherWY +m_y ; m_wz = fatherWZ +m_z ; if (m_pSibling !=NULL ) m_pSibling -&gt;ComputeWorldPos (fatherWX , fatherWY , fatherWZ ); if (m_pFirstChild !=NULL ) m_pFirstChild -&gt;ComputeWorldPos (m_wx , m_wy , m_wz ); &#125; BoneOffset m_boneOffset ; //called after compute world pos when bone loaded but not animated void ComputeBoneOffset () &#123; m_boneOffset .m_offx = -m_wx ; m_boneOffset .m_offy = -m_wy ; m_boneOffset .m_offz = -m_wz ; if (m_pSibling !=NULL ) m_pSibling -&gt;ComputeBoneOffset (); if (m_pFirstChild !=NULL ) m_pFirstChild -&gt;ComputeBoneOffset (); &#125; void Draw () &#123; glColor3f (0,0,1.0); glPointSize (4); glBegin (GL_POINTS ); glVertex3f (m_wx ,m_wy ,m_wz ); glEnd (); if (m_pFather !=NULL ) &#123; glBegin (GL_LINES ); glVertex3f (m_pFather -&gt;m_wx ,m_pFather -&gt;m_wy ,m_pFather -&gt;m_wz ); glVertex3f (m_wx ,m_wy ,m_wz ); glEnd (); &#125; if (m_pSibling !=NULL ) m_pSibling -&gt;Draw (); if (m_pFirstChild !=NULL ) m_pFirstChild -&gt;Draw (); &#125;&#125;;//--------------------------------------------------------------#define MAX_BONE_PER_VERTEX 4class Vertex&#123;public : Vertex ():m_boneNum (0) &#123; &#125; void ComputeWorldPosByBone (Bone * pBone , float &amp; outX , float &amp; outY , float &amp; outZ ) &#123; //step1: transform vertex from mesh space to bone space outX = m_x +pBone -&gt;m_boneOffset .m_offx ; outY = m_y +pBone -&gt;m_boneOffset .m_offy ; outZ = m_z +pBone -&gt;m_boneOffset .m_offz ; //step2: transform vertex from bone space to world sapce outX += pBone -&gt;m_wx ; outY += pBone -&gt;m_wy ; outZ += pBone -&gt;m_wz ; &#125; void BlendVertex () &#123; //do the vertex blending,get the vertex's pos in world space m_wX = 0; m_wY = 0; m_wZ = 0; for ( int i =0; i &lt;m_boneNum ; ++i ) &#123; float tx , ty , tz ; ComputeWorldPosByBone (m_bones [i ], tx , ty , tz ); tx *= m_boneWeights [i ]; ty *= m_boneWeights [i ]; tz *= m_boneWeights [i ]; m_wX += tx ; m_wY += ty ; m_wZ += tz ; &#125; &#125; float m_x , m_y , m_z ; //local pos in mesh space float m_wX , m_wY , m_wZ ; //blended vertex pos, in world space //skin info int m_boneNum ; Bone * m_bones [MAX_BONE_PER_VERTEX ]; float m_boneWeights [MAX_BONE_PER_VERTEX ]; void SetBoneAndWeight ( int index , Bone * pBone , float weight ) &#123; m_bones [index ] = pBone ; m_boneWeights [index ] = weight ; &#125; &#125;; //----------------------------------------------------------- class SkinMesh &#123; public : SkinMesh ():m_vertexNum (0) &#123; &#125; SkinMesh ( int vertexNum ):m_vertexNum (vertexNum ) &#123; m_vertexs = new Vertex [vertexNum ]; &#125; ~SkinMesh () &#123; if (m_vertexNum &gt;0) delete [] m_vertexs ; &#125; void UpdateVertices () &#123; for ( int i =0; i &lt;m_vertexNum ; ++i ) &#123; m_vertexs [i ].BlendVertex (); &#125; &#125; void DrawStaticMesh ( float x , float y , float z ) &#123; glColor3f (0,1.0,0); glPointSize (4); glBegin (GL_POINTS ); for ( int i =0; i &lt;m_vertexNum ; ++i ) glVertex3f (m_vertexs [i ].m_x +x ,m_vertexs [i ].m_y +y ,m_vertexs [i ].m_z +z ); glEnd (); glBegin (GL_LINE_LOOP ); for ( int i =0; i &lt;m_vertexNum ; ++i ) glVertex3f (m_vertexs [i ].m_x +x ,m_vertexs [i ].m_y +y ,m_vertexs [i ].m_z +z ); glEnd (); &#125; void Draw () &#123; glColor3f (1.0,0, 0); glPointSize (4); glBegin (GL_POINTS ); for ( int i =0; i &lt;m_vertexNum ; ++i ) glVertex3f (m_vertexs [i ].m_wX ,m_vertexs [i ].m_wY ,m_vertexs [i ].m_wZ ); glEnd (); glBegin (GL_LINE_LOOP ); for ( int i =0; i &lt;m_vertexNum ; ++i ) glVertex3f (m_vertexs [i ].m_wX ,m_vertexs [i ].m_wY ,m_vertexs [i ].m_wZ ); glEnd (); &#125; int m_vertexNum ; Vertex * m_vertexs ; //array of vertices in mesh &#125;; //-------------------------------------------------------------- Bone * g_boneRoot ; Bone * g_bone1 , *g_bone2 , *g_bone31 , *g_bone32 ; void buildBones () &#123; g_boneRoot = new Bone (0, 0, 0); g_bone1 = new Bone (0.2, 0, 0); g_bone2 = new Bone (0.2, 0, 0); g_bone31 = new Bone (0.2, 0.1, 0); g_bone32 = new Bone (0.2, -0.1, 0); g_boneRoot -&gt;SetFirstChild (g_bone1 ); g_bone1 -&gt;SetFirstChild (g_bone2 ); g_bone2 -&gt;SetFirstChild (g_bone31 ); g_bone31 -&gt;SetSibling (g_bone32 );&#125;void deleteBones ()&#123; delete g_boneRoot ; delete g_bone1 ; delete g_bone2 ; delete g_bone31 ; delete g_bone32 ;&#125;void animateBones ()&#123; static int dir =-1, dir2 =-1; //animate bones manually g_bone1 -&gt;m_y +=0.00001f*dir ; if (g_bone1 -&gt;m_y m_y &gt;0.2) dir *=-1; g_bone32 -&gt;m_x +=0.00001f*dir2 ; if (g_bone32 -&gt;m_x m_x &gt;0.2) dir2 *=-1;&#125;SkinMesh * g_mesh ;void buildMesh ()&#123; float _meshData []= &#123; //x,y,z -0.1,0.05,0, 0.1,0.05,0, 0.3,0.05,0, 0.45,0.06,0, 0.6,0.15,0, 0.65,0.1,0, 0.5,0,0, 0.65,-0.1,0, 0.6,-0.15,0, 0.45,-0.06,0, 0.3,-0.05,0, 0.1,-0.05,0, -0.1,-0.05,0, &#125;; float _skinInfo []= &#123; //bone_num,bone id(0,1,2,31 or 32), bone weight 1~4, 1, 0, -1, -1, -1, 1.0, 0.0, 0.0, 0.0, 2, 0, 1, -1, -1, 0.5, 0.5, 0.0, 0.0, 2, 1, 2, -1, -1, 0.5, 0.5, 0.0, 0.0, 2, 2, 31, -1, -1, 0.3, 0.7, 0.0, 0.0, 2, 2, 31, -1, -1, 0.2, 0.8, 0.0, 0.0, 1, 31, -1, -1, -1, 1.0, 0.0, 0.0, 0.0, 2, 31, 32, -1, -1, 0.5, 0.5, 0.0, 0.0, 1, 32, -1, -1, -1, 1.0, 0.0, 0.0, 0.0, 2, 2, 32, -1, -1, 0.2, 0.8, 0.0, 0.0, 2, 2, 32, -1, -1, 0.3, 0.7, 0.0, 0.0, 2, 1, 2, -1, -1, 0.5, 0.5, 0.0, 0.0, 2, 0, 1, -1, -1, 0.5, 0.5, 0.0, 0.0, 1, 0, -1, -1, -1, 1.0, 0.0, 0.0, 0.0, &#125;; int vertexNum = sizeof (_meshData )/( sizeof ( float )*3); g_mesh = new SkinMesh (vertexNum ); for ( int i =0; i m_vertexs [i ].m_x = _meshData [i *3]; g_mesh -&gt;m_vertexs [i ].m_y = _meshData [i *3+1]; g_mesh -&gt;m_vertexs [i ].m_z = _meshData [i *3+2]; &#125; //set skin info for ( int i =0; i m_vertexs [i ].m_boneNum = _skinInfo [i *9]; for ( int j =0; j &lt;g_mesh -&gt;m_vertexs [i ].m_boneNum ; ++j ) &#123; Bone * pBone = g_boneRoot ; if (_skinInfo [i *9+1+j ]==1) pBone = g_bone1 ; else if (_skinInfo [i *9+1+j ]==2) pBone = g_bone2 ; else if (_skinInfo [i *9+1+j ]==31) pBone = g_bone31 ; else if (_skinInfo [i *9+1+j ]==32) pBone = g_bone32 ; g_mesh -&gt;m_vertexs [i ].SetBoneAndWeight (j , pBone , _skinInfo [i *9+5+j ]); &#125; &#125; //compute bone offset g_boneRoot -&gt;ComputeWorldPos (0, 0, 0); g_boneRoot -&gt;ComputeBoneOffset ();&#125;void deleteMesh ()&#123; delete g_mesh ;&#125;void myInit ()&#123; buildBones (); buildMesh ();&#125;void myQuit ()&#123; deleteBones (); deleteMesh ();&#125;void myReshape ( int width , int height )&#123; GLfloat h = (GLfloat ) height / (GLfloat ) width ; glViewport (0, 0, (GLint ) width , (GLint ) height ); glMatrixMode (GL_PROJECTION ); glLoadIdentity ();// glFrustum(-1.0, 1.0, -h, h, 5.0, 60.0); glFrustum (-1.0, 1.0, -h , h , 1.0, 100.0); glMatrixMode (GL_MODELVIEW ); glLoadIdentity (); glTranslatef (0.0, 0.0, -1.0);&#125;void myDisplay ( void )&#123; glClear (GL_COLOR_BUFFER_BIT ); //draw original mesh g_mesh -&gt;DrawStaticMesh (0,0,0); //move bones animateBones (); //update all bone's pos in bone tree g_boneRoot -&gt;ComputeWorldPos (0, 0, 0); //update vertex pos by bones, using vertex blending g_mesh -&gt;UpdateVertices (); //draw deformed mesh g_mesh -&gt;Draw (); //draw bone g_boneRoot -&gt;Draw (); glFlush (); glutSwapBuffers ();&#125;void myIdle ( void )&#123; myDisplay ();&#125;int main ( int argc , char *argv [])&#123; glutInit (&amp;argc , argv ); glutInitDisplayMode (GLUT_RGB | GLUT_DEPTH | GLUT_DOUBLE ); glutInitWindowPosition (100, 100); glutInitWindowSize (640, 480); glutCreateWindow ( "A simplest skinned mesh DEMO, by happyfirecn@yahoo.com.cn" ); glutDisplayFunc (myDisplay ); glutReshapeFunc (myReshape ); glutIdleFunc (myIdle ); myInit (); glutMainLoop (); myQuit (); return 0;&#125; //]]></content>
  </entry>
  <entry>
    <title><![CDATA[Actor模型原理]]></title>
    <url>%2F2018%2F03%2F23%2Factor%2F</url>
    <content type="text"><![CDATA[1.Actor模型在使用Java进行并发编程时需要特别的关注锁和内存原子性等一系列线程问题，而Actor模型内部的状态由它自己维护即它内部数据只能由它自己修改（通过消息传递来进行状态修改），所以使用Actors模型进行并发编程可以很好避免这些问题，Actor由状态(state),行为(Behavior)和邮箱(mailBox)三部分组成1.状态(state):Actor中的状态指的是Actor对象的变量信息，状态由Actor自己管理，避免了并发环境下的锁和内存原子性等问题2.行为(Behavior):行为指的是Actor中计算逻辑，通过Actor接收到消息来改变Actor的状态3.邮箱(mailBox):邮箱是Actor和Actor之间的通信桥梁，邮箱内部通过FIFO消息队列来存储发送发Actor消息，接收方Actor从邮箱队列中获取消息 Actor的基础就是消息传递 2.使用Actor模型的好处1.事件驱动—Actor之间的通信是异步的，即使Actor在发送消息后也无需阻塞或者等待就能够处理其他事件2.强隔离性—Actor中的方法不能由外部部署直接调用，所有的一切都通过消息传递进行的，从而避免了Actor之间的数据共享，想要观察到另一个Actor的状态变化只能通过消息传递进行询问3.位置透明—无论Actor地址实在本地还是在远程机上对于代码来说都是一样的4.轻量性—Actor是非常轻量的计算单机，单个Actor仅占400多字节，只需少量内存就能达到高并发 3.Actor模型原理以下通过学生于教师之间的邮件通信来理解akka中的Actor模型 学生-教师的消息传递首先只考虑学生单向发送消息给教师（学生—》教师），如下图：图解：1.学生创建一个ActorSystem2.通过ActorSystem创建ActorRef，将QuoteRequest消息发送到ActorRef(教师代理)3.ActorRef(教师代理)消息传到Dispatcher中4.Dispather依次的将消息发送到TeacherActor邮箱中5.Dispather将邮箱推送到一条线程中6.邮箱取出一条消息并委派给TeacherActor的Receiver方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[简单介绍多进程和多线程服务器]]></title>
    <url>%2F2018%2F03%2F22%2Fthread-process%2F</url>
    <content type="text"><![CDATA[首先贴下多进程单线程和单进程多线程的特点：多进程：有独立的地址空间，进程之间不共享内存和变量，但可以通过共享内存实现，每个进程只有一个线程，一般用于单机系统开发。多线程：在同一个进程下所有线程可以共享内存和变量。而共同点是，同开辟的进程数/线程数多余系统cpu核数时，无法继续提供应用的性能。而多线程架构的服务器，只要适当将一些任务分出来用新的进程启动，就可以扩展成分布式架构，使用tcp通信即可。当然多进程也可以这么干，通信方式也是使用tcp。而操作系统对于线程的切换是比进程的切换要快。 下面先介绍下多进程单线程服务器架构，以单机系统为例：下贴架构图：一个游戏服大概就有这几个进程。router:作用如其名，路由。每个功能进程启动时，会先连接router,router会给连上来的进程分配一个唯一标识，所有功能进程都是靠这个router进程通信。login:登录服务器，client登录验证在这个进程进行。login:玩家单人逻辑操作处理进程，login会将登录的玩家平台到这些logic上。global_login:全局操作进程，多人玩法的功能，例如战斗匹配，工会等操作会放在这里进行。log:游戏日志输出进程，所有功能进程的日志输出都发到这个进程，log进程会输出到磁盘文件。db:redis作为内存数据库，Mysql作为数据持久化，其它功能进程取数据都会发送请求到db。back:后台进程，集成了一个http服务器。处理http请求，这里可以集成一些第三方服务功能，如gm指令。 以上每个进程都是单线程，所以无需考虑锁的问题。对于每个进程收发数据： 发数据：直接把{target_id:data}发送到router 收数据：帧驱动，如100ms主动向router询问是否有数据，有则取过来处理。单机系统下，如果采用共享内存方式，通信效率将非常高。所以多进程的服务器架构设计起来还是比较简单的。 在介绍下多线程服务器架构，这里我想介绍actor模型。一个Actor指的是一个最基本的计算单元。它能接收一个消息并且基于其执行计算。这个理念很像面向对象语言，一个对象接受一条消息（方法调用），然后根据接受的消息做事（调用了哪个方法）。Actors一大重要特征在于actors之间相互隔离，它们并不互相共享内存。这点区别于上述的对象。也就是说，一个actor能维持一个私有的状态，并且这个状态不可能被另一个actor所改变。每个Actor都有一个邮箱，用于接受其他actor发送的消息。 这里重点讲一下Actor模型的调度是怎样做的。Actor模型实际上可以有成千上万个，但目前一台通用服务器最多只有24核，当然不可能也开成千上万个线程。 我们可以把Actor简单想象成这样一个类实例： 1234567891011class Actor&#123; public: void process_1(); void process_2(); void fetch_msg(); private: int actor_id; string actor_name; list&lt;msg&gt; msg_queue;&#125; 每个Actor定义了自己实现的功能(process_1,process_2)当msg_queue邮箱有消息到来的时候，就调用fetch_msg取获取这些消息进程处理。这一步就靠调度线程来做了。 Actor模型的调度实现起码要有： 1.一个位于主线程的Actor队列，如global_queue gq,当某个Actor收到消息时，就会被放进这个gp，等待工作线程进行调度。 2.n个工作线程，这个就要根据机器的核数来决定开多少个了，例如只是一台双核的机器，那么开一个就好了，开多了会浪费时间在线程切换上，得不尝试。每个工作线程做的事件很简单，向主线程询问任务，获取任务，处理任务，然后又继续询问，大致如下：12345while(true)&#123; task_list = fetch_task(); process_task(task_list);&#125; 所以一个Actor的创建和调度过程如下：1.在主线程创建并放入管理列表2.其他actor往本actor发送消息，消息进入msg_queue,本actor进入global_queue等待调度。3.有工作线程处理完一堆任务了，向主线程询问任务，主线程把本actor分配给这个工作线程。4.该工作线程取出msg，调用actor相应处理函数处理这个消息。 所以可见，actor数目于工作线程数目没有必然的关系，当然理想状态是，每个actor都有自己的处理线程，这里有消息来到时，就可以马上处理，不用等待。 理论上，actor开的越多，业务逻辑就分的越细，每次处理的时间就越短，只要actor的数目超过线程数，就可以最大限度利用多核的优势，cpu的调度就越充分。所以actor模型设计关键在于如何将业务逻辑平摊到更多的actor上，而不是集中，例如上面提到global_logic是多人玩法的业务逻辑，只要一细分，可以分成帮会actor,组队actor,战斗actor等等，这样三个消息同时就有机会被三个cpu处理，而不是固定只有一个。 Actor可以理解成用户级别的进程，于操作系统级别的进程分离，即使开很多Actor，只要工作线程数目设计合理（&lt;=系统cpu核数),就能保证线程能一直在同一个cpu上进行操作，减少线程切换的消耗，这对于cpu核数小的机器非常游泳，而对于像24核的机器，因为开辟的线程数是配置的，所以也很好规划一台机器能部署多少个服。而多线程如果要对某些功能进程扩展，如增加login,增加Logic,就是要增加一个系统线程，一旦进程超过cpu核，就会有时间浪费在切换线程上了，这是一个缺点。而Actor模型本身是优秀的，但是Actor的调度算法会有很多中实现，而且必然涉及到锁的涉及，这就需要设计者的设计功力了。]]></content>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM的新生代、老年代、MinorGC、MajorGC]]></title>
    <url>%2F2018%2F03%2F21%2FJVM-heap%2F</url>
    <content type="text"><![CDATA[JVM中的堆，一般分为三大部分：新生代、老年代、永久代：一、新生代主要时用来存放新生的对象。一般占据堆的1/3空间。由于频繁创建对象，所以新生代会频繁发MinorGC进行垃圾回收。新生代又分为Eden区、ServivorFrom、ServivorTo三个区。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM初探：内存分配、GC原理与垃圾收集器]]></title>
    <url>%2F2018%2F03%2F21%2FJVM%2F</url>
    <content type="text"><![CDATA[JVM内存的分配与回收大致可分为如下4个步骤：何时分配-》怎样分配-》何时回收-》怎样回收，除了在概念上可简单认为new时分配外，我们着重介绍后面三个步骤 1.怎样分配-》JVM内存分配策略对象内存主要分配在Eden区，如果启用了本地线程分配缓存，则有限在TLAB上分配，少数情况能会直接分配在老年代，或被拆分成标量类型在栈上分配（JIT优化）。分配的规则并不是百分百固定，细节主要取决于垃圾收集器组合，以及VM内存相关的参数。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String-StringBuffer-StringBuilder]]></title>
    <url>%2F2018%2F03%2F21%2FString-StringBuffer-StringBuilder%2F</url>
    <content type="text"><![CDATA[JAVAString 字符串常量StringBuffer 字符串变量（线程安全）StringBuilder 字符串变量（非线程安全）String类型和StringBuffer类型的主要性能区别其实在于String是不可变的对象，因此每次对String类型进行改变的时候其实都等同于生成了一个新的String对象，然后将指针指向新的String对象，所以经常改变内容的字符串最好不要用String，因为每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后，JVM的GC就会开始工作， CString和JAVA中的一样]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unity手游开发-使用Lua来开发大型游戏（下）]]></title>
    <url>%2F2018%2F03%2F19%2FUnity-Lua-2%2F</url>
    <content type="text"><![CDATA[基本原理Hotfix的基本原理依然是基于动态语言的Reload功能，更加准确的说是Function Reload。下图简单描述了整个Hotfix的流程：更加具体地可以描述为：1.程序发现要修复的bug，编写特殊的Hotfix代码进行修复，测试通过后上传svn服务器；2.通过发布指令，将svn上更新后的Hotfix代码同步到服务器上；3.服务器发现Hotfix代码有更新，则将其压缩序列化后通过socket发送给所有在线的客户端，同时带上字符串的MD5值供客户端验证；4.客户端收到Hotfix消息之后，首先反序列化数据得到代码内容，校验MD5值之后，如果和本地已经执行过的Hotfix的MD5值，则执行替换逻辑，并记录当前已经执行过的Hotfix的MD5值，如果相同则不再执行；5.客户端连接服务器的时候会主动请求一次Hotfix。 实现方式(项目通过打一个更新包来实现，如果是表格的话可以走Hotfix)执行Hotfix执行的代码非常简单，基于loadstring函数即可：1234local f = loadstring(GameContent.HotfixData)if f then ClientUtils.trycall(f)end 这里的实现就没有reload那么复杂，但是也是有一定的限制，比如local的函数或者在闭包的函数依然很难做正确的hotfix,需要编写特殊的Hotfix代码。 向lua中注册c函数的过程是通过lua_pushcclosure(luaState, fn, n)函数实现的]]></content>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown]]></title>
    <url>%2F2018%2F03%2F19%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[代码引用 需要引用代码时，如果引用的语句只有一段，不分行，可以用`将语句包起来。 如果引用的语句为多行，可以将```置于这段代码的首行和末行。]]></content>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity-Lua]]></title>
    <url>%2F2018%2F03%2F19%2FUnity-Lua-1%2F</url>
    <content type="text"><![CDATA[逻辑使用脚本来做的好处： 使用脚本语言的动态特性，客户端可以做Hotfix,服务器可以做Refresh，无论在运营还是开发期这一特性都很有用； 脚本语言在虚拟机运行，有效控制崩溃率 上手难度低缺点是运行效率低，但是之前看的LuaJit的效率只是略低于c（有待验证),动态语言容易出一些运行时错误（一般是语法错误），但是调试难度在真机下相对容易一些lua的集成在目前维护的这个项目集成了uLua(感觉算是toLua的前身吧)和sLua(腾讯的SDK集成的).具体性能对比自己就不测试了，（懒）在这里可以看到http://link.zhihu.com/?target=http%3A//qiankanglai.me/2016/07/31/unity-lua/性能差异的可能原因之一个人感觉ToLua在属性操作方面性能较好，而Vectore的向量操作，因为可能会有Lua层的优化，即在Lua层完全实现了对应的操作（vector.bytes),因此需要针对源码进行详细的对比。至于性能差异的原因，我没有从Lua虚拟机的实现部分分析，只是查看两种生成的Warp后的接口进行一个简单的猜想。选取同一个接口进行对比，UnityEngine.Animator的GetFloat接口，ToLua的实现如下：1234567891011121314151617181920212223242526[MonoPInvokeCallbackAttribute(typeof(LuaCSFunction))]static int GetFloat(IntPtr L)&#123; try &#123; int count = LuaDLL.lua_gettop(L); if (count == 2 &amp;&amp; TypeChecker.CheckTypes(L, 1, typeof(UnityEngine.Animator), typeof(int))) &#123; UnityEngine.Animator obj = (UnityEngine.Animator)ToLua.ToObject(L, 1); int arg0 = (int)LuaDLL.lua_tonumber(L, 2); float o = obj.GetFloat(arg0); LuaDLL.lua_pushnumber(L, 0); return 1; &#125; //此处省略另一个重载接口 else &#123; return LuaDLL.luaL_throw(L, "invalid arguments to method: UnityEngine.Animator.GetFloat"); &#125; &#125; catch(Exception e) &#123; return LuaDLL.toluaL_exception(L, e); &#125;&#125; SLua生成的代码如下：12345678910111213141516171819202122[MonoPInvokeCallbackAttribute(typeof(LuaCSFunction))]static public int GetFloat(IntPtr l)&#123; try &#123; int argc = LuaDLL.lua_gettop(l); if(matchType(l, argc, 2, typeof(int))) &#123; UnityEngine.Animator self = (UnityEngine.Animator)checkSelf(l); System.Int32 a1; checkType(l, 2, out a1); var ret = self.GetFloat(a1); pushValue(1, true); pushValue(1, ret); return 2; &#125; catch(Exception e) &#123; return error(1,e); &#125; &#125;&#125; 我们注意到，这一函数只需要一个返回值的，但是SLua往栈里pushValue了两个值，然后返回2。SLua使用一个单独的值来表示函数运行的结果，这对于错误可以进行更好的处理，但是多出的压栈和出栈操作有额外的性能消耗。 导出方式对比ToLua导出的使用的是白名单的方式，在CustomeSetting.cs文件中定义的接口才会导出，也提供了导出引擎所有的接口功能；而SLua是以黑名单的方式进行，默认提供的功能是导出了除了黑名单中的所有模块接口，也是了一个导出最简接口的方式。从使用角度来看，SLua黑名单的方式在开发期比较方便，默认会导出所有接口，因此不需要每次想要增加一个已经存在的类Lua接口都要自己定义然后重新导出，发布的时候也可以使用最简接口。维护起来ToLua因为所有的导出类都是我们自己定义的，因此更加清晰明确。鉴于这部分内容有源码可以进行修改 ，因此不是一个核心需要考虑的内容，两种方式各有利弊。 如何使用Lua语言在进行了初步集成后，怎样让开发人员可以更好地使用Lua语言是接下来面临的问题。ToLua对应有一套之前uLua作者开发的LuaFramework，这一框架集成了脚本打包和二进制脚本读取，UI制作流程等多个功能，但是也如作者自己所有，这一框架最初源自一个示例形式的Demo，因此其中代码有很多部分是和示例写死的绑定的逻辑，比如启动逻辑，Lua二进制脚本的加载需要手动指定等等。相对应的，SLua也有多套已经开源的框架，其中最为完善的KSFramwork，这套框架集成了资源打包，导表，Lua热重载在内的多个功能，而且代码质量初步开起来还不错，因此最后我们决定把KSFramwork中的SLua部分替换成ToLua的部分来结合使用。改造的过程还比较简单，由于该部分使用Lua耦合的只有两块内容，一是UIControler部分，二是LuaBehavior部分，所有的接口都由LuaModule模块提供。因此改造的过程也就比较明确了：1.删除源代码中的SLua部分，接入ToLua的部分；2.使用ToLua重写LuaModule的实现；3.改造LuaUIController，使用新的LuaModule接口实现之前的功能；4.改造LuaBehavior模块；代码删除和LuaModule模块的重新实现都比较简单，着重介绍一下LuaUIController和LuaBehavior模块的改造。 改造初衷之前的KSFramwork还是一个核心逻辑在C#，Lua只承载UI等逻辑的模块，其实目前逻辑也是这样的，但是个人比较同意“轻引擎，重脚本”，引擎可以看作渲染，资源加载，音效等功能的提供者，脚本逻辑负责使用这些功能构建游戏内容。那这样大部分与逻辑相关的控制权就应该从引擎交给脚本来进行。Unity作为一个比较特殊的例子，虽然对于它来说，C#部分已经是脚本了，但是对于希望着重使用Lua脚本的我们来说，因为C#不可更新，因此被视作了引擎部分。最为简单的设计就是当引擎初始化完毕之后，通过一个接口调用把后续的逻辑都交由脚本来控制，大部分与游戏玩法相关的模型加载、声音播放、特效播放、动画等由脚本控制。tick逻辑为了减少调用次数，没帧也由引擎调用注册的一个脚本接口进行统一调用，脚本层自己做分发。 LuaUIController的改造LuaUIController原始的方式是在C#层通过ui模块的名称加载对应的一个lua文件，获取一个lua table 进行缓存，在比如OnInit等需要接口调用的地方查找这个table中对应的函数进行调用。这种方式的界面是由C#层的逻辑来驱动加载和显示的，而且在加载过程要有文件的搜索和检查过程。这样会存在一个问题，就是脚本层的逻辑无法或者很难或者很难去控制界面对象的生命周期。针对资源的生命周期，“谁创建谁管理”的策略不在可以很方便地来明确责任的划分，因此要进行改造。改造的方向很简单，讲界面在家和显示的接口开放到Lua层，然后在创建的时候由lua层传递一个table对象进来，C#中进行缓存，当界面资源异步加载完毕，需要进行接口调用的地方的实现与之前保存一致。这样，界面资源的生命周期全部交由脚本层来管理，在脚本构建一个结构合理功能齐全的UIManager来进行一些功能的封装，就可以满足大部分的需求。 LuaBehavior的改造MonoBehavior是Unity为了方便开发而提供的一个很好的功能，脚本以组件的方式挂接在GameObject身上，就可以在Awake,Start,Update等接口中处理想要的逻辑。为了能够继续使用Unity的这一特性，在Lua层也实现了一个简单的LuaBehavior封装。KSFramwork中的思路非常简单，同样根据名称来把一个LuaBehavior和一个Lua脚本进行绑定，在对应的逻辑中调用与之对应的接口就可以了，比如Awake接口的实现如下：12345678protected virtual void Awake()&#123; if (!string.IsNullOrEmpty(LuaPath)) &#123; Init(); CallLuaFunction("Awake"); &#125;//else Null Lua Path, pass Awake!&#125; CallLuaFunction的实现也很明确，从缓存的lua table中获取名称为Awake的function进行调用。这种方式没有问题，但是当场景中挂在了LuaBehavior(项目中是LuaComponent)的GameObject很多的时候，每一帧都会有非常多次的update(这个函数就不要暴露了),这个调用从C#层传递到Lua层，有很多额外的性能消耗。前文也提到了，比较好的方式是没帧只有一个C#到Lua层的Update方法调用，然后脚本层自己做分发。因此，针对这一需求，我们使用ToLua#自带的LuaLooper来实现的这一功能。LuaLooper(项目是自己包装的一个luatimer)是全局只创建一个的MonoBehaviour,注意这里只创建一个只由逻辑来决定的，而不是一个单例模式。这里针对单例模式适合场合的讨论不再展开，此处由逻辑来保证只有一个Looper存在是一件比较合理的事情，预留了一些扩展的可能。LuaLooper以时间的方式讲三种Update分发出去：Update,LateUpdate,FixedUpdate,它在自己对应的函数中调用luaState的对应函数来将事件告知脚本，脚本中需要的模块向分发模块注册回调来监听事件,就可以做到每帧只有一次Update调用了。具体的代码实现可以去看ToLua#中的LuaLooper.cs的类实现。-注意 这里有一个小心的点是当事件在脚本层分发的时候，要注意执行时序问题的影响，最好能够保证任意的执行顺序都可以不影响游戏逻辑的结果，否则可能会出现很难查的诡异bug。对于Awake,Start等一次性调用的函数，由于不是频繁的逻辑，因此保留了原始的实现方式，这样可以让Lua层对应的代码实现更加简洁。而使用事件注册的方式，让不需要update逻辑的脚本没有任何额外的性能消耗。]]></content>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XCAAFS]]></title>
    <url>%2F2018%2F03%2F18%2FXCAAFS%2F</url>
    <content type="text"><![CDATA[负载均衡服务器，应用在登录模块上，开新服的时候入口流量会增大，一段时间以后流量会递减或者趋于平缓，市面上已经有了成熟的解决方案了。一般最常用，最简单的也是基于DNS的负载均衡系统了]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http]]></title>
    <url>%2F2018%2F03%2F18%2Fhttp%2F</url>
    <content type="text"><![CDATA[什么是http超文本传输协议（HTTP）的设计目的是保证客户机与服务器之间的通信。HTTP的工作方式客户端和服务器之前的请求-应答协议 两种HTTP请求方法：GET和POST GET - 从指定的资源请求数据 POST - 向指定的资源提交要被处理的数据 GET方法请注意，查询字符串（名称/值对）是在GET请求的URL中发送的： /test/deme_from.asp?name1=value1&amp;name2=value2 有关GET请求的其它一些注释： GET请求可被缓存 GET请求保留在浏览器历史纪录中 GET请求可悲收藏为书签]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty]]></title>
    <url>%2F2018%2F03%2F18%2Fopenresty%2F</url>
    <content type="text"><![CDATA[/usr/local/openresty/luajit:luajit环境，luajit类似于java的jit,即即时编译，lua是一种解释语言，通过luajit可以即时编译lua代码到机器代码，得到很好的性能。/usr/local/openresty/lualib:要使用的lua库，里边提供了一些默认的lua库，如redis,json库等，也可以把自己开发的或者第三方放在这；/usr/local/openresty/nginx:安装的nginx /usr/local/openresty/nginx/sbin/nginx -V 查看nginx版本和安装的模块 启动 nginxnginx -p `pwd`/ -c conf/nginx.conf 重启nginx/usr/local/openresty/nginx/sbin/nginx -s reload nginx.pid no filenginx -c /home/www/conf/nginx.conf add_header directive is not allowed here in]]></content>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity打包详细流程]]></title>
    <url>%2F2018%2F03%2F13%2FUnity-PGK%2F</url>
    <content type="text"><![CDATA[打包策略：按照目录划分目录进行分类配置文件如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159&#123; &quot;AssetBundleInfo&quot;: [ &#123; &quot;assetBundleName&quot;: &quot;ui.bytes&quot;, &quot;dirPrefix&quot;: [ &quot;Art/ResExport/GUI/&quot;, &quot;Art/GUI/Atlas/&quot;, &quot;res/GUI/res/&quot;, &quot;res/GUI/&quot; ] &#125;, &#123; &quot;assetBundleName&quot;: &quot;ui_font.bytes&quot;, &quot;dirPrefix&quot;: [ &quot;res/GUI/res/Font/&quot; ] &#125;, &#123; &quot;assetBundleName&quot;: &quot;particles.bytes&quot;, &quot;dirPrefix&quot;: [ &quot;res/Particles/&quot;, &quot;Art/Particles/&quot; ] &#125;, &#123; &quot;assetBundleName&quot;: &quot;gfx.bytes&quot;, &quot;dirPrefix&quot;: [ &quot;res/FX/&quot;, &quot;res/SkillWarning/&quot;, &quot;res/Shader/&quot;, &quot;PluginsScripts/NGUI/Resources/Shaders/&quot;, &quot;Art/Graphics/shader/&quot; ] &#125;, &#123; &quot;assetBundleName&quot;: &quot;misc.bytes&quot;, &quot;dirPrefix&quot;: [ &quot;Art/&quot;, &quot;res/&quot;, &quot;Resources/&quot;, &quot;Plugins/&quot;, &quot;PluginsScripts/&quot;, &quot;Models/&quot; ] &#125;, &#123; &quot;assetBundleName&quot;: .bytes&quot;, &quot;dirPrefix&quot;: [ &quot;Scenes/Assets Skyboxes/&quot; ] &#125;, &#123; &quot;assetBundleName&quot;: &quot;scenes.bytes&quot;, &quot;dirPrefix&quot;: [ &quot;res/Scenes/&quot;, &quot;Scenes/&quot; ] &#125; ], &quot;PackageInfo&quot;: [ &#123; &quot;pkgName&quot;: &quot;cfg&quot;, &quot;dirPrefix&quot;: [ &quot;cfg/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;lang&quot;, &quot;dirPrefix&quot;: [ &quot;Assets/Art/lang&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;code&quot;, &quot;dirPrefix&quot;: [ &quot;cfg/&quot;, &quot;mb/&quot;, &quot;Lua/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;gfx&quot;, &quot;dirPrefix&quot;: [ &quot;FX/&quot;, &quot;MaterialEx/&quot;, &quot;Shader/&quot;, &quot;SkillWarning/&quot;, &quot;Textures/&quot;, &quot;Still/&quot;, &quot;bones/&quot;, &quot;weapons/&quot;, &quot;Equips/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;gui&quot;, &quot;dirPrefix&quot;: [ &quot;GUI/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;particles&quot;, &quot;dirPrefix&quot;: [ &quot;Particles/&quot;, &quot;Assets/Art/Particles/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;scenes&quot;, &quot;dirPrefix&quot;: [ &quot;Scenes/&quot;, &quot;scn/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;sounds&quot;, &quot;dirPrefix&quot;: [ &quot;Sounds/&quot;, &quot;Assets/Art/Sounds/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;animations&quot;, &quot;dirPrefix&quot;: [ &quot;Animations/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;scenes_mesh&quot;, &quot;dirPrefix&quot;: [ &quot;Assets/Art/Scene/_Mesh/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;scenes_assets&quot;, &quot;dirPrefix&quot;: [ &quot;Assets/Scenes/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;models&quot;, &quot;dirPrefix&quot;: [ &quot;Assets/Models/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;misc&quot;, &quot;dirPrefix&quot;: [ &quot;Assets/&quot; ] &#125;, &#123; &quot;pkgName&quot;: &quot;pandora&quot;, &quot;dirPrefix&quot;: [ &quot;pandora/&quot; ] &#125; ]&#125; 不使用Resources的原因是，打包程序的时候会将Resources目录下的全部文件都加密压缩达到包内，这样如果我们想使用assetbundle方式打小包就不行了（比如更新包）。1.多语言文件先导入2.根据配置文件生成包信息，AssetBundleInfo,AssetBundleIndex3.处理Res目录资源4.AssetDatabase.GetDependencies12345678910111213141516171819202122232425262728293031323334353637383940414243string nameParam = new string[1];string[] GetDirectDeps(string uri)&#123; DepInfo depInfo = new DepInfo(); nameParam[0] = uri; var deps = AssetDatabase.GetDependenices(nameParem, true);//查找这个资源引用了哪些资源,cs和js文件不用处理 depInfos[uri] = depInfo;//global return deps;&#125;string[] MakeDepends(string uri)&#123; var deps = GetDirectDeps(uri);&#125;static void addPkgFile(string filePath, bool isCompress, string accessPath, byte fileType, byte loadType)&#123; accessPath = accessPath.ToLower(); PkgInfo.FileInfo fileInfo = NewPkgFileInfo(filePath, isCompress, accessPath, )&#125;public IEnumerator ProcessSounds()&#123; titleText = "处理音频"; yield return null; string soundsDir = Application.dataPath + "/Art/Sounds"; if (System.IO.Exists(soundsDir)) &#123; int rootSize = Application.dataPath.Length - 6;//Assets string[] file = System.IO.Directory.GetFiles(soundsDir, "*.bank", SearchOption.AllDirectories); foreach (var file in files) &#123; string path = file.SubString(rootSize).ToLower().Replace('\\', '/'); addPkgFile(path, false, 0, 0); addFileProcessed.Add(path); &#125; &#125;&#125;public IEnumerator DoProcess()&#123; yield return ProcessRes(resUri); if (!isRuning) yield return; yield return ProcessSounds();//smod,因为unity自带的容易崩溃&#125; 打包常见问题整理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185CommandInvokationFailure: Gradle build failed. C:\Program Files\Unity_2018.3.0f2\Editor\Data\PlaybackEngines\AndroidPlayer/Tools\OpenJDK\Windows\bin\java.exe -classpath &quot;C:\Program Files\Unity_2018.3.0f2\Editor\Data\PlaybackEngines\AndroidPlayer\Tools\gradle\lib\gradle-launcher-4.6.jar&quot; org.gradle.launcher.GradleMain &quot;-Dorg.gradle.jvmargs=-Xmx4096m&quot; &quot;assembleRelease&quot;stderr[FAILURE: Build failed with an exception.* What went wrong:A problem occurred configuring root project &apos;gradleOut&apos;.&gt; Could not resolve all artifacts for configuration &apos;:classpath&apos;. &gt; Could not download bcpkix-jdk15on.jar (org.bouncycastle:bcpkix-jdk15on:1.56) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/bouncycastle/bcpkix-jdk15on/1.56/bcpkix-jdk15on-1.56.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/bouncycastle/bcpkix-jdk15on/1.56/bcpkix-jdk15on-1.56.jar&apos;. &gt; Connection reset &gt; Could not download bcprov-jdk15on.jar (org.bouncycastle:bcprov-jdk15on:1.56) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/bouncycastle/bcprov-jdk15on/1.56/bcprov-jdk15on-1.56.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/bouncycastle/bcprov-jdk15on/1.56/bcprov-jdk15on-1.56.jar&apos;. &gt; Connection reset &gt; Could not download fastutil.jar (it.unimi.dsi:fastutil:7.2.0) &gt; Could not get resource &apos;https://jcenter.bintray.com/it/unimi/dsi/fastutil/7.2.0/fastutil-7.2.0.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/it/unimi/dsi/fastutil/7.2.0/fastutil-7.2.0.jar&apos;. &gt; Connection reset &gt; Could not download jimfs.jar (com.google.jimfs:jimfs:1.1) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/google/jimfs/jimfs/1.1/jimfs-1.1.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/google/jimfs/jimfs/1.1/jimfs-1.1.jar&apos;. &gt; Connection reset &gt; Could not download guava.jar (com.google.guava:guava:23.0) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/google/guava/guava/23.0/guava-23.0.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/google/guava/guava/23.0/guava-23.0.jar&apos;. &gt; Connection reset &gt; Could not download gson.jar (com.google.code.gson:gson:2.8.0) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/google/code/gson/gson/2.8.0/gson-2.8.0.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/google/code/gson/gson/2.8.0/gson-2.8.0.jar&apos;. &gt; Connection reset &gt; Could not download httpclient.jar (org.apache.httpcomponents:httpclient:4.5.2) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar&apos;. &gt; Connection reset &gt; Could not download httpcore.jar (org.apache.httpcomponents:httpcore:4.4.5) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/apache/httpcomponents/httpcore/4.4.5/httpcore-4.4.5.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/apache/httpcomponents/httpcore/4.4.5/httpcore-4.4.5.jar&apos;. &gt; Connection reset &gt; Could not download kotlin-reflect.jar (org.jetbrains.kotlin:kotlin-reflect:1.2.0) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-reflect/1.2.0/kotlin-reflect-1.2.0.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-reflect/1.2.0/kotlin-reflect-1.2.0.jar&apos;. &gt; Connection reset &gt; Could not download antlr4.jar (org.antlr:antlr4:4.5.3) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/antlr/antlr4/4.5.3/antlr4-4.5.3.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/antlr/antlr4/4.5.3/antlr4-4.5.3.jar&apos;. &gt; Connection reset &gt; Could not download juniversalchardet.jar (com.googlecode.juniversalchardet:juniversalchardet:1.0.3) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/googlecode/juniversalchardet/juniversalchardet/1.0.3/juniversalchardet-1.0.3.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/googlecode/juniversalchardet/juniversalchardet/1.0.3/juniversalchardet-1.0.3.jar&apos;. &gt; Connection reset &gt; Could not download kotlin-stdlib.jar (org.jetbrains.kotlin:kotlin-stdlib:1.2.20) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-stdlib/1.2.20/kotlin-stdlib-1.2.20.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-stdlib/1.2.20/kotlin-stdlib-1.2.20.jar&apos;. &gt; Connection reset &gt; Could not download proguard-base.jar (net.sf.proguard:proguard-base:6.0.3) &gt; Could not get resource &apos;https://jcenter.bintray.com/net/sf/proguard/proguard-base/6.0.3/proguard-base-6.0.3.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/net/sf/proguard/proguard-base/6.0.3/proguard-base-6.0.3.jar&apos;. &gt; Connection reset &gt; Could not download auto-value.jar (com.google.auto.value:auto-value:1.5.2) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/google/auto/value/auto-value/1.5.2/auto-value-1.5.2.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/google/auto/value/auto-value/1.5.2/auto-value-1.5.2.jar&apos;. &gt; Connection reset &gt; Could not download protobuf-java.jar (com.google.protobuf:protobuf-java:3.4.0) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/google/protobuf/protobuf-java/3.4.0/protobuf-java-3.4.0.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/google/protobuf/protobuf-java/3.4.0/protobuf-java-3.4.0.jar&apos;. &gt; Connection reset &gt; Could not download jdom2.jar (org.jdom:jdom2:2.0.6) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/jdom/jdom2/2.0.6/jdom2-2.0.6.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/jdom/jdom2/2.0.6/jdom2-2.0.6.jar&apos;. &gt; Connection reset &gt; Could not download commons-compress.jar (org.apache.commons:commons-compress:1.12) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/apache/commons/commons-compress/1.12/commons-compress-1.12.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/apache/commons/commons-compress/1.12/commons-compress-1.12.jar&apos;. &gt; Connection reset &gt; Could not download commons-codec.jar (commons-codec:commons-codec:1.9) &gt; Could not get resource &apos;https://jcenter.bintray.com/commons-codec/commons-codec/1.9/commons-codec-1.9.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/commons-codec/commons-codec/1.9/commons-codec-1.9.jar&apos;. &gt; Connection reset &gt; Could not download jaxb-runtime.jar (org.glassfish.jaxb:jaxb-runtime:2.2.11) &gt; Could not get resource &apos;https://jcenter.bintray.com/org/glassfish/jaxb/jaxb-runtime/2.2.11/jaxb-runtime-2.2.11.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/org/glassfish/jaxb/jaxb-runtime/2.2.11/jaxb-runtime-2.2.11.jar&apos;. &gt; Remote host closed connection during handshake &gt; Could not download FastInfoset.jar (com.sun.xml.fastinfoset:FastInfoset:1.2.13) &gt; Could not get resource &apos;https://jcenter.bintray.com/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar&apos;. &gt; Could not GET &apos;https://jcenter.bintray.com/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar&apos;. &gt; Connection reset* Try:Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.* Get more help at https://help.gradle.orgBUILD FAILED in 5m 15s]stdout[Download https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/3.2.0/gradle-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/lint/lint-gradle-api/26.2.0/lint-gradle-api-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/androidx/databinding/databinding-compiler-common/3.2.0/databinding-compiler-common-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/transform-api/2.0.0-deprecated-use-gradle-api/transform-api-2.0.0-deprecated-use-gradle-api.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/builder/3.2.0/builder-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle-api/3.2.0/gradle-api-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/analytics-library/shared/26.2.0/shared-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/bundletool/0.5.0/bundletool-0.5.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/jetifier/jetifier-core/1.0.0-alpha10/jetifier-core-1.0.0-alpha10.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/jetifier/jetifier-processor/1.0.0-alpha10/jetifier-processor-1.0.0-alpha10.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/analytics-library/crash/26.2.0/crash-26.2.0.pomDownload https://jcenter.bintray.com/org/ow2/asm/asm-analysis/6.0/asm-analysis-6.0.pomDownload https://jcenter.bintray.com/org/ow2/asm/asm/6.0/asm-6.0.pomDownload https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-stdlib-jre8/1.2.0/kotlin-stdlib-jre8-1.2.0.pomDownload https://jcenter.bintray.com/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.pomDownload https://jcenter.bintray.com/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.pomDownload https://jcenter.bintray.com/net/sf/proguard/proguard-gradle/6.0.3/proguard-gradle-6.0.3.pomDownload https://jcenter.bintray.com/org/ow2/asm/asm-util/6.0/asm-util-6.0.pomDownload https://jcenter.bintray.com/org/ow2/asm/asm-parent/6.0/asm-parent-6.0.pomDownload https://jcenter.bintray.com/net/sf/proguard/proguard-parent/6.0.3/proguard-parent-6.0.3.pomDownload https://jcenter.bintray.com/org/ow2/ow2/1.3/ow2-1.3.pomDownload https://jcenter.bintray.com/org/sonatype/oss/oss-parent/7/oss-parent-7.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/sdk-common/26.2.0/sdk-common-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/ddms/ddmlib/26.2.0/ddmlib-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/common/26.2.0/common-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/analytics-library/tracker/26.2.0/tracker-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/analytics-library/protos/26.2.0/protos-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/manifest-merger/26.2.0/manifest-merger-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/sdklib/26.2.0/sdklib-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/builder-model/3.2.0/builder-model-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/apkzlib/3.2.0/apkzlib-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/apksig/3.2.0/apksig-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/builder-test-api/3.2.0/builder-test-api-3.2.0.pomDownload https://jcenter.bintray.com/org/bouncycastle/bcpkix-jdk15on/1.56/bcpkix-jdk15on-1.56.pomDownload https://jcenter.bintray.com/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.pomDownload https://jcenter.bintray.com/it/unimi/dsi/fastutil/7.2.0/fastutil-7.2.0.pomDownload https://jcenter.bintray.com/org/bouncycastle/bcprov-jdk15on/1.56/bcprov-jdk15on-1.56.pomDownload https://jcenter.bintray.com/com/googlecode/json-simple/json-simple/1.1/json-simple-1.1.pomDownload https://jcenter.bintray.com/com/squareup/javawriter/2.5.0/javawriter-2.5.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/annotations/26.2.0/annotations-26.2.0.pomDownload https://jcenter.bintray.com/com/google/guava/guava/23.0/guava-23.0.pomDownload https://jcenter.bintray.com/com/google/code/gson/gson/2.8.0/gson-2.8.0.pomDownload https://jcenter.bintray.com/com/google/code/gson/gson-parent/2.8.0/gson-parent-2.8.0.pomDownload https://jcenter.bintray.com/com/google/guava/guava-parent/23.0/guava-parent-23.0.pomDownload https://jcenter.bintray.com/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.pomDownload https://jcenter.bintray.com/org/apache/httpcomponents/httpcore/4.4.5/httpcore-4.4.5.pomDownload https://jcenter.bintray.com/org/apache/httpcomponents/httpmime/4.5.2/httpmime-4.5.2.pomDownload https://jcenter.bintray.com/org/apache/httpcomponents/httpcomponents-client/4.5.2/httpcomponents-client-4.5.2.pomDownload https://jcenter.bintray.com/org/apache/httpcomponents/httpcomponents-core/4.4.5/httpcomponents-core-4.4.5.pomDownload https://jcenter.bintray.com/org/apache/httpcomponents/project/7/project-7.pomDownload https://jcenter.bintray.com/org/apache/apache/13/apache-13.pomDownload https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-reflect/1.2.0/kotlin-reflect-1.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/databinding/baseLibrary/3.2.0/baseLibrary-3.2.0.pomDownload https://dl.google.com/dl/android/maven2/androidx/databinding/databinding-common/3.2.0/databinding-common-3.2.0.pomDownload https://jcenter.bintray.com/commons-io/commons-io/2.4/commons-io-2.4.pomDownload https://jcenter.bintray.com/com/squareup/javapoet/1.8.0/javapoet-1.8.0.pomDownload https://jcenter.bintray.com/org/antlr/antlr4/4.5.3/antlr4-4.5.3.pomDownload https://jcenter.bintray.com/com/googlecode/juniversalchardet/juniversalchardet/1.0.3/juniversalchardet-1.0.3.pomDownload https://jcenter.bintray.com/org/apache/commons/commons-parent/25/commons-parent-25.pomDownload https://jcenter.bintray.com/org/antlr/antlr4-master/4.5.3/antlr4-master-4.5.3.pomDownload https://jcenter.bintray.com/org/sonatype/oss/oss-parent/9/oss-parent-9.pomDownload https://jcenter.bintray.com/org/apache/apache/9/apache-9.pomDownload https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-stdlib-jre7/1.2.0/kotlin-stdlib-jre7-1.2.0.pomDownload https://jcenter.bintray.com/org/jetbrains/kotlin/kotlin-stdlib/1.2.0/kotlin-stdlib-1.2.0.pomDownload https://jcenter.bintray.com/net/sf/proguard/proguard-base/6.0.3/proguard-base-6.0.3.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/build/aapt2-proto/0.3.1/aapt2-proto-0.3.1.pomDownload https://jcenter.bintray.com/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.pomDownload https://jcenter.bintray.com/com/google/auto/value/auto-value/1.5.2/auto-value-1.5.2.pomDownload https://jcenter.bintray.com/com/google/protobuf/protobuf-java/3.4.0/protobuf-java-3.4.0.pomDownload https://jcenter.bintray.com/com/google/protobuf/protobuf-java-util/3.4.0/protobuf-java-util-3.4.0.pomDownload https://jcenter.bintray.com/com/google/auto/auto-parent/3/auto-parent-3.pomDownload https://jcenter.bintray.com/com/google/protobuf/protobuf-parent/3.4.0/protobuf-parent-3.4.0.pomDownload https://jcenter.bintray.com/com/google/errorprone/error_prone_parent/2.2.0/error_prone_parent-2.2.0.pomDownload https://jcenter.bintray.com/com/google/google/1/google-1.pomDownload https://jcenter.bintray.com/org/jdom/jdom2/2.0.6/jdom2-2.0.6.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/dvlib/26.2.0/dvlib-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/layoutlib/layoutlib-api/26.2.0/layoutlib-api-26.2.0.pomDownload https://dl.google.com/dl/android/maven2/com/android/tools/repository/26.2.0/repository-26.2.0.pomDownload https://jcenter.bintray.com/org/apache/commons/commons-compress/1.12/commons-compress-1.12.pomDownload https://jcenter.bintray.com/org/apache/commons/commons-parent/39/commons-parent-39.pomDownload https://jcenter.bintray.com/org/apache/apache/16/apache-16.pomDownload https://jcenter.bintray.com/javax/inject/javax.inject/1/javax.inject-1.pomDownload https://jcenter.bintray.com/net/sf/kxml/kxml2/2.3.0/kxml2-2.3.0.pomDownload https://jcenter.bintray.com/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.pomDownload https://jcenter.bintray.com/commons-logging/commons-logging/1.2/commons-logging-1.2.pomDownload https://jcenter.bintray.com/commons-codec/co&lt;message truncated&gt;]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mono-1]]></title>
    <url>%2F2018%2F03%2F13%2FMono-1%2F</url>
    <content type="text"><![CDATA[Mono主要包含了C#的编译器，CLI(Common Language Infrastructure)实现和一系列相关的开发工具。 源码结构msc: msc: Mono实现的基于Ecma标准的C#编译器。 class:CLI的C#的实现。类似于Android中的Java蹭，应用程序看到的是这一层提供的接口。这一层是平台无关的。 ilasm:反汇编器，将Native code反汇编成bytecode。mono: mini:JIT编译器，将bytecode编译成native code。 metadata:Mono的runtime,CLI的Native级的下实现。 io-layer:与操作系统的接口实现，像socket,thread,mutex这些。liggc:GC实现的一部分。 Mono主要工作框架12345678910111213141516171819202122232425262728293031mini/main.c:main() mono_main_with_options() mono_mian() mini_ini() mono_assembly_open() main_thread_handler()//assembly(也就是bytecode)的编译执行 mini_cleanup()main_thread_handler() mono_jit_exec() mono_assembly_get_image()//得到image信息，如&quot;test.ext&quot; mono_image_get_entry_point()//得到类，方法信息 mono_runtime_run_main(method,argc,argv,NULL) mono_thread_set_main(mono_thread_current());//把当前线程设为主线程 mono_assembly_set_main() mono_runtime_exec_main() //编译及调用目标方法mono_runtime_exec_main() mono_runtime_invoke(method, NULL, pa, exc)//要调用的方法，如&quot;ClassName::Main()&quot; default_mono_runtime_invoke()//实际上是调用了mono_jit_runtime_invoke() info-&gt;compiled_method = mono_jit_compile_method_with_opt(method)//编译目标函数 info-&gt;runtime_invoke = mono_jit_compile_method()//编译目标函数的runtime wrapper mono_jit_compile_method_with_opt(method,default_opt,&amp;ex) runtime_invoke=info-&gt;runtime_invoke runtime_invoke(obj,pararms,exc,info-&gt;compiled_method)//调用wrapper,wrapper会调用目标方法mono_jit_compile_method_with_opt() mono_jit_compile_method_inner() mini_method_compile(method, opt, target_domain, TRUE, FALSE, 0)//通过JIT编译给定方法 mono_runtime_class_init_full()//初始化方法所在对象 method=mono_class_get_cctor()//得到类的构造函数 if(do_initialization)//对象需要初始化 mono_runtime_invoke()//调用相应构造函数来构造对象，如&quot;System.console:.cctor()&quot; mono_jit_runtime_invoke() 垃圾回收垃圾回收(GC)是CLI中很重要的部分， 线程池应用程序或者Mono runtime中的一些异步恩物可以交由单独线程完成。Mono中提供了两个线程池:async_tp和async_io_tp。往线程池加线程函数为threadpool_append_jobs()，当第一次试图往里边加线程时，会进行初始化，起一个”Monitor”线程(该线程执行monotor_thread())。现在假设 Mono内存内存占用： 库代码：Unity库、第三方库 Native堆：资源、Unity逻辑、第三方逻辑 Mono堆：C#代码 Unity游戏逻辑代码所使用的语言为C#，我们知道C#代码所占用的内存又称为mono内存，由于Unity它是通过mono来跨平台解析并运行C#代码的，它在Android系统上面，因此游戏的lib目录下存在的libmono.so文件，就是mono在Android系统上的实现。 C#的代码是通过mono来解析执行的，所需要的内存字然也是由mono来进行分配管理，下面来介绍一个mono的内存管理策略以及内存泄漏分析。 Mono内存管理的基本策略Mono通过垃圾回收机制(GarbageCollect，简称GC)堆内存进行管理。Mono内存分为两部分，已用内存(used)和堆内存(heap)，已用内存它指的是mono实际需要使用的内存，堆内存指的是mono向操作系统申请的内存，两者的差值就是mono的空闲内存。 当mono需要分配内存时，首先是会查看空闲内存是否足够，若足够的话，则是直接在空闲内存中分配，否则mono会进行一次GC以释放更多的内存，如果GC之后仍然没有足够的空闲内存，则mono会向操作系统申请内存，并扩充堆内存。 C/C++ Mono运行时 托管代码(CIL) 将Mono运行时潜入应用，可以分为三个步骤： 编译C++程序和链接]]></content>
      <tags>
        <tag>Mono</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试经历]]></title>
    <url>%2F2018%2F03%2F13%2Finterview-1%2F</url>
    <content type="text"><![CDATA[程序的优化处理，这个是面试考察的重点，内存的管理也是Unity开发的重中之重。内存管理无非就是对内存的使用，针对UI的内存管理使用的图集方式，Unity自身的图集功能浪费内存，比如2048 * 2048的图集大小，它占的内存是4M，也就是说不管图集是否填满，它都需要在内存中开辟4M的空间，但是如果使用Texture Packer工具就可以节省没有填满的空间，针对大量UI的加载可以采用分类打包图集的方法处理。当然内存池的使用也是可以应用到UI的管理，另外就是3D场景资源的管理，需要场景图片有自己的图库，这样图片可以重复利用，另外模型的面熟，骨骼数量，材质数量都是需要去关注。 内存优化还需要涉及到图片的格式，不带Alpha通道的图片采用jpg格式，带有Alpha通过的采用png格式，这是一种处理方式，另外一种处理方式就是将Alpha通道单独拿出来，所有的图片都是jpg格式，然后用带有Alpha通道的图片跟jpg格式文件进行结合使用。 在结构涉及方面，就要注意了，代码的编写，比如常用的设计模式，工厂模式，单例模式，MVC模式，FSM模式，观察者模式等，这些模式作为开发者必须要掌握的。 接下来就是Shader的编写了，可以使用Shader Forge编辑器，对于一些材质渲染非常好用，这个可以作为读者学习Shader的工具。 九、另外对于C#中定义的String，StringBuilder或者List,ArrayList等它们之间的区分要搞清楚。 热更新技术的实现，市面上应用比较广的ulua作为脚本语言架构设计。 作为客户端开发者也需要了解网络方面的知识，比如tcp,udp,http这些协议的处理方式。 场景、导航、寻路 作为渲染场景的后处理方式，比如Bloom,Blur,HDR,SSAO,PSSM等等。 C#中的事件监听，委托的使用也要熟练掌握。 协程与多线程的区别。 文本文件的加载，比如json,xml,csv,二进制等等。 GC是Mono运行时的机智，而非Unity3D引擎的机制，所以GC也主要是针对Mono对象来说的。 1String s = new String("lyf"); 在运行时涉及了几个String Object两个，一个是字符串字面量”lyf”所对应的，驻留(intern)在一个全局共享的字符串常量池中的实例，i另一个是通过new String(String)创建并初始化的、内容于”lyf”相同的实例 OpenGL中要用到哪几种buffer帧缓冲(Frame Buffer)颜色缓冲(Color Buffer)模版缓冲(Stencil Buffer)顶点缓冲(Vertice Buffer)深度缓冲(Depth Buffer) 冰川网络1.啥子是泛型？给你一个CBase基类，写一个继承CBase的泛型。百度答：所谓泛型，即通过参数化类型来实现在同一份代码操作多种数据类型。我答：类的数据成员不固定，成员函数的返回值和传参类型不固定的，这样的方式叫做泛型。本想说这样的类叫做泛型类，但是人家问的是泛型，只能说这样的方式了。 我不知道写一个继承CBase的泛型考点是啥子，然后我就开始瞎写12345public class CDrive:public CBase // 为毛还要加public，难道还有公有继承，保护继承，私有继承？？？&#123; public void Do&lt;T&gt;(T t) // 这他妈写的什么玩意。 &#123;&#125;&#125; 3.啥子是反射？写一段加载程序集，然后获取类型Type，然后通过方法名调用网上答案：123456789101112131415161718192021222324252627282930313233343536373839404142434445using System;using System.Collections;using System.Collections.Generic;using System.Reflection;using UnityEngine;public class InvokeReflection : MonoBehaviour&#123; void Start() &#123; Learn00(); &#125; public void Learn00() &#123; /* * System.Reflection.Assembly类有两个静态方法：Assembly.Load(string assemblyname)和Assembly.LoadFrom(string filename) 。 * 通常用这两个方法把程序集加载到应用程序域中。 如果你希望加载的程序集超出了CLR的预定探查范围，你可以用Assembly.LoadFrom直接从一个文件位置加载程序集。 * Assembly.LoadFrom()和Assembly.LoadFile()，两者的主要区别有两点： * 一：Assembly.LoadFile()只载入指定的dll文件，而不会自动加载相关的dll文件。如果下文例子使用Assembly.LoadFile()加载SayHello.dll，那么程序就只会加载 * SayHello.dll而不会去加载SayHello.dll引用的BaseClass.dll文件。 * 二：Assembly.LoadFrom()载入一个Assembly时，会先检查前面是否已经载入过相同名字的Assembly；Assembly.LoadFile()则不会做类似的检查。 */ //C:\Users\Administrator\Desktop\New Unity Project\Assets\DLL Assembly assemly2 = Assembly.LoadFrom(@"C:\Users\Administrator\Desktop\New Unity Project\Assets\Scripts\TestReflection.dll"); Assembly assemly1 = Assembly.LoadFile(@"C:\Users\Administrator\Desktop\New Unity Project\Assets\Scripts\TestReflection.dll"); Assembly assemly = Assembly.Load("TestReflection");//1填加DLL Type testType = assemly.GetType("HaiLan.TestReflection.TestReflectionDLL");//2获取对应的类信息，需要填加对应的命名空间 object oTestReflectionDLL = Activator.CreateInstance(testType);//3 创建对象 IReflectionDLL iTestReflectionDLL = oTestReflectionDLL as IReflectionDLL;//4 类型转换 iTestReflectionDLL.TestShow1();//5 方法调用 foreach (var item in assemly.GetModules()) &#123; Debug.Log(item.Name);//打印结果 TestReflection.dll &#125; foreach (var type in assemly.GetTypes()) &#123; Debug.Log(type.Name); foreach (var item in type.GetMethods()) &#123; Debug.Log(item.Name); &#125; &#125; &#125;&#125; 4.avatar如何换装？5.啥子是Prefab，如何获取一个Prefab实例化的GameObject的类型？PrefabInstance和PrefabModelInstance有啥子区别（我都不知道他在问啥子）6.获取一个Render的材质，然后设置流光shader的uniform/7.地震了，狗跑了，房屋塌了，人慌了，这是哪个设计模式？写出伪代码或者画出流程图；要求可扩展8.给你一个新项目，内存贼高，FPS贼低，咋优化，是Xlua和C#写的。 AssetBundle的打包和加载 如何判断线段和多边形是否相交？ 深圳易凡互动 NGUI的uv和顶点是怎么生成的？ 客户端网络是否有用多线程？为什么要用？ TCP IPV6是怎么实现的？ Unity5.6和Unity2018的光照图有什么区别，流程是怎样的？ 深圳奇妙能力 TCP粘包可以描述一下吗？ Shader Bloom泛光是怎么实现的？ B树，B+树是啥子？ 从一堆无序的数字中找到不重复的数字，重复的数字是都是双数个。 牛蛙互动 点和多边形相交（曲线先交）？ 输出下列的结果？ 123456789101112public class Program&#123; readonly int b = a + 10; readonly int a = 10; static int d = c + 10; static int c = 10; static void Main(string[] args) &#123; Program p = new Program(); Console.WriteLine("a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;, d = &#123;3&#125;", p.a, p.b, c, d); &#125;&#125; 设计一种存储结构实现字典查找。 600个一M的纹理，给一个UI使用，每次只会加载一个，是打成一个AB包好，还是多个好？ IGG TCP粘包和三次握手的联系? 动静分离？ Overdraw的优化？ 半透明和不透明物体的渲染流程？ 珠海西山居 工作中遇到过什么困难，如何解决，获得什么成就？ Array和List的区别？ 闭包是什么？ Lua Table如何实现的，Hash是什么，如何解决Hash冲突？ new Struct存放在哪里？堆和栈的区别？ 什么是元表？有什么应用？ 堆和栈在C++中的运用以及实现方式以及优缺点？ UI的overdraw如何解决，异步加载造成数据不同步如何解决？ 剧情编辑器如何不根据地形制作剧情？ 协程的原理？ 乐易网络 NGUI如何优化？ NGUI是如何绘制的？ UIWidget如何提交渲染的？ 一个已经排好序的链表构成一个数组，如何合成一个新的链表？（机试题） 四维时代 进程间是如何交互的？各自有啥好处还坏处？ 漫反射原理？ lua的加载流程是怎样的？ TCP/UDP/HTTP运用场景，优缺点？ 线程和协程的区别？ 乐逗 TTF字体 传输层解释一下为什么UDP在手机上要优于TCP Lua的Hash是如何实现的 红黑树的时间复杂度 渲染流程管线，相机抖动是如何出现的 new free malloc delete 区别在哪里？ 广州百田 介绍过往工作、项目经历 unity的基本框架有哪些？请描述或者简单画一画项目核心的架构分层图，以及核心模块间的交互时序（Unity框架范围问题比较泛，最好能结合业务说下某个业务的框架），如果没用过unity，那就画一下目前项目的业务框架。 是否做过发布打包相关的工作？用unity是怎么管理和加载资源的？如何热更新资源，对热更资源和放置路径有什么要求？（可以说下热更新分哪些内容，以及对AssetBundle的理解） 是否完成过大型模块，如战斗，场景，副本等；（说设计思路） 是否做过游戏相关优化，如GPU，CPU，Shader等；（优化工作的具体方面：1.资源包大小的优化，2.内存占用，内存分配和碎片的优化，3.cpu热点和毛刺优化，4.gpu性能开销优化） 同步、异步相关问题；（执行时序的概念，资源加载，网络通信，逻辑调用的各种时序流程） AI框架有哪些；（这个问题，成熟的AI解决方案就是行为树，面试官会问，对行为树的了解情况，是怎么组合完成复杂AI的，这个是加分题，大部分面试人其实说的不太透） 底层网络用哪些协议（补充：tcp，udp（以及可靠版的udp）的区别，分别适用于哪些业务场景） 用过哪些开源库；（单纯考察你对业内相关开源库的敏感度，知识广度） 了解哪些比较好的AI插件； NGUI相关问题（补充问题：NGUI绘制开销如何优化，减少drawcall需要在制作UI和图集的时候注意什么） 怎么做内存、显存优化； 图片的处理格式（补充：怎么选择图片的格式，安卓和IOS图片压缩分别是什么格式，有什么要求，不同业务场景下图片尺寸位数，mipmap又分别有什么要求和区别） 服务器的战斗同步方案，给出一个优质的方案；（你需要针对不通的游戏类型和玩法做出不同的针对性优化，优化策略和网络同步方案都不同，典型代表2类，传统CS同步和帧同步） 渲染管线流程是由哪些部分组成，分别有什么作用，能讲透彻是加分题； vertexshader和pixel shader作用分别是什么，如何协作的； 后处理是什么？你所知道的后处理效果有哪些，大概说说这些后处理实现的原理 延迟渲染是什么？ 延迟渲染和延迟光照的区别？ shadow map的原理 简单描述1，2个你认为最具有挑战性的功能，你是怎么思考，设计，优化的，是否还有不足，还能否继续改进。 结构体和类的区别 ArrayList和List的区别 如果想将一个class作为字典表的Key需要实现哪些函数 字典表的赋值与key的遍历需要注意的地方。 interface与抽象类的区别 Unity monobehaviour的生命周期中OnEnable() Awake() Start() Update()的顺序，以及哪些会重复调用 MipMap是什么，以及它的作用 Renderer是什么，MeshRenderer与SkinnedMeshRenderer的区别 AplhaBlend与AlphaTest的区别 Unity自带的Diffuse着色器，里面的灯光运算是顶点灯光还是像素灯光，这两者有什么区别 在一个固定视角的场景中有一个固定方向的方向光，怎样给渲染物体时做优化 介绍项目客户端资源分包策略 介绍客户端代码热更新的实现方式 介绍ZTEST ZWRITE的作用 渲染实体对象和半透明对象，有什么优化手段 AlphaTest为什么在部分移动设备存在性能问题，如何规避 介绍行为树的各类节点，各类节点返回值对于父节点的影响。 如何实现镜面效果 是否使用过NGUI，NGUI如何管理Widget和组织drawcall 后处理中，如何根据深度缓存还原出世界坐标？ 简述Shadow Map的原理，Shadow bias的作用是什么？ 热更新断点续传？ 图形相关面试题 软蒙皮和硬蒙皮的区别，硬蒙皮的限制 阴影的实现方式有哪些，优缺点各是什么，方向光，点光源，聚光灯的阴影实现又有什么区别 自阴影如何实现 延迟渲染的原理 HDR，bloom，径向模糊这几个后处理的实现原理 Unity里Shader怎么做LOD OpenGL ES3.0相比2.0增加了哪些特性 终面技巧技术终面 回顾自己的简历，对简历上所有提到的技术要点一定要非常熟悉，因为面试官会针对简历上的技术问题进行扩展； 重点准备项目技术框架，包括如何搭建，技术选型，为何选用这个框架，优劣势，项目开发过程中，上线过程中，维护过程中所出现的问题，针对不通的问题有哪些解决方案，为何选用这种解决方案，优劣势对比等； 重点阐述自己在项目开发中承担的角色，对项目开发的共享，自己在工作中解决的问题； 时刻显示出自己对工作，对技术的热情，对新技术的关注（特别关注近期新技术，新闻等） 可以重点阐述自己工作之余喜爱研究的底层技术 何回答对待加班的看法：强调自己是效率性员工，自己开发所用时间段，bug少（此处可举例说明），但项目紧急会资源加班，和团队一起完成紧急任务。 态度面带微笑，不卑不亢，无论是待会HR还是技术面试都给予足够尊重，当不懂技术的HR问到技术问题时，一定要当作对方是懂技术的人员去认真回答这个问题。越是简单的问题，越考察基础，遇到简单问题要认真回答。 离职意愿 家里和自己更喜欢深圳这个城市，也是家人强烈要求到深圳长期发展，广州深圳的游戏环境也更好 从个人职业发展上来说，很向往XXX这样的平台，自己也私下了解了一下相关的信息，觉得XXX将来会发展的很好，希望能过来学习更多的东西； 本身XXX是老牌的研发公司，研发实力很强，但是就现阶段来说，自己上升及发展到达了一个瓶颈期，期望出来寻求给多的技术。 9130客户端 Lua的Hash是怎么实现的？ Hash是怎么实现的？ 介绍一下项目中导航？ 介绍一下Mono Google的Probuffer介绍 Lua的module是如何实现的？ C++和Lua是如何交互的？ 服务器 描述服务器架构？ 全球服中如何管理玩家连接，当有一个逻辑服宕机之后如何处理？ 对称加密和非对称加密？ TCP/IP的滑动窗口 搜狐二面 针对项目情况问一些技术问题吧，不过问了好几次有遇到什么技术问题或者技术难点之类的。 问了一下AssetBundle管理 还有资源管理 还有问了一下内存占用，面数，drawcall占用，drawcall如何合理分配。模型划分。15.2K的三角形数，14.6k的顶点数，Batches：83，Draw Calls：85 好游科技 角色遮挡显示 渲染管线 Unity是左手坐标系还是右手坐标系 屏幕坐标如何转换到世界坐标 1Camera.main.ScreenToWorldPoint(new vector3(x,y,0)) 播放动作到一定时间的时候如何播放粒子 如何将3DMAX的模型导入UNITY中，如何播放3DMAX动作文件 2D场景，3D人物如何实现 如何实现热更新 如何读取StreamingAsset下面的资源 GameObject.Find和transform.Find的区别第一个返回GameObject类型并且未激活的对象不会被查找到，第二个返回Transform类型。 结构体和Class的区别 Foreach遍历类里面所有的成员 什么是协程，为什么协程可以分布执行 类内初始化变量和构造函数初始化变量的区别 网易TA 判断点在多边形内部 不用分支语句推导三角波函数图像的函数 GPU instance中，渲染大量草用什么方式存储草的颜色位置比较好 双线性过滤 4倍各向异性过滤 邻近点过滤和三次插值，双三次插值，线性插值优化过后的采样次数 给你场景物体的顺序和混合因子让你计算最后的颜色的rgba rgb转hsv的公式 美术给模型做细分和GPU曲面细分的适用场合和优缺点 正交投影下计算良好效果边缘光的方法 描述一下沙漠的地貌特征和形成原因 色相差的表现和实现方法]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Real Time Rendering 3rd 第二部分]]></title>
    <url>%2F2018%2F03%2F13%2FReal-Time-Rendering-3rd-2%2F</url>
    <content type="text"><![CDATA[图形渲染与视觉外观渲染与视觉物理现象]]></content>
      <tags>
        <tag>Real Time Rendering 3rd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能优化，永无止境---CPU篇]]></title>
    <url>%2F2018%2F03%2F05%2Foptimzation-cpu%2F</url>
    <content type="text"><![CDATA[性能优化是游戏项目开发工程中一个永恒的话题。玩家的需求和项目的要求永远都在不停增长，同屏人数、屏幕特效和场景复杂度永远在向着”榨干“硬件的趋势毕竟。所以，无论硬件设备发展到何种成都，无论研发团队有多么丰富的经验积累，性能优化永远是一个非常棘手而又无法绕开的问题。 就当前游戏而言，性能优化主要是围着CPU、GPU和内存三大方面进行。下面，我们就这三方面说说当前移动游戏项目中存在的普遍问题的相应的解决方案。 CPU方面就目前的Unity移动游戏而言，CPU方面的性能开销主要可归结为两大类：引擎模块性能开销和自身代码性能开销。其中，引擎模块中又可细致划分为渲染模块、动画模块、物理模块、UI模块、粒子系统、加载模块和GC调用等等。正因如此，我们在UWA测评报告中，就这些模块进行详细的性能分析，以方便大家快速定位项目的性能瓶颈，同时，根据我们的分析和建议对问题进行迅速排查和解决。通过大量的性能测评数据，我们发现渲染模块、UI模块和加载模块，往往占据了游戏CPU性能开销的Top3。 一、渲染模块渲染模块可以说是任何游戏中最为消耗CPU性能的引擎模块，因为几乎所有的游戏都离不开场景、物体和特效的渲染。对于渲染模块的优化，主要从以下两个方面入手： （1）降低Draw CallDraw Call是渲染模块优化方面的重中之重，一般来说，Draw Call越高，则渲染模块的CPU开销越大。究其原因，要从底层Driver和GPU的渲染流程讲起，限于篇幅我们不在这里做过的的介绍。https://stackoverflow.com/questions/4853856/why-are-draw-calls-expensive降低Draw Call的方法则主要是减少所渲染物体的材质种类，并通过Draw Call Batching来减少其数量。Unity文档对于Draw Call Batching的原理和注意事项有非常详细的讲解。 但是，需要主要的是，游戏性能并非Draw Call越小越好。这是因为，决定渲染模块性能的除了Draw Call之外，还有用于传输渲染数据的总线带宽。当我们使用Draw Call Batching将同种材质的网格模块拼合在一起，可能会造成同一时间需要传输的数据(Texture、VB/IB等)大大增加，以至于造成带宽”阻塞”，在资源无法及时传输过去的情况下，CPU只能等待，从而反倒降低了游戏的运行帧率。 Draw Call和总线带宽是天平的两端，我们需要做的是尽可能维持天平的平衡，任何一边过高或过低，对性能来说都是无益的。 （2）简化资源简化资源是非常行之有效的优化手段。在大量的移动中，其渲染资源其实是“过量”的，过量的网格资源、不合规的纹理资源等等。所以，我们在UWA测评报告中对资源的使用进行了详细的展示（每帧的三角形片数、网格和纹理资源的具体使用情况等），以帮助大家查找和完善存在问题的资源。 关于渲染模块在CPU方面的优化方法还有很多，比如LOD、Occlusion Culling和Culling Distance等等。我们会在后续的渲染模块技术专题中进行更为详细的讲解，敬请期待。 二、UI模块UI模块同样也是几乎所有的游戏项目中必备的模块。一个性能优异的UI模块可以将用户体验在抬高一个档次。在目前国内的大量项目中，NGUI作为UI解决方案的占比仍然非常高。所以，UWA测评报告对NGUI的性能分析进行了极大的支持，我们会根据用户所使用的UI解决方案（UGUI或NGUI）的不同提供不同的性能分析和优化建议。 在NGUI的优化方面，UIPanel.LateUpdate为性能优化的重中之重，它是NGUI中CPU开销最大的函数，没有之一。UI模块制作的难点并不在于其表现上，因为UI界面的表现力是由设计师来决定的，但两套表现完全一直的UI系统，其底层的性能开销则可能千差万别。如何让UI系统使用尽可能小的CPU开销来达到设计师所设计的表现力，则足以考验每一位UI开发人员的制作功底。对于UIPanel.LateUpdate的优化，主要着眼于UIPanel的布局，其原则如下： 尽可能将动态UI元素和静态UI元素分离到不同的UIPanel中(UI的重建以UIPanel为单位)，从而尽可能将因为变动的UI模块引起的重构控制在较小的范围内； 尽可能让动态UI元素按照同步性进行划分，即运动频率不同的UI元素尽可能分离放在不同的UIPanel中； 控制同一个UIPanel中动态UI元素的数量，数量越多，所创建的Mesh越大，从而使得重构的开销显著增加，比如，战斗过程中的HUD运动血条可能会出现较多，此时，建议研发团队将运动血条分离成不同的UIPanel，每组UIPanel下5~10个动态UI为宜，其本质是从概率上尽可能降低单帧中UIPanel的重建开销。 三、加载模块加载模块同样也是任何游戏项目中所不可缺少的组成成分。与之前两个模块不同的是，加载模块的性能开销比较集中，主要出现于场景切换处，且CPU占用峰值均较高。 场景切换时的主要性能开销比较集中，主要出现于场景切换处，且CPU占用峰值均较高。 1.场景卸载对于Unity引擎而言，场景卸载是由引擎自动完成的，即当我们调用类似Application.LoadLevel的API时，引擎即会开始对上一场景进行处理，其性能开销主要被以下几个部分占据： Destroy 引擎再切换场景时会收集未标识成”DontDestoryOnLoad”的GameObject及其Component，然后进行Destroy。同时，代码中的OnDestroy被触发执行，这里的性能开销主要取决于OnDestroy回调函数中的代码逻辑。]]></content>
      <tags>
        <tag>uwa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第六部分 GPU计算]]></title>
    <url>%2F2018%2F03%2F03%2Fnote6%2F</url>
    <content type="text"><![CDATA[第六部分 GPU计算第三十五章 使用CPU进行病毒特征的快速匹配35.1 介绍35.2 模式匹配35.3 GPU实现35.4 结果35.5 结论和后续工作35.6 参考资料第三十六章 用CPU进行AES加密和解密第三十七章 使用CUDA进行高效的随机数生成及应用第三十八章 使用CUDA进行地球内部成像第三十九章 使用CUDA的并行前缀和（扫描方法）第四十章 高斯函数的增量计算第四十一章 使用几何体着色器处理紧凑和可变长度的GPU反馈]]></content>
      <tags>
        <tag>GPU Gems[3]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第五部分 物理仿真]]></title>
    <url>%2F2018%2F03%2F03%2Fnote5%2F</url>
    <content type="text"><![CDATA[第五部分 物理仿真第二十九章 CPU上实时刚体仿真第三十章 实时仿真与3D流体渲染第三十一章 使用CUDA进行快速N-body仿真第三十二章 使用CUDA进行快速宽阶段碰撞检测第三十三章 用于碰撞检测的LCP算法的CUDA实现第三十四章 使用单过程的GPU扫描和四面体转换的有向距离场]]></content>
      <tags>
        <tag>GPU Gems[3]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第四部分 图像效果]]></title>
    <url>%2F2018%2F03%2F03%2Fnote4%2F</url>
    <content type="text"><![CDATA[第四部分 图像效果第二十一章 真正的Impostor第二十二章 在GPU上处理发现贴图第二十三章 高速的离屏粒子第二十四章 保持线性的重要性第二十五章 在CPU上渲染向量图第二十六章 通过颜色进行对象探测：使用CPU 进行实时视频图像处理第二十七章 作为后置处理效果的运动模糊第二十八章 使用景深后期处理]]></content>
      <tags>
        <tag>GPU Gems[3]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三部分 渲染]]></title>
    <url>%2F2018%2F03%2F03%2Fnote3%2F</url>
    <content type="text"><![CDATA[第三部分 渲染第十四章 用于真实感实时皮肤渲染的高级技术第十五章 可播放的全方位捕捉第十六章 Crysis 中植被的过程化动画和着色第十七章 鲁棒的多镜面反射和折射第十八章 用于浮雕映射的松散式锥形步进第十九章 Tabula Rasa中的延迟着色第二十章 基于GPU的重要性采样]]></content>
      <tags>
        <tag>GPU Gems[3]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二部分 光照和阴影]]></title>
    <url>%2F2018%2F03%2F03%2Fnote2%2F</url>
    <content type="text"><![CDATA[第二部分 光照和阴影第八章 区域求和的差值阴影贴图8.1 介绍8.2 相关工作8.3 percentage-closer 过滤8.4 插值阴影贴图8.5 区域求和插值阴影贴图8.6 percentage-closer 软阴影8.7 结论8.8 参考资料第九章 使用全局照明实现互动的电影级重光照9.1 介绍9.2 算法总览9.3 聚集样本9.4 一次反射的间接照明9.5 用于压缩的小波9.6 增加多次反射9.7 对稀疏矩阵进行压缩9.8 基于GPU的重光照引擎9.9 结果9.10 结论9.11 参考资料第十章 在可编程的GPU中实现并行分割的阴影贴图第十一章 使用层次化的遮挡剔除和几何体着色器得到高效鲁棒的阴影体第十二章 高质量的环境遮挡第十三章 作为后置处理的体积光照散射]]></content>
      <tags>
        <tag>GPU Gems[3]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一部分 几何体]]></title>
    <url>%2F2018%2F03%2F03%2FGPU-Gems-3-note%2F</url>
    <content type="text"><![CDATA[第一部分 几何体尽管像素和像素着色器更加吸引人们的目光，但几何体才是一切的根源所在。没有了几何体，我们将发现光照、阴影和反射毫无意义。这是为什么呢？因为提高底层几何体的复杂度，将同时像素的质量。该书本部分描述的主题正式“复杂性”，以前需要使用CPU来增强场景复杂度的方法，现在已经能在GPU上实现。很多解决方案由于图形硬件的新功能和DirectX 10的问世变得可能，这些新功能包括几何体着色器（geometry shader）、流输出（stream out）和缓存获取（buffer fetches）。当然，很多文章也改进了那些曾经适用于以前硬件的技术。第1章，“使用GPU生成复杂的程序化地形”，用程序化方法生成复杂几何体，NVIDIA公司的Ryan Geiss阐述了如何使用许多硬件的新功能来生成带有一些特性的地标，而这些特性在使用通常的程序化合成时很少见到。特别值得一提的是，Geiss提议对程序化地形进行控制，从而可以imian程序化方法的最大弊端。第4章，“下一代SpeedTree渲染”，介绍了另一个室外环境几何体的渲染：树。NVIDIA的Alexander Kharlaov、lain Cantlay和Yury Stepanenko共同合作，提供了那些相对靠近观察者的树木的细节表现。本章涉及了渲染的所有方面，从增强几何体到改进光照和阴影。作为树主题的扩展，第6章，即Electronic Arts/Digital lllusions CE 的Renaldas Zioma所写的“GPU生成的树的过程式风吹动画”，阐述了如何改进树的动画效果。过程式的风效果允许开发者超越目前简单的许多应用的限制。处理大量简单动画的功能同样对于改进复杂度意义重大。第2章中“群体动画渲染” 第一章 使用CPU生成复杂的程序化地形1.1介绍传统上，程序化地形(procedural terrains)受限于CPU生成的并用GPU进行渲染的高度长(height fields)。然而，生成复杂的地形是一项高度并行化的任务，CPU的串行处理本质并不适合完成这项工作。此外，CPU生成高度场的方法也无法提供吸引人的地形特征（如凹洞和凸起物）。 为了在交互级的帧速率下，生成高度复杂的程序化地形，我们转而使用GPU。通过使用DirectX 10的新特性，我们可以快速生成大块的复杂程序化地形。最终，这些块共同创建一个大型的、具有细节的多边形网格，以表示当前视锥观察到的地形。 1.2 Marching Cubes算法和密度函数理论上，地形表面可以用单个函数完整的描述，这个函数被称为密度函数(density function)。对于3D空间的任意一点(x,y,z)，密度函数产生一个单精度浮点值。这些值 1.3 地形生成系统概述1.4 在地形块中生成多边形1.5 纹理和光影1.6 对实际应用的考虑1.7 结论1.8 参考资源第二章 群体动画渲染2.1 目的2.2 实例化的简单回顾2.3 技术细节2.4 其它考虑因素结论参考资料第三章 DirectX 10 混合形状：打破限制3.1 介绍Dawn例子的实现运行例子性能参考资料第四章 下一代SpeedTree 渲染4.1 介绍4.2 轮廓裁减4.3 阴影4.4 树叶光照4.5 高动态范围和反锯齿4.6 半透明覆盖4.7 结论4.8 参考资料第五章 普遍自适应的网格优化5.1 介绍5.2 总览5.3 自适应优化模式5.4 渲染工作流5.5 结果5.6 结论和改进5.7 参考资料第六章 GPU生成的树的过程式风动画6.1 介绍6.2 GPU上的过程式动画6.3 现象学方法6.4 模拟步骤6.5 渲染树6.6 分析和比较6.7 结论6.8 参考资料第七章 GPU上基于点的变形球可视化7.1 变形球、光滑粒子流体力学和表面粒子7.2 限制粒子7.3 局部粒子斥力7.4 全局粒子传播7.5 性能7.6 渲染7.7 结论7.8 参考资料]]></content>
      <tags>
        <tag>GPU Gems</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚幻引擎学习之路：渲染模块之光照系统]]></title>
    <url>%2F2017%2F12%2F10%2FStudy_unreal4_Rendering_1%2F</url>
    <content type="text"><![CDATA[我们准备从三方面来介绍Unreal 4引擎的渲染模块，主要包括：光照系统，材质系统喝图像后处理。本篇文章重点讲解第一部分：光照系统。在对比Unreal 4与Unity两者引擎时，本文分别采用的版本是Unreal 4.18.1和Unity 5.3.8.f1。 本节将介绍Unreal 4引擎的光照系统。在介绍基础功能时，本文将分四块进行介绍，主要包括：光源、全局光照、阴影以及反射效果。同时，本文将与Unity引擎中的这些功能进行对比。另外，对于Unreal 4引擎中的特殊功能，本文将单独介绍。 一、光源光源对于游戏引擎的光照系统来说时最为基础的功能模块。游戏渲染中光照计算的每一部分都离不开光源。通常游戏引擎通过三个重要属性对员光源进行了分类：光源类型、实时性以及渲染管线。对于不同属性的光源，其光照计算方式和复杂程度都有所不同。在接下来的内容中，本文将对Unreal 5和Unity引擎的光源在这三个方面进行比较。 1、光源类型Unreal 4引擎中，可在场景中创建的光源类型有四种：方向光、点光源、聚光灯和天空光。 创建方式跟Unity类似，只需通过在Unreal 4地图编辑器中点击左上角的”Modes”页面，选择”Lights”标签，即可在其子菜单选择需要的光源拖放的场景中，如下图所示：Unreal 4引擎中的天空光其作用是：自动获取远处的入射光信息，然后用于场景中物体的光照计算。远处的入射光信息涵盖了”Sky Distance Threshold”设置的距离以外的所有入射光来源，包括远景=天空盒=云雾等。它的实现方式是先将远处的入射光信息渲染到Cube Map中，然后使用这张Cube Map来计算光照。在Unity中也可以在Lighting设置中采用Sky Box作为环境光的输入，但是Unity没有将其作为单独可放入场景的光源。 2、实时性在Unreal 4的光源属性中，有一项Mobility表示光源的可移动性以及光照计算实时性。它包含了三种类型：Static、Stationary以及Movable。它与Unity中光源类型的Static、Mixed、Realtime具有类似含义，如下图所示：]]></content>
      <tags>
        <tag>Unreal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界boss设计]]></title>
    <url>%2F2017%2F11%2F07%2Fword-boss%2F</url>
    <content type="text"><![CDATA[设计目的作为主要的金钱额外发放通道，驱动尽可能多的玩家参与。将世界boss分为大小两个类型，阶梯性的学习，鼓励低级用户参与，降低挫折感在世界boss和潜在的竞争对手的压力下，让玩家开始自发的组织，逐步形成社会关系。由于小boss需要的组织难度较低，玩家很容易形成组织。而大boss普通玩家只需要依托公会，而公会的组织主要来源于高端玩家，普通玩家只需要参与到这种社会关系中，而不需要耗费额外的精力去组织同时，世界boss还是一个玩家印证自我价值（和其他玩家同比）的方式，通过PVE和pvp的比拼来作为成长压力的宣泄。 大概描述世界上散落着很多个伏魔阵的阵眼通过各种方式激活阵眼，并击破阵眼后，玩家就会被传入到封印世界boss的禁阵中多个队伍（公会）攻击boss，当限时结束或者成功击杀后，伤害名列前茅的队伍获得额外奖励每个被传入禁阵中的玩家，每对boss造成一次伤害，都会获得和伤害成正比的金钱数，同时在阵中的这段时间内，都会源源不断的获得经验 基础原则世界boss分为大小两种由于一个场景可能存在n条线并行的原因，而这个n并不确定，世界boss如果再单独刷在大世界的场中，则刷多少个boss完全无法确定，作为一个重要和敏感的发放渠道，这种方式将是完全不可接受的。因此需要更改世界boss的形式。世界boss单独刷在一个特定场景（暂且称之为禁阵）中，该场景除了boss以外几乎没有其他NPC和其他逻辑，因此该场景可以容纳更多的玩家，缓解了服务器的逻辑压力必须由击破阵眼来获得进入boss战场景的资格 详细设计世界boss分为大小两种 低级boss设计基础思路 以小队为单位，强调队伍之间的对抗和博弈过程分为【大世界击破阵眼】【禁阵内击杀boss】两个阶段。在大世界上pvp模式不做更改，由玩家控制。默认为和平，玩家可以通过开红来发动pk在禁阵内，是否pk仍然交给玩家决定，想主动发起pk的一方可以先开启【杀戮】和【公会杀戮模式】——【公会杀戮模式】现在还没实现，需要负责人苏博跟进实现开启禁阵无规定时间，无固定时间开启玩家在世界探索中会获得【低级boss召唤符】，在伏魔阵的阵眼附近使用该道具，可以打开伏魔阵。只要拥有道具【召唤符】，就可以随时（世界大boss活动时间内不允许）开启禁阵召唤符有N种，一一对应N个世界小boss，例如：玄黄坤龙召唤符就只能召唤玄黄坤龙，姥姥召唤符就只能召唤姥姥。每个召唤符只能在唯一对应的场景使用（道具tips上有说明，例如玄黄坤龙召唤符，tips上写着“该召唤符只能在海底的伏魔阵周围使用”）有些场景有伏魔阵，有些场景没有。拥有伏魔阵的场景都对应有5个阵眼，想要召唤的玩家必须走到一个阵眼附近使用道具。召唤者身边一定会生成一个阵眼地图上其他的4个阵眼位置会随机生成2个阵眼阵眼生成的时间为30秒（期间会有阵眼逐渐生成的特效表现）阵眼生成的阶段，会有跑马灯和世界聊天提升—-类似：玩家xxx正在【某个场景】打开伏魔阵阵眼。（方括号的为链接，点击后可以直接传送到该场景）如果该召唤场景存在着多条分线，也只能在使用召唤符的本线打开阵眼，其他的分线无动静阵眼持续2分钟，2分钟内每30秒通知一次全服，2分钟后阵眼消失。阵眼生成和持续时间内，跑马灯和世界聊天通知全服，会有以下的处理点击提示上的链接，会自动寻路走到阵眼所在的场景如果和召唤者不在同一个场景，自动寻路到切场景时，自动进入阵眼所在的场景线（如果多线）在同一个场景不在同一条线的，自动切线到阵眼所在线到达召唤场景后，自动寻路中止，接下来需要玩家手动去寻找打开的阵眼如何进入禁阵每个阵眼被击破，都会传送一队人进入boss场景阵眼击破后，都会在阵眼刷出的位置出现一个传送门，该门存在时间由策划填表调整控制如何挑选进入boss场景的人伤害最高的队伍进入boss场景1.一个阵眼被攻击时候，记录对其造成的伤害，对应的玩家，并进行排名2.每次记录的时候，是以队伍为基础单位进行记录，不记录玩家的个人伤害3.攻击阵眼的过程中，会在客户端出现伤害排行榜A.只有走到阵眼附近20米的范围内且当时正处于开启状态下，该排行榜才会在客户端上显示（为什么是20米，20米是玩家有可能对阵眼造成伤害的最大攻击距离）B.该排行榜出现在任务栏的位置，临时顶替掉任务栏C.该排行榜有且只有3行D.如果自己的队伍排名第一，则在下方显示伤害最接近自己的两个组E.如果不排名第一，则显示伤害排名比自己高一名和低一名的队伍F.该排行榜每1秒动态更新一次G.伤害排行的上仅仅显示名次和造成的伤害数值H.自己队伍在排行榜上所在行会凸起显示，让人直观上一眼就能看出这行是自己队伍的数据每个阵眼仅仅只挑选一个队伍进入1.最大只开启3个阵眼，也就是说最多有3个队可以被传入boss场景2.那些玩家可以进入？A.当阵眼被击破的时候，系统才开始挑人B.此时，先确定伤害最高的队伍C.再确定当前队伍里的玩家，并记录这些玩家D.把这些玩家都传入到boss场景里阵眼存在2分钟，阵眼消失前如果阵眼没有被击破，该阵眼不会传送任何一个玩家进入boss场景特别注意1.当阵眼传送人之前，需要判断玩家是否在阵眼所在的场景，只有玩家处于阵眼所在的场景，才把玩家传送。2.阵眼被击碎后的2分钟内（也就是传送门穿在的2分钟内），每秒都会检测拥有进入资格的玩家是否出现在阵眼附近20米区域，如果出现，则把玩家传送进入boss场景（预防阵眼开启前掉线，预防阵眼开启前切了场景）[后面会引用]3.玩家如果死在附近，也可以被传送，传送后复活 Boss战怎么玩场景1.使用天劫副本场景修改A.该场景由中央的大圆形平台和周围的3个浮空阁楼组成B.大平台和阁楼之间没有导航连接，没法通过走路互通C.需要通过对话，触发飞行寻路飞到中间的战斗区域D.该场景禁止玩家手动的飞行2.出生点和复活点A.出生点和复活点在3个小平台上B.玩家随机出生和复活在3个点上C.怎么从出生点到达战斗场景对话，确定后随机选一条该出生点连接到boss平台的飞行路线进行自动寻路飞行使用tx01-85帧的动画，大世界探索动画策划在技能编辑调整为5秒，300帧需要一个运气聚敛云朵的粒子效果5秒后吟唱结束，脚底驾云飞行路径相关在每个复活点种多条飞行寻路路径，让一堆人一起飞出来的时候不重合，感觉更有仪式感飞行寻路花费5-10秒飞到场景中央飞行寻路过程中不能使用技能，不能驾云，坐骑等所有互动功能（最好客户端所有相关互动按钮都隐去）状态处理复活后无敌，初次传入时无敌，无敌时间无限长，跨场景删除，飞行寻路完毕后，删除无敌3.战斗场景A.中间的大圆形区域为boss场景B.战斗只能发生在这里规则1.场景内玩家关系A.可以自由组队和退队B.默认pk模式为善恶C.可以开各种杀戮模式pk2.特殊玩法（二期制作？？）A.阶段性出现特殊玩法B.特殊玩法1：PK鼓励向，boss血量到某个阶段后开启，该阶段一旦击杀了其他玩家，每杀一个玩家获得一层状态，提升攻击10%3.战斗限时A.3-4分钟的时间为宜（策划填表）B.时间长了疲惫C.时间短了拉不开差距Boss战斗属性1.每一个boss都有其固定的属性。2.对应该boss刷出来的阵眼的属性也固订。也就是一个boss对应一个阵眼，boss的阵眼的属性都是固定不变的。比如：姥姥的属性就是npcgrowup里的1101，对应的阵眼cha_list id为11001，属性也对应为1102.3.Boss的等级由玩家决定A.Boss的等级取决由有资格传送进入boss战的玩家中等级最高的玩家，boss的等级等于该玩家的等级B.玩家传送进入boss场景后，boss场景才刷出boss4.Boss最初的1级属性确定，之后的每级属性有npc——growup决定（如果boss属性据此控制不力，则可以使用分段控制法，每个关键等级点单独取一条属性，该属性包括了boss的基础属性和成长属性，直到下一个等级关键点之前的所有等级都使用该属性，到达下个关键点后，取新的关键点的战斗属性匹配给boss（比如30-39使用npc成长表属性ID1000,40-45使用1001,45-50使用1002）5.注意：阵眼的等级等于开启伏魔阵队伍里等级最高的玩家的等级，其属性由其等级匹配到相应的表得到）奖励相关首先需要伤害统计Boss战的时候，类似阵眼击破，对所有对boss造成的伤害进行记录和统计伤害统计栏还是出现在任务栏，隐去任务栏还是只以队伍为单位进行排行和统计参与就有奖励只要进入战斗状态，每秒获得一定经验（策划填表），根据玩家等级获得经验只要对boss造成伤害，就能获得金钱奖励每个boss对应不同等级都有一个总金钱掉落书每次造成的伤害对应boss总血量的必烈决定单次获得基础金钱数1.Boss等级越高，总金钱数越多2.玩家伤害越高，单次获得金钱越多3.可能会一秒判定很多次，获得金钱的间隔就设定为一秒如果有玩家完成了最终一击的击杀，则额外奖励该玩家3%boss掉落金钱的奖励不同的职业在基础金钱数上还有个系数加成（系数策划填表），用来平衡不同职业定位下，职业之间的伤害有差距的问题每个玩家造成的伤害都记录下来，到最后boss战结束的时候统一结算，通过邮件发放额外的排名奖励以队伍伤害排名为标杆选择伤害最高的队伍发奖发奖以道具为基础形式，通过邮件发送。如何退出副本战斗时间倒计时结束后进行结算。因此屏幕中央上方位置有本次挑战的限时倒计时显示，倒计时是从boss刷出开始计时。结算时弹出结算界面（结算界面见界面设计）界面上表明谁的队伍获得了额外奖励，并显示奖励礼包，点击礼包可以看到tips显示自己获得的金钱和经验奖励点击确定离开boss场景，该界面仅仅有确定按钮Boss战结束后，会用跑马灯宣布【xxx（队长）和他的队友击败了xxboss，获取了丰厚的回报】掉线问题的处理大世界掉线阵眼击破前就重新上线了1.队伍还存在，无需特殊处理，因为记录的是队伍伤害和队伍信息2.全队都掉线，队伍只要不删除，还记录有队伍信息即可阵眼开启后才重新上线1.参考【如何进入禁阵】里的【特别注意】第二条 ：链接在此Boss挑战时掉线战斗结束前就重新上线1.单人掉线，队伍还在就出现在掉线前位置，伤害和队伍信息继承2.队伍解散，上线还是出现在掉线前位置，但伤害信息清零3.全队掉线，保留伤害统计和队伍信息，等上线后继续战斗结束后才上线1.结束前没有散队，奖励照发，从邮件获得2.散队了，没有奖励 高阶boss玩的是什么公会间的竞争，同时小队为基础的竞争单元阵眼会开启多次，一个公会怎么保证自己的人尽可能多的在前两轮进入，是很重要的竞争和博弈Boss战时候的竞争和博弈，主要体现在pve伤害的竞争，以及多个公会间因为PK策略的选择展开的博弈Pk规则大世界上默认组队前的pk模式，pk自由交给玩家，玩家可以手段选择开启。基本以公会杀戮为主，不排斥其他pvp模式Boss场景的pk决定权同上，交给玩家怎么开启系统上指定时间点上自动打开地图上的大伏魔阵阵眼，需要打破阵眼，该阵眼才会挑选参与过击破自己的玩家，符合规则被选中的人才能被传送到世界boss身边规定时间开启每天都会开启每天开启2次，分别是中午12:00-12:30,晚上20:00-20:30开启时间内和开启前10分钟内，所有伏魔阵无法使用召唤符召唤小世界boss，（表现为这段时间内，伏魔阵的符咒纹理显示为红色，表明大伏魔阵激活，小伏魔阵无法开启—-小伏魔阵的纹理采用蓝色或者其他做区别）开启时间策划填表决定，原则就是和其他活动不冲突，并安排在大部分玩家有闲的时间段。指定地点开启开启地点1.只能在指定地点生成阵眼2.指定点规则A.要素1：不同boss对应的场景组不一样例如场景ID有1到101号boss对应：1352号boss对应：246如果是打1号boss，则只会在1 3 5场景刷出阵眼B.要素2：一个场景包含了5个阵眼如果该场景可以召唤小boss，该场景的大小boss阵眼点相同世界boss定时活动开启后，一定是5个阵眼一起打开C.要素3：允许一个场景多条线：如果一个场景开了多条线，则每条线的指定点都会生成阵眼D.要素4：PVE和PVP场景都会有指定点PVE场景选择等级略高的地方Pvp的场景也尽量选择等级比较高的地方，但考虑玩家参与情况，可以选择个别对应等级比较低的场景。阵眼开启通知1.阵眼开启前5分钟，每20秒跑马灯提醒一次全服玩家2.阵眼开启后，跑马灯通知全服（完全和小boss相同）A.点击跑马灯和世界聊天的链接，自动寻路走到阵眼所在的场景B.。。。怎么进入每次阵眼被击破，都会传送一定数量的玩家进入boss场景每个阵眼可以被击破3次，随着被击破的次数增加，阵眼扩大，下一次可以被传送的玩家数量随之增加挑选进入boss场景的规则阵眼每次被击碎后，挑选玩家进入boss禁阵阵眼可以被击碎三次，三次后，阵眼不再生成阵眼有存活时间，该时间策划填表决定，时间一到，该阵眼如果还未被击破，阵眼消失，本次不传送攻击阵眼的过程中，会统计伤害并排行，并显示在客户端1.该排行榜最多出现3行2.完全类似小boss的大世界伤害统计（略过不表）第一次传送1.精英传送：只传最厉害的一组人进入A.当阵眼被击破时，才开始挑人B.确定伤害最高的队伍C.确定当前这个队伍的玩家，记录D.把这些玩家传入boss副本E.如果有掉线，不在阵眼同一场景，参考特殊处理2.传送完毕后，有个阵眼重新打开过程，该过程持续时间策划填表决定（改好等于boss场景中复活点到战斗场景时间或更大）3.屏幕提示：阵眼被击碎后，显示【阵眼受到攻击，禁制松动，下一次阵眼会稍后打开】第二次传送1.高级传送：传送最厉害的1组人进入A.类似第一次传送B.这次仍然只传送1队人2.传送完毕后，类似第一次传送，仍然有个阵眼重新打开过程该过程持续时间策划填表决定（改好等于boss场景中复活点到战斗场景时间或更大）3.屏幕提示：阵眼被击碎后，显示【阵眼受到猛烈攻击，禁制受损严重，稍后将会打开最后一次阵眼】第三次传送1.普世传送：仍然只传送一队人A.当阵眼被击碎，所有参与的有伤害的人都被传入B.阵眼有个存活时间，时间到还没被击破，伏魔阵关闭，符文熄灭，阵眼消失，木有传送门2.该次传送后，阵眼不再生成，但会 有传送门存在2分钟初步计算和预估一个boss对应3个场景每个场景2条线一个场景5阵眼每个着眼前两轮传2只队每队6个玩家第一轮最多30个阵眼，可传180个玩家，实际普遍情况可能最多15个阵眼传入90个玩家（参考另个情况：一个大公会100人满员）第二轮第三轮同理一共540，其实最大估计270。Boss战玩法Boss战场景场景内容完全继承小boss出生点和复活点几乎等同于小boss，不同点在于：出生点和复活点随机在预设的3个点，3个点刚好平均分在3个小阁楼上。战斗场景就是中间的大圆圈Boss战规则场景内可以自由组队和退队默认pk模式为善恶，是否开红，自主权给玩家阶段性玩法（二期）1.例如小boss也有的阶段性强化pk玩法战斗限时1.策划填表决定限时。15-20分钟适宜2.时间太长疲惫3.时间短了拉不开伤害差距4.如果需要进一步强化boss战的交互和互动，那可以适当增加写时间，反正由策划手动填表控制Boss的战斗属性Boss的属性是可以升级和降级的世界boss的等级是固定的服务器玩家封顶等级（策划填表）每一级的属性从表里匹配，匹配方式类似小bossBoss如果当次被击杀，则boss会自动升一级，那么boss的属性也会升级如果当次没有被击杀，则boss会自动降一级，那么boss的属性也会降低动态的调整boss等级，等于动态的调整了boss的属性，保证了boss的属性总是趋向于贴合本服务器玩家的当前战斗力水平预期的另外注意：阵眼的等级等于boss的等级，其属性也是动态升级和降级的（也由策划填表控制）奖励发放首先需要伤害统计为依据Boss战的时候，类似阵眼，会对所有造成的伤害记性记录和统计队伍伤害统计1.隐去任务栏，在该处出现伤害统计2.以队伍为单位进行统计和排行公会伤害统计1.在队伍伤害统计下方，客户单显示公会伤害统计2.以公会为单位进行排行和统计3.样式完全类似队伍的4.该伤害统计和排行只能出现在boss战阶段参与就发奖励只要进入战斗状态，每秒获得一定经验（策划填表），根据玩家等级获得经验只要对boss造成伤害，就能获得金钱奖励1.每个boss对应不同等级都有一个总金钱掉落书2.每次造成的伤害对应boss总血量的必烈决定单次获得基础金钱数A.Boss等级越高，总金钱数越多B.玩家伤害越高，单次获得金钱越多C.可能会一秒判定很多次，获得金钱的间隔就设定为一秒3.不同的职业在基础金钱数上还有个系数加成（系数策划填表），用来平衡不同职业定位下，职业之间的伤害有差距的问题4.如果有玩家完成了最终一击的击杀，则额外奖励该玩家3%boss掉落金钱的奖励5.每个玩家造成的伤害都单独记录，直到活动完毕时一并结算成金钱，并通过邮件发放给玩家排名的额外奖励分为队伍和公会两部分奖励队伍1.以队伍伤害为标杆2.选择伤害最高的队伍发奖公会1.排名前3名的公会会的额外奖励，前几名可以获奖，奖励什么都由策划填表控制2.前N名可以获得世界boss妖丹，该妖丹是个直接发放给公会仓库的道具（N暂时取5）3.妖丹的道具只决定了召唤出来的boss的类型4.妖丹的等级等于本次活动的世界boss的等级，不同等级的妖丹召唤出来的门派boss的等级也不相同5.排名第一名的公会得到的妖丹等级等于世界boss的等级，而后的2-5名得到的妖丹都会有个等级修正（策划填表），他们得到的妖丹的等级需要用世界boss的等级减去修正值得到。怎么退出战斗过程中无法主动退出活动倒计时为0时，结束战斗，开始结算结算时弹出结算界面表明那个公会拔得头筹（伤害最高的公会）表明那只队伍贡献最大表明本公会获得奖励表明自己队伍获得的奖励点击确定离开boss场景Boss战结束后，会用跑马灯宣布【xxx公会是降伏世界boss xxx的中流砥柱，获取了丰厚的回报】 掉线处理类似小boss特别注意当阵眼传送人之前，需要判断玩家是否在阵眼所在的场景，只有玩家处于阵眼所在的场景，才把玩家传送。阵眼前两次被击碎后，会有1-2分钟聚力重塑的时间，（时间策划填表）该时间内每秒都会检测拥有进入资格的玩家是否出现在阵眼20米区域，如果出现，则把玩家传送进入boss场景（预防阵眼开启前掉线，预防阵眼开启前切了场景）当第三次阵眼击碎后，阵眼位置生成一个缝隙，存在2分钟，2分钟内有资格进入的玩家走到缝隙附近20米，被传入玩家如果死在附近，也可以被传送，传送后复活]]></content>
  </entry>
  <entry>
    <title><![CDATA[Shell]]></title>
    <url>%2F2017%2F11%2F02%2Fshell%2F</url>
    <content type="text"><![CDATA[${}用来做变量替换。一般情况下，$var与${var}并没啥不一样但是用${}会比较精确的界定变量名称的范围，比方说：$ A=B$ echo $ABg++ -DLINUX -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -Wall -Wno-multichar -g -D_DEBUG -DPG_MEMORY_DISABLE_POOL -march=core2 -m32 -rdynamic -std=c++0x -o ../../bin/debug/xxsy/ScnSvr_AllInOne/ScnSvr_AllInOne_d ../../temp/debug/xxsy/ScnSvr_AllInOne/ScnSvr_AllInOne.o_d /root/work_code/src/lib/libGSDB_Lib_d.a /root/work_code/src/lib/libScnSvr_d.a /root/work_code/src/lib/libGZSGamePlay_Lib_d.a /root/work_code/src/lib/libMCE4Chat_d.a /root/work_code/src/lib/libMCE_d.a /root/work_code/src/lib/libDIA4DBI_d.a /root/work_code/src/lib/libDIA_d.a /root/work_code/src/lib/libPNGS_d.a /root/work_code/src/lib/libWHNET_d.a /root/work_code/src/lib/libWHCMN_d.a /root/work_code/src/lib/libxxsy_cmn_d.a /root/work_code/src/lib/libpgcmn_d.a -lpathfind_d -lcJSON_d -lcryptlib_d -llua_d -lzlib_d -ltss_sdk_d /root/work_code/3rd/lib/libqos_client.a -lz -ldl -lssl -lpthread -ldl -lrt -march=prescott -L/root/work_code/3rd/lib -L/root/work_code/src/lib -pthread/usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../lib/libm.so when searching for -lm #0 这个是shell的执行名字 #n 这个是shell的第n个参数值，n=1..9 $* 这个是shell的所有参数 $# 表示参数的个数 $$ shell的PID $! 执行上一个的PID $? 执行上一个指令的返回值（显示最后的退出状态，0表示没有错误，其它任何值表明有错误） $- 显示shell使用的当前选项，与set命令功能相同 $@ 跟$* 类似，但是可以当作数组用 -eq 等于 -ne 不等于 -le 小于等于 -ge 大于等于 -lt 小于 -gt 大于 = 就是赋值运算:= 就是当冒号前面的变量不存在或者值为空时，就把等号后的值赋值给变量 删除十天前的文件ltfind ./ -mtime +10 -name &quot;*.*&quot; -exec rm -rf {} \; 文件传输（Windows向Linux传输）安装yum install openssh-clients -y 传输文件scp -p ./file/yum.log root@192.168.199.150:/tmp/yum.log 传输目录scp -rp ./file/ root@192.168.199.150:/tmp/ 查看那个共享内存被哪些进程使用着 lsof | grep &quot;shmid&quot; 将静态库文件解析成.o文件 ar -x libexpat.a 查看归档文件的函数名 nm -s xmltok.o 查看汇编代码 objdump -j .text -Sl tbus.o | more]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日记]]></title>
    <url>%2F2017%2F10%2F30%2Fzentia-note1%2F</url>
    <content type="text"><![CDATA[SetUseAuth由于个人喜欢sublime也在使用，遇到不支持ANSI编码，特标注：ConvertToUtf8 import urllib.request,os; pf = ‘Package Control.sublime-package’; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), ‘wb’).write(urllib.request.urlopen( ‘http://sublime.wbond.net/‘ + pf.replace(‘ ‘,’%20’)).read())上面的是安装package controls grep key1 * | grep key2 并所有文件 find ./ -name &quot;*.ext&quot; | xargs -i rm -rf {} # 查询某个后缀名的所有文件，然后移除，-i表示对文件操作 解决树冲突： svn resolve --accept working dir https://github.com/Unity-Technologies/UnityCsReference README.mdUnity 2018.1.0b12 C# reference source code The C# part of the Unity engine and editor source code.May be used for reference purposes only. https://github.com/duanjiahao/UnityDecompiled https://github.com/MattRix/UnityDecompiled https://github.com/jameslinden/unity-decompiled IP Username Password Environment 106.12.98.12 root lyf8068353A@ Outter net 虚拟机Centos的密码都是123456789Mac的密码都是123456PC的密码是123456]]></content>
      <tags>
        <tag>日记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[port-security]]></title>
    <url>%2F2017%2F10%2F30%2Fport-security-1%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[端口映射]]></title>
    <url>%2F2017%2F10%2F30%2Fport-security%2F</url>
    <content type="text"><![CDATA[端口安全（Port Security），从基本原理上讲，Port Security特性会通过MAC地址表记录连接到交换机端口的以太网MAC地址（即网卡号），并只允许某个MAC地址通过本端口通信。其它MAC地址发送的数据包通过此端口是，端口安全特性会组织它。使用端口安全特性可以防止未经允许的设备访问网络，并增强安全性。]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PS]]></title>
    <url>%2F2017%2F10%2F30%2Fps%2F</url>
    <content type="text"><![CDATA[快捷键 解释 Alt+Delete 修改图层颜色]]></content>
      <tags>
        <tag>PS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[poll]]></title>
    <url>%2F2017%2F10%2F28%2Fpoll%2F</url>
    <content type="text"><![CDATA[Poll就是监控文件是否可读的一种机制，作用与select一样。应用程序的调用如下： int poll(struct pollfd *fds, nfds_t nfds, int timeout) Poll机制会判断fds中的文件是否可读，如果可读则立即返回，返回的就是可读fd的数量，如果不可读，那么进程就会休眠。 内核实现流程：当应用程序调用poll函数的时候，系统会调用sys_poll函数，该函数最终调用do_poll函数，do_poll函数中有一个死循环，在里面又会利用]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XXSY服务器游戏架构]]></title>
    <url>%2F2017%2F10%2F27%2Fgame-framework%2F</url>
    <content type="text"><![CDATA[总体架构图 大区架构图 逻辑服务器架构图]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache]]></title>
    <url>%2F2017%2F10%2F27%2FApache%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435[1] 安装 httpd.[root@linuxprobe ~]# yum -y install httpd# 删除默认欢迎页面[root@linuxprobe ~]# rm -f /etc/httpd/conf.d/welcome.conf[2] 配置httpd，将服务器名称替换为您自己的环境[root@linuxprobe ~]# vim /etc/httpd/conf/httpd.conf# line 86: 改变管理员的邮箱地址ServerAdmin root@linuxprobe.org# line 95: 改变域名信息ServerName www.linuxprobe.org:80# line 151: none变成AllAllowOverride All# line 164: 添加只能使用目录名称访问的文件名DirectoryIndex index.html index.cgi index.php# add follows to the end# server&apos;s response header（安全性）ServerTokens Prod# keepalive is ONKeepAlive On[root@linuxprobe ~]# systemctl start httpd[root@linuxprobe ~]# systemctl enable httpd[3] 如果Firewalld正在运行，请允许HTTP服务。，HTTP使用80 / TCP[root@linuxprobe ~]# firewall-cmd --add-service=http --permanentsuccess[root@linuxprobe ~]# firewall-cmd --reloadsuccess[4] 创建一个HTML测试页，并使用Web浏览器从客户端PC访问它。如果显示以下页面，是正确的[root@linuxprobe ~]# vi /var/www/html/index.html&lt;html&gt;&lt;body&gt;&lt;div style=&quot;width: 100%; font-size: 40px; font-weight: bold; text-align: center;&quot;&gt;Welcome access LinuxProbe.org,This is Test Page!&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; http://blog.csdn.net/wh211212/article/details/52982917]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vs]]></title>
    <url>%2F2017%2F10%2F26%2Fvs%2F</url>
    <content type="text"><![CDATA[$(TargetDir)\XGZS_d.exe../data/cfg/network/cfg_relation.txt]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstat]]></title>
    <url>%2F2017%2F10%2F26%2Fnetstat%2F</url>
    <content type="text"><![CDATA[netstat -tln 查看端口占用情况\p 可以显示进程每一列含义协议类型 接受流量 发送流量 本机地址 目的地址 状态自己的IP地址就是本地地址，需要连接的地址的就是目的地址 nmap 127.0.0.1 查看本机开放的端口0.0.0.0 表示网络的所有主机[{“type”:0,”pid”:-1,”Attr1”:0,”id”:1,”Attr2”:0,”name”:”PC主支”,”tag”:0},{“type”:0,”pid”:1,”Attr1”:0,”id”:2,”Attr2”:0,”name”:”策划大区”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:3,”Attr2”:0,”name”:”程序大区”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:4,”Attr2”:0,”name”:”3.0.90.0”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:22,”Attr2”:0,”name”:”4.0.30.0”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:28,”Attr2”:0,”name”:”云服务器”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:34,”Attr2”:0,”name”:”4.0.0.0”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:35,”Attr2”:0,”name”:”3.0.60.0”,”tag”:1},{“type”:0,”pid”:1,”Attr1”:0,”id”:41,”Attr2”:0,”name”:”合服”,”tag”:1},{“type”:1,”pid”:2,”id”:381,”RoleCount”:0,”RoleInfos”:{},”name”:”[1]策划主支”,”Attr1”:4,”Flag”:64,”Url”:”192.168.3.6:16400”,”Attr2”:0,”tag”:3},{“type”:1,”pid”:2,”id”:382,”RoleCount”:0,”RoleInfos”:{},”name”:”[2]策划主支”,”Attr1”:3,”Flag”:64,”Url”:”192.168.6.113:16400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:256,”RoleCount”:0,”RoleInfos”:{},”name”:”[1]程序主支”,”Attr1”:2,”Flag”:64,”Url”:”192.168.3.6:26400”,”Attr2”:0,”tag”:3},{“type”:1,”pid”:3,”id”:257,”RoleCount”:0,”RoleInfos”:{},”name”:”[2]程序主支”,”Attr1”:1,”Flag”:64,”Url”:”192.168.6.113:26400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:259,”RoleCount”:0,”RoleInfos”:{},”name”:”yhy-1”,”Attr1”:0,”Flag”:32,”Url”:”192.168.7.13:3100 192.168.7.13:3110”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:53,”RoleCount”:0,”RoleInfos”:{},”name”:”yhy-2”,”Attr1”:0,”Flag”:32,”Url”:”192.168.7.13:13100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:19,”RoleCount”:0,”RoleInfos”:{},”name”:”218(zy)”,”Attr1”:0,”Flag”:32,”Url”:”192.168.5.106:3100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:20,”RoleCount”:0,”RoleInfos”:{},”name”:”190(zmq)”,”Attr1”:0,”Flag”:32,”Url”:”192.168.5.228:26400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:21,”RoleCount”:0,”RoleInfos”:{},”name”:”230(hjz)”,”Attr1”:0,”Flag”:32,”Url”:”10.96.205.230:26400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:310,”RoleCount”:0,”RoleInfos”:{},”name”:”测试专服”,”Attr1”:0,”Flag”:64,”Url”:”192.168.6.113:7100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:3,”id”:268,”RoleCount”:0,”RoleInfos”:{},”name”:”主支跨服大区”,”Attr1”:0,”Flag”:64,”Url”:”192.168.3.6:10010”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:4,”id”:93,”RoleCount”:0,”RoleInfos”:{},”name”:”[1]3.0.90.0”,”Attr1”:0,”Flag”:64,”Url”:”192.168.3.6:51100”,”Attr2”:0,”tag”:3},{“type”:1,”pid”:4,”id”:94,”RoleCount”:0,”RoleInfos”:{},”name”:”[2]3.0.90.0”,”Attr1”:0,”Flag”:64,”Url”:”192.168.6.113:51100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:22,”id”:95,”RoleCount”:0,”RoleInfos”:{},”name”:”[1]4.0.30.0”,”Attr1”:0,”Flag”:64,”Url”:”192.168.3.6:43100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:22,”id”:96,”RoleCount”:0,”RoleInfos”:{},”name”:”[2]4.0.30.0”,”Attr1”:0,”Flag”:64,”Url”:”192.168.6.113:43100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:28,”id”:5999,”RoleCount”:0,”RoleInfos”:{},”name”:”IOS游客”,”Attr1”:0,”Flag”:64,”Url”:”139.199.37.182:48100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:28,”id”:4999,”RoleCount”:0,”RoleInfos”:{},”name”:”IOS微信”,”Attr1”:0,”Flag”:64,”Url”:”139.199.37.182:53100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:28,”id”:3999,”RoleCount”:0,”RoleInfos”:{},”name”:”IOS手Q”,”Attr1”:0,”Flag”:64,”Url”:”139.199.37.182:33100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:28,”id”:1999,”RoleCount”:0,”RoleInfos”:{},”name”:”安卓手Q”,”Attr1”:0,”Flag”:64,”Url”:”139.199.37.182:23100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:28,”id”:2999,”RoleCount”:0,”RoleInfos”:{},”name”:”安卓微信”,”Attr1”:0,”Flag”:64,”Url”:”139.199.37.182:28100”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:34,”id”:97,”RoleCount”:0,”RoleInfos”:{},”name”:”[1]4.0.0.0”,”Attr1”:0,”Flag”:64,”Url”:”192.168.3.6:20400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:34,”id”:98,”RoleCount”:0,”RoleInfos”:{},”name”:”[2]4.0.0.0”,”Attr1”:0,”Flag”:64,”Url”:”1921.68.6.113:20400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:35,”id”:90,”RoleCount”:0,”RoleInfos”:{},”name”:”[1]3.0.60.0”,”Attr1”:6,”Flag”:64,”Url”:”192.168.3.6:6400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:35,”id”:91,”RoleCount”:0,”RoleInfos”:{},”name”:”[2]3.0.60.0”,”Attr1”:5,”Flag”:64,”Url”:”192.168.6.113:6400”,”Attr2”:0,”tag”:1},{“type”:1,”pid”:41,”id”:311,”RoleCount”:0,”RoleInfos”:{},”name”:”合服后(3014+3016)”,”Attr1”:0,”Flag”:64,”Url”:”192.168.6.113:7100”,”Attr2”:0,”tag”:9},{“type”:1,”pid”:41,”id”:312,”RoleCount”:0,”RoleInfos”:{},”name”:”3014”,”Attr1”:0,”Flag”:64,”Url”:”192.168.6.113:23100”,”Attr2”:0,”tag”:9},{“type”:1,”pid”:41,”id”:313,”RoleCount”:0,”RoleInfos”:{},”name”:”3016”,”Attr1”:0,”Flag”:64,”Url”:”192.168.6.113:37100”,”Attr2”:0,”tag”:9}]]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多语言规范]]></title>
    <url>%2F2017%2F10%2F25%2Flang%2F</url>
    <content type="text"><![CDATA[概述部分多语言资源，客户端和服务器放在不同目录里，公用的部分使用外链。 客户端多语言根目录：Assets\Art\lang二级目录mb：存放mb的多语言数据二级目录res: 存放界面文本，以及其它资源的多语言数据（比如图片和prefab等）三级目录：用各种语言名字来命令的目录config.txt：保存当前语言的名字 服务器多语言根目录：bin\data\lang二级目录mb：存放mb的多语言数据（这个是上面的客户端二级mb的外链）二级目录mbs：存放mbs多语言数据三级目录：用各种语言名字来命名的目录config.txt：保存当前语言的名字（服务器和客户端需要分别配置） 程序需要做的事情:： 处理表格配置，合理设置翻译列； 在界面prefab里，给UILabel等控件填写langId，需要同时创建对应的文字资源文件； 界面用到的Lua/text里的json文件，需要转换成txt文件资源； 脚本里的中文，需要放到文本资源里； 图片文字，需要整理放到单独目录里，便于提供海外运营商； res目录规范此目录是界面文本资源表格，表格无标题行，分三列：名字，文本，英文长度，某些按钮类的空间，如果需要限制文本长度，那么需要填写英文长度列。不要有任何子目录，子目录是无效的。非翻译文本（比如目录配置文本），放到lua里就好，不要放在txt里。此目录里的所有文件，都是用到的时候加载的文本资源使用方式： C#代码访问方式：LangMgr.Find(“login.Username”),此函数无GC prefab访问方式：填写UILabel的langId,格式同上，所有中文标签都要做修改。 lua脚本访问方式：lua_core.LoadLangFile(“login”).Username目录file：可替换掉相同路径的资源，比如字体替换，文字图片替换等，也可以直接用这个替换整个界面的prefab，但是轻易不要这样用。 Json转Text工具在Unity里，选中Lua/text/目录里的某个文件点击菜单项Pangmei/Translate/json转text，这样可以将原本的json文件转txt表格。转换后的文件放在了Assets\Art\lang\res\zh_cn\text\temp里，需要重新命名后挪出来。原本的子目录都不要有了，如果有重命名，就自己改个名字。建议文件别太多，太小的文件自己合并一下，文件少会更容易管理。 新文本merge方式可以使用string.merge()来格式化字符串，这个是仿造C#的Format来设计功能。用{0}引用首个参数，其余参数类推。这个函数在客户端没有C#级别的GCAlloc，大量使用的时候推荐这个，不要用CSFormat系列了。部分带%s的文本，建议都检查一下，多个%s的文本有可能会导致某些语言翻译错误（主谓宾和汉语次序不同导致） mb目录规范翻译列配置表格的json配置文件，每列可以加防疫配置”translate”:true指定翻译的列：会被翻译工具检索出来生成翻译词条。 目录text有工具生成的表格翻译文本，运行期动态替换掉中文表格文本。 目录cell替换掉同名表格指定单元格的内容，不需要写子目录。多个文件可以同名，以二级扩展名区分，比如：item_list.a.txt,item_list.b.txt同名文件按照二级扩展名排序依次执行，重复配置的单元格，以最后的为准。首行是标题，第二行是json配置里的表格列的名字，后续航是替换的内容。第二行的名字，可以不填写，就表示忽略该列。此特性通常用于注释或者名字之类的。空单元格表示不需要替换，如果需要替换为空，那么填写“##” 目录file整文件替换表格，对应的参照目录是mb目录。这个功能尽量别用，使用cell来精确替换某个单元格更可控。 mbs目录规范翻译列配置：规则同mb 目录text规则同mb 目录cell基本规则同mb有子目录npc_refresh和flag，分别对应那两组表，目录内的规则也同mb 目录file规则同mb 翻译工具海外专员翻译工具路径：svn://zentia/welcome/LangTool海外专员一般是市场部同学。负责将待翻译的文本到处，然后发给海外运营商翻译，并且将译文导入公用词条库里。 项目分支翻译工具路径：svn://zentia/trunk/xxpub/LangTool（其余分支路径类似）项目的导入职能由产品负责需要在每个海外版本发布前，将特定分支生成海外文本资源并且上传。 多语言名字参照微软的多语言名称参考网站：https://www.microsoft.com/en-us/locale.aspx]]></content>
      <tags>
        <tag>sy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fork]]></title>
    <url>%2F2017%2F10%2F25%2Ffork%2F</url>
    <content type="text"><![CDATA[通过系统调用创建一个与原来进程几乎完全相同的进程，也就是说两个进程可以做完全相同的事情，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。一个进程调用fork()函数之后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后吧原来的进程的所有值都复制到新的进程中，只有少数值与原来进程的值不同。相当于克隆了一个自己。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849int whdaemon_init(bool bAutoCloseFD)&#123; printf("Transform to daemon ... "); pid_t pid; if( (pid=fork()) &lt; 0) &#123; printf("Failed!%s", WHINEED); return -1; &#125; else if(pid !=0) &#123; //parent goes bye-bye printf("SUCCESS, pid might be:%d!%s", pid+1, WHLINEEND); exit(0); &#125; // 关闭所有句柄 if (bAutoCloseFD) &#123; for (int i =0; i &lt; MAXFD; i++) &#123; close(i); &#125; &#125; else &#123; // 否则至少关闭标准的输入输出 close(0); close(1); close(2); &#125; // 变成seeion leader setsid(); signal(SIGHUP, SIG_IGN); // 结束第一个紫禁城 if ((pid=for() != 0)) &#123; exit(0); &#125; umask(0); return 0;&#125;]]></content>
      <tags>
        <tag>linux</tag>
        <tag>gcc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[time]]></title>
    <url>%2F2017%2F10%2F24%2Ftime%2F</url>
    <content type="text"><![CDATA[设置时间同步timedatectl set-ntp yes]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[systemctl]]></title>
    <url>%2F2017%2F10%2F24%2Fsystemctl%2F</url>
    <content type="text"><![CDATA[显示防火墙状态：systemctl status firewalld.service关闭防火墙：systemctl stop firewalld.service开启防火墙：systemctl start firewalld.service上面的firewalld的，不过我后来安装了iptables换一下就好了]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器搭建和日常维护]]></title>
    <url>%2F2017%2F10%2F24%2Fserver-set%2F</url>
    <content type="text"><![CDATA[1 概述2 系统软硬件要求软件：所有的服务器程序都可以在linux和windows系统上。推荐使用linux系统。我们一般使用的系统是suse10.1，不过按要求，我们在tlinux的服务器上实验编译并运行了我们的所有服务器成。Gcc版本：gcc(GCC)4.8.5数据库使用MYSQL。版本：5.6.38硬件：参考先前提供的硬件配置资料另外，请在启动文件/etc/rc.d/rc.local中设置共享内存、网络参数以及core文件模式123456789101112131415#increase Linux SHM maxecho 300000000 &gt; /proc/sys/kernel/shmmax#increase Linux TCP buffer limitsecho 8388608&gt;/proc/sys/net/core/rmem_maxecho 8388608&gt;/proc/sys/net/core/wmem_maxecho 262114&gt;/proc/sys/net/core/rmem_defaultecho 262114&gt;/proc/sys/net/core/wmem_default#increase Linux autotruning TCP buffer limitsecho &quot;4096 87380 8388608&quot;&gt;/proc/sys/net/ipv4/tcp_rmemecho &quot;4096 65536 8388608&quot;&gt;/proc/sys/net/ipv4/tcp_wmemecho &quot;8388608 8388608 8388608&quot;&gt;/proc/sys/net/ipv4/tcp_memecho &quot;840&quot;&gt;/proc/sys/net/ipv4/echo &quot;core-%e-%p-%s&quot;&gt;/proc/sys/kernel/core_pattern 3 维护人员账号配置为了安全的原因，请不要使用root账号进行服务器的维护工作。 4 MySQL的配置5 服务程序简介6 服务程序的版本辨认7 日志服务程序启动过程7.1 启动日志服务7.2 检查8 游戏服务器启动过程8.1 启动日志服务8.2 启动游戏总控框架8.3 启动游戏场景线8.4 检查9 服务组关闭过程10 YYCGZS的维护]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器安装说明]]></title>
    <url>%2F2017%2F10%2F24%2Fserver-install%2F</url>
    <content type="text"><![CDATA[解压服务器执行文件xx_svr_binfull_XXXX.tgz到指定文件夹。 解压配置文件xx_svr_cfgfull_XXXX.tgz到相同的文件夹。 解压配置文件xx_svr_resfull_XXXX.tgz到相同的文件夹。 将我们提供的key文件修改文件名为auth-info.key放在XCAAFS和XCLS文件夹下 XGMS目录下创建filecache目录，并给予执行服务器帐号写权限。 XLBA目录下创建siglog目录，并给予执行服务器帐号写权限。 确认pid文件目录/tmp有写权限，确认/data日志目录有写权限。 创建数据库，执行SQL下ca.sh，命令为：./ca.sh 版本后缀 地址如：./ca.sh sy xxsy.cxebfhyvgemb.us-east-2.rds.amazonaws.com 修改配置文件cmncfg.txt，主要修改如下：SVRGRPID 大区ID，如果需要在一个集群建立多个大区，则大区ID不可重复VER_EXT 版本后缀，同一台机器配置多组大区的时候必须不同ONEOUTERIP 对外IP，客户端主要从此IP连接服务器ONEINNERIP 服务器组内部IP，服务器间通信通过此IPMYSQLIP 数据库IPGDB_PORT 数据库端口DB_USER 数据库帐号DB_PASSWORD 数据库密码PORTSHIFT 同一台机器上启动多组服务器必须不同SHMSHIFT 同上注：如分开多台服务器架设还需要修改指定服务器地址 按照《服务器搭建和日常维护》文档第2节修改共享内存限制和tcp相关配置。 runGlog.sh启动日志服务器，一共15个进程。 执行run.sh启动服务器组。 共有IP:18.219.246.109私有IP:172.31.29.118]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uwa]]></title>
    <url>%2F2017%2F10%2F23%2Fuwa%2F</url>
    <content type="text"><![CDATA[AssetBundle lockpersistentmanager开销观察性能曲线，发现某一帧AssetBundle加载中，lockpersistentmanager耗时比较大。请问这块是否能够优化？这说明当前帧或前几帧中存在较大量的资源在通过LoadAsync来进行加载，其本质是所加载的资源过大所致，对自身资源进行合理优化可降低Loading.LockPersistentManager的开销。另外，将异步加载换成同步加载，LockPersistentManager就不会出现了，但其总加载耗时是没有变化的，因为总加载量没变。关于主要资源的加载优化，可参考如下链接：https://blog.uwa4d.com/archives/LoadingPerformance_Texture.htmlhttps://blog.uwa4d.com/archives/LoadingPerformance_Mesh.htmlhttps://blog.uwa4d.com/archives/LoadingPerformance_Shader.htmlhttps://blog.uwa4d.com/archives/Loading_AnimationClip.htmlhttps://blog.uwa4d.com/archives/livebroadcast6-8.html ** IN DIR:3rd, make dep with Makefile_debug.mk dep ** make[1]: 进入目录“/root/work_code/3rd” ** IN DIR:cryptlib, make dep with Makefile_debug.mk dep ** make[2]: 进入目录“/root/work_code/3rd/cryptlib” g++ -DLINUX -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -march=core2 -m32 -MM -MT &quot;../temp/debug/cryptlib/cpu.o_d&quot; -MF ../temp/debug/cryptlib/cpu.d_d cpu.cpp -I/usr/include/mysql -I/root/work_code/3rd -I/root/work_code/3rd/freetype221 -I/root/work_code/src/engine -I/root/work_code/src/svr -I/root/work_code/src/xxsy -I/root/work_code/src/svr/glogger/tlog/linux &lt;built-in&gt;:0:0: 致命错误：打开依赖文件 ../temp/debug/cryptlib/cpu.d_d：没有那个文件或目录 -DLINUX #define LINUX -D_FILE_OFFSET_BITS #define _FILE_OFFSET_BITS -D_LARGFEFILE64_SOURCEmarch指定的是当前cpu的架构，而mtune是真正作用于某一型号cpu的选项。 -M 生成文件关联的信息。 -MM 忽略由#include造成的依赖关系 -MF 指一个文件用于存放生成文件的关联信息，这些信息与-M或-MM是一样的， -MT 指定目标文件名 Camera.Render里面Animation.RebuildInternalState耗时较多之所以出现这一项，主要可以说以下两点：（1）项目用的是Animation老版动画系统；（2）对含有Animation组件的GameObject进行了大量频繁的Active或者Instantiate操作，一般这种情况比较常见于特效、UI HUD、角色/怪物等。 是否可以针对特定GameObject提升它的物理模拟次数我们在做一个尽速项目，发现有时候物理的计算并不是非常准确，在运动速度较快时，依然会和墙体造成部分穿插，这给我们的游戏带来了很不好的体验，我知道可以通过Fixed TimeStep来提升物理系统的每帧的计算速度，目前该值为0.02，也就是1秒计算50次，Edit&gt;Project Settings&gt;Time&gt;Fixed TimeStep=0.02。我们曾将其设置为0.005，穿插问题明显好转，但是看上去该值是对所有GameObject均使用的，所以我想问问能否仅针对某一个GameObject来进行提升它的物理计算频率？这是不行的，因为Fixed TimeStep是Unity引擎物理模块的全局参数。建议题主可以考虑将碰撞检测的模式改为”Continuous Dynamic”，看看是否满足需求。但是，需要说明的是，如果物体的速度确实非常快，那么任何一种碰撞模式都不能100%达到不穿插的效果。建议题主可以考虑增大碰撞体的Size或者通过射线求交的方式来将出现穿插问题的概率降到最低。 请教AssetBundle Diff Patch 方案是否可行我原先的更新方案是比对AssetBundle文件的hash值直接替换整个AssetBundle和manifest来达到更新效果的，有没有其它方案类似diff patch,可以减少更新包体，如果可以做diff patch，资源颗粒度是不是九可以忽略了基于AB的直接Diff更新目前没有成熟的方案，不过只把完整的Resources库中的部分资源更新的项目，已经做了2个了。思路其实很简单：1、出整包的时候，用ScriptableObject记录下AssetsDataBase中所有被发布资源的MD5码（不能用Unity自己的hash码）。2、用工具调出哪些assets是代码动态Load的，分一个Res包中；找出这些资源的依赖资源，分入一个Share包中，并记录每个Asset所属的AB包。3、出补丁时，对比当前AssetsDataBase中哪些代码中动态Load的资源出现了增加和改动（删除可以无视），包括他们依赖的资源。仍然把代码中动态Load的资源ResPatch中，依赖放入SharePatch中。对于没有变化的资源，仍然维持原来AB名字。4、记录下次补丁之后，更新每个Asset所属的AB包。5、下一次补丁时的Res和Share可能会依赖上一次的补丁的Share。6、运行时，对所有补丁入的Res建立一个字典索引。Load的时候，有限判断这个Asset是否在补丁的Res包中，如果是则读补丁的AB包，并按套路处理依赖包。否则就用二进制版本内建的包 这种做法的好处是：1、充分利用版本中的已经发布的资源，以减小补丁包的体积2、补丁包的打包规则可以几乎无视完整包的分包规则，方便后续折腾 当然缺点也是很严重的： Reserved Total - Unity引擎在内存方面的总体分配量。Unity引擎的内存并不是随用随取，而是预先从操作系统中申请一块，然后再进行使用。 Uesd Total - Unity引擎再内存方面的总体使用量。 Reserved Unity &amp; Used Unity - Unity引擎自身各个模块内部的内存分配，宝库偶各个Manager的内存占用、序列化信息的内存站哟个，WebStream/SerializedFile内存占用和部分资源的内存暂用等等。 看知乎的时候发现一个好玩的东西，https://lab.uwa4d.com/lab/5bc42d5404617c5805d4d685 UGUI绘制图表工具，一直想做一个性能分析工具。GDC2018中描述了Northlight引擎的内部实现和渲染相关的一些最新进展。前育碧的两位资深老员工成立Second Order公司后，开发了第一款游戏《Claybook》，其中包括了许多创新技术，比如基于GPU渲染的粘土与流体模拟、完全可变性的世界与角色、光线追踪的视觉效果。 请问Unity的stats窗口上显示的Batches和SnapdragonProfiler转出来的DC差距比较大可能是因为什么？ 这个Batches的数量其实并不代表DrawCall的数量，他其实和Render面板Total Batches的数量匹配，你如果要看DrawCall的数量，那么可以查看Render面板上面的DrawCall统计，这个统计应该和你SnapdragonProfiler抓出来的差不多。然后再贴一下Rendering面板上几个参数代表啥意思，仅供参考。这是我本机的截图 Render界面各个参数说明SetPass Calls:shader状态切换次数Draw Calls:绘制调用次数Total Batches:总合批的数量=静态合批+动态合批+实例合批；这个数一定是比Draw Calls的数量小，小的越多说明合并的物体越多。动态合批：Batched Draw calls:表示合批过的mesh数，比如上面显示的60个mesh合批。动态合批：Batched：表示合批的次数，上面截图数据说明60个mesh通过47次合批才完成。其实如果情况好的时候可能几次合批就能够合并掉60个mesh，可惜可能是很多属性不符合动态合并要求。静态合批与实例化与上面动态合批的解释相同。 so热更新除了只更新il2cpp.so还是修改global-metadata.data，其他的so不需要更新。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcc]]></title>
    <url>%2F2017%2F10%2F23%2Fgcc%2F</url>
    <content type="text"><![CDATA[extern staticextern 指为导出到其它文件所使用的非statice变量static是当前文件的静态变量二者不能同时定义setarch i386 ./config -m32编译32位的openssh缺少 gnu/stubs-32.h yum install glibc-devel.i686 gcc没有找到 yum install libstdc++-devel.i686 yum install -y gcc gcc+ gcc-c++]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>gcc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader PBR]]></title>
    <url>%2F2017%2F10%2F23%2FShaderLab%2F</url>
    <content type="text"><![CDATA[观察两个空间阴影映射(Shadow Mapping)牵涉到两个空间的Z深度比较,一个是灯光空间,一个是相机空间,首先打开ShadowMapping_2下的场景,场景是默认的相机视角,单击下面的Light View按钮,可以切换到灯光视角,13.1.2 两个视角的Z深度分别单机LightView Depth和CamView Depth,然后到Shadow/ShadowMapping工程文件夹下面找到_CamViewZDepth和_LightViewZDepth两张Render Texture,查看一下渲染输出的ZDepth13.1.3 渲染Z深度的材质这两张ZDepth是分别在灯光视角和相机使用Replacement Shader 渲染出来的在vertex函数vert中,主要操作除了对物体形体的必要输出外,就是UNITY_TRANSFERDEPTH(o.depth),打开UnityCG.cginc文件,会发现它一般情况下的操作就是o.depth = o.pos.zw,把物体在投影空间做的zw值赋给o.depth,再将它的值输出到一张Render Texture 之前,通过Linear01Depth(d)函数把Z的值变换到01空间,这样我们可以看到一张对比度更强的Z深度图,就像在上面所看到的那样,而不是一张大多数情况下都朦朦胧胧的Z深度图13.2 投射Z深度13.2.1 准备灯光视角的投影矩阵 在进行映射阴影经典的Z深度比较之前,我们需要把灯光视角ZDepth深度图投射到相机视角.打开ShadowMapping_3下的场景.和上一个场景系相比,附加在Main Camera物体上的ShadowMapping_3.cs13.3.4 对Z值进行偏移显然,Z的精度是个问题,而且通过上述编码操作我们已经解决了Shadow ance的问题,但是主要问题依然,这个现象叫Peter Panning,源自迪尼斯的一部动画主角Peter Pan,他的影子可以脱离自身活动起来,打开 分开处理反射面的绝缘体特性和金属属性，最后光照应该是Diffuse+Specular 纯金属没有Diffuse，非金属主要是Diffuse，有一点反射 光部分主要有3个东西影响：微表面的法线分布（NDF），微表面的入射和反射遮挡（Geometry Function），反射率和入射角的关系（Fresnel反射）。]]></content>
      <tags>
        <tag>Shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[index newindex rawset rawget setmetatable]]></title>
    <url>%2F2017%2F10%2F23%2Fnewindex%2F</url>
    <content type="text"><![CDATA[__index可以当作get方法，获取一个value值，不在当前表的时候就会去元表查询，元表首先调用这个函数，如果这个函数没有重写，那么直接从元表中查找key对应的value，如果函数被重写了，任何从元表的get方法都只走这里，而不从元表查找，规则如下： 如果__index是一个函数，则读取table不存在的字段时，会调用这个函数。 如果__index是一个table，则读取table不存在的字段时，会直接读取__index的table值。 __newindex可以当作set方法，设置一个key,value值，如果当前表没有这个值，那么会调元表中的__newindex方法，规则如下： 如果__newindex是一个函数，则在给table不存在的字段赋值时，会调用这个函数。 如果__newindex是一个table，则在给table不存在的字段赋值时，会直接给__newindex的table赋值。 rawset使用这个函数，直接设置当前表的key,value值，不管是否有__newindex方法。 rawget使用这个函数，仅能从当前表获取值，即使当前表没有值，元表有值，也不会返回元表的值，而是返回nil。 setmetatable使用这个函数，可以给当前表设置一个元表。 12345678910111213141516local smartMan = &#123; name = "lyf", money = 900, sayHello = function() print("hello,I’m lyf"); end&#125;local t1 = &#123;&#125;local mt = &#123; __index = smartMan,&#125;setmetatable(t1, mt);t1.sayHello = function() print("en");endt1.sayHello() 这是一个模仿继承结构的例子mt作为t1的元表,设置__index为smartMan，于是，当我们调用t1中不存在的字段时，就会自动去smartMan中查找，比如我们调用了t1.sayHello()，自然就能找到对应的函数。12345678910111213141516171819local smartMan = &#123; name = "none", money = 9000000, sayHello = function() print("Hello world!"); end&#125;local t1 = &#123;&#125;;local mt = &#123; __index = smartMan, __newindex = function(table, key, value) print(key .. "字段是不存在的，不要试图给它赋值！"); end&#125;setmetatable(t1, mt);t1.sayHello = function() print("en");endt1.sayHello() 留意mt元表,我们给他加了一个__newindex，导致sayHello字段赋值失败，因为给sayHello字段赋值的时候，调用了__index元方法，代替了赋值操作，和__index一样，__newindex元方法也可以赋值一个table。 Lua类和继承实现Lua本身不能像C++那样直接实现继承，但是可以用table来实现1234567Object = &#123;class_id = 0&#125;funtion Object:New(o) o = o or &#123;&#125; setmetatable(o, self) -- 对象o调用不存在的成员时会去self中查找，而这里的self指的就是Object self.__index = self return oend]]></content>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言高级部分总结]]></title>
    <url>%2F2017%2F10%2F22%2Fc%2F</url>
    <content type="text"><![CDATA[先被声明为‘extern’后又被声明为‘static’In file included from src/mt_mysql_connector.cpp:14:0:/usr/include/mysql/my_global.h: 在函数‘double log2(double)’中:/usr/include/mysql/my_global.h:823:35: 错误：‘double log2(double)’先被声明为‘extern’后又被声明为‘static’ [-fpermissive] static inline double log2(double x)static 声明的全局变量只能在当前源文件中使用。extern不是定义，是引入（声明）在其它源文件中定义的非static全局变量 内存大话题内存就是程序的立足之地，体现内存重要性。内存理解:内存物理看是有很多个Bank（就是行列珍式的存储芯片），每一个Bank的列就是位宽，每一行就是Words，则存储单元数量=行数（words）x列数（位宽）xBank的数量；通常也用MxW的方式来表示芯片的容量（或者说是芯片的规格/组织结构）。M是以位宽为单位的总容量，单位是兆，W代表位宽，单位是bit。计算出来的芯片容量也是以bit为单位，但用户可以采用除以8的方法换算为字节（Byte）。比如8Mx8，这是一个8bit位宽芯片，有8M个存储单元，总容量是64Mbit（8MB）。 c语言中其实没有bool类型:以0表示假，非0表示真，则在内存存储是以int型存放的。如果想要表示真假，可以用int/char型做替换，在c++中就有bool x=true/false。 内存对齐:提高内存访问效率，编译器一般默认是4字节 char/int/short/long/float/double类型放在内存的长度和解析作用。(int*)0，使用0地址指向一个int行。又如0000111010101可以解析成int型也可以解析成float型。 Linux内核是面向对象的，而c语言是面向过程的，但可以用结构体内嵌指针变成面向对象。如 1234567struct student&#123; int age; int length; char *name; void (*eat)(void); // 实现多态&#125;; 栈的理解： 运行时自动分配&amp;自动回收：栈是自动管理的，代码无需干预。（表现在汇编代码，编译时，会自动编译成汇编实现函数调用完立即改变栈顶） 反复使用：栈内存在程序中其实就是那一块空间，程序反复使用这一块空间（硬件上有个寄存器，用来存放栈的栈顶地址，栈是有大小的空间） 脏内存：栈内存由于反复使用，每次使用后程序不会去清理，因此分配到原来保留的值。 临时性：函数不能返回栈变量的指针，因为这个空间是临时的。 栈会溢出：因为操作系统事先给定了栈的大小，如果在函数中无穷尽的分配栈内存总能用完。栈的操作是由具体硬件干预的，我们只要明白原理就可以了，但是要给相应的栈寄存器赋值。当调用函数时，变量会自动放在栈中（入栈）当函数调用完后，栈会自动出栈。 栈的“发展”有四种情况，满增栈，满减栈，空增栈，空减栈，至于是哪种要根据编译器决定，而s5pv32是满减栈。 堆的理解 操作系统堆管理器管理，堆管理器是操作系统的一个模块，堆管理器内存分配灵活，按需分配。 大块内存：堆内存管理者总量很大的操作系统内存块，各进程可以按需申请使用，使用完释放。 脏内存：堆内存也是反复使用的，而且使用者用完释放前不会清除，因此也是脏的。 临时性：堆内存只在malloc和free之间属于当前进程，可以访问，在malloc和free之后都不能在访问，否则会有不可预料的后果。 程序手申请释放]]></content>
      <tags>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua-select]]></title>
    <url>%2F2017%2F10%2F20%2Flua-select%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Lua]]></title>
    <url>%2F2017%2F10%2F20%2Flua%2F</url>
    <content type="text"><![CDATA[让lua编译时计算由于lua的编译速度相当快，而且这种迭代编译的过程仅仅在程序加载的时候进行一次，故而可以带来性能的提高；一些在系统初始化可以决定的参数（比如从配置文件中读出来的数据直接编译为常量置入程序中。 1234567891011121314151617local select = selectlocal setmetatable = setmetatablelocal getfenv = getfenvlocal setfenc = setfenvlocal loadstring = loadstringlocal type = typelocal tostring = tostringlocal next = nextlocal unpack = unpacklocal assert = assertlocal string = stringlocal table = tablelocal io = iolocal function result(...) return select("#", ...), select(1, ...) -- 参数的个数，第一个参数end Lua的upvalue和闭包Lua函数可以被当成参数传递，也可以被当成结果返回，在函数体中仍然可以定义内嵌函数，Lua闭包是Lua函数生成的数据对象。每个闭包可以有一个upvalue值，或者多个闭包共享一个upvalue值。 什么是JITJIT=Just In Time即时编译，是动态编译的一种形式，是一种优化虚拟机运行的技术。程序运行通常有两种方式，一种是静态编译，一种是动态编译，即使编译混合了这二者。Java和.Net/mono中都使用了这种技术。然而IOS中禁止使用（不是针对JIT，而是所有的动态编译都不支持） 为什么要使用JIT解释执行： 效率低 代码暴露 静态编译： 不够灵活，无法热更新 平台兼容性差。 JIT： 效率：高于解释执行，低于静态编译。 安全性：一般都会先转换成字节码。 热更新：无论源码还是字节码本质都是资源文件。 兼容性：虚拟机会处理平台差异，对用户透明。 JIT是如何实现的这里讲的实际上是JIT的一个变种：自适应动态编译(adaptive dynamic compilation)。它分为两种：Method JIT和Trace JIT。简单来讲： 跟踪热点函数或trace，编译成机器码执行，并缓存起来供以后使用。 非热点函数解释执行。 为什么只编译热点函数？对只执行一次的代码而言，解释执行其实总是比JIT编译要快。对这些代码做JIT编译在执行，可以说是得补偿式。而对于只执行少量次数的代码，JIT编译带来的执行速度的提升也未必必能抵消掉最初编译带来的开销。只有对频繁执行的代码，JIT编译才能保证有正面的收益。 Lua元素(Metatable)1.定义算术操作符和关系操作符的行为 + __add * __mul - __sub / __div - __unm(for negation) 自减 % __mod ^ __pow 关系操作符 == __eq &lt; __lt &lt;= __le 当我们访问某个不存在的字段的时候，就会调用__index元方法。 源文件划分1.虚拟机运转核心功能|源文件名 |功能 |前缀||———————:|———————————————:|—-:||lapi.c |C语言接口 |luaC||lctype.c |C标准库中ctype相关实现 |||ldebug.c |Debug 接口 |||ldo.c |函数调用以及栈管理 |luaD||lfunc.c |函数原型及闭包管理 |||lgc.c |垃圾回收 |||lmem.c |内存管理接口 |||lobject.c |对象操作的一些函数 |||lopcodes.c |虚拟机的字节码定义 |||lstate.c |全局状态机 |||lstring.c |字符串池 |||ltable.c |表类型的相关操作 |luaH||ltm.c |元方法 |||lvm.c |虚拟机 |||lzio.c |输入流接口 |luaZ| 2.源代码解析以及预编译字节码|源文件名 |功能 |前缀||———————:|———————————————:|—-:||lcode.c |代码生成器|||ldump.c |序列化预编译的Lua字节码|||llex.c |词法分析器|||lparser.c |解析器|||lundump.c |还原预编译的字节码|| 3.内嵌库|源文件名 |功能 |前缀||———————:|———————————————:|—-:||lauxlib.c |库编写用到的辅助函数库|||lbaselib.c |基础库|||lbitlib.c |位操作库|||ldblib.c |Debug库|||lini.c | 内嵌库的初始化|||liolib.c |IO库|||lstrlib.c |字符串库|||ltablib.c |表处理库|| 4.可执行的解析器，字节码编译器|源文件名 |功能 |前缀||———————:|———————————————:|—-:||lua.c |解释器|||luac.c |字节码编译器|| Lua核心Lua核心部分仅包括Lua虚拟机的运转。Lua虚拟机的行为是由一组组opcode控制的。这些opcode定义在lopcodes.h及lopcodes.c中。而虚拟机对opcode的解析和运作在lvm.c中，其API以luaV为前缀。 Lua虚拟机的外在数据形式是一个lua_State结构体，取名State大概意为Lua虚拟机的当前状态。全局State引用了整个虚拟机的所有数据。这个全局State的相关代码放在lstate.c中，API使用luaE为前缀。 函数的运行流程：函数调用及返回则放在ldo.c中，相关API以luaD为前缀。 Lua中最复杂和重要的三种数据类型function、table、string的实现分属在lfunc.c、ltable.c、lstring.c中。这三组内部API分别以luaF、luaH、luaS为前缀命名。不同的数据类型最终呗统一定义为LuaObject，相关操作在lobject.c中，API以luaO为前缀。 Lua从第五版后增加了元表，元表的处理在ltm.c中，API以luaT为前缀。 另外，核心系统还用到两个基础设施：内存管理lmem.c，API以luaM为前缀；带缓存的流处理lzio.c，API以luaZ为前缀。 最后是核心系统里最为复杂的部分，垃圾回收部分，在lgc.c中实现，API以luaC为前缀。 Lua设计的初衷之一就为了最好的和宿主系统相结合。它是一门嵌入式语言，所以必须提供和宿主系统交互API。这些API以C函数的形式提供，大多数实现在lapi.c中。API直接以lua为前缀，可供C编写的程序库直接调用。 代码翻译及预编译字节码光有核心代码和一个虚拟机还无法让Lua程序运行起来。因为必须从外部输入将Lua运行起来。Lua的脚本需要经过解析得到内部的数据结构（常量和opcode的集合）。这个是用parser:lparser.c （luaY:语法解析)及词法分析llex.c(luaX) 解析完脚本代码，还需要最终生成code码，在lcode.c中实现。luaK 为了满足某些需求，加快代码翻译的流程。还可以采用预编译的过程。把运行时编译的结果，生成为字节码。这个过程以及逆过程由ldump.c和lundump.c实现。luaU 内嵌库作为嵌入式语言，其实完全可以不提供任何库及函数。全部由宿主系统注入到State中即可。也的确有许多系统是这么用的。但Lua的官方版本还是提供了少量必要的库。尤其是一些基础函数paris、error、setmetatable、type等等，完成了语言的一些基本特性，几乎很难不使用。 而coroutine、string、table、math等等库，也很常用。Lua提供了一套简洁的方案，允许你自由加载你需要的部分，以控制最终执行文件的体积和内存的占用量。主动加载这些内建库进入lua_State，是由在lualib.h中的API实现的。 1234567891011121314static TValue *index2addr (lua_State *L, int idx) &#123; CallInfo *ci = L-&gt;ci; if (idx &gt; 0) &#123; TValue *o = ci-&gt;func + idx; api_check(L, idx &lt;= ci-&gt;top - (ci-&gt;func + 1), "unacceptable index"); if (o &gt;= L-&gt;top) return NONVALIDVALUE; else return o; &#125; else if (!ispseudo(idx)) &#123; /* nagative index */ api_check(L, idx != 0 &amp;&amp; -idx &lt;= L-&gt;top - (ci-&gt;func + 1), "invalid index"); return L-&gt;top + idx; &#125; ...&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class LuaMgr&#123; public static Module GetModule(string name) &#123; Module m = m_modules.PG_TryGetValue(name); if (m == null) &#123; ... &#125; // repeat if (m.m_state != Module.State.None) &#123; if (m.m_state == Module.State.Failed) return null; return m; &#125; var L = m_L;//lua_State string[] names = name.Split(m_dotSep); // mulit file LuaDLL.lua_pushvalue(L, LuaIndexes.LUA_GLOBALSINDEX); // 0 for (int i = 0; i &lt; names.Length; ++ i) &#123; LuaDLL.lua_pushstring(L, names[i]); LuaDLL.lua_rawget(L, -2); // var t = LuaDLL.lua_type(L, -1); // 1 switch (t) &#123; case LuaTypes.LUA_TNIL: LuaDLL.lua_pop(L, 1); luaDLL.lua_newtable(L); luaDLL.lua_pushstring(L, names[i]); luaDLL.lua_pushvalue(L, -2); LuaDLL.lua_rawset(L, -4); // _G.name = module LuaDLL.lua_rawgeti(L, LuaIndexes.LUA_REGISTRYINDEX, m_ref_globalMeta); LuaDLL.lua_setmetatable(L, -2); LuaDLL.lua_pushvalue(L, -1); LuaDLL.lua_setfield(L, -2, "_M"); // module._M = module break; case LuaTypes.LUA_TTABLE: break; default: m.m_state = Module.State.Failed; LuaDLL.lua_pop(L, 2); return null; &#125; LuaDLL.lua_remove(L, -2); &#125; m.m_index = ++m_moduleIndex; m.m_ref_module = LuaDLL.luaL_ref(L, luaIndexes.LUA_REGISTRYINDEX); ReloadModule(m); return m; &#125;&#125;public static int LoadModule()&#123; var L = LuaMgr.m_L; string name = LuaDLL.lua_tosting(L, 1); var m = LuaMgr.GetModule(name); LuaDLL.lua_pushboolean(L, m != null); return 1;&#125; 阅读源代码的次序首先、阅读外围的库是如何实现功能扩展的，这样可以熟悉Lua公开API，不必陷入功能细节。然后、阅读API的具体实现。Lua对外暴露的API可以说是一个对内部模块的一层封装，这个层次尚未触及核心，但可以对核心代码有个初步的了解。之后、可以开始了解Lua VM的实现。接下来就是分别理解函数调用、返回，string,table,metatable等如何实现。debug模块是一个额外的设施，但可以帮助你理解Lua内部细节。最后是parser等编译相关的部分。垃圾回收是最难的部分，可能会花掉最多的时间去理解细节。 Lua模块与包模块类似于一个封装库，从Lua5.1开始，Lua加入了标准的模块管理机制，可以把一些公用的代码放在一个文件里，以API接口的形式在其他地方调用，有利于代码的重用和降低代码耦合度。Lua的模块是由变量、函数等已知元素组成的table，因此创建一个模块很简单，就是创建一个table，然后把需要导出的常量、函数放入其中，最后返回这个table就行。以下为创建自定义模块module.lua，文件代码格式如下：1234567891011121314151617-- 文件名module.lua-- 定义一个名为module的模块module = &#123;&#125;-- 定义一个常量module.constant = "这是一个常量"-- 定义一个函数function module.func1() io.write("这是一个公有函数！\n")endlocal function func2() print("这是一个私有函数！")endfunction module.func3() func2()endreturn module 由上可知，模块的结构就是一个table的结构，因此可以像操作table里的元素那样来操作调用模块里的常量或函数。上面的func声明为程序块的局部变量，即表示一个私有函数，因此是不能从外部访问模块里的这个私有函数，必须通过模块的公有函数来调用。 require 函数Lua提供了一个名为require的函数用来加载模块。要加载一个模块，只需要简单地调用就可以了。例如： require(&quot;&lt;模块名&gt;&quot;) 或者 require &quot;&lt;模块名&gt;&quot; 执行require后会返回一个由模块常量或函数组成的table，并且还会定义一个包含该table的全局变量。 加载机制对于自定义的模块，模块文件不是放在哪个目录都行，函数require有它自己的文件路劲加载策略，它会尝试从Lua文件或C程序库中加载模块。require用于搜索Lua文件的路径是存放在全局变量package.path中，当Lua启动后，会以环境变量LUA_PATH的值来初始这个环境变量。如果没有找到该环境变量，则使用一个编译时定义的默认路径来初始化。当前目录也会加载]]></content>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[expect]]></title>
    <url>%2F2017%2F10%2F19%2Fexpect%2F</url>
    <content type="text"><![CDATA[安装 yum install -y tcl tclx tcl-develExpect是一个免费的免费的编程工具语言，用来实现自动和交互任务进行通信，而无需人的干预。expect是交互性很强的脚本语言，可以帮助运维人员实现批量管理成千上百台服务器操作，是一款很实用的批量部署工具！下载：expect-5.43.0.tar和tcl8.4.11-src.tar]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作记录]]></title>
    <url>%2F2017%2F10%2F19%2Fserver%2F</url>
    <content type="text"><![CDATA[pwd: ~/work_codemkdbg_allvim src/ini/Jenkins_Script/compile.sh IN DIR:BNMSGamePlay, make all with Makefile_debug.mk all 115 make[3]: 进入目录“/root/work_code/src/svr/BNMSGamePlay”116 ==== making DLL file … ====117 g++ -DLINUX -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -Wall -Wno-multichar -g -D_DEBUG -DPG_MEMORY_DISABLE_POOL -march=core2 -m32 -rdynamic -std=c++0x -o ../../bin/debug/svr/BNMSGamePlay/BNMSGamePlay_d.so ../../temp/debug/svr/BNMSGamePlay/BNMSGamePlay.s.o_d /root/work_code/src/lib/libBNMSGamePlay_Lib_d.s.a /root/work_code/src/lib/lib PNGS_d.s.a /root/work_code/src/lib/libWHNET_d.s.a /root/work_code/src/lib/libWHCMN_d.s.a -lpthread -ldl -lrt -march=prescott -shared -L/root/work_code/3rd/lib -L/root/work_code/src/lib118 /usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/4.8.5/libstdc++.so when searching for -lstdc++119 /usr/bin/ld: cannot find -lstdc++120 /usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/4.8.5/libgcc_s.so when searching for -lgcc_s121 /usr/bin/ld: cannot find -lgcc_s122 collect2: 错误：ld 返回 1123 make[3]: * [../../bin/debug/svr/BNMSGamePlay/BNMSGamePlay_d.so] 错误 1124 make[3]: 离开目录“/root/work_code/src/svr/BNMSGamePlay” 1ldconfig #更新缓冲 g++ -DLINUX -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -Wall -Wno-multichar -g -D_DEBUG -DPG_MEMORY_DISABLE_POOL -march=core2 -m32 -rdynamic -std=c++0x -o ../../bin/debug/xxsy/ScnSvr_AllInOne/ScnSvr_AllInOne_d ../../temp/debug/xxsy/ScnSvr_AllInOne/ScnSvr_AllInOne.o_d /root/work_code/src/lib/libGSDB_Lib_d.a /root/work_code/src/lib/li bScnSvr_d.a /root/work_code/src/lib/libGZSGamePlay_Lib_d.a /root/work_code/src/lib/libMCE4Chat_d.a /root/work_code/src/lib/libMCE_d.a /root/work_code/src/lib/libDIA4DBI_d.a /root/work_code/src/lib/libDIA_d.a /root/work_code/src/lib/libPNGS_d.a /root/work_code/src/lib/libWHNET_d.a /root/work_code/src/lib/libWHCMN_d.a /root/work_code/src/lib/libxxsy_cmn_d.a /root/work_code/src/lib/libpgcmn_d.a -lpathfind_d -lcJSON_d -lcryptlib_d -llua_d -lzlib_d -ltss_sdk_d -lz -ldl -lssl -lpthread -ldl -lrt -march=prescott -L/root/work_code/3rd/lib -L/root/work_code/src/libg++ -DLINUX -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -Wall -Wno-multichar -g -D_DEBUG -DPG_MEMORY_DISABLE_POOL -march=core2 -m32 -rdynamic -std=c++0x -o ../../bin/debug/xxsy/ScnSvr_AllInOne/ScnSvr_AllInOne_d ../../temp/debug/xxsy/ScnSvr_AllInOne/ScnSvr_AllInOne.o_d /root/work_code/src/lib/libGSDB_Lib_d.a /root/work_code/src/lib/libScnSvr_d.a /root/work_code/src/lib/libGZSGamePlay_Lib_d.a /root/work_code/src/lib/libMCE4Chat_d.a /root/work_code/src/lib/libMCE_d.a /root/work_code/src/lib/libDIA4DBI_d.a /root/work_code/src/lib/libDIA_d.a /root/work_code/src/lib/libPNGS_d.a /root/work_code/src/lib/libWHNET_d.a /root/work_code/src/lib/libWHCMN_d.a /root/work_code/src/lib/libxxsy_cmn_d.a /root/work_code/src/lib/libpgcmn_d.a -lpathfind_d -lcJSON_d -lcryptlib_d -llua_d -lzlib_d -ltss_sdk_d -lz -ldl -lssl -lpthread -ldl -lrt -march=prescott -L/root/work_code/3rd/lib -L/root/work_code/src/lib -pthread/root/work_code/3rd/lib/liblua_d.a(core_profiler.o_d)：在函数‘lprofP_init_core_profiler’中：/root/work_code/3rd/lua/profiler/core_profiler.c:154: 警告：the use of tmpnam&#39; is dangerous, better usemkstemp’/usr/bin/ld: /root/work_code/src/lib/libScnSvr_d.a(RegScn.o_d): undefined reference to symbol ‘EVP_sha256@@libcrypto.so.10’/lib/libcrypto.so.10: error adding symbols: DSO missing from command line]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware12中CentOS7网络设置]]></title>
    <url>%2F2017%2F10%2F18%2FVm%2F</url>
    <content type="text"><![CDATA[VMware提供了三种将虚拟网卡和物理网卡捆绑起来的方式，即桥接(Bridge）模式，网络地址转换(Network Address Transformation, NAT)模式和主机(Host Only)模式。三种模式区别，参见关于三种模式的区别，简单而言，Bridge模式直接将虚拟机添加到局域网中，使虚拟机看起来像网内的一台真实计算机，虚拟网卡和宿主物理网卡之间不存在名义上的从属关系，因而需要局域网内具有多余的IP地址能够提供给虚拟机网卡，如果局域网内严格给每台计算机分配固定的IP，那这种Bridge模式就基本失效。在Bridge模式下虚拟机既可以访问到Internet也可以同局域网内的其他真实计算机通信；NAT模式下宿主的物理网卡就充当了路由器或交换机的角色，这时VMware会根据宿主的真实IP提供很多Subset IP供虚拟机使用，这样所有的虚拟机都是通过宿主的网络端口进行对Internet的访问，但看起来这些虚拟计算机都合法地访问到了局域网或者Internet，因为他们的IP地址通过NAT技术之后看起来是合法的。Host Only模式下虚拟机之间可以相互通信，但虚拟机并不能同局域网内的其他真实计算机直接通信，但该模式下通过宿主访问Internet还是可以的。VM的虚拟网卡可以被设置成上述的三种网络连接模式，默认情况下，VMnet0被设置成为Bridge模式，VMnet1被设置为Host Only模式，而VMnet8的默认连接方式为NAT模式。VMnet2-VMnet7和VMnet9这七块虚拟网卡用户可以自定义，但是在所有的虚拟网卡中仅有一块能被设置为NAT模式，默认情况就是VMnet8。用户可以在VMware workstation-&gt;编辑-&gt;虚拟网络编辑器 中查看这些信息。这里已NAT模式配置 打开“网络和共享中心”选择“VMware Virtual Ethernet Adapter for VMnet8”网卡右键属性，选择VMware Bridge Protocol,同时设置ip自动获取 将物理网卡网络分享给VMware Virtual Ethernet Adapter for VMnet8 虚拟机网络连接设置为NAT模式，选择虚拟机，右键》设置》网络适配器》NAT 模式 检验网络是否正常，不正常，检测ifcfg-e**(每台可能不一样)中的bootproto是不是dhcp，如果不是则修改为dhcp，此外还需要设置onboot = yes; 然后用命令service network restart重启网络连接，就可以连上网络了]]></content>
      <tags>
        <tag>VMware</tag>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[www]]></title>
    <url>%2F2017%2F10%2F16%2Fwww%2F</url>
    <content type="text"><![CDATA[StartCoroutine开启一个协程，yield return是迭代器返回调用迭代的地方。协程至少产生十几还是多少B的GC具体是多少我忘记了，至少在5.3.8f2之前的版本是，未来如果有时间和有机会我会讲解一个可以避免掉GC的办法。CoroutineTool，本篇不再介绍范围内。一个协程的执行可以在任何地方用yield语句来暂停，yield return的值决定了什么时候协程恢复执行。WWW的加载方式，本身会增加FileSystem的崩溃率，然后还增加显存占用提高了Present的崩溃率。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins]]></title>
    <url>%2F2017%2F10%2F16%2FJenkins%2F</url>
    <content type="text"><![CDATA[添加Jenkins的源（repository） sudo wget -O /etc/yum.repos.d/jenkins.repo http://jenkins-ci.org/redhat/jenkins.repo sudo rpm —import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key 安装/检查JDK java —version # 这个必须安装成功 sudo yum install java-1.6.0-openjdk # 我用的1.8 安装Jenkins: sudo yum install jenkins 安装完成后，有如下相关目录：/usr/lib/jenkins/ :jenkins安装目录，WAR包会放在这里。 cd /usr/lib/jenkins ll 启动Jenkins echo &amp;JAVA_HOME /usr/java/…(懒的复制了)昨天还好好的，今天不知道为什么访问不了，各种查最后通过 service jenkins start搞定了，但是昨天一直没关，ps -aux | grep “jenkins” 也能找到。奇怪。不过使用service jenkins start之后多了一个。]]></content>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[makefile]]></title>
    <url>%2F2017%2F10%2F15%2Fmakefile%2F</url>
    <content type="text"><![CDATA[make: Nothing to be done for xxxx中间文件、链接文件C、C++要把源文件编译成中间代码文件，在Windows是.obj文件，在Linux是.o文件，即Object File，这一步叫做编译。然后把这些Object File合成可执行文件，这一步叫做链接(link)。编译时，编译器需要的是语法正确，函数和变量声明正确，然后编译中中间目标文件。一般来说每个源文件都对应一个中间目标文件（O文件或者OBJ文件）。链接主要是链接函数和全局变量，所以我们可以使用这些中间目标文件来链接我们的可执行文件。链接器并不考虑源文件，只考虑中间目标文件（OBJ文件），大点的项目文件成千上百，导致会变成生成太多的中间文件，而链接时需要明确指出中间目标文件名，这对于编译很不方便，所以出现了库文件来合并这些目标文件windows下“库文件”（Library File）.lib文件，在Liunx下叫Archive File（.a）文件，所以一般包Link 错误就是指没有找到这个中间文件，即没有找到该声明的实现（一般情况下）。 Makefilemake命令执行时，需要一个Makefile（一般是.mk 缺省Makefile或者makefile，作者习惯Makefile.mk）文件，告诉make命令如何编译和链接程序。规则：1234target ... : prerequisites ... command ... ... target也就是一个目标文件，可是是Object File，也可以是执行文件。还可以是一个标签（Label）。prerequisites就是，要生成那个target所需要的文件或目标。command是make需要执行的命令。（Shell命令）这是一个依赖关系，就是说，target这一个或多个目标文件依赖于prerequisties中的文件，而规则是由command决定的。也就是说，prerequisites中如果有一个以上的文件比target文件要新的话，command所定义的命令就会被执行。这就是Makefile的规则。 ifeq的用法 ifeq($(SRCFILE),) else ifeq() endif如果没有变量值，则判断是否定义，有则判断是否相等./test.sh -f config.conf -v —prefix=/home我们称-f为选项，它需要一个参数，即config.conf，-v也是一个选项，但它不需要参数。—prefix我们称之为长选项，即选项本身多余一个字符，它也需要一个参数，用等号连接，当然等号不是必须的，/home可以直接卸载—prefix后面，即—prefix/home。伪目标、虚目标伪目标不是一个真正的文件名，在执行make时可以指定这个目标执行 如果我们需要书写这样一个规则：规则所定义的命令不是去创建目标文件，而是使用make指定具体的目标来执行一些特定的命令。像下边那样： clean: rm .o temp规则中”rm”不是创建文件”clean”的命令，只是删除当前目录下的所有.O文件和temp文件。在工作目录下不存在”clean”这个文件时，我们输入”make clean”后，”rm .o temp”总会被执行。这是我们的初衷。但当前工作目录下存在”clean”时情况就不一样了，在我们输入”make clean”时。规则没有依赖文件，所以目标被认为是最新的而不去执行规则所定义的命令，命令”rm”将不会被执行。这并不是我们的初衷。为了避免这个问题，我们可以将目标”clean”明确声明为伪目标。讲一个目标声明为伪目标需要将它作为特殊目标.PHONY的依赖。如下： .PHONY: dummy_help all dep obj cleanobj cleanint cleanout clean veryclean verycleanint install dirint dirout dirs pch cleanpch这样dummy_help等就是一些伪目标或者说是虚目标，无论当前目录下是否存在”clean”这个文件。我们输入”make clean”之后，”rm”命令都会被执行。而且当一个目标被声明为伪目标后，make在执行规则时不会试图去查找隐含规则来创建这个目标。这样也提高了make的执行效率，同时我们也不用担心由于目标和文件名重名而使我们的期望失败。在书写伪目标规则时，首先需要声明目标是一个伪目标，之后才是伪目标的规则定义。目标”clean”书写格式应该如下： .PHONY: clean cleanint: cleanobj 移除所有临时文件(目标文件、依赖文件) $(RM) -f $(DEPFILE_TO_DEL) cleanout: ifeq ($(ISWHAT),LIB) 库 $(RM) -f $(TargetOutFile).* else ifeq ($(ISWHAT),EXE) EXE文件 $(RM) -f $(TargetOutFile) else DLL或其他 $(RM) -f $(TargetOutFile).* ifneq ($(OutDirLib),) $(RM) -f $(TargetOutFileLib).* endif endif endif cleanpch: $(RM) -f $(PchFile) clean: cleanint cleanout cleanpch @echo ==== clean now ==== 通配符通配符是一种特殊语句，主要有星号(*)和问号(?)，用来模糊搜索文件 Makefile中的wildcard用法在Makefile规则中，通配符会被自动展开。但在变量的定义和函数引用时，通配符将失效。这种情况下如果需要通配符有效，就需要使用函数”wildcard”，它的用法是：$(wildcard PATTERN…)。在Makefile中，它被展开为已经存在的、使用空格分开的、匹配此模式的所有文件列表。如果不存在任何符合此模式的文件，函数会忽略模式字符并返回空。需要 Linux make 保存错误日志$mkdbg all 2&gt;&amp;1|tee xxx.log这条命令是编译并保存打印信息。在Linux Shell的设备定义中，“0”表示标准输入，“1”表示标准输出，“2”表示标准出错信息输出。2&gt;&amp;1表示把2设备的信息重定向到1设 备；“|”是管道符号，把标准输出的信息直接传递给后面的命令；tee是创建文件并保存信息的工具；xxx.log是文件名。这种管道的用法在Linux Shell命令中使用非常普遍。编译过程中都可以使用这个方法，生成日志文件，保存到buildlogs目录下。 1 # 编译模式名 2 ConfigurationName := debug 3 # 用于体现该编译模式的文件标记 4 # (对于debug版来说，比如目标文件后缀就会变成._do) 5 CfgFileTag := _d 6 # 编译选项 7 #CCFlag := -Wall -g -D_DEBUG -march=native 8 CFlag := -Wall -Wno-multichar -g -D_DEBUG -DPG_MEMORY_DISABLE_POOL -march=core2 -m32 -rdynamic 9 CCFlag := $(CFlag) -std=c++0x 10 11 #CCFlag := -finput-charset=gb2312 -Wall -g -D_DEBUG 12 # 连接选项 13 #LNFlag := -lpthread -march=native 14 LNFlag := -lpthread -ldl -lrt -march=prescott]]></content>
      <tags>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb]]></title>
    <url>%2F2017%2F10%2F15%2Fgdb%2F</url>
    <content type="text"><![CDATA[断点 break filename:linenum 在源文件filename的linenum行处停住。d 清除所有断点|—|—||step(s)|执行下一句，如果有函数则进入函数里面执行|set follow-fork-mode parentglibc-2.17-196.el7.i686 libgcc-4.8.5-16.el7.i686 libstdc++-4.8.5-16.el7.i686gdb debugme pidclear 删除所在行的所有断点clear 12 //删除12行的所有断点clear list.c:12 //删除该文件该行号的所有断点b list.c:12 // 在该文件该行号添加断点backtrace\bt 打印全部栈帧的简要信息，按Ctrl-c可终止打印。finish 跳出当前函数。 调试守护进程如果需要调试子进程，在启动gbd后：set follow-fork-mode child并在子进程代码设置断点此外还有detach-on-fork参数，只是gdb在fork之后是否断开(detach)某个进程的调试，或者都交由GDB控制。 观察点(WatchPoint)在变量读、写或变化时中断，这类方式常用来定位bug。 watch 变量发生变化时中断 rwatch 变量被读时中断 awatch 变量值被读或写时中断 条件断点(gdb) b 13 if i == 8 程序运行参数set args 可指定运行时的参数。(如：set args 10 20 30 40 50show args 命令可以查看设置好的运行参数 打印堆栈bt显示所有的函数调用的栈帧信息，每个帧一行。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux]]></title>
    <url>%2F2017%2F10%2F15%2Flinux%2F</url>
    <content type="text"><![CDATA[例子：将目录A重命名为B mv A B 例子：将/a目录移动到/b下，并重命名为c mv /a /b/c yum install wget yum install gcc yum install gcc-c++ wget http://ftp.gnu.org/pub/gnu/ncurses/ncurses-5.6.tar.gz tar -zxvf ./configure -prefix=/usr/local -with-shared-without-debug make &gt; t.log make install no termcap library foundwget http://ftp.gnu.org/gnu/termcap/termcap-1.3.1.tar.gztar -zxvf termcap-1.3.1.tar.gzcd termcap./configure —helpset t.logvim t.log/MACHTYPE=x86_64-redhat-linux-gnuyum install gdb (这尼玛坑爹呀) du查看某个文件或目录占空间大小du -ah du -sh linux下修改.bash_profile立即生效的方法 source .bash_profile exec bash —login linux中文乱码查看当前系统默认的字符集locale安装中文包yum -y groupinstall chinese-support 生效export LANG=”zh_CN.UTF-8”重新载入. /etc/profile 解决中文乱码export LC_ALL=”zh_CN.utf8” Linux中安装gcc g++ yum方式123yum -y install gccyum -y install gcc-c++yum intall make Linux注销用户who 列出登陆的用户列表 whoroot@localhost:~/work_code/src/svr&gt; whoroot pts/0 2017-10-20 06:33 (192.168.171.1)root@localhost:~/work_code/src/svr&gt; pkill -kill -t pts/0 cannot find -lgcc_s在64位Centos7上编译32位C程序，因为是编译32位的目标程序，所以使用gcc编译的时候需要加上-m32选项，但是编译的话会报错，如下：1234root@localhost:~/work_code&gt; gcc -g -m32 -o hello hello.c/usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/4.8.5/libgcc_s.so when searching for -lgcc_s/usr/bin/ld: cannot find -lgcc_scollect2: 错误：ld 返回 1 getconf LONG_BIT #查看自己版本是32位还是64位32位的库yum install glibc-devel.i686yum install libstdc++-devel.i686 kill -2 和 kill -9的区别-2类似Ctrl + C 是程序在结束之前，能够保存相关数据，然后在退出。-9直接强制结束程序。 硬链接(hard link)和软链接(符号链接，fsoft link或symbolic link)我们知道文件都有文件名和数据，在Linux上被分成两个部分：用户数据(user data)和元数据(metadata)。用户数据，即文件数据块(data block)，数据块时记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在Linux中，元数据中的inode号(inode是文件元数据的一部分但其并不包含文件名，inode号即索引节点号)才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过inode号寻找正确的文件数据块。若一个inode号对应多个文件名，则称这些文件为硬链接。换言之，硬链接就是同一个文件使用了多个别名。硬链接可由命令link或ln创建。 link oldfile newfile ln oldfile newfile由于硬链接有着相同inode号仅文件名不同的文件，因此硬链接存在以下几点特性： 文件有相同的inode及data block； 只能对已存在的文件进行创建； 不能交叉文件系统进行硬链接的创建； 不能对目录进行创建，只可对文件创建； 删除一个硬链接文件并不影响其它有相同inode号的文件。软连接与硬链接不同，若文件用户数据块存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是普通文件，只是数据块内容有点特殊。软链接有着自己的inode号以及用户数据块usage: ln -s 源文件 目标文件 ssh登录方法ssh -l username ip 永久性获取ROOT权限sudo passwd su 64位linux机器上编译32位openssl库setarch i386 ./config -m32 wget http://zlib.net/zlib-1.2.11.tar.gz tar -zxvf zlib-1.2.111.tar.gz cd zlib-1.2.11 ./configure --prefix=/usr/local make &amp;&amp; make install find ./ -name &quot;*.o&quot; -exec rm {} \; make: ***[install_docs] Error 1 vim /usr/bin/pod2man 注释69行# i386 几乎所有的X86平台i686 只是i386的一个子集 Linux内存管理&lt;% img asset_img Linux1.webp %&gt;在linux中，每一个进程都被抽象为task_struct结构体中，成为进程描述符，存储着进程各方面的信息；例如打开的文件，信号以及内存等等；然后task_struct中的一个属性mm_struct管理着进程的所有虚拟内存，成为内存描述符。在mm_struct结构体中，存储着进程各个内存段的开始以及结尾，如上图所示；进程使用的物理内存，即常驻内存RSS页数，这个内存使用的虚拟地址空间VSZ页数，还有进程虚拟内存区域集合和页表。从上图可以看出，进程有代码段Text segment,数据段（已初始化的全局，静态变量），BSS段（未初始化的全局，静态变量），堆，内存映射区以及栈；每一块虚拟内存区（VMA）都是由一块连续的虚拟地址组成，这些地址从不覆盖。一个vm_area_struct实例描述了一块内存区域，包括这块内存区域开始以及结尾地址；flags标志决定了这块内存的访问权限和行为；vm_file决定这块内存是由哪个文件映射的，如果没有文件映射，则这块内存为匿名的(anonymous)。上图中提到的每个内存段，都对应一个vm_area_struct结构。如下图所示&lt;% asset_img Linux2.webp %&gt;上图即为/bin/gonzo进程的内存布局。程序的二进制文件映射到代码段和数据段，代码段为只读只执行，不可更改；全局以及静态的未初始化的变量映射到BSS段，为匿名映射，堆和栈也是匿名映射，因为没有相对应的文件映射；内存映射区可以映射共享库，映射文件以及匿名映射，所以这块内存段可以使文件映射也可以是匿名映射。而且不同的文件，映射到不同的vm_area_struct区。这些vm_area_struct集合存储在mm_struct中的一个单向链表和红黑树中；当输出/proc/pid/maps文件时，只需要遍历这个链表即可。红黑树主要是为了快速定位到某一个内存块，红黑树的跟存储在mm_rb域。线性地址需要通过页表才能转换为物理地址。每个进程的内存描述符也保存了这个进程页表指针pgd,每一块虚拟内存页都和页表的某一项对应。虚拟内存是不存储任何数据的，它只是将地址空间映射到物理内存。物理内存有内核伙伴系统分配，如果一块物理内存没有被映射，就可以被伙伴系统分配给虚拟内存。刚分配的物理内存可能是匿名的，存储进程数据，也可能是缓存，存储文件或块设备的数据。一块虚拟内存vm_area_struct块是由连续的虚拟内存也组成的，而这些虚拟内存块映射的物理内存却不一定连续，如下图所示：&lt;% asset_img Linux3.webp %&gt; 挂载mount -t cifs -o username=administrator,passwd=,uid=&quot;1000&quot;,gid=&quot;1000&quot;,vers=2.0 //192.168.0.102/workspace /home/develop]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn]]></title>
    <url>%2F2017%2F10%2F15%2Fsvn%2F</url>
    <content type="text"><![CDATA[svn: E200002: line 19: Option expected错误解决这是因为修改svnserve.conf时，打开注释时，配置的前面有空格，应该顶格写。修改后即可。 解决svn Authorization failed错误出现该问题基本都是三个配置文件的问题，下面把这个文件列出来svnserve.conf:[general]anon-access = readauth-access = writepassword-db = passwdauthz-db = authzpasswd:[users]admin=123authz:[groups][/]admin= rw出现authorization failed异常，一般都是authz文件里，用户组或者用户权限没有配置好，只要设置[/]就可以，代表根目录下所有的资源，如果要限定资源，可以加上 子目录即可。 checkoutsvn checkout path（path是服务器上的目录） 例如：svn checkout svn://192.168.171.128/zentia/trunk/xxprj/server revertsvn revert [-R] dir CentOS下svn迁移备份的三种方法一般采用三种方式： svnadmin dump svnadmin hotcopy svnsync注意，svn备份不宜采用普通的文件拷贝方式（除非你很懂svn，并且将库暂停），如copy、rsync命令。svnadmin dump是官方推荐的备份方式，优点是比较灵活，可以全量备份也可以增量备份，并提供了版本恢复机制。缺点：如果版本比较大，如版本数增长到数万、数十万，那么dump的过程将非常慢；备份耗时，恢复更耗时；不利于快速进行灾难恢复。个人建议在版本数比较小的情况下使用这种备份方式。svnadmin hotcopy原设计目的估计不是用来备份的，只能进行全量拷贝，不能进行增量备份；优点是：备份过程较快，灾难恢复也很快；如果备份机上已经搭建了svn服务，甚至不需要恢复，只需要进行简单配置即可切换到备份库上工作。缺点是：比较消耗硬盘，需要有较大的硬盘支持。svnsync实际上是CentOS下SVN服务的启动语关闭svnserve -d -r /home/svn/home/svn 为版本的根目录关闭SVN服务：ps aux | grep svnkill -s 9 6443464434为进程ID 或者 killall svnserve linux下SVN中改变执行权限本地文件在commit到仓库之前若没有chmod+x权限的话，拿在svn仓库里的文件将会保持当前无可执行属性状态，我们可以做svn命令修改。SVN中，如果我们在linux下提交权限为755文件，就会在svn的属性中存在一个svn:executable。只在本地chmod 644 ，是不能造成修改的。svn propset svn:executable on * （注意，如果包含目录会执行失败）svn commit 前一个操作被卡住的问题去官网下载win32那个包就可以了。sqlite3.exe .svn/wc.db “delete from wc_lock”sqlite3.exe .svn/wc.db “delete from work_queue”/OUT:”F:\zentia\server\bin\vc120debugs\glogger_d.exe” /MANIFEST /NXCOMPAT /PDB:”F:\zentia\server\bin\vc120debugs\glogger_d.pdb” /DYNAMICBASE:NO “WHCMN_d.lib” “WHNET_d.lib” “PNGS_d.lib” “cryptlib_d.lib” “zlib_d.lib” “kernel32.lib” “user32.lib” “gdi32.lib” “winspool.lib” “comdlg32.lib” “advapi32.lib” “shell32.lib” “ole32.lib” “oleaut32.lib” “uuid.lib” “odbc32.lib” “odbccp32.lib” /FIXED /LARGEADDRESSAWARE /IMPLIB:”F:\zentia\server\bin\vc120debugs\glogger_d.lib” /DEBUG /MACHINE:X86 /OPT:NOREF /SAFESEH:NO /INCREMENTAL /PGD:”F:\zentia\server\bin\vc120debugs\glogger_d.pgd” /SUBSYSTEM:CONSOLE”,5.01” /MANIFESTUAC:”level=’asInvoker’ uiAccess=’false’” /ManifestFile:”F:\zentia\server\temp\vc120\glogger2010\debug\glogger_d.exe.intermediate.manifest” /OPT:NOICF /ERRORREPORT:PROMPT /NOLOGO /LIBPATH:”F:\zentia\server\src\svr\glogger\/lib/win32” /LIBPATH:”F:\zentia\server\lib\vc120lib\” /LIBPATH:”F:\zentia\server\3rd\lib\vc120\” /LIBPATH:”F:\zentia\server\3rd\lib” /LIBPATH:”%(AdditionalLibraryDirectories)” /TLBID:1g++ -DLINUX -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -Wall -Wno-multichar -g -D_DEBUG -DPG_MEMORY_DISABLE_POOL -march=core2 -m32 -rdynamic -std=c++0x -o ../../bin/debug/svr/GBNMS/GBNMS_d.so ../../temp/debug/svr/GBNMS/GBNMS.s.o_d /root/work_code/src/lib/libGBNMS_Lib_d.s.a /root/work_code/src/lib/libDIA_d.s.a /root/work_code/src/lib/libPNGS_d.s.a /root/work_code/src/lib/lib WHNET_d.s.a /root/work_code/src/lib/libWHCMN_d.s.a /usr/lib64/mysql/libmysqlclient_r.a -lz -lpthread -ldl -lrt -march=prescott -shared -L/root/work_code/3rd/lib -L/root/work_code/src/lib 拉分支svnserve -d -r /var/svn启动svn服务器，但是客户端还是一直连接不上 svn info 查看库版本路径 客户端一直连接不上服务器，最后发现是防火墙的问题，最暴力直接关掉防火墙就好啦。 post-commit.tmpl它在事务外城后运行，创建一个新的修订版本。大多数人用这个钩子来发送关于提交的描述性邮件，或者作为版本库的备份。版本库传给程序两个参数：到版本库的路径和被创建的新的修订版本号。退出程序时被忽略。 关闭防火墙重启后生效开启: chkconfig iptables on关闭: chkconfig iptables off即时生效，重启后失效开启：service iptables start关闭：service iptables stop 查看磁盘空间df -h 创建版本库12345678mkdir /var/svn# 进入svn目录cd /var/svn # 用svn管理员创建bigsvrsvnadmin create /var/svn/bigsvr# 进入库cd bigsvr subversion目录说明db 所有版本控制的数据存放目录hooks 放置hook脚本locks 用户操作的锁文件format 记录当前文件库的版本号conf 配置文件 Svn命令行总结 上传项目到SVN服务器上 svn import project_dir(本地项目全路径) 下载checkout svn项目到本地 svn checkout 简写：svn co 添加新文件 svn add file(文件名) svn add *.php(添加当前目录下所有的php文件) 提交到版本库 svn commit -m “LogMessage” [-N] [—no-unlock] PATH(如果选择了保持锁，就使用—no-unlock开关) 更新文件 svn update svn update -r 修正版本 文件名 svn update (后面没有目录，默认将当前目录以及子目录下的所有文件都更新到最新版本) svn update -r 200 test.cpp (将版本库中的文件test.cpp还原到修正版本(revision)200) svn update test.php (更新于版本库同步) 设置忽略 svn propset svn:ignore Temp . relocate svn switch —relocate svn://18.223.184.177/project/ss/ss/bin/data svn://18.223.184.177/project/ss/ss/bin/data]]></content>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7下 vim]]></title>
    <url>%2F2017%2F10%2F14%2Fvi%2F</url>
    <content type="text"><![CDATA[1yum -y install vim 环境配置 /etc/vimrc 全局 vim ~/.vimrc 新建1234567set nu // 行号set showmode //显示当前模式set ruler //显示行数信息set autoindent //回车对齐syntax on //语法检测set encoding=urf-8 fileencodings=ucs-born,utf-8,cp936 //自动识别编码，如果没有找到，用latin-1(ASCII)编码打开(解决乱码问题)set ts=4 //四个空格 vi查看文件编码格式 :set fileencoding:edit ++enc=utf-8 最后来看看处理中文文档最典型的几种情况和设置方式： 1，系统locale是utf-8（很多linux系统默认的locale形式），编辑的文档是GB2312或GBK形式的（Windows记事本 默认保存形式，大部分编辑器也默认保存为这个形式，所以最常见），终端类型utf-8（也就是假定客户端是putty类的unicode软件） 则vim打开文档后，encoding=utf-8（locale决定的），fileencoding=latin1（自动编码判断机制不准导致的），termencoding=空（默认无需转换term编码），显示文件为乱码。 解决方案1：首先要修正fileencoding为cp936或者euc-cn（二者一样的，只不过叫法不同），注意修正的方法不是:set fileencoding=cp936，这只是将文件保存为cp936，正确的方法是重新以cp936的编码方式加载文件为:edit ++enc=cp936，可以简写为:e ++enc=cp936。 解决方案2：临时改变vim运行的locale环境，方法是以LANG=zh_CN vim abc.txt的方式来启动vim，则此时encoding=euc-cn（locale决定的），fileencoding=空（此locale下文件 编码自动判别功能不启用，所以fileencoding为文件本身编码方式不变，也就是euc-cn），termencoding=空（默认值，为空则等 于encoding）此时还是乱码的，因为我们的ssh终端认为接受的数据为utf-8，但vim发送数据为euc-cn，所以还是不对。此时再用命令: set termencoding=utf-8将终端数据输出为utf-8，则显示正常。 2，情况与1基本相同，只是使用的ssh软件为secure CRT类ansi类软件。 vim打开文档后，encoding=utf-8（locale决定的），fileencoding=latin1（自动编码判断机制不准导致的），termencoding=空（默认无需转换term编码），显示文件为乱码。 解决方案1：首先要保证运行secure CRT的windows机器的默认代码页为CP936，这一点中文windows已经是默认设置了。其他的与上面方案1相同，只是要增加一步，:set termencoding=cp936 解决方案2：与上面方案2类似，不过最后一步修改termencoding省略即可，在此情况下需要的修改最少，只要以locale为zh_CN开 启vim，则encoding=euc-cn，fileencoding和termencoding都为空即为encoding的值，是最理想的一种情 况。 可见理解这3个关键点和3个参数的意义，对于编码问题有很大助力，以后就可以随心所欲的处理文档了，同时不仅仅是应用于vim，在其他需要编码转换的环境里，都可以应用类似的思路来处理问题解决问题。 行跳转 12gg / 12G :12 打开文件时输入vim +12 filename vim 精确匹配查找单词精确匹配查找单词如果你输入 “/the”，你也可能找到”there”。要找到以”the”结尾的单次，可以用: /the> “>“是一个特殊的记号，表示只匹配单词末尾。类似的，”\&lt;” 只匹配单词的开头。这样要匹配一个完整的单词”the”，只需要: /\ :e 刷新文件内容]]></content>
      <tags>
        <tag>vi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql]]></title>
    <url>%2F2017%2F10%2F14%2Fmysql%2F</url>
    <content type="text"><![CDATA[修改mysql密码12345mysql -uroot -puse mysql;UPDATE user SET password=password(&quot;123456&quot;) WHERE user=&apos;root&apos;; flush privileges;exit; 1SHOW DATABASES; 首先CentOS7 已经不支持mysql，因为收费了你懂得，所以内部集成了mariadb，而安装mysql的话会和mariadb的文件冲突，所以需要先卸载掉mariadb，以下为卸载mariadb，安装mysql的步骤。 列出所有被安装的rpm packagerpm -qa | grep mariadb 卸载rpm -e mariadb-libs-5.5.37-1.el7_0.x86_64错误：依赖检测失败：libmysqlclient.so.18()(64bit) 被 (已安裝) postfix-2:2.10.1-6.el7.x86_64 需要libmysqlclient.so.18(libmysqlclient_18)(64bit) 被 (已安裝) postfix-2:2.10.1-6.el7.x86_64 需要 强制卸载，因为没有—nodepsrpm -e —nodeps mariadb-libs-5.5.37-1.el7_0.x86_64 安装mysql依赖yum install vim libaio net-tools 其他情况： 1、centos下yum暂时没有mysql-server直接安装包；MariaDB是MySQL社区开发的分支，也是一个增强型的替代品; 2、安装MariaDB（目前还是先不要安装了）yum -y install mariadb-server mariadb mariadb-develsystemctl start mariadbsystemctl enable mariadbmysql_secure_installationfirewall-cmd —permanent —add-service mysqlsystemctl restart firewalld.serviceiptables -L -n|grep 3306 CentOS7的yum源中默认好像是没有mysql的。为了解决这个问题，我们要先下载mysql的repo源。 下载mysql的repo源 $ wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm 安装mysql-community-release-el7-5.noarch.rpm包 $ sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm 安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo。 安装mysql $ sudo yum install mysql-server根据步骤安装就可以了，不过安装完成后，没有密码，需要重置密码。 重置密码重置密码前，首先要登录$ mysql -u root登录时有可能报这样的错：ERROR 2002 (HY000): Can‘t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock‘ (2)，原因是/var/lib/mysql的访问权限问题。下面的命令把/var/lib/mysql的拥有者改为当前用户：$ sudo chown -R openscanner:openscanner /var/lib/mysql然后，重启服务：$ service mysqld restart 开放3306端口$ sudo vim /etc/sysconfig/iptables添加以下内容：-A INPUT -p tcp -m state —state NEW -m tcp —dport 3306 -j ACCEPT保存后重启防火墙：$ sudo service iptables restart这样从其它客户机也可以连接上mysql服务了。MYSQL启动后报：ERROR! The server quit without updating PID file错误的问题解决MYSQL日志：Can’t find file: ‘./mysql/plugin.frm’ (errno: 13 - Permission denied) 权限不够：chown -R mysql:mysql /home/mysql/data” chmod -R 755 /home/mysql/data centos7的selinux问题：打开/etc/selinux/config，把SELINUX=enforcing改为SELINUX=disabled后存盘退出重启机器。查看存储过程的创建代码show create procedure proc_name; ERROR 1728 (HY000): Cannot load from mysql.proc. The table is probably corrupted【错误过程】：MySQL从5.1升级至5.5后在调用存储过程时报出“Cannot load from mysql.proc. The table is probably corrupted。”【造成原因】：MySQL升级完成后未对相关数据库执行升级.【解决办法】：在命令行中执行mysql_upgrade -uroot -p 即可~ 查看Mysql端口show global variables like &#39;port&#39;; 字符集系统变量 character_set_server 默认的内部操作字符集 character_set_client 客户端来源数据使用的字符集 character_set_connection 连接层字符集 character_set_results 查询结果字符集 character_set_database 当前选中数据库的默认字符集 character_set_system 系统元数据（字段名等）字符集 查看show variables like &#39;character_set_database&#39;; show variables like &#39;%character%&#39;; show variables like &#39;collation%&#39;; 修改临时修改alter database xxx CHARACTER SET gb2312; // 修改库的字符集 SET character_set_client = utf8; 永久修改修改my.cnf 位置在/etc/my.cnf在[mysqld]上面加下面两句话 [client] default-character-set=utf8 在[mysqld]最下面加入下面几句话 default-storage-engine=INNODB character-set-server=utf8 collation-server=utf8_general_ci 然后保存 重启Mysql service mysqld restart 查看MYSQL所支持的字符集show charset; 查看库的字符集show create database db_xxsy_game_1004\G; 查看表的字符集show table status from db_xxsy_game_1004 like &#39;common_accounts&#39;; CentOS7 开放3306端口访问CentOS 7.0默认使用的是firewall作为防火墙，这里改为iptables防火墙。1、关闭firewall：systemctl stop firewalld.servicesystemctl disable firewalld.servicesystemctl mask firewalld.service 2、安装iptables防火墙yum install iptables-services -y 3.启动设置防火墙 # systemctl enable iptables # systemctl start iptables 4.查看防火墙状态 systemctl status iptables 5编辑防火墙，增加端口vi /etc/sysconfig/iptables #编辑防火墙配置文件-A INPUT -m state —state NEW -m tcp -p tcp —dport 22 -j ACCEPT-A INPUT -m state —state NEW -m tcp -p tcp —dport 80 -j ACCEPT-A INPUT -m state —state NEW -m tcp -p tcp —dport 3306 -j ACCEPT:wq! #保存退出 3.重启配置，重启系统systemctl restart iptables.service #重启防火墙使配置生效systemctl enable iptables.service #设置防火墙开机启动 Host ‘192.168.171.128’ is not allowed to connect to this MySQL serverERROR 1044 (42000):Access denied for user ‘’@’localhost’ to database ‘mysql’在mysql数据库的user表里，存在用户名为空的账户即为匿名账户，导致登陆的时候虽然用的时root，但实际时匿名登陆的。解决办法： 关闭mysqlservice mysqld stop 屏蔽权限mysqld_safe —skip-grant-table 新开一个终端mysql -u root mysqldelete from user where user=’’;flush privileges; mysql.h no found file or directoryyum install mysql-devel 数据类型 解释 存储范围 字节 TINYINT 有符号值:-128到127unsigned : [0 255] 1 SMALLINT signed[-32768,32767]unsigned [0,65535] 2 BINARY 用来表示二进制数据 VARBINARY 大小写忽略 CHAR和VARCHAR类型都用来存储字符串VARCHAR 可以存储可变长度的字符串CHAR 存储定长字符串定义如下CHAR(M)或者VARCHAR(M)M指的是字符串的最大长度比如插入值’ab’CHAR(4) 需要4个字节VARCHAR(4) 需要3个字节当数据为CHAR(M)类型时，不管插入值的长度是多少，所占用的存储空间都是M个字节。当为VARCHAR(M)类型时，所占用的字节数为实际长度加1。 BINARY和VARBINARY类型类似于CHAR和VARCHAR用来表示二进制数据定义如下BINARY(M)或者VARBINARY(M)M指的是二进制数据的最大字节长度注意BINARY类型的长度是固定的，如果数据的长度不足最大长度，在后面用”\0”补齐。比如，数据类型为BINARY(3)，当插入a时，实际存储的时”a\0\0” Centos7安装Mysqlyum install mysql yum install mysql-devel yum install mariadb-server mariadb systemctl start mariadb]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 服务器搭建]]></title>
    <url>%2F2017%2F10%2F13%2Fgit-server%2F</url>
    <content type="text"><![CDATA[首先要明确现在代码的分布情况，开发者电脑上的本地仓库，git服务器上的远端仓库，web服务器上的另一个本地仓库，我们浏览器访问的就是这里的代码。其实自动部署就是要当开发者本地仓库提交代码到远端仓库的时候，自动把代码部署到web服务器的本地仓库，实现开发着本地仓库和web服务器的本地仓库同步。（即通过GitHook中的post-receive脚本文件） 1、安装Git12yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-develyum install git 接下来我们创建一个git用户组和用户，用来运行git服务：12groupadd gitadduser git -g git 3、初始化Git仓库12$ git init --bare runoob.gitInitialized empty Git repository in /home/gitrepo/ git init 使用当前目录作为Git仓库,该命令执行完后回生成一个.git目录git init zentia 指定目录创建Git仓库 修改/etc/ssh/sshd_config文件，将其中的PermitRootLogin no修改为yes,PublicAuthentication yes修改为no,AuthorizedKeysFile .ssh/authorized_keys前面加上的#屏蔽掉,PasswordAuthentication no修改为yes就可以了ssh -l username hostname 在服务器checkout出一份代码123# In remote servercd ~git clone sample.git/ my_repo 这个时候就会出现my_repo文件夹，里面就会有你的代码。同时，这个代码文件夹的默认origin远端（remote）就会变成my_repo文件夹。当你做git fetch git pull等动作的时候就会从my_repo取信息。3.配置Git Hook进入到/home/gitrepo/sample.git文件夹，使用vi post-receive创建一个脚本，当你在本地仓库执行git push后就会触发post-receive。 /usr/games/project.git/git clone git@ec2-18-191-158-223.us-east-2.compute.amazonaws.com:/usr/games/project.git/添加到本地仓库 git add . 添加提交描述 git commit -m ‘内容’ 提交前先从远程仓库🐖分支中拉取请求 git pull origin master 把本地仓库代码提交 git push -u origin master 查看远程仓库地址 git remote -v]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git clone 命令]]></title>
    <url>%2F2017%2F10%2F13%2Fgit-clone%2F</url>
    <content type="text"><![CDATA[git clone 命令将存储库克隆到新目录中。]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh]]></title>
    <url>%2F2017%2F10%2F13%2Fssh-key%2F</url>
    <content type="text"><![CDATA[ssh中，有两个钥匙：公钥、私钥，公钥主要是用于对一些敏感信息进行加密，私钥适用于解密。ssh的文件都存在于机器~/.ssh中。 客户端：id_rsa(私钥)、id_rsa.pub(公钥)、known_hosts(已知远程主机) 服务端: authorized_keys(验证过的公钥列表)、sshd_config(ssh配置文件) 设置ssh连接不断开vim /etc/ssh/sshd_config # 客户端每隔多少秒向服务器发送一个心跳数据 ClientAliveInterval 30 # 客户端多少秒没有响应，服务器自动断掉连接 ClientAliveCountMax 1800 service sshd restart]]></content>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站部署规则]]></title>
    <url>%2F2017%2F10%2F13%2Fsite-dealy-role%2F</url>
    <content type="text"><![CDATA[网站发布只在自己笔记本电脑发布，公司电脑只能hexo s —debug,不能 hexo d -g本地内容修改完成之后记得123git add . git commit -am "m"git push origin master]]></content>
  </entry>
  <entry>
    <title><![CDATA[fatal:remote error You can't push to git 的解决办法]]></title>
    <url>%2F2017%2F10%2F13%2Fgithub-remote-error%2F</url>
    <content type="text"><![CDATA[branch正确的情况下，不知为什么，在push的时候出现:123fatal: remote error:You can't push to git://github.com/zentia/hexo.gitUse git@github.com:zentia/hexo.git 解决办法:123git remote rm origingit remote add origin git@github.com:zentia/hexo.gitgit push origin master]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wm]]></title>
    <url>%2F2017%2F10%2F13%2Fwm%2F</url>
    <content type="text"><![CDATA[第一个问题：昨天一直提示hexo command no found，然后本地的hexo/node_module下找到一个.bin目录，里面还有hexo的执行文件，天真的以为这个就是执行路径，然后搞了一天，无果。今天去program files(x86)找到全局的npm下的hexo然后修改环境变量解决。第二个问题：hexo new _post 文章的时候提示fatal：admin-hey（一个管理员控制的）module no found ，以前配置这个过，后来感觉没啥用，就不用了，开始下载这个module，但是可能是今天的网络问题还是怎么回事，github一直很慢，然后去node_module里面看的时候发现有hexo-hey，但是发现里面文件目录结构不对，然后删掉就好了。本来想做一个单纯的技术博客，但是王苗喜欢这个视频，就放上去吧。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unity Shader]]></title>
    <url>%2F2017%2F10%2F12%2Fshader%2F</url>
    <content type="text"><![CDATA[CGPROGRAM和ENDCG包裹的部分就是CG\HLSL语言部分。 Vertex &amp; Fragment Shader: 顶点/片元着色器。它是最基本，也是非常强大的着色器类型。一般用于2D场景、特效之类的。Unlit Shader(无光照着色器，不包含无效)在世界三维空间中，一开始传入Shader处理的数据其实就是网格数据(Mesh Data)但是一般情况下，光是网格数据不能满足我们处理画面的需求，这时就需要引入一些常数属性数据(Properties)属性的声明规则如下： 1_Name("Display Name", type)=defaultValue[&#123;options&#125;] _Name是属性的名字，也就是变量名，在之后整个Shader代码中将使用这个名字来获取该属性的内容，切记要添加下划线。 Displayer Name 这个字符串将显示在Unity的Inspector中作为Shader的使用者可读的内容，即显示的名称。 type属性的类型。常用的有几种：Color颜色，一般为RGBA的数组；2D纹理，宽高为2的幂次尺寸；Rect纹理，对应非2的幂次尺寸；Cube立方体，即6张2D纹理组成；Float和Range，都是浮点数，但是Range要求定义最小值和最大值，以Range(min,max)形式显示；Vector四位数。 defauleValue默认值，与类型直接挂钩。一开始赋予该属性的初始值，但是在检视窗口调整过属性值之后，不再有效。Color以0~1定义rgba颜色，比如(1,1,1,1)；2D/Rect/Cube，对于纹理来说，默认可以为一个代表默认tint颜色字符串，可以使空字符串或者”white”，”black”等中的一个；Float和Range为某个指定的浮点数；同样，Vector的是一个四维数值，(x,y,z,w)的形式。 Options可选项，它只对2D，Rect或者Cube纹理有关，一般填入OpenGL中TexGen的模式。这样我们可以尝试解读上图中的那些属性声明的是声明了。比如_MainTex(“A Texture”, 2D)=””{},就是声明了一个变量名为_MainTex的2次幂尺寸纹理，它在检视窗口中显示的名称是A Texture，默认是空的。 语义语义（Semantics）是附加到着色器输入或输出的字符串，其传达关于参数的预期使用的信息。对于在着色器级之间传递的所有变量都需要语义，通常，在流水线级之间传递的数据是完全通用的，并且不被系统唯一地解释；允许任意语义没有特殊意义。 Surface Shader: 表面着色器。它拥有更多的光照运算，其实在系统内部它会被编译成一个比较复杂的顶点/片元着色器。Standard Surface Shader(标准光照模型表面着色器) Standard Shader: 标准着色。它是表面着色器升级版，因为它使用了Physically Based Rendering（简称PBR）技术，即基于物理的渲染技术。所以在这个着色器中开放了更多处理光照与材质的参数。 Tag表面着色器可以被若干的标签(tags)所修饰，而硬件将通过判定这些标签来决定什么时候调用该着色器。比如我们的粒子中SubShader的第一句Tags{“RenderType”=”Opaque”}告诉了系统应该在渲染非透明物体的时调用我们。Unity定义了一系列这样的渲染过程，与RenderType是Opaque相对应的显而易见的是”RenderType”=”Transparent”，表明渲染含有透明效果的物体时调用它。在这里Tags其实暗示了你的Shader输出的是什么，如果是渲染非透明物体，那添加”Queue”=”Opaque”标签；如果渲染透明或者半透明的像素，那添加”Queue”=”Transparent”。另外比较有用的标签”IgnoreProject”=”True”(不背Projectors影响)，”ForceNoShadowCasting”=”True”(从不产生阴影)以及”Queue”=”xxx”(指定渲染顺序队列)。这里想要赵忠说一下的是Queue这个标签，如果你使用Unity做过一些透明和不透明物体的混合的话，很可能已经遇到过不透明物体无法呈现在透明物体之后的情况。这种情况很可能是由于Shader的渲染顺序不正确导致的。Queue指定了物体的渲染顺序，预定义的Queue有： Background - 最早被调用的渲染，用来渲染天空盒或者背景 Geometry - 这是默认值，用来渲染非透明的物体（普通情况下，场景中的绝大多数物体应该是非透明的） AlphaTest - 用来渲染经过Alpha Test的像素，单独为AlphaTest设定一个Queue是出于对效率的考虑 Overlay - 用来渲染效果的叠加，是渲染的最后阶段（比如镜头光晕等效果） 这些预设值本质是一组整数，Background = 1000(背景), Geometry = 2000(几何体), AlphaTest = 2450(alpha测试), Transparent = 3000(透明),最后Overlay = 4000。在我们实际设置Queue值时，不仅能使用上面的几个预定义值，我们也可以指定自己的Queue值，写成类似这样：”Queue”=”Transparent+100”,表示一个在Transparent之后100的Queue上进行调用。通过调整Queue值，我们可以确保某些物体一定在另一些物体之前或者之后渲染。 LODLOD很简单，它是Level of Detail的缩写，在这里例子里我们指定了其为200（其实这是Unity的内建Diffuse着色器的设定值）。这个数值决定了我们能用上面样的Shader。在Unity的Quality Settings中我们可以设定允许最大LOD，当设定的LOD小于SubShader所指定的LOD时，这个SubShader将不可用。Unity内建Shader定义了一组LOD的数值，我们在实现自己的Shader的时候可以将其作为参考来设定自己的LOD数值，这样在之后调整根据设备图形性能来调整画质时可以紧急性比较精确的控制。 VertexLit及其系列 = 100 Decal,Reflective VertexLit = 150 Diffuse = 200 Diffuse Detail,Reflective Bumped Unlit,Reflective Bumped VertexLit = 250 Bumped,Specular = 300 Bumped Specular = 400 Parallax = 500 Parallax Specular = 600 Shader本体123456789101112131415CGPROGRAM#pragma surface surf Lambertsampler2D _MainTex;struct Input &#123; float2 uv_MainTex;&#125;;void surf(Input IN, inout SurfaceOutput o)&#123; half4 c = tex2D(_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a;&#125;ENDCG 还是逐行来看，首先是CGPROGRAM。这是一个开始标记，表明从这里开始是一段CG程序（我们在写Unity的Shader时用的是Cg/HLSL语言）。最后一行的ENDCG与CGPROGRAM是对应的，表明CG程序到此结束。接下来是一个编译指令：#program surface surf Lambert,它表明了我们要写一个表面Shader，并指明了光照模型。它的写法是这样的 #pragma surface surfaceFunction lightModel [optionalparams] surface -表明的是一个表明着色器 surfaceFunction -着色器代码的方法的名字 lightModel -使用的光照模型我们声明了一个表面着色器，实际的代码在surf函数，使用Lambert(也就是普通的diffuse)作为光照模型。接下来一句sampler2D MainTex,sampler2D是个啥？其实在CG中，sampler2D就是和Texture所绑定的一个数据容器接口。等等..这个说法还是太复杂了，简单理解的话，所谓加载以后的texture(贴图)说白了不过是一块内存存储的，使用了RGB(也许还有A)通道，且每个通道8bits的数据。而具体想知道像素与坐标的对应关系，以及获取这些数据，我们总不能一次次去自己计算内存地址或者偏移，因此可能通过sampler2D来对贴图进行操作。更简单理解，sampler2D就是GLSL中的2D贴图类型，相应的，还有smapler1D,sampler2D,samplerCube等等格式。解释通了sampler2D是什么之后，还需要解释下为什么在这里需要一句对_MainTex的声明，之前我们不是已经在Properties里声明过它是贴图了么。答案是我们用来实力的这个shader其实是由两个相对独立的块组成的，外层的属性声明，回滚等等是Unity可以直接使用和编译的ShaderLab;而现在我们是CGPROGRAM..ENDCG这样一个代码块中，这是一段CG程序。对于这段CG程序，要想访问在Properties中所定义的变量的话，必须使用和之前变量形同的名字进行声明。于是其实sampler2D _MainTex;做的事情就是再次声明并链接了_MainTex,使接下来的CG程序能够使用这个变量。解释通了sampler2D是什么之后，还需要解释为什么在这里需要一句对_MainTex的声明，之前我们不是已经在Properties里声明过它是贴图了吗。答案是我们用来实力的这个shader其实是由两个独立的快组成的，外层的属性声明，会。- 在CG中，函数就像C中那样声明。你可以随意的指定传递给函数的参数，以及将被函数啊发你会的值。下面是一个简单的函数声明：1234float getX(float3 v)&#123; return v.x;&#125; 这个函数采用了一个三元向量v作为一个参数，并且将v的x分量作为返回值，其类型为float。关键字return被用来返回函数的结果。你可以像调用任何其它Cg函数那样调用getX函数：123456//声明一个临时使用的向量float3 myVector = float3(0.5,1.0,-1.0);//取得myVector的x分量float x = getX(myVector);//现在 x=0.5 有些时候，你想要一个函数返回几个结果而不仅仅是一个结果。在这种情况下，你能够使用out修饰符来指定一个程序的某个特定的参数只用于输出。下面的例子用一个向量作为输入，然后返回它的x、y和z分量。123456void getComponents(float3 vector, out float x, out float y, out float z)&#123; x = vector.x; y = vector.y; z = vector.z;&#125; 注意这个函数被声明为void类型，因为它通过参数来返回所有的值。下面的代码示例显示了getComponents是如何被使用的：12345678//声明一个临时使用的向量float3 myVector = float3(0.5,1.0,-1.0);//声明一个临时使用的变量flaot x,y,z;//获得myVector的x、y和z分量getComponents(myVector, x,y,z);//现在x=0.5,y=1.0,z=-1.0 一个光照函数因为光照是一个复杂的过程，你能够编写许多不同类型的光照函数，每个函数都能接受不同的参数。现在，你只需要采用你实现的简单模型，并为它创建一个函数。下面是这个函数的最基本的样子：1234float3 lighting(float Ke, float3 Ka, float3 Kd,float3 Ks,float shininess,float3 lightPosition,float3 lightColor,float3 globalAmbient,float3 P,float3 N,float3 eyePosition)&#123; //在这里计算光照&#125; 这个方法的一个主要问题是这个函数需要很多参数。把这些参数组成“材质参数”和“光参数”，然后把每个参数集当成一个单独变量来传递，这将使得整个函数整洁许多。幸运的是Cg支持这种结构，恰好能够提供这种功能。 结构Cg的结构使用与C和C++同样的方法来声明。struct关键字被用来声明结构，它后面跟随的是结构的成员。下面是一个结构的例子，它分封装了基于基本光照模型的某个材质的所有性质： Fog语法: Fog {Fog Commands} Mode Off | Global | Linear | Exp | Exp2(雾的模式，缺省值是Global) Color ColorValue(雾的颜色) Density FloatValue(雾的浓度，影响Exp/Exp2) Range FloatValue,FloatValue(雾的开始和结束距离，影响Linear) 注意如果使用了片段着色器的话，着色器种的雾设定仍然是有效的。另外可以通过菜单Edit-&gt;Render Settings可以打开渲染设置 Alpha Test和Alpha BlendingAlpha Test是不需要关闭ZWrite的。Alpha Test要么完全透明，要么完全不透明 Alpha Blending 需要关闭ZWrite，如果不关闭ZWrite，那么在进行深度检测的时候，它背后的物体本来可以被外面看到的，但由于深度检测时大于它的深度就被剔除了，从而我们就看不到它后面的物体了。因此，我们需要保证物体的渲染顺序是从后往前，并且关闭该半透明对象的ZWrite。 Appha Blending 只是关闭ZWrite，但是不会关闭ZTest。这意味着，在输出一个Alpha Blending的fragment时，它还是会判断和当前Color Buffer种的fragment的深度关闭，如果它比当前的fragement深度更远，那么它就不会再做后续的混合操作了； ColorMaskColorMask可让我们指定渲染结果的输出通道，而不是通常情况下的RGBA这4个通道皆会被写入。可选参数是RGBA的任意组合以及0，这将意味着不会写入到任何通道，可以用来单独做一次Z Test，而不将结果写入颜色通道。 _Time_Time是个4维向量，跟Unity3D中的deltaTime（这个是一维的，数值）不同。 名称 类型 说明 _Time float4 t是自该场景加载开始所经过的时间，4个分量分别是(t/20,t,t2,t3) _SinTime float4 t是时间的正弦值，4个分量分别是(t/8,t/4,t/2,t) _CosTime float4 t是时间的余弦值，4个分量分别是(t/8,t/4,t/2,t) unity_DeltaTime float4 dt是时间增量，4个分量分别是(dt,1/dt,smoothDt,1/smoothDt) shader中函数的基本理解 smoothstep获取较为平滑的过渡效果length(uv)降维效果 length(uv)将2D转换为1D atan(u,v)获取角度，配合length可以得到极坐标 pow(f,n)将曲线变化变得平滑或尖锐 sin cos 周期函数，用于实现周期的效果（如来回移动，循环的移动等） hash获取标志ID，常用于基于空间划分的效果的实现 noise同时具有随机性和连续性的函数 fbm在基本函数的基础上，不断的叠加高频信息，丰富细节 frac返回小数部分 fmod(x, y) 返回x/y的余数 假如uv是(-0.5,-0.5)到(.5,0.5) smoothstep eg:绘制smoothstep曲线f(x)=xx(3.0-2.0*x)具有淡入淡出效果123456float3 DrawSmoothstep(float2 uv)&#123; uv+=0.5； float val = smoothstep(0.0,1.0,uv.x); val = step(abs(val-uv.y),0.01); return float3(val,val,val);&#125;]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器配置文件说明]]></title>
    <url>%2F2017%2F10%2F12%2Fservercfg%2F</url>
    <content type="text"><![CDATA[摘要：本文档描述手游服务器的各个配置文件的使用和配置参数说明。关键字：服务器 维护 配置 1.概述请先参考《游戏系统架构》以了解手游的服务器架构状况。手游的所有配置文件都采用相同的格式。运维人员会经常用到的配置文件特性有：注释，文件包含include、宏定义、条件读取。 2.各个服务器主要配置参数说明2.1 公共配置文件文件名：cmncfg.txt该文件主要用来被所有的配置文件包含，可以定义一些全局性的信息（比如在不同的服务器配置信息不同的地方就可以放在这个文件里，这样不同的服务器只要修改这一个文件即可。）它一般放在所有服务器程序目录的上层目录，命名为cmncfg.txt典型内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788////////////////////////////////////////////// 经常要变的部分////////////////////////////////////////////// 大区的ID（这个配置很重要，如果配置错误会导致所有的角色和物品ID错误，影响合服）#defene SVRGRPID 2// 代表版本字串#define VERMAIN 0.7100// 各类服务器IP定义// 日志服务器的地址#define LOGSVR 192.168.0.49// GMS4Chat#define GMS4CHATINNERIP 192.168.0.49// CAAFS4CHAT#define CAAFS4CHATOUTTERIP 192.168.0.49// GMS4Game#define GMS4GAMEINNERIP 192.168.0.49// DBS#define DBSINNERIP 192.168.0.49// P2PSERVER#define P2POUTTERIP 192.168.0.49// XGMS#define XGMSINNERIP 192.168.0.49// TTYGZS#define TTYGZSINNERIP 192.168.0.49// XCAAFS#define XCAAFSOUTTERIP 192.168.0.49// XCLS#define XCLSOUTERIP 192.168.0.49// 本组配置的端口增量（主要用于在同一台机器上启动多组服务器）#define PORTSHIEF 0// 共享内存增量#define SHMSHIFT 0// 日志的跟路径（注意这个配置，如果在后面加上了"/"则会导致目录创建失败，因为字串中后来形成的//会被当成注释）#define LOGPATH /ITC/LOG// 数据库相关的定义#define DB_HOST localhost// 如果DB_HOST是localhost则需要填写这个，默认值是/tmp/mysql.sock#define DB_SOCKET /TMP/mysql.sock#define DB__USER root#define DB_PASSWORD zentiadb2017#define DB_CHARSET utf8// 用户数据库#define PLAYERDB zentia0// 全局总控相关数据库（GMS4Game使用的）#define IMSDB ims0////////////////////////////////////////////////////// 不经常变的部分////////////////////////////////////////////////////// 表面这是debug版本#define DEBUG// 表明这是内部调试用的，可以放宽一些限制（正常运营时应该注视掉）// #define INNERDEBUG// 表明客户端超时不要太长（在内部测试的时候可能有用，因为有时候需要长时间不断，有时候需要正常超时断）// define QUICKDROP/////////////////////////////////////////////////////// 日志服务定义/////////////////////////////////////////////////////// 日志服务的描述串（根据各个服务器需求的不同分为下面三个等级）#define LOGADDRSTR_0 0,$(LOGSVR):2000+$(PORTSHIFT), 1,$(LOGSVR):2001+$(PORTSHIFT), 2,$(LOGSVR):2002+$(PORTSHIFT)#define LOGADDRSTR_1 0,$(LOGSVR):2000+$(PORTSHIFT), 1,$(LOGSVR):2001+$(PORTSHIFT), 2,$(LOGSVR):2002+$(PORTSHIFT), 3,$(LOGSVR):2003+$(PORTSHIFT), 4,$(LOGSVR):2004+$(PORTSHIFT), 5.$(LOGSVR):2005+$(PORTSHIFT), 6,$(LOGSVR):2006+$(PORTSHIFT)#define LOGADDRSTR_1 0,$(LOGSVR):2000+$(PORTSHIFT), 1,$(LOGSVR):2001+$(PORTSHIFT), 2,$(LOGSVR):2002+$(PORTSHIFT), 3,$(LOGSVR):2003+$(PORTSHIFT), 4,$(LOGSVR):2004+$(PORTSHIFT), 5.$(LOGSVR):2005+$(PORTSHIFT), 6,$(LOGSVR):2006+$(PORTSHIFT), 7,$(LOGSVR):2007+$(PORTSHIFT), 8,$(LOGSVR):2008+$(PORTSHIFT), 9,$(LOGSVR):2009+$(PORTSHIFT), 10,$(LOGSVR):2010+$(PORTSHIFT), 11,$(LOGSVR):2011+$(PORTSHIFT), 12.$(LOGSVR):2012+$(PORTSHIFT), 13,$(LOGSVR):2013$(PORTSHIFT), 14,$(LOGSVR):2014$(PORTSHIFT)// 本大区最多支持的同时在线用户数量#define MAXPLAYER 16000// 服务器间tcp通讯的消息缓冲设置#define MSGBUFFLEN 10*1024*1024// debug版的文件后缀#ifdef DEBUG#define CFGEXT#else#define CFGEXT#endif// 这个只有配置caafs4chat的时候才需要，正常的配置不需要，这个一般不变的，因为CAAFS4Chat一般就起一个即可#define CAAFS4CHATID 1// 是否在GSZ宕掉之后重新拉起自动载入用户#define GZSDOWNRESTOREPLAYER true// CNL网络超时（和客户端的断线超时）#ifdef INNERDEBUG#define DROPTIMEOUT 2000000#else#define DROPTIMEOUT 100000#endif#ifdef QUICKDROP#define DROPTIMEOUT 600000#endif 2.2 GMS4Game配置文件：gms4game_cfg.txt典型内容如下：123456789101112131415161718192021#include ../cmncfg.txtCMN&#123; stream_size = $(MSGBUFFLEN) // 本地监听的地址和端口（供其他服务器连接） tcp_listen_host = $(MYOUTERIP):5000+$(PORTSHIFT) // 和其他服务器TCP连接的超时设置 keepalive_idle = 60000 keepalive_interval = 2000 // MySQL配置 db_host = $(DB_HOST) db_user = $(DB_USER) db_password = $(DB_PASSWORD) db_database = $(IMSDB) db_charset = $(DB_CHARSET) db_socket = $(DB_SOCKET) // 日志服务（这个只需要比较少的日志种类） logger_addr = $(LOGADDRSTR_0) // szPIDFile = /tmp/GMS4Game-$(SVRGRPID).pid&#125; 2.3 XLBA配置文件：lba_cfg.txt典型内容如下（基于XCMNSVR的配置）:gzs_cfg1.txt12 附录1.基于XCMNSVR的配置 XCMNSVR是PNGS框架中的一种标准服务器程序结构。 通过该结构配置的服务器由一个主程序框架：XCMNSVR和一系列的动态连接库插件构成。 其配置文件一般都是下面的样子：12345678910111213141516171819CMN&#123; // 用于记录日志中表示程序名和在windows下显示窗口标题栏上 szSvrName = 服务器名 // 是否运行为后台守护进程（这个选项一般在GDB启动程序进行调试比较有用） bDaemon = true // 日志服务地址 szLoggerAddr = $(LOGADDRSTR) // 每个逻辑循环的最大时间（其大小会影响服务器在没有网络输入输出的情况下的逻辑tick精度） nSelectInterval = 50&#125;PlugIn&#123; // 各个插件的载入和创建参数 // 注意：插件的文件名必须是带路径的。即便是当前路径下也需要写&quot;./&quot;前缀 DLL = 0,/TCPReceiver$(CFGEXT).so,TCPReceiver_Create DLL = 0,/TCPReceiver$(CFGEXT).so,LBACDTest_Create&#125;// 后面跟着各个插件自己需要的参数配置 附录2.CNTRSVR的配置附录3.GSMEM的配置附录4.IP的允许禁止文件的配置]]></content>
      <tags>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Manual]]></title>
    <url>%2F2017%2F10%2F12%2Fhexo%2F</url>
    <content type="text"><![CDATA[&lt;span id=&quot;jump&quot;&gt;跳转到的地方&lt;/span&gt;跳转到的地方 安装npm install -g hexo-cli如果提示timeout的话，使用下面指令npm config delete proxy 关闭背景动画背景动画基于canvas，个人感觉比较耗，毕竟i3，所以关闭，在\themes\next_config.yml中修改字段1three_waves: false 嵌入PDFnpm install --save hexo-pdf添加hexo deploy -- 发布编辑主题的 source/css/_variables/custom.styl 文件，新增变量：12345// 修改成你期望的宽度$content-desktop = 700px// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px 发布hexo d -g如果发布失败的话，将ssh换成https://github.com/zentia/zentia.github.io.git Font&lt;font size = 4 color=red&gt;&lt;/font&gt; # 字体大小颜色设置 列表嵌套 上一级和下一级之间敲三个空格即可 用pass-by-refrence-to-const替换pass-by-value内置类型，STL迭代器，和函数对象采用pass-by-value不要返回pointer或者reference指向一个on stack对象（被析构）不要返回pointer或者reference指向一个on heap对象（需要用户delete）不要返回pointer或者reference指向local static对象切记将成员变量声明为privateprotected并不比public更有封装性（其实我不是很喜欢封装这个东西）多一个成员函数，就多一分破坏封装性若所有参数都需要类型转换，采用non-member函数（member类型转换不行吗？） 腾讯开发者平台 http://zentia.coding.me git@git.dev.tencent.com:Zentia/Hexo.git github http://zentia.github.io git@github.com:zentia/zentia.github.io.git 码云 http://zentia.gitee.io git@gitee.com:zentia/zentia.git 修复图片展示新建博文，设置type: “picture”，使用{\% gp x-x \%} … {\% endgp \%}标签引用要展示的图片地址，如下所示：12345678910111213141516---title: Naruto-Picturescategories: [图片]tags: [picture,naruto]date: 2016-09-02 14:36:04keywords: picture,narutotype: &quot;picture&quot;top: 999---&#123;% gp 5-3 %&#125;![](https://cdn.ehlxr.top/post/18210.jpg)![](https://cdn.ehlxr.top/post/196232.jpg)![](https://cdn.ehlxr.top/post/224147.jpg)![](https://cdn.ehlxr.top/post/199301.jpg)![](https://cdn.ehlxr.top/post/213318.jpg)&#123;% endgp %&#125; {\% gp 5-3 \%}：设置图片展示效果，参考 theme/next/scripts/tags/group-pictures.js 注释示意图。主题目前首页可以正常显示步骤 8.2 设置的图片效果，但是点击进入后显示效果丢失，所以需要修改一下文件 themes\next\source\css_common\components\tags\group-pictures.styl 中的以下样式：123456.page-post-detail .post-body .group-picture-column &#123; // float: none; margin-top: 10px; // width: auto !important; img &#123; margin: 0 auto; &#125;&#125; algolia由于zentia.site这个域名没有备案，导致一直无法使用，然后只能使用zentia.github.io。然后一直没有更新algolia导致搜索还是访问之前的源，这个问题痛苦了好久。然后今天解决hexo algolia可能会提示ERROR [hexo-algolia] Please set an HEXO_ALGOLIA_INDEXING_KEY environment varia这个问题，然后export HEXO_ALGOLIA_INDEXING_KEY=&#39;f4ca7ae2408d2e27ffc8269ad8d34273&#39;这样就解决了。 上下标H&lt;sub&gt;2&lt;/sub&gt;O CO&lt;sub&gt;2&lt;/sub&gt;引用&lt;sup&gt;&lt;a href=&quot;http://www.baidu.com&quot; target=&quot;_blank&quot; title=&quot;百度一下&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;引用[1] 跳转[点击跳转](#jump)点击跳转]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git笔记]]></title>
    <url>%2F2017%2F10%2F12%2Fgit-question%2F</url>
    <content type="text"><![CDATA[warning:LF will be replaced by CRLF问题解决方法CRLF — Carriage-Return Line-Feed回车(ASCLL 13, \r)换行(LF, ASCLL 10, \n)。解决方法1git config --global core.autocrlf false 切换httpgit remote set-url origin https://github.com/zentia/blog.git]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The following untracked working tree files would be overwritten by merge]]></title>
    <url>%2F2017%2F10%2F12%2FThe-following-untracked%2F</url>
    <content type="text"><![CDATA[git pull的时候遇到的问题。解决办法：git clean -d -fxnote:会删除没有add到仓库的文件，操作记得慎重，以免改动文件的丢失。]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初始化云服务器]]></title>
    <url>%2F2017%2F10%2F11%2Finit-server%2F</url>
    <content type="text"><![CDATA[搭建git服务器yum install -y gitadduser git //创建用户gitgit clone git@10.173.32.7:/home/git/sample.git //克隆远程仓库 clone git仓库上传代码git commit -am ““, 将所有修改，但未进stage的改动加入stage,并记录commit信息（某种程度上相当于git add 和 git commit -m的组合,前提是被改动文件已经是tracked)1find ./ -type d -name "del_dir" -exec rm -r &#123;&#125; \; 注意中间的空格]]></content>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity 2D Outline]]></title>
    <url>%2F2017%2F10%2F05%2F2d-outline%2F</url>
    <content type="text"><![CDATA[像素着色器描边：首先最直观的想法，就是使用fragment shader找出2D角色贴图透明像素和非透明像素的边界，然后通过边界周边Alpha值Blur的方式，给边界上描边色。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Shader "Hidden/NewImageEffectShader"&#123; Properties &#123; _MainTex ("Texture", 2D) = "white" &#123;&#125; _Offset ("Offset", Range(0,1)) = 0.1 // 偏移 _Color ("Color", Color) = (1,0,0,1) // 边缘色 _AlphaThreshold("Alpha Threshold", Range(0,1)) = 0.5 &#125; SubShader &#123; Tags &#123;"Queue"="Transparent"&#125; Blend SrcAlpha OneMinusSrcAlpha Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "UnityCG.cginc" struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; &#125;; struct v2f &#123; float2 uv[5] : TEXCOORD0; float4 vertex : SV_POSITION; &#125;; sampler2D _MainTex; float4 _MainTex_ST; fixed _Offset; // 偏移 fixed4 _Color; // 边缘色 fixed _AlphaThreshold; // Alpha 阀值 v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv[0] = v.uv; o.uv[1] = v.uv + float2(0, _Offset);// 上 o.uv[2] = v.uv + float2(0, -_Offset); // 下 o.uv[3] = v.uv + float2(-_Offset, 0); // 左 o.uv[4] = v.uv + float2(_Offset, 0); // 右 return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 col = tex2D(_MainTex, i.uv[0]); fixed alpha = col.a; fixed p1 = tex2D(_MainTex, i.uv[1]).a; fixed p2 = tex2D(_MainTex, i.uv[2]).a; fixed p3 = tex2D(_MainTex, i.uv[3]).a; fixed p4 = tex2D(_MainTex, i.uv[4]).a; alpha = (alpha + p1 + p2 + p3 + p4) / 5; fixed ret = step(alpha, _AlphaThreshold); col.rgb = ret * _Color.rgb + col.rgb * (1-ret); return col; &#125; ENDCG &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566Shader &quot;Hidden/NewImageEffectShader&quot;&#123; Properties &#123; _Edge (&quot;Edge&quot;, Range(0,0.5)) = 0.1 // 边缘 _EdgeColor (&quot;Edge Color&quot;, Color) = (1,0,0,1) // 边缘色 _FlowColor (&quot;Flow Color&quot;, Color) = (0,1,0,1) // 流动色 _Speed (&quot;Speed&quot;, Range(0, 2)) = 1 // 旋转速度 _MainTex(&quot;MainTex&quot;, 2D) = &quot;white&quot; &#123;&#125; // 主纹理 &#125; SubShader &#123; Tags &#123;&quot;Queue&quot; = &quot;Transparent&quot;&#125; Blend SrcAlpha OneMinusSrcAlpha Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; // 纹理uv坐标 &#125;; struct v2f &#123; float4 vertex : SV_POSITION; float2 uv : TEXCOORD0; &#125;; sampler2D _MainTex; float4 _MainTex_ST; fixed _Edge; // 边缘阀值 fixed4 _EdgeColor; // 边缘色 fixed4 _FlowColor; // 流动色 fixed _Speed; // 旋转速度 v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = v.uv; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed x = i.uv.x; fixed y = i.uv.y; if (x &lt; _Edge || abs(1 - x) &lt; _Edge || y &lt; _Edge || abs(1 - y) &lt; _Edge) // 求边缘 &#123; x -= 0.5; y -= 0.5; fixed w = _Speed * _Time.y; fixed temp = saturate(x* cos(w) - y* sin(w)); return (temp )* _EdgeColor + (1-temp)*_FlowColor; &#125; return tex2D(_MainTex, i.uv); &#125; ENDCG &#125; &#125;&#125; 后处理+像素着色器描边： 于是，很自然的想到，使用Postprocessing 的方式来处理屏幕最终渲染出来的仅包含有需要描边的角色的图片，然后进行上述的fragment描边处理。 首先，在场景中添加一个专用的描边相机，Depth设为比默认相机高一级，视口大小、位置全部和默认相机一致。另外给场景物体添加一个”Outline1”layer，设置到专用相机的cullingmask，需要描边的角色的layer都设置为”Outline1”。 这个时候专用相机只渲染描边物体，然后给相机添加Monobehavior脚本，在OnRenderImage里对相机渲染的图像进行像素着色器的描边处理，得到如下效果： 描边效果的确是预期的效果，但是还是有两个问题： 一个是：由于我们游戏UI是使用Screen space - camera的方式，它和游戏中对象都是在默认相机渲染的，专用相机的depth比默认相机高一级，所以所有渲染内容都会在UI层次之上，这显然也不是我们想要的。 另一个是：角色的不同行动状态需要用不同的描边颜色来区分，上述方式只支持一种描边颜色。 RenderTarget + 像素着色器描边： 现在我们着重来解决上述两个问题：第一个遮挡UI的问题： 描边效果需要在默认相机中进行z轴排序，让其渲染在UI之后，所以，我们需要让描边效果作为一个默认相机渲染的常规游戏对象放到游戏中。于是，我想到的是给它创建一个和屏幕尺寸同大小的Mesh，再将描边渲染的图片放到Mesh上，所以，做法是给专用相机分配一个屏幕尺寸同大小的RenderTarget，然后将RenderTarget渲染到创建的Mesh上。如下图所示，该Mesh在骨骼动画和相机之间创建。 第二个颜色区分的问题： 查询Unity Camera的API有两个回调接口可以用： OnPreRender 在相机渲染场景之前被调用。 OnPostRender 在相机完成场景渲染之后被调用。 我们给专用相机添加这两个回调，在OnPreRender里： 给所有需要描边的物体更换Material，该Material负责绘制该物体的状态纯颜色到RenderTarget上，并保存原有Material。在OnPostRender里： 将原有Material又置换回来供默认相机正常渲染。得到的RenderTarget如下， 这个时候，再用像素着色器对应用了RenderTarget的Mesh进行描边，得到如下效果]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pixel-and-voxel]]></title>
    <url>%2F2017%2F10%2F05%2Fpixel-and-voxel%2F</url>
    <content type="text"><![CDATA[原文地址: https://medium.com/retronator-magazine/pixels-and-voxels-the-long-answer-5889ecc18190#.8gf6zy8mc 伪3D等轴游戏 赛达尔, Sir Carma, 2016 像素和体素，一个详细的答案Retronator Stray Pixels 像素和体素的区别是什么？ 我很清楚他的问题。你会在生活中看到类似像素大战电影海报这样的东西，而你会对此产生困惑。它是像素吗？还是体素？它是一只鸟？还是一架飞机？这个东西一定不简单。不必害怕，我来解释这个问题。当你阅读完这篇文章后你会知道所有关于像素和体素的知识以及它们之间的联系。 首先我先介绍一点背景知识以便你更好的了解该领域的全貌。在计算机中有两种表示图像的方法：向量和栅格（raster）。 向量图像（左）的数学准确性和栅格图像（右）的离散性向量图像使用各种表示直线，曲线和不同形状的数学方程描述图像。相反，栅格图像将图像描述为一个含有颜色值的数组，该数组中的颜色值依次被放置在一个网格系统中。 计算机图像学中的第二个区别在于2D和3D空间之间的差别。算上向量/栅格的区别总共有四种情况： 大家都喜欢象限！向量图像在2D向量图像中，直线或不同形状上的每个点都由具有两个分量（x和y）的向量来表示。这就是它被称为2D的原因（两个分量——两个维度）。 2D向量是这样表示2D向量图像中每个点的以下是一张所谓的低多边形2D向量图像 伟大梦想着乌鲁鲁（Uluru the Mighty Dreamer）, Anh Tran, 2015它完全使用了2D多边形（在这个情况中为三角形）。低多边形这个术语意味着制成图像所需的多边形数量相对较少。这使得三角形容易被识别出来。我们加入一个维度。在3D向量图像中情况相同，但是每个向量使用了三个分量（x，y，z）。三个分量——三个维度。我们看一张3D低多边形的作品。 iOS概念游戏 赛道, Timothy J. Reynolds, 2013 之前的Ayers Rock的2D图像和这里的3D跑道之间的区别在于我们可以在我们想要的任意位置看这个跑道。 iOS概念游戏 赛道 (另外视角), Timothy J. Reynolds, 2013为了在你的屏幕（一个2D平面）上显示跑道，我们需要一个特定的视点（viewpoint）然后从那一点将3D几何体投影到2D中。 从3D向2D的变换叫做投影这是我们得到一个特定2D图片的方法。 但是我们可以使用一个小技巧来在2D中显示3D几何体的体积特征——我们可以制作一个动画，将我们的视点设置为绕物体旋转（或者固定视点，旋转物体，如下图所示） 旅行车, Timothy J. Reynolds, 2013耶！我们真的看到了3D，不需要3D眼镜！ 栅格图像这只是热身。向量暂告一段落，我们继续看看栅格图像如何处理2D和3D。在2D栅格图像中，图片被分为若干行列的小方格，这些小方格大小相等。 Turbo Esprit Sprite, Matej ‘Retro’ Jan, 2014每个单元被称作一个像素（来自图片的元素）。除了网格中的2D坐标（x，y）它的主要性质还有那个坐标的颜色。 我们已经见过低多边形向量方法如何使用易于辨认的大多边形。如果我们在栅格图像中也这样做（使用明显的大像素）我们得到了像素艺术。 Tribute (修正版), Matej ‘Retro’ Jan, 2005, 2012对于2D像素图片来说，尽管它们想要表示三维物体（一个Lotus Esprit 或者一个X-wing），但是它们被直接画到了2D像素网格上。你不能像前面旋转3D向量小汽车那样旋转这张图片。同样，文章开始的那张Ayers Rock图片也不能被旋转。尽管是由多边形构成的，它们没有被放置在3D空间内，而是直接被放在2D中。 目前我们已经介绍完了2D和3D向量图像以及2D栅格图像。最后我们介绍3D栅格图像。 即将介绍激动人心的东西！在3D栅格图像中，体积被均匀分到行和列中，覆盖了全部三个不同的方向（上下，左右，里外）。这样3D空间被分为许多小立方体，称为体素（体积元素或者体积像素）。每个体素由一个3D坐标和位于该坐标的颜色定义。 和像素艺术（指的是精心安排像素位置的艺术）一样，我们现在有了体素艺术，其中每个小方块都需仔细安排。 星球大战场景, Sir Carma, 2015太像乐高了，你不这么认为吗？注意由于我们在3D场景中，我们可以从各种方向观察体素。这是从另一个角度看Tatooine的体素。 星球大战场景 (从另一视点观测), Sir Carma, 2015 我们甚至可以做动画！这是Sir Carma的动画体素角色中的一个例子： 骑士快跑（Knight Run）, Sir Carma, 2015将它和2D像素艺术角色作比较： 最后元素（Last Element）中的精灵, Glauber Kotaki, 2015你可以看出在体素艺术中，动画是如何改变小方块——也就是体素——的外表（颜色）的，以及在像素艺术中颜色的改变是如何发生在小方块——像素上的。现在你知道了像素和体素之间的差别（以及更多……哈哈，对于这一点很抱歉）。但是还没完。瞧，我之所以解释向量/栅格，以及2D/3D是因为在现代显示设备上，每种图像类型最后都会被显示为2D栅格图片。 我们在一本像素艺术杂志中提及这个的原因是我们可以使用这类变换来创造出现代像素艺术的风格，此风格使用非像素艺术象限中的艺术资源。“我可以使用体素或3D模型制作像素图像？”你觉得呢？没错就是这样！巧妙地运用着色和渲染技术可以使我们创造出独特的视觉风格，将像素艺术带入到未来。向量的显示和投影上面的图示并不全部正确。有一种直接显示2D向量图像的方法，它使用了一个小技巧。 一张2D向量图像只能直接显示在一个向量显示器上，和Atari的街机游戏太空射击使用的那些一样。 太空射击, Atari, 1979这是它实际看上去的样子（示波器上显示的是一款类似于太空射击的游戏） 太空岩石(游戏), Autopilot, 见 Wikimedia Commons [CC BY-SA 3.0]我们还可以这样显示3D向量图像（通常被称为3D模型）。与之前提到的一样，3D模型首先需要被投影到两个维度上，产生一张可以显示在向量显示器上的2D向量图像。 VEC9, Andrew Reitano &amp; Todd Bailey, 2013我极度推荐观看VEC9宣传片以及80年代的硬汉片：https://youtu.be/rSPixmsLfn4 VEC9, Andrew Reitano &amp; Todd Bailey, 2013 栅格化处理如今你很难在博物馆以外的地方找到一个向量显示器。相反，我们使用像素进行显示！ RGB LCD, Luís Flávio Loureiro dos Santos, 见 Wikimedia Commons [CC BY 3.0]一个现代LCD显示器通过开启和关闭（或半开半关）小的红绿蓝LCD（液晶显示器）创造出不同的颜色。以免你有疑问，CRT（阴极射线管）原理类似，只不过它们使用三种荧光体进行搭配以便电子束撞击的时候产生红绿蓝三种颜色。 CRT 荧光点, 见 Wikipedia [CC-SA] 那么我们该如何将一张向量图片显示在一个栅格显示器上呢？嗯，从2D向量图片到2D栅格图片，图片需要被渲染或者被栅格化处理。每个多边形（通常一个三角形）被渲染为网格中的一个像素。 使用抽样法进行栅格化处理, Making WebGL Dance的一张幻灯片, Steven Wittens, 2013 这可以被拓展到在栅格显示器上渲染3D模型。首先，3D三角形被投影为2D三角形。然后2D向量三角形被栅格化处理为像素。 星际火狐, Nintendo, 1993 三角化那么体素呢？现在体素艺术使用的最常见方法是将每个体素表示为一个3D向量方块，为此我们可以创建一个沿体素方块边缘摆放三角形的3D模型 世界上最激动人心的3D模型, Matej ‘Retro’ Jan, 2016 和之前一样，3D三角形接着被投影到2D图像空间中最后被栅格化处理来显示一张2D栅格图像。 旋转的方块 (技术演示), Matej ‘Retro’ Jan, 2016这是我们现在得到最常见的体素艺术风格的方法，几乎完全使用免费建模工具MagicaVoxel完成。 长发公主的塔（Rapunzel tower）, Thibault Simar, 2016 无题, Argo San, 2016 口袋妖怪的体素, Playiku, 2016 猫咪 vs 体素, Stefan Smiljkovic, 2016 战壕奔跑（Trench Run）, Gabriel de Laubier, 2015 体素气球, Gabriel de Laubier, 2015 空中追击, Sir Carma, 2015 塔拉克村庄（Talaak village）, Sir Carma, 2016 Latica悬崖, Sir Carma, 2015 光线投射其实我们可以不采用立方体方法。每个体素都可以被认为是3D空间中的一个点，那个位置的一个blob（二进制大对象）体积。你可以通过在2D空间中的一个位置放置一个（或多个）像素来直接在2D空间中画出每个体素。或者相反——你可以选择屏幕中的一个像素然后找出场景中出现在那个位置的体素。 该逆向方法被称为光线投射。你可以从视点向场景内投射一束光线然后找出击中的体素。事实上，你可以射出多个射线来扫过全部的视界。 使用鱼眼矫正的简单光线投射, Kieff, 见 Wikimedia Commons [public domain] 这个技巧被首次使用在德军司令部中，其中它的体素全部是房间中的小方块，所以这只是另一种将体素作为小方块进行渲染的方法。不过它的速度很快，因为你只需将一整列的像素投射到屏幕中。这本质上是一个2D过程，也就是为什么我们有时将这类3D图像称为2.5D（某种程度上讲第三个维度是假的，因为它是沿着突出的2D平面的）。 德军司令部, id Software, 1992 不过通常我们不认为Wolfenstein使用了体素。我们必须让单元足够小并让它们有不同的高度。于是到了90年代我们有了经典体素图像引擎。 超级科曼奇, NovaLogic, 1992 一开始体素只被用于地形制作。它们必须简化物体使得全部的体积信息只有存储在2D图像（又被称为高度贴图）中的地形高度。 一个高度贴图（左）告诉我们体素的垂直高度有多少（黑代表低，白代表高） 将体素信息限制在高度贴图中意味着不能有类似于突出的悬崖的东西。但是已经很好了，地形含有的的细节数量是所有之前游戏不能企及的。 三角洲特种部队, NovaLogic, 1998 时空英豪, Appeal, 1999 体素的结束光线投影不是90年代的游戏渲染体素信息所用的唯一方法。其它的方法各有优势，例如支持可以毁坏的地形或者可以渲染汽车或者人物。这些在当时都是最先进的方法了！讽刺的是，这种富有创造的多样性也预示着这项技术迎来迟暮。 万杰赛车, K-D Lab, 1998问题是，直到2000年底图形加速卡诞生了。这些硬件专门处理投影和栅格化3D多边形（现在我们管这些芯片叫做图像处理单元或GPU）。它们渲染三角形的速度飞快，不过这也是它们所能做的全部工作了。自定义体素渲染算法，包括光线投射，在它们的能力之外。 Hexplore, Doki Denki Studio, 1998体素引擎继续在CPU（中央处理单元）上实现，但是CPU另外还要接管剩余的工作，包括物理模拟，游戏流程和人工智能。在GPU上处理图像的主要原因是将渲染放在一张单独的芯片上完成，提高渲染速度的同时还给予了CPU更多的空间做更复杂的模拟。体素引擎跟不上多边形图像的性能所以死翘翘了…… ……直到大约十年后有一款游戏将它们带到了一个新的受欢迎程度。它摒弃了旧的方法，为“将体素作为小方块”方法铺平了道路。现在这可以有效地使用GPU进行渲染而其它的皆成为历史。 我的世界, Mojang, 2009–今 定义我们总结一下我们学到的内容，然后使用一点数学知识回答一开始的关于什么是像素和体素的问题。 一个像素是将2D空间分割为离散的，均匀的（大小相同的）区域时得到的最小单位。 每个像素可以使用一个两个分量均为整数的向量来表示。这是为什么像素空间是离散的，而不是像连续的向量图像那样每个坐标都是一个实数（使用浮点数表示）。 相似地，一个体素是将3D空间分割为离散的，均匀的区域时得到的最小单位。这下你明白了。 我说完了吗？还没有，我还没说完。 被定义得如此宽泛，像素和体素可以以许多不同的方式出现，而我们可以创造性地将概念以各种形式表达出来。尤其，我们考虑综合了4象限的栅格/向量，2D/3D。 纯2D图像 在早些时候如果你想将2D 精灵（sprite）画到屏幕上你必须将一块储存精灵颜色的内存直接复制到另一块储存屏幕显示颜色的内存中（这个复制过程也被称为位块转换，或者叫bit BLT）。如今几乎没人单纯使用这种方法进行2D渲染了。幻想主机PICO-8作为现代的范本向过去那个位块转移作为唯一方法的时代致敬。 PICO-8, Lexallofle Games (以及各自特征小车的作者), 2014–今 3D图像中的纹理 如今大多图像引擎在基础层次使用向量，因为GPU就是这样工作的。在这个系统中使2D图像出现在屏幕上的主要方法是使用一种叫做纹理映射的方法将它们画在多边形上。 纹理是2D栅格图片，可以被放置在（或被映射到）3D多边形上。 这是大多数3D视频游戏（广泛上讲还有3D图像）在制作中所采用的最简单的方法。 例如，这是一个高多边形的3D模型，我们加入一张高分辨率的纹理： 镜之边缘：催化剂 Keyart, Per Haagensen, 2016 由于我们使用平滑的多边形着色和纹理映射我们甚至不需要那么多的三角形来创造出人物好看的外表。这是一个低多边形3D模型外加一个高分辨率的纹理。 低多边形的工匠, Mark Henriksen, 2015当我们也将高分辨率纹理转换为低分辨率时，我们得到了类似于下面这个低多边形3D模型和一个像素艺术纹理： 漂移阶段, 2014–今 (正在制作中)这个情况最出色的例子当然是我的世界了。尽管我的世界的块根据定义是体素（它们是游戏中最小的离散体积单位），但是它们以各种低多边形模型和像素艺术纹理代表的类型出现。尽管它们是一个个的小块，它们中的许多都不是简单的立方体。 我的世界, Mojang, 2009–今 这样所有的3D模型情况就都讲完了（高多边形3D模型和低分辨率纹理的组合并不是很常见，但是如果错了请纠正我） 镜之边缘(左上), 马克思佩恩(左下) 和我的世界 (右下) 2D图像中的纹理 回到2D！当我们将纹理投影应用到2D矩形上时，我们得到了现在常见的2D游戏。使用当今的硬件，每张2D图像（在这种情况下常被称为精灵）被放在一个由两个三角形组成的矩形中进行显示。两个三角形（加起来也被称为一个四边形）通过映射到它们上面的精灵进行渲染，使得图像出现在正确的位置。 人物图像的一部分(左) 被纹理映射到动画四边形中(右)。羽毛球, Matej ‘Retro’ Jan, 2006 高分辨率图像就很直接了…… 时空幻境, Number None, 2008 地狱边境, Playdead, 2010……但是低分辨率，像素艺术纹理就稍微复杂一些了。它完全取决于我们采用什么显示分辨率来渲染精灵。 时空幻境(左上), 通往天空的路(右上), 王国(右下) 我们已经见识到了可以将像素艺术纹理应用到一个低多边形3D模型上，但是仍使用高分辨率进行渲染。考虑一下我的世界。低多边形模型，低分辨率16x16像素纹理，放在一个显示分辨率为1920x1080的场景中。 我的世界, Mojang, 2009–今 同样2D多边形也可以这样做。我们使用一张像素艺术图片，将它放在一个2D四边形上，然后将它渲染到高分辨率屏幕上，这样一来源图像中的每个像素都包含了显示中的多个像素。 迈阿密热线, Dennaton Games, 2012 我们将此风格称为大像素艺术风格。每个精灵像素按照大于显示像素进行渲染，以便它在图像中作为一个大方块出现。 每个源精灵像素被渲染为3x3显示像素， 登月者, Ben Porter, 2011–今 （正在制作中) 大像素风格在精灵被旋转或倾斜时变得明显： 通往天空的路, Johannes ‘Dek’ Märtterer, 2011–今 (正在制作中) 看看上图中的树叶，然后将它和低分辨率渲染下的旋转精灵进行对比。 王国, Noio &amp; Licorice, 2015 你看到水轮的像素是如何水平/垂直排列开来的，而在通往天空的路中树叶，小鸟，和桥梁的大像素都被调整了角度和做了变换吗？ 王国在低分辨率下渲染整个游戏然后只将结果图像放大（调大尺度）到显示分辨率。另一方面，通往天空的路，迈阿密热线和登月者直接将精灵渲染到高分辨率显示。 回到3D王国是一款2D游戏，但是它所采用的方法也能放到3D中。 我们可以使用像素艺术纹理的3D模型，但是在低分辨率中渲染它们，我们得到如下： 像素艺术学院技术演示, Matej ‘Retro’ Jan, 2016你会发现我们正确地得到了带有投射阴影的3D着色。尽管结果看上去像2D像素艺术，但它实际上是一个使用像素艺术纹理在低分辨率下进行渲染得到的3D场景。 像素艺术学院技术演示 (场景视觉), Matej ‘Retro’ Jan, 2016 基于向量（使用骨骼绑定）的动画也可以利用这个优势。这是它们在大像素风格中的样子： 动画绑定, Matej ‘Retro’ Jan, 2016 但是当在低分辨率下渲染时，它们显得更像像素艺术，排成一列的像素和上面的王国相似。 像素艺术学院动画测试, Matej ‘Retro’ Jan, 2016 这和手绘的、一帧一帧的动画相差甚远，但是具有一定的美感，让人想起了90年代的rotoscope（动态遮罩）动画。 波斯王子, Jordan Mechner, 1989 3D效果回到高分辨率，一个充分利用3D优势的游戏是Odd Tales的Last Night 最后一夜中的WIP场景, Tim Soret, 2016 这样他们构建了一个可以从不同角度观察的三维世界。 最后一夜中的3D场景构建, Tim Soret, 2016 另一个动态3D光照的例子是拥有优秀场景但是命运不佳的游戏致命快递。 致命快递, Maksym Pashanin, 2013–2014 (未发布) 虽然美术资源仍是2D的，但是它们还包括了从多个方向的着色的图片。这些是使用类似于Sprite Lamp这样的工具进行处理的，并且任何位置的光源都会产生精灵的平滑照明。 来自于体素的像素艺术以上方法的问题在于只有精灵的着色可以准确完成，而它们投射的阴影缺少所需的3D几何因此不能正确生成。为此你还是需要体积信息。又到体素了！ 这种方法一个很棒的例子是最近宣布的Pathway： 道路（Pathway）, Robotality, 2016 (正在制作中) 图像看上去完全像是在使用像素艺术精灵，但是其背后的信息却是体积的。和90年代试图看上去更现代和更现实的体素引擎不同，Robotality的开发者最多只将体素和显示像素的大小相匹配。这制造了一个巧妙的伪装，使它看上去像像素艺术，但是实际上它们拥有所有的3D信息来创造出完全正确的动态光照。 不过使用体素几何产生像素艺术并不完全是个新方法。之前FEZ使用了被其称之为三像素（3d 像素）的方法。三像素就是被综合为16x16x16方格（3d方格）的体素。 FEZ的游戏开发截图, Polytron, 2007 当一个FEZ场景在游戏中被渲染时我们基本上看到的是一个2D正交投影，这样他们既达到了传统像素艺术的外观又加入了FEZ标志性的视角旋转功能。 FEZ GDC ’09年宣传片, Polytron Corporation, 2009 FEZ, Polytron Corporation, 2012 纯体素最终，由于我们绕了一大圈终于回到了体素几何上，我们可以完全不管像素，仅在3D空间中渲染纯离散体素（使用不带任何纹理的立方体方法）。 Lexallofle’s Voxatron 是这个空间内的游戏名字. Voxatron, Lexallofle Games, 2010–今(正在制作中) 你注意到Lexallofle虚拟主机中的一个主题了吗？Pico-8有一个纯2D图像引擎而Voxatron则有一个3D体素的。它们是完美的搭档。 Voxatron, Lexallofle Games, 2010–今 (正在制作中)Voxatron是少数几个（如果不是唯一的话）真正使用3D空间的纯离散分割的游戏。但是与之相似的大像素风格却应用于许多游戏中，尤其在移动设备中。 天天过马路, Hipster Whale, 2014 Shooty Skies, Mighty Games, 2016 吃豆人256, Hipster Whale, 2015我们绕了一整圈回到了Sir Carma。在成为最著名的体素艺术师后，他现在在使用Unity将仅含体素的美学推向更高的高度，得到各种视觉效果，和Odd Tales对于像素艺术做出的贡献一样。 返回之路, Sir Carma, 2016 (正在制作中) 返回之路, Sir Carma, 2016 (正在制作中)有人知道Voxel Zelda/Atic Atac吗? 返回之路, Sir Carma, 2016 (正在制作中)好了，我们介绍了2D/3D/栅格/向量/低分辨率/高分辨所有我能想到的组合。我确定我忘记了一些内容，但是我更确定未来会有更多有趣的方法，但是目前这样就不错了。 我希望你们阅读愉快——为我们一路到尾欢呼！我希望你更深刻地了解了像素和体素图像，以及对它们下一步如何发展有了一些创造性的想法。想要更多有关像素艺术特征的信息你可以在Tumblr，Twitter，和Facebook上关注Retronator。每天都有新发现哦！—Retro]]></content>
      <tags>
        <tag>渲染</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大规模场景的资源拆分合动态加载]]></title>
    <url>%2F2017%2F10%2F04%2FassetSplit-dynamicLoad%2F</url>
    <content type="text"><![CDATA[概要 资源拆分 地形，地表 动态加载/卸载 打包策略资源拆分 地形资源拆分 Unity原始地形有网格尺寸的限制（4096） Mesh地形有面片数限制 降低内存占用，仅需载入部分地形数据 降低渲染面片数，视域体剔除 制作大规模地形 Terrain Composer 2 T4M 建模软件… 拆分现有地形 Terrain Slicing &amp; Dynamic Loading Kit 地形数据 filed meaning basemapDistance Heightmap patches beyond basemap distance will use a preomputed low res basemap. castShadows Should terrain cast shadows? ollectDetailPatches Collect Detail patches from memory. detailObjectDensity Density of detail objects. detailObjectDistance Detail objets will be displayed up to this distance. heightmapMaxmumLOD Lets you essentially lower the heightmap resolution used for rendering. heightmapPixelError An approximation of how many pixels the terrain will pop in the worst case when switching lod. lightmapindex The index of the lightmap applied to this renderer. terrainData The Terrain Data that stres htightmaps,terrain textures,detail meshes and trees. treeBillboardDistance Distance from the camera where trees will be rendered as billboards only. terrCrossFadeLength Total distance delta that trees will use to transition from billboard orientation to to mesh orientation. treeDistance The maximum distance at which trees are rendered. treeMaximumFullLODCount Maximum number of trees rendered at full LOD. Lightmap 拆分后重新烘培 切分烘培好的Lightmap exr 格式，FreeImage 切割跨地形的大模型 按地形块分组动态加载 关键在于：流畅 卡顿分析 Instantiate 前自动加载未加载的引用资源 Shader(Fallback) Texture Mesh AnimationClip 预加载资源 Shader(Fallback) Texture 预加载资源异步加载 Resources.LoadAsync AssetBundle.LoadAsync 实例化引起的序列化操作(Loading.LoadFileHeaders) 避免一次性实例化过多的粒子系统（预加载） 避免层级复杂，组件Awake过多 尝试拆分Prefab，流失Instantiate 加载策略(Assetbundle) Shared包常驻内存 大纹理等资源采用LoadFromCacheOrDownload Material/Mesh等可采用new WWW 卸载策略（AssetBundle） Prefab 包 GameObject可通过Destroy来销毁 TerrainData,Object等可通过Resources.UnloadAsset来进行卸载 Shared包 建议在确认不适用或切换场景时进行卸载 切换场景时调用UnloadUnusedAssets来卸载Texture，Mesh等加载的共享资源 注意事项 加载方式 九宫格 适用于非自由视角 建立缓冲池，防止反复实例化。 Load vs LoadAsync 进场景预加载，推荐Load 游戏中，推荐LoadAsync Lightmap动态加载 LightmapSettings lightmapindex/lightmapScaleOffset Shader Stripping Terrain动态加载 Lightmapld Terrain.SetNeighbors 动态 Static Batching (StaticBatchingUtility) 运行时CPU/堆内存开销较大 优先推荐手动拼合 推荐分组拼合 防止资源泄露 运行时创建 new Material,Mesh Material set AssetBundle重复加载 共享资源 Texture,Mesh,Font Prefab 隐形资源 TerrainData/AlphaMap打包策略 地形资源 12345List&lt;Object&gt; groundObjs = new List&lt;Object&gt;();groundObjs.AddRange(Resources.LoadAll(BundleConfig.GroundObjectsPath, typeof(Texture2D)));groundObjs.AddRange(Resources.LoadAll(BundleConfig.GroundObjectsPath, typeof(GameObject)));BuildPipeline.PushAssetDependencies(); 地表资源 复杂资源拆分 “流失”实例化 按地形块分组打包]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[光照贴图]]></title>
    <url>%2F2017%2F10%2F03%2Flightmap%2F</url>
    <content type="text"><![CDATA[在很多情况下，我们为了提高渲染效率，一般都会让美术同学在制作场景时，设置场景相关节点的lightmap static属性，提前给整个场景烘培出静态的光照贴图lightmap，烘培的数据保存在场景目录下的LightmapSnapshot文件中，主要包括的数据有：lightmaps：烘培出的光照贴图数组；gameobject uid：被烘焙的gameobject的唯一标识；renderer的lightmapIndex：被烘培的gameobject的renderer组件所指向的光照贴图用于采样的区域坐标和宽高。这个文件目前没有相关api读写，如果你想烘培完场景之后，把场景里面的gameobject抽出来做prefab，等切换玩场景之后再用于动态加载是不可行的，因为抽出来的prefab咋Instantiate之后将会是一个新的gameobject，uid自然和LightmapSnapshot文件里面记录的不一样，导致找不到对应的光照数据而造成模式没光照变暗或渲染错乱。还有一种比较常见的需求是，在游戏运行时，通过更换光照贴图数据，营造场景在不同时间或季节的光照氛围，例如白天和黑夜。 由于漫反射表面的颜色可以由单个RGB颜色值描述，其记载的是辐射照度值，如果光源和整个场景是静态的，则这个辐射照度值为一个常数，因此可以被预存起来，我们称记录辐射照度值的纹理为一个辐射照度贴图（irradiance maps）或光照贴图（light maps），由于光照传输是线性的，因此其它动态光源所形成的光照可以在这个辐射照度值上进行累加。光照贴图仍然是先阶段实时渲染中漫反射间接光照的主流解决方案[Unity,2017b,Unreal Engine 4,2018b,Iwanicki and Sloan,2017]，它最早被用于[Abrash,1997]中，光照贴图的概念如图11.31所示。图 11.31：一个简单的场景（左）及其光照贴图（右），由此可以看出光照贴图的分辨率很低，因此它通常用来存储间接光照（图片来自Wikipedia） 在像素着色器中，每个像素都需要读取光照贴图中的一个辐射照度值；而另一方面，漫反射表面的每个像素还存储了一个漫反射系数值，它也是一个常数值。直观上思考，我们希望将这两个值预乘起来，形成一个直接的出射辐射亮度值。]]></content>
      <categories>
        <category>theGIbook</category>
      </categories>
      <tags>
        <tag>theGIbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AssetBundle管理机制]]></title>
    <url>%2F2017%2F10%2F02%2FABTheory%2F</url>
    <content type="text"><![CDATA[什么是AssetBundleAssetBundle就像一个Zip压缩文件，里面存放着一些数据对象。它包含一些平台相关的运行时序列化对象。 Bundle之间也存在着依赖。AssetBundle带有三种压缩选项：不压缩，LZMA，LZ4。默认的就是LZMA，而BuildAssetBundleOptions.ChunkBasedCompression就是LZ4的压缩形式。另外我们有两种类型的Bundle，一种是我们场景的Bundle（*.unity打包的常务），另一种是松散的Bundle。 WebExtract &amp; Binary2TextAssetBundle对于大家来说会是一个黑盒子，其实在Unity的安装目录下（Data/Tools）有WebExtract &amp; Binary2Text这两个工具，可以帮你把AssetBundle这个黑盒子打开。例如：升级版本AssetBundle变大了，二次构建AssetBundle出现差异了，AssetBundle内到底包含了那些资源等。 对于构建出来的AssetBundle，我们先通过WebExtract来解开，这时候可以得到一个文件夹，里面包含一些文件。 Usage: WebExtractor &lt;unitywebfile&gt; AssetBundle加载基础通过AssetBundle加载资源，分为两步，第一步获取AssetBundle对象，第二步是通过该对象加载需要的资源。而第一步又分为两种方式，下文中将结合常用的API进行详细的描述。 获取AssetBundle对象常用的API直接获取AssetBundle: public static AssetBundle CreateFromFile(string path);通过未压缩的Bundle文件，同步创建AssetBundle对象，这是最快的创建方式。创建完成后只会在内存中创建较小的SerializedFile，而后续的AssetBundle.Load需要通过IO从磁盘中过去。 public static AssetBundleCreateRequest CreateFromMemory(byte[] binary);通过Bundle的二进制数据，异步创建AssetBundle对象。完成后会在内存中创建较大的WebStream。调用时，Bundle的解压时异步进行的，因此对于未压缩的Bundle文件，该接口与CreateFromMemoryImmediate等价。 public static AssetBundle CreateFromMemoryImmediate(byte[] binary);该接口是CreateFromMemory的同步版本。 注：5.3下分别改名为LoadFromFile,LoadFromMemory,LoadFromMemoryAsync并增加了LoadFromFileAsync，且机制也有一定的变化，可详见Unity官方文档。 从AssetBundle加载资源的常用API public ObjectLoad(string name, Type type);通过给定的名字和资源类型，加载资源。加载时会自动在家其依赖的资源，即Load一个Prefab时，会自动Load其引用的Texture资源。 public Object[] LoadAll(Type type);一次性加载Bundle中给定资源类型的所有资源。 public AssetBundleRequest LoadAsync(string name, Type type);该接口是Load的异步版本。 注：5.x下分别改名为LoadAsset,LoadAllAssets,LoadAssetAsync，并增加了LoadAllAssetsAsync。 AssetBundle加载进阶注意点 CreateFromFile只能适用于未压缩的AssetBundle,而Android系统下StreamingAssets是在压缩目录(.jar)中，因此需要先将未压缩的AssetBundle放到SD卡中国才能对其使用CreateFromFile。 iOS系统有256个开启文件的上限，因此，内存中通过CreateFromFile加载的AssetBundle对象也会低于该值。 CreateFromFile的调用会增加ResistenManager.Remapper的大小，而PersistentManager负责维护资源的持久化存储，Remapper保存的是加载到内存的资源HeapID与源数据FileID的映射关系，它是一个MemoryPool,其行为类似Mono堆内存，只增不减，因此需要对两个接口的使用做合理的规划。 对于存在依赖关系的Bundle包，在加载时主要注意顺序，举例来说，假设CanvasA在BundleA中，所依赖的AtlasB在BundleB中，为了确保资源正确引用，那么最晚创建BundleB的AssetBundle对象的时间点是在实例化CanvasA之前，即，创建BundleA的AssetBundle对象时，Load(“CanvasA”)时，BundleB的AssetBundle对象都可以不在内存中。 根据经验，建议AssetBundle文件的大小不超过1MB，因为在普遍情况下Bundle的加载时间与其大小并非呈线性关系，过大的Bundle可能引起较大的加载开销。 由于WWW对象的加载是异步的，因此逐个加载容易出现下图中CPU空间的情况（选中帧处Vsync占了大部分）此时建议适当的同时加载多个对象，以增加CPU的使用率，同时加快加载的完成。 AssetBundle卸载前文提到了通过AssetBundle加载资源时的内存分配情况，下面，我们结合常用的API介绍如何将已分配的内存进行卸载，最终达到清空所有相关内存的目的。 一·内存分析 在上图中的右侧，我们列出了各种内存物件的卸载方式： 场景物件(GameObject):这类物件可通过Destroy函数进行卸载； 资源(包括Prefab):除了Prefab以外，资源文件可以通过三种方式来卸载1）通过Resources.UnloadAsset卸载指定的资源，CPU开销小；2）通过Resources.UnloadUnusedAssets一次性卸载所有未被引用的资源，CPU开销大；3）通过Resources.Unload(true)在卸载AssetBundle对象时，将加载出来的资源一起卸载。而对于Prefab,目前仅能通过DestroyImmediate来卸载，且卸载后，必须重新加载AssetBundle才能重新加载该Prefab。由于内存开销较小，通常不建议进行针对性的卸载。 WWW对象：调用对象的Dispose函数或将其置为null即可； WebStream:在卸载WWW对象以及对应的AssetBundle对象后，这部分内存即会被引擎自动卸载； SerializedFile:卸载AssetBundle后，这部分内存会被引擎自动卸载; AssetBundle对象：AssetBundle的卸载方式有两种：1）通过AssetBundle.Unload(false),卸载AssetBundle对象时保留内存中已加载的资源；2)通过AssetBundle.Unload(true),卸载AssetBundle对象时卸载内存中已加载的资源，由于该方法容易引起资源引用丢失，因此并不建议经常使用；二·注意点在通过AssetBundle.Unload(false)卸载AssetBundle对象后，如果重新创建该对象并加载之前加载过的资源的时候，会出现冗余，即两份相同的资源。 被脚本静态变量引用的资源，在调用Resources.UnloadUnusedAssets时，并不会被卸载，在Profiler中能够看到其引用情况。 推荐方案通过以上的讲解，相信您对AssetBundle的加载和卸载有了明确的了解。下面，我们简单地做一下API选择上的推荐： 对于加载完后即卸载的Bundle文件，则分两种情况：优先考虑速度（加载场景时）和优先考虑流畅度（游戏进行时）。1）加载场景的情况下，需要注意的是避免WWW对象的逐个加载导致的CPU空间，可以考虑使用加载速度较快的WWW.LoadFromCacheOrDownload或AssetBundle.CreateFromFile，但需要避免后续大量地进行Load资源的操作，引起IO开销（可以尝试直接LoadAll）。2）游戏进行的情况下，则需要避免使用同步操作引起卡顿，因此可以考虑使用new WWW配合AssetBundle.LoadAsync来进行平滑的资源加载，但需要注意的是，对于Shader，较大的Texture等资源，其初始化操作通常很耗时，容易引起卡顿，因此建议将这类资源在加载场景时进行预加载。 只在Bundle需要加密的情况下，考虑使用CreateFromMemory，因为该接口加载速度较慢。 尽量避免在游戏进行中调用Resources.UnloadUnusedAssets(),因为该接口开销较大，容易引起卡顿，可尝试使用Resources.Unload(obj)来逐个进行卸载，以保证游戏的流畅度。 需要说明的是，以上内存管理交适合于Unity5.3之前的版本。Unity引擎在5.3中对AssetBundle的内存占用进行了一定的调整，目前我们也在进一步的学习和研究中。 原文链接：https://blog.uwa4d.com/archives/ABTheory.html]]></content>
      <categories>
        <category>Unity</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI]]></title>
    <url>%2F2017%2F09%2F29%2FAI%2F</url>
    <content type="text"><![CDATA[ML（机器学习）与AI(人工智能）首先来介绍下Machine Learning(机器学习，下文简称ML）和游戏Artificial Intelligence(人工智能，下文简称AI）间的关系。现存的大部分游戏AI都是手工源码，由大量决策树组成，有时会包含多达数千条规则。而且必须由手工维护和测试。而ML所依赖的算法可以自动从原始数据寻找规律，无需专家预先定义数据的解读方式。 以图片内容分类这个计算机视觉问题为例。直到几年前，专家们仍然通过手工编写过滤器，提取图像的有用特征，用于分辨某个图像中包含的是猫还是狗。而ML，特别是i最新的深度学习方法，仅需图像和类型标签，就可以自动学习有用的特征。我们相信这种自动化学习不仅可以扩展Unity平台的应用范围，例如用于ML场景模拟，还可以帮助所有开发者简化和加速游戏的开发过程。 这种自动化学习尤其可以应用于游戏代理（即NPC）的行为方面。我们可以使用Reinforcement Learning(增强学习，简称RL）来训练代理，预估某一环境中施行特定行为的价值。一旦训练完成，代理即可以最佳行为模式做出反应，无需通过程序对行为进行显示的编码。 采用老虎机算法的增强学习RL背后的一个核心概念是价值估计，并据此进行相应动作。在继续深入之前，最好先了解一些术语。 在RL中，实施动作的个体被称为agent(代理),它使用policy(策略)进行动作决策。一个代理通常嵌入一个environment中，并在任意给定的时刻都处于某个特定的state(状态).从哪个状态，它可以进行一系列actions(动作）。某个给定状态的value(值)指的是处于该状态的最终回报价值。在某个状态的value(值)指的是处于该状态的最终回报值。在某个状态执行一个动作可以让代理进入另一个新的状态，获得一个reward(回报),或者同事拥有两者。所有的RL代理都在尽可能最大化累计回报。]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Real Time Rendering 3rd]]></title>
    <url>%2F2017%2F09%2F29%2FReal-Time-Rendering-3rd%2F</url>
    <content type="text"><![CDATA[Overviewurl: www.realtimerendering.com The Graphics Rendering Pipeline 核心内容分节提炼图像渲染管线架构概述 Architecture渲染管线的主要功能就是决定在给虚拟相机，三维物体，光源，照明模式，以及纹理等诸多条件的情况下，生成或绘制一幅二维图像的过程。对于实时渲染来说，渲染管线就是基础。因此，我们可以说，渲染管线是实时渲染的底层工具。 上图，相机放在棱锥的顶端（四条线段的交汇点），只有可视体内部的图元会被渲染。在概念上可以将图形渲染管线分为三个阶段： 应用程序阶段（The Application Stage) 几何阶段(The Geometry Stage) 光栅化阶段(The Rasterizer Stage) 绘制管线的基本结构包括3个阶段：应用程序，几何，光栅化。 几个要点： 每个阶段本身也可能是一条管线，如图中的几何阶段所示。此外，还可以对有的阶段进行全部或者部分的并行化处理，如图中的光栅化阶段。应用程序阶段虽然是一个单独的过程，但是依然可以对之进行管线化或者并行化处理。 最慢的管线阶段决定绘制速度，即图像的更新速度，这种速度一般用FPS表示，也就是帧率。 应用程序阶段（The Application Stage） 应用程序阶段一般是图形渲染管线概念上的第一个阶段。应用程序阶段是通过软件方式来实现的阶段，开发者能够对该阶段发生的情况进行完全控制，可以通过改变实现方法来改变实际性能。其他阶段，他们全部或者部分建立在硬件的基础上，因此要改变实现过程会非常困难。 正因应用程序阶段是软件方式实现，因此不能像集合和光栅化阶段那样继续分为诺干个子阶段。但为了提高性能，该阶段还是可以在几个并行处理器上同时执行。在CPU设计商，称这种形式为超标量体系(superscalar)结构，因为它可以在同一个阶段同一个时间做不同的几件事情。 应用程序阶段通常实现的方法有碰撞检测，加速算法，输入检测，动画，力反馈以及纹理动画，变化仿真，几何变形，以及一些不在其他阶段执行的计算，如层次堆裁剪等加速算法就可以在这里实现。 应用程序阶段的主要任务：在应用程序阶段的末端，将需要在屏幕(具体形式取决于具体输入设备)显示出来绘制的几何体(也就是绘制图元,rendering primitives,如点，线，矩形等)输入到绘制管线的下一个阶段。 对于被渲染的每一帧，应用程序阶段将摄像机位置，光照和模型的图元输出到管线的下一个主要阶段-几何阶段。几何阶段 The Geometry Stage 几何阶段主要负责大部分多边形操作和顶点操作。 GPU渲染管线和可编程着色器GPU渲染管线流程图 其中： 绿色的阶段都是完全可以编程的。 黄色的阶段可配置，但不可编程。 蓝色的阶段完全固定。 顶点着色器顶点着色器（The Vertex Shader）是完全可编程的阶段，顶点着色器可以对每个顶点进行诸如变换和变形在内的很多操作，提供了修改/创建/忽略顶点相关属性的功能，这些顶点属性包括颜色、法线、纹理坐标和位置。顶点着色器的必须完成的任务是将顶点从模型空间转换到齐次裁剪空间。 几何着色器几何着色器（The Geometry Shader）位于顶点着色器之后，允许GPU高效的创建和销毁几何图元。几何着色器是可选的，完全可编程的阶段，主要对图元（点、线、三角形）的顶点进行操作。几何着色器接受顶点着色器的输出作为输入，通过高效的几何运算，将数据输出，数据随后经过几何阶段和光栅化的其他处理后，会发送给片段着色器。几何着色器可以改变信新传递进来的图元的拓扑结构，且几何着色器可以接受任何拓扑类型的图元，但是只能输出点、折线（line strip）和三角形条（triangle strips）。 裁剪裁剪（Clipping）属于可配置的功能阶段，在此阶段可选运行的裁剪方式，以及添加自定义的裁剪面。 屏幕映射屏幕映射（Screen Mapping）、三角形设置（Triangle Setup）和三角形遍历（Triangle Traversal）阶段是固定功能阶段。 像素着色器像素着色器（Pixel Shader，Direct3D中的叫法）常常又称为片段着色器，片元着色器（Fragment Shader，OpenGL中的叫法），是完全可编程的阶段，主要作用是进行像素的处理，让复杂的着色方程在每一个像素上执行。像素着色器常用来处理场景光照和与之相关的效果，如凹凸纹理映射和调色。称之为片段着色器似乎更加准确，因为对于着色器的调用和屏幕上的像素并非是一一对应的。比如，对于一个像素，片段着色器可能会被调用若干次来决定它最终的颜色，那些被遮挡的物体也会被计算，直到最后的深度缓冲才将各物体前后排序。需要注意，像素着色器通常在最终合并阶段设置片段颜色以进行合并，而深度值也可以由像素着色器修改。模版缓冲（stencil buffer）值是不是修改的，而是将其传递给合并阶段（Merge Stage）。在SM 2.0以及以上版本，像素着色器也可以丢弃（discard）传入的片段数据，即不产生输出。这样的操作会消耗性能，因为通常在这种情况下不能使用由GPU执行的优化。诸如雾计算和alpha测试的操作已经从合并操作转移到SM 4.0中的像素着色器里计算。可以发现，顶点着色程序的输出，在经历裁剪、屏幕映射、三角形设定、三角形遍历后，实际上变成了像素着色程序的输入。在Shader Model 4.0中，共有16个向量（每个向量含有4个值）可以从顶点着色器传到像素着色器。当使用几何着色器时，可以输出32个向量到像素着色器中。像素着色器的追加输入是Shader Model 3.0中引入的。例如，三角形的哪一面是可见的通过输入标志来假如的。这个值对于在单个通道中的正面和背面渲染不同材质十分重要。而且像素着色器也可以获得片段的屏幕位置。 合并合并阶段（The Merger Stage）处于完全可编程和固定功能之间，尽管不能编程，但是高度可配置，可以进行一系列的啊哦做。其除了进行合并操作，还分管颜色修改（Color Modifying），Z缓冲（Z-Buffer），混合（Blend），模版（Stencil）和相关缓存的处理。 可编程着色模型 现代着色阶段（比如支持Shader Model 4.0，DirectX 10以及之后）使用了通用着色核心（common-shader core），这就表明顶点，片段，几何着色器共享一套编程模型。 早起的着色模型可以用汇编语言直接编程，但DX10之后，汇编就只在调试输出阶段可见，改用高级着色语言。 目前的着色语言都是C-like的着色语言，比如HLSL，CG和GLSL，其被编译成独立于机器的汇编语言，也称为中间语言（IL）。这些汇编语言在单独的阶段，通常实在驱动中，被转化成实际的机器语言。这样的安排可以兼容不同的硬件实现。这些汇编语言可以被看做是定义一个作为着色语言编译器的虚拟机。这个虚拟机是一个处理多种类型寄存器和数据源、预编了一系列指令的处理器。 着色语言虚拟机可以理解为一个处理多种类型寄存器和数据源、预编译一系列指令的处理器。考虑到很多图形操作都使用短矢量（最高四位），处理器拥有4路SIMD（single-instruction multiple-data，单指令多数据）兼容性。每个寄存器包含四个独立的值。32位单精度浮点的标量和矢量是其基本数据类型；也随后支持32位整型。浮点矢量通常包含数据如位置（xyzw），法线，矩阵行，颜色（rgba），或者纹理坐标（uvwq）。而整型通常用来表示，计数器，索引，或者位掩码。也支持综合数据类型比如结构体，数组，和矩阵。而为了便于使用向量，向量操作如调和（swizzling，也就是向量分量和重新排序或复制），和屏蔽（masking，只是用指定的矢量元素），也能够支持。 上图为DX10下的通用Shader核心虚拟机架构以及寄存器布局。每个资源旁边显示最大可用编号。其中，用两个斜杠分开的三个数值，分别是顶点、几何、像素着色器对应的可用最大数量。 一个绘制调用（Draw Call）会调用图形API来绘制一系列的图元，会驱使图形管线的运行。 每个可编程着色阶段拥有两种类型的输入： uniform输入，在一个draw call中保持不变的值（但在不同draw call之间可以改变） varying输入，shader里对每个顶点和像素的处理都不同的值。纹理是特殊的uniform输入，曾经一直是一张应用到表面的彩色图片，但现在可以认为是存储着大量数据的数组。 在现代GPU上，图形运算中常见的运算操作执行速度非常快。通常情况下，最快的操作是标量和向量的乘法和加法，以及他们的组合，如乘加运算（multiply-add）和点乘（dot-product）运算。其它操作，比如倒数（reciprocal），平方根（square root），正弦（sine），余弦（cosine），指数（exponentiation），对数（logarithm）运算，往往会稍微更加昂贵，但依然相当快捷。纹理操作非常高效，但他们的性能可能受到诸如等待检索结果的时间等因素的限制。 着色语言表示出了大多数常见的操作（比如加法和乘法通过运算符+和*来表示）。其余的操作用固有的函数，比如atan()，dot()，log()等。更复杂的操作也存在内建函数，比如矢量归一化（vector normalization），反射（reflection）、叉乘（cross products）、矩阵的转置（matrix transpose）和行列式（determinant）等。 流控制（flow control）是指使用分支指令来改变代码执行流程的操作。这些指令用于实现高级语言结构，如“if”和“case”语句，以及各种类型的循环。Shader支持两种类型的流控制。静态流控制（Static flow control）是基于统一输入的值。这意味着代码的流在调用时是恒定的。静态流控制的主要好处是允许在不同的情况下使用相同的着色器（例如，不同数量的光源）。动态流控制（Dynamic flow control）基于不同的输入值。但动态流控制远比静态流量控制更强大但同时也需要更高的开销，特别是在调用shader之间，代码流不规律改变的时候。而评估一个shader的性能，是评估其在一段时间内处理顶点或像素的个数。如果流对某些元素选择“if”分支，而对其他元素选择“else”分支，这两个分支必须对所有元素进行评估（并且每个元素的未使用分支将被丢弃）。 Shader程序可以在程序加载或运行时离线编译。和任何编辑器一样，有生成不同输出文件和使用不同优先级别的选项。一个编译过的Shader作为字符串或者文本来存储，并通过驱动程序传递给GPU。 SM 2.0/2.X SM 3.0 SM 4.0 引入版本 DX 9.0,2002 DX 9.0c,2004 DX 10,2007 VS指令槽位 256 ≥512 4096 VS最大执行步长 65536 65536 ∞ PS指令槽位 ≥96 ≥512 ≥65536 PS最大执行步长 ≥96 65536 ∞ 临时寄存器 ≥12 32 4096 VS常量寄存器 ≥256 ≥256 14×4096 PS常量寄存器 32 224 14×4096 流程控制，判断 Optional Yes Yes VS纹理贴图 None 4 128×512 PS纹理贴图 16 16 128×512 整数支持 No No Yes VS输入寄存器 16 16 16 插值寄存器 8 10 16/32 PS输出寄存器 4 4 8]]></content>
      <tags>
        <tag>计算机图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity-Weather]]></title>
    <url>%2F2017%2F09%2F26%2FUnity-Weather%2F</url>
    <content type="text"><![CDATA[抄：https://zhuanlan.zhihu.com/p/29668925]]></content>
  </entry>
  <entry>
    <title><![CDATA[UE3的3D渲染流水线处理流程]]></title>
    <url>%2F2017%2F09%2F24%2F3%E7%9A%843D%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[流水线3D渲染流水线也类似一个工厂的流水线，它的原材料是一系列的3D网格数据，最终产品就是显示在2D屏幕的3D场景。3D渲染流水线的处理和照相机的原理很像，它们都同样是通过将3D世界的内容放置到2D平面上，通过2D的方式来展示3D世界，顶点管线中有这么几个坐标空间：局部空间-&gt;世界空间-&gt;相机空间-&gt;投影空间-&gt;屏幕空间(视口空间),初始的网格数据是在局部空间中的，顶点管线将其从局部空间变换到屏幕空间作为输入供”像素管线”处理。比如局部空间内，一个人物的骨骼模型，它的中心点就是根骨骼的位置，在进行骨骼层次计算的时候，根谷歌放在中心位置是易于计算的，如果将其放置到世界空间中进行骨骼计算，那么根骨骼的位置不在原点且朝向也不为0，计算起来相当复杂。而世界空间中，易于描述场景中各个物体间的关系，易于作碰撞处理，伤害计算，顶点光照计算等。在相机空间中，容易描述被观察物体与观察者之间的关系，利用相机视锥体对物体进行裁剪，把观察不到的物体剔除掉。 VertexShader—顶点着色器是用来替换这个阶段中固定管线的定点变换及光照计算的，传统管线处理顶点及光照的方式都是固定流程的，所以固定管线下的3D程序特效都有很大的局限性，引入顶点着色器之后，顶点在空间中的变换以及光照处理都可以可编程化了。顶点着色器主要是用来改变顶点固定流程中的变换过程，所以使用顶点着色器表现出来的大多是几何外形的变化以及顶点的光照，纹理等数据的变化。 在UE3中，是不能直接编写Shader语言的，UE3中把所有的Shader特效都绑定到材质中，只能通过材质编辑器来间接的编辑顶点着色器和像素着色器内容。UE3中修改顶点着色器的方式也是在材质编辑器中进行的，其中比较典型的一个输入节点叫做WorldPositionOffset，它就是在顶点管道阶段对材质对应的网络物体顶点进行编辑的一个节点，对应到底层是修改了该材质对应的顶点着色器代码(通过HLSL按钮能够看到该材质对应的Shader代码 这个阶段会逐像素地处理该像素的纹理映射，光照颜色，alpha融合，深度测试，模板测试等，并且根据该像素的距离信息进行雾化公式的应用，所以，顾名思义，像素管道主要处理的是像素信息，最终输出像素最终的颜色。 传统的3D管线只能通过有限几个图形API接口来操作像素，比如DX中设置多纹理的一些接口以及Alpha融合的接口，能够操作的范围很有限。 像素着色器所替换固定流水线的功能就是在这个阶段，在引入像素着色器之后，就可以根据需要对像素做许多自由的处理，因为帧缓存内的像素信息不止包含该像素的颜色、Alpha值、深度信息和模版信息，还可以包含该像素对应的法线贴图信息、高光贴图信息、凹凸贴图信息等（这些贴图实际上保存的是一系列向量信息），通过传入一定的参数，比如时间信息、物理量等，就能制作出各种贴近现实的精美特效。 UE3中的像素着色器也是通过材质编辑器中的表达式来处理的，UE3材质编辑器中的大部分输入节点都是用于处理像素着色的，如图所示]]></content>
      <categories>
        <category>虚幻引擎</category>
      </categories>
      <tags>
        <tag>计算机图形学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UGUI vs NGUI]]></title>
    <url>%2F2017%2F09%2F24%2FUGUIvsNGUI%2F</url>
    <content type="text"><![CDATA[Tables NGUI UGUI 锚点 Anchor RectTransform Anchor 图片 Sprite Image 文字 Label Text 根节点 UIRoot Canvas UI面板 Panel Canvas UI容器 Lets you essentially lower the heightmap resolution used for rendering. heightmapPixelError An approximation of how many pixels the terrain will pop in the worst case when switching lod. lightmapindex The index of the lightmap applied to this renderer. terrainData The Terrain Data that stres htightmaps,terrain textures,detail meshes and trees. treeBillboardDistance Distance from the camera where trees will be rendered as billboards only. terrCrossFadeLength Total distance delta that trees will use to transition from billboard orientation to to mesh orientation. treeDistance The maximum distance at which trees are rendered. treeMaximumFullLODCount Maximum number of trees rendered at full LOD. NGUI 上图是UIWidget，UIGeometry和UIDrawCall的关系图UIPanel用来收集和管理它下面所有的widget的组件。通过widget的geometry创建实际的draw call。没有panel所有东西都不能被渲染出来。可以把UIPanel当作Renderer。 每一个UIWidget都有一个UIGeometry，但是并不都有一个UIDrawCall，而是要通过Batch合并达到减少DrawCall的数量。所有Panel都有一个Depth值，会影响所有它包含的widget。Panel的depth权重要高于widget的depth权重，但是低于render queue。 当勾选static的时候，该panel下面所有的widget都不会被移动，这样可以提高性能。此时，NGUI会忽略所有的position/rotation/scale改变。所以在运行时移动widget不会有效。 UIDrawCall1.成员变量a) List mActiveList和mInactiveList，mActiveList保持当前激活的UIDrawCall，mInactiveList主要是用于回收UIDrawCall.Destroy()的UIDrawCall，以达到循环利用避免内存的反复申请和释放，减少GC的次数。b) Material mMaterial和mDynamicMat，mMaterial是图集的Material，mDynamicMat是实际采用的Material，因为UIPanel的Clipping有AlphaClip和SoftClip这两个是要通过切换Shader实现的，所以需要对应动态创建一个Material，这个就是mDynamicMat的存在。c) bool mRebuildMat和isDirty，这两者表示UIDrawCall所处的状态，当改变UIDrawCall的Material和Shader，mRebuildMat就变成true，就会引起RebuildMaterial()的调用。isDirty若为true，表示UIDrawCall要进行重写“填充”，调用Set函数。 负责将uv、顶点、color等信息输入到mesh中，继而绘制图形。 1234567891011121314151617void UpdateGeometry()&#123; if (mFilter == null) &#123; mFilter = gameObject.AddComponent&lt;MeshFilter&gt;(); mMesh = new Mesh(); mTriangles = (verts.size &gt;&gt; 2); mMesh.verticess = verts.buffer; mMesh.uv = uvs.buffer; mFilter.mesh = mMesh; &#125; if (mRenderer == null) &#123; mRenderer = gameObject.AddComponent&lt;MeshRenderer&gt;(); &#125; UpdateMaterial();&#125; 以上所有的buffer都是用BetterList来存储的。 1234567891011121314151617void UpdateMaterial()&#123; if (mDynamicMat == null || mRebuildMat || mClipCount != panel.clipCount) &#123; RebuildMaterial(); mRebuildMat = false; &#125; else if (mSharedMat != mDynamicMat) &#123; mSharedMaterials = new Material[]&#123;mDynamicMat&#125;; &#125;&#125;void RebuildMaterial()&#123; CreateMaterial();&#125; 优化DrawCall使用相同material的连续UIWidget(UILbale,UISprite)共用一个UIDrawCall。对UIWidget.list进行排序，使得相同的material的UIWidget在UIWidget.list相连，而UIWidget.list是根据UIWidget的depth进行排序。（但是这样不会改变渲染顺序吗？）1) 修改UIWidget(UILabel,UISprite)的depth，限定好UIWidget.list的排序2) 重写UIWidget的CompareFunc方法。夹层问题 UIRootUIRoot的作用是缩放UI PixelPerfect 保持原分辨率FiexedSize 根据比例缩放FixedSizeOnMobile PC保持原分辨率，Mobile缩放 UICamera 带有这个组件渲染出来的物体可以接受NGUI事件 UIPanelPanel的集合，一个Panel中包含多个Widget，负责更新会决定何时绘制Widget。 123456789101112131415static public List&lt;UIPanel&gt; list = new List&lt;UIPanel&gt;();public RenderQueue renderQueue = RenderQueue.Automatic; //渲染次序类型public int startingRenderQueue = 3000;public List&lt;UIWidget&gt; widgets = new List&lt;UIWidget&gt;();public List&lt;UIDrawCall&gt; drawcalls = new List&lt;UIDrawCall&gt;();int mDepth = 0; // 深度int mSortingOrder; // 队列排序值bool mRebuild = false;//如果为true，需要重构所有的Drawcall，Panel中的OnEnable、RemoveWidget、AddWidget等和改变depth会将该值设置为true。void LateUpdate()&#123; if (mUpdateFrame != Time.frameCount) &#123; &#125;&#125;]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[游戏对象和脚本]]></title>
    <url>%2F2017%2F09%2F20%2F%E6%B8%B8%E6%88%8F%E5%AF%B9%E8%B1%A1%E5%92%8C%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[原文：http://catlikecoding.com/unity/tutorials/basics/game-objects-and-scripts/ 用简单的脚本构建一个时钟 用C#写脚本 让时钟转动起来 完成 这边文章通过创建简单的组件脚本来实现一个时钟。您仅需几分钟来熟悉Unity编辑器，如果您已经熟悉此部分，可以跳过本篇文章。 构建一个简单的时钟打开Unity创建一个3D对象，你不需要任何额外的资源包. 1.1 创建一个游戏对象默认的场景包含两个游戏对象，他们在层次窗口中而且你能看到他们的图标在场景窗口中，第一个是主相机，它是用来渲染的，第二个是方向光，照明场景的。使用GameObject-&gt;Create Empty 选项，也可以选择层级窗口添加一个新的对象在scene上。 监视窗口(Inspector window)展示游戏对象的细节，当选择时钟对象的时候，Inspector会展示他的name和一些额外的属性,默认为可用，非静态，没有标签属于一个默认的层。并且展示了所有的组件，transform组件是一定有的。 transform组件包括位置，旋转和缩放在3D空间，确保position和rotation是0，scale是1（这里指的都是本地坐标) 1.2 创建一个时钟虽然我们有了clock object,但是我们什么也做不了,我们还得创建3D模型来渲染，Unity包含一些原始的对象，用这些我们能构建一个简单的时钟，s首先添加一个cylinder(圆柱Gameobject-&gt;3D Object-&gt;Cylinder) 圆柱体有一个Mesh Filter包含一个圆柱体的mesh，第二个是Capsule Collider(胶囊碰撞体)用来搞物理的，第三是Mesh Renderer确保可以得到渲染的，也用来控制用那个材质来渲染，最后一个就是材质(Material). 虽然对象是一个圆柱体，但是它用了capsule collider,因为unity没有原生的cylinder collider,我们不需要它，干掉！如果你不需要物理的话，你可以选择Mesh Collider 组件,组件能被干掉。 为了搞一个时钟的脸，我们必须把这玩意搞平，缩减scale的y值， 将圆柱体的名字改为Face,表示clock的脸, 1.3 创建时钟刻度时钟有一圈刻度来告诉你现在几点了。添加一个立方体对象通过Gameobject-&gt;3D Object-&gt;Cube,改变缩放(0.5,0.2,1)刻度是难以看到的，因为他和表盘的颜色相同，让我们通过材质来区分吧，Assets-&gt;Create-&gt;Material，或者Proect Window都可以的，这个材质是复制默认的材质的，]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unity渲染1 材质]]></title>
    <url>%2F2017%2F09%2F20%2FUnity%E6%B8%B2%E6%9F%931-%E6%9D%90%E8%B4%A8%2F</url>
    <content type="text"><![CDATA[PS：翻译Catlike的文章 创建一个立方体格子 支持缩放，位移，旋转 创建简单的相机投影 这是关于渲染的第一篇文章，]]></content>
  </entry>
  <entry>
    <title><![CDATA[scene和prefab的区别]]></title>
    <url>%2F2017%2F09%2F17%2Farticle-title%2F</url>
    <content type="text"><![CDATA[如果一个场景有多个相同的pfb(指引用相同的pfb，具体每个pfb可能有参数不同），那么Scene里每个pfb都是独立的对象，加载时每个对象都要走全套的流程: 文件I/O -&gt;反序列化 (解析，new obj + ctor) -&gt; awake -&gt; shader\texture\vbo create\upload，如果走pfb+Instantiate，那么前面的流程(文件I/O，反序列化）只用走一遍，直接Instantiate复制内存中现有的对象就行.另外pfb可以在合适的时候提前异步预加载，这样切场景的时候就更快了（场景也可以异步预加载，不过awake\upload to gpu这些必须在主线程做，所以会卡一下），pfb也便于做细粒度的热更. 但pfb对美术日常调整场景不友好，除非有个一键生成场景+一键存pfb.单论切换速度，什么都比不过预加载 + 大内存永驻 CentOS1.yum install subversion2.创建svn版本目录: mkdir -p /var/svn/svnrepos3.创建版本库: svnadmin create /var/svn/svnrepos4.cd /var/svn/svnrepos/conf (authz文件是权限控制文件;passwd是帐号密码文件;svnserve.conf SVN服务器配置文件)5.设置帐号密码 vi passwd 在[users]块中添加用户和密码，格式：帐号=密码，如zentia=zentia6.设置权限vi authz在末尾添加如下代码[/]zentia=rwliyanfeng=r意思是版本库的根目录zentia对其有读写权限，liyanfeng只有读权限。7.修改svnserve.conf文件打开下面几个注释：anon-access=read #匿名用户可读auth-access = write #授权用户可写password-db = passwd #使用哪个文件作为帐号文件authz-db = authz #使用哪个文件作为权限文件realm = /var/svn/svnrepos #认证空间名，版本库所在目录8.启动svn版本库svnserve -d -r /var/svn/svnreposps aux | grep svnserve #查看服务是否启动 SVN客户端搭建1.修改host文件 10.173.32.4 zentiasvr]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
</search>
